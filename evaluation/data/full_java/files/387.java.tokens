package org . apache . cassandra . db . compaction ; import java . util . Collection ; import java . util . HashMap ; import java . util . Map ; import java . util . Set ; import java . util . UUID ; import java . util . concurrent . TimeUnit ; import com . google . common . base . Predicate ; import com . google . common . collect . Iterables ; import com . google . common . collect . Sets ; import org . apache . cassandra . db . Directories ; import org . apache . cassandra . db . compaction . writers . CompactionAwareWriter ; import org . apache . cassandra . db . compaction . writers . DefaultCompactionWriter ; import org . apache . cassandra . io . sstable . format . SSTableReader ; import org . apache . commons . lang3 . StringUtils ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; import org . apache . cassandra . config . DatabaseDescriptor ; import org . apache . cassandra . db . ColumnFamilyStore ; import org . apache . cassandra . db . SystemKeyspace ; import org . apache . cassandra . db . compaction . CompactionManager . CompactionExecutorStatsCollector ; import org . apache . cassandra . db . lifecycle . LifecycleTransaction ; import org . apache . cassandra . service . ActiveRepairService ; import org . apache . cassandra . utils . FBUtilities ; import org . apache . cassandra . utils . concurrent . Refs ; public class CompactionTask extends AbstractCompactionTask { protected static final Logger logger = LoggerFactory . getLogger ( CompactionTask . class ) ; protected final int gcBefore ; protected final boolean offline ; protected final boolean keepOriginals ; protected static long totalBytesCompacted = <int> ; private CompactionExecutorStatsCollector collector ; public CompactionTask ( ColumnFamilyStore cfs , LifecycleTransaction txn , int gcBefore ) { this ( cfs , txn , gcBefore , false , false ) ; } public CompactionTask ( ColumnFamilyStore cfs , LifecycleTransaction txn , int gcBefore , boolean offline , boolean keepOriginals ) { super ( cfs , txn ) ; this . gcBefore = gcBefore ; this . offline = offline ; this . keepOriginals = keepOriginals ; } public static synchronized long addToTotalBytesCompacted ( long bytesCompacted ) { return totalBytesCompacted + = bytesCompacted ; } protected int executeInternal ( CompactionExecutorStatsCollector collector ) { this . collector = collector ; run ( ) ; return transaction . originals ( ) . size ( ) ; } public boolean reduceScopeForLimitedSpace ( ) { if ( partialCompactionsAcceptable ( ) & & transaction . originals ( ) . size ( ) > <int> ) { logger . warn ( <str> , StringUtils . join ( transaction . originals ( ) , <str> ) ) ; SSTableReader removedSSTable = cfs . getMaxSizeFile ( transaction . originals ( ) ) ; transaction . cancel ( removedSSTable ) ; return true ; } return false ; } protected void runMayThrow ( ) throws Exception { assert transaction ! = null ; if ( transaction . originals ( ) . isEmpty ( ) ) return ; CompactionStrategyManager strategy = cfs . getCompactionStrategyManager ( ) ; if ( DatabaseDescriptor . isSnapshotBeforeCompaction ( ) ) cfs . snapshotWithoutFlush ( System . currentTimeMillis ( ) + <str> + cfs . name ) ; long expectedWriteSize = cfs . getExpectedCompactedFileSize ( transaction . originals ( ) , compactionType ) ; long earlySSTableEstimate = Math . max ( <int> , expectedWriteSize / strategy . getMaxSSTableBytes ( ) ) ; checkAvailableDiskSpace ( earlySSTableEstimate , expectedWriteSize ) ; assert ! Iterables . any ( transaction . originals ( ) , new Predicate < SSTableReader > ( ) { @Override public boolean apply ( SSTableReader sstable ) { return ! sstable . descriptor . cfname . equals ( cfs . name ) ; } } ) ; UUID taskId = transaction . opId ( ) ; StringBuilder ssTableLoggerMsg = new StringBuilder ( <str> ) ; for ( SSTableReader sstr : transaction . originals ( ) ) { ssTableLoggerMsg . append ( String . format ( <str> , sstr . getFilename ( ) , sstr . getSSTableLevel ( ) ) ) ; } ssTableLoggerMsg . append ( <str> ) ; logger . debug ( <str> , taskId , ssTableLoggerMsg ) ; long start = System . nanoTime ( ) ; long totalKeysWritten = <int> ; long estimatedKeys = <int> ; try ( CompactionController controller = getCompactionController ( transaction . originals ( ) ) ) { Set < SSTableReader > actuallyCompact = Sets . difference ( transaction . originals ( ) , controller . getFullyExpiredSSTables ( ) ) ; Collection < SSTableReader > newSStables ; long [ ] mergedRowCounts ; int nowInSec = FBUtilities . nowInSeconds ( ) ; try ( Refs < SSTableReader > refs = Refs . ref ( actuallyCompact ) ; AbstractCompactionStrategy . ScannerList scanners = strategy . getScanners ( actuallyCompact ) ; CompactionIterator ci = new CompactionIterator ( compactionType , scanners . scanners , controller , nowInSec , taskId ) ) { if ( collector ! = null ) collector . beginCompaction ( ci ) ; long lastCheckObsoletion = start ; if ( ! controller . cfs . getCompactionStrategyManager ( ) . isActive ) throw new CompactionInterruptedException ( ci . getCompactionInfo ( ) ) ; try ( CompactionAwareWriter writer = getCompactionAwareWriter ( cfs , getDirectories ( ) , transaction , actuallyCompact ) ) { estimatedKeys = writer . estimatedKeys ( ) ; while ( ci . hasNext ( ) ) { if ( ci . isStopRequested ( ) ) throw new CompactionInterruptedException ( ci . getCompactionInfo ( ) ) ; if ( writer . append ( ci . next ( ) ) ) totalKeysWritten + + ; if ( System . nanoTime ( ) - lastCheckObsoletion > TimeUnit . MINUTES . toNanos ( <int> ) ) { controller . maybeRefreshOverlaps ( ) ; lastCheckObsoletion = System . nanoTime ( ) ; } } newSStables = writer . finish ( ) ; } finally { if ( collector ! = null ) collector . finishCompaction ( ci ) ; mergedRowCounts = ci . getMergedRowCounts ( ) ; } } long dTime = TimeUnit . NANOSECONDS . toMillis ( System . nanoTime ( ) - start ) ; long startsize = SSTableReader . getTotalBytes ( transaction . originals ( ) ) ; long endsize = SSTableReader . getTotalBytes ( newSStables ) ; double ratio = ( double ) endsize / ( double ) startsize ; StringBuilder newSSTableNames = new StringBuilder ( ) ; for ( SSTableReader reader : newSStables ) newSSTableNames . append ( reader . descriptor . baseFilename ( ) ) . append ( <str> ) ; double mbps = dTime > <int> ? ( double ) endsize / ( <int> * <int> ) / ( ( double ) dTime / <int> ) : <int> ; long totalSourceRows = <int> ; String mergeSummary = updateCompactionHistory ( cfs . keyspace . getName ( ) , cfs . getColumnFamilyName ( ) , mergedRowCounts , startsize , endsize ) ; logger . debug ( String . format ( <str> , taskId , transaction . originals ( ) . size ( ) , newSSTableNames . toString ( ) , getLevel ( ) , startsize , endsize , ( int ) ( ratio * <int> ) , dTime , mbps , totalSourceRows , totalKeysWritten , mergeSummary ) ) ; logger . trace ( String . format ( <str> , CompactionTask . addToTotalBytesCompacted ( endsize ) ) ) ; logger . trace ( <str> , totalKeysWritten , estimatedKeys , ( ( double ) ( totalKeysWritten - estimatedKeys ) / totalKeysWritten ) ) ; if ( offline ) Refs . release ( Refs . selfRefs ( newSStables ) ) ; } } @Override public CompactionAwareWriter getCompactionAwareWriter ( ColumnFamilyStore cfs , Directories directories , LifecycleTransaction transaction , Set < SSTableReader > nonExpiredSSTables ) { return new DefaultCompactionWriter ( cfs , directories , transaction , nonExpiredSSTables , offline , keepOriginals ) ; } public static String updateCompactionHistory ( String keyspaceName , String columnFamilyName , long [ ] mergedRowCounts , long startSize , long endSize ) { StringBuilder mergeSummary = new StringBuilder ( mergedRowCounts . length * <int> ) ; Map < Integer , Long > mergedRows = new HashMap < > ( ) ; for ( int i = <int> ; i < mergedRowCounts . length ; i + + ) { long count = mergedRowCounts [ i ] ; if ( count = = <int> ) continue ; int rows = i + <int> ; mergeSummary . append ( String . format ( <str> , rows , count ) ) ; mergedRows . put ( rows , count ) ; } SystemKeyspace . updateCompactionHistory ( keyspaceName , columnFamilyName , System . currentTimeMillis ( ) , startSize , endSize , mergedRows ) ; return mergeSummary . toString ( ) ; } protected Directories getDirectories ( ) { return cfs . getDirectories ( ) ; } public static long getMinRepairedAt ( Set < SSTableReader > actuallyCompact ) { long minRepairedAt = Long . MAX_VALUE ; for ( SSTableReader sstable : actuallyCompact ) minRepairedAt = Math . min ( minRepairedAt , sstable . getSSTableMetadata ( ) . repairedAt ) ; if ( minRepairedAt = = Long . MAX_VALUE ) return ActiveRepairService . UNREPAIRED_SSTABLE ; return minRepairedAt ; } protected void checkAvailableDiskSpace ( long estimatedSSTables , long expectedWriteSize ) { while ( ! getDirectories ( ) . hasAvailableDiskSpace ( estimatedSSTables , expectedWriteSize ) ) { if ( ! reduceScopeForLimitedSpace ( ) ) throw new RuntimeException ( String . format ( <str> , estimatedSSTables , expectedWriteSize ) ) ; } } protected int getLevel ( ) { return <int> ; } protected CompactionController getCompactionController ( Set < SSTableReader > toCompact ) { return new CompactionController ( cfs , toCompact , gcBefore ) ; } protected boolean partialCompactionsAcceptable ( ) { return ! isUserDefined ; } public static long getMaxDataAge ( Collection < SSTableReader > sstables ) { long max = <int> ; for ( SSTableReader sstable : sstables ) { if ( sstable . maxDataAge > max ) max = sstable . maxDataAge ; } return max ; } } 
