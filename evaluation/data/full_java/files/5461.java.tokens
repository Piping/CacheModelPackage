package org . elasticsearch . action . termvectors ; import org . apache . lucene . index . * ; import org . apache . lucene . search . CollectionStatistics ; import org . apache . lucene . search . DocIdSetIterator ; import org . apache . lucene . search . TermStatistics ; import org . apache . lucene . util . BytesRef ; import org . elasticsearch . action . termvectors . TermVectorsRequest . Flag ; import org . elasticsearch . common . Nullable ; import org . elasticsearch . common . bytes . BytesReference ; import org . elasticsearch . common . io . stream . BytesStreamOutput ; import org . elasticsearch . search . dfs . AggregatedDfs ; import java . io . IOException ; import java . util . ArrayList ; import java . util . EnumSet ; import java . util . List ; import java . util . Set ; final class TermVectorsWriter { final List < String > fields = new ArrayList < > ( ) ; final List < Long > fieldOffset = new ArrayList < > ( ) ; final BytesStreamOutput output = new BytesStreamOutput ( <int> ) ; private static final String HEADER = <str> ; private static final int CURRENT_VERSION = - <int> ; TermVectorsResponse response = null ; TermVectorsWriter ( TermVectorsResponse termVectorsResponse ) throws IOException { response = termVectorsResponse ; } void setFields ( Fields termVectorsByField , Set < String > selectedFields , EnumSet < Flag > flags , Fields topLevelFields , @Nullable AggregatedDfs dfs , @Nullable TermVectorsFilter termVectorsFilter ) throws IOException { int numFieldsWritten = <int> ; PostingsEnum docsAndPosEnum = null ; PostingsEnum docsEnum = null ; boolean hasScores = termVectorsFilter ! = null ; for ( String field : termVectorsByField ) { if ( ( selectedFields ! = null ) & & ( ! selectedFields . contains ( field ) ) ) { continue ; } Terms fieldTermVector = termVectorsByField . terms ( field ) ; Terms topLevelTerms = topLevelFields . terms ( field ) ; if ( topLevelTerms = = null ) { topLevelTerms = fieldTermVector ; } TermsEnum topLevelIterator = topLevelTerms . iterator ( ) ; boolean positions = flags . contains ( Flag . Positions ) & & fieldTermVector . hasPositions ( ) ; boolean offsets = flags . contains ( Flag . Offsets ) & & fieldTermVector . hasOffsets ( ) ; boolean payloads = flags . contains ( Flag . Payloads ) & & fieldTermVector . hasPayloads ( ) ; long termsSize = fieldTermVector . size ( ) ; if ( hasScores ) { termsSize = Math . min ( termsSize , termVectorsFilter . size ( field ) ) ; } startField ( field , termsSize , positions , offsets , payloads ) ; if ( flags . contains ( Flag . FieldStatistics ) ) { if ( dfs ! = null ) { writeFieldStatistics ( dfs . fieldStatistics ( ) . get ( field ) ) ; } else { writeFieldStatistics ( topLevelTerms ) ; } } TermsEnum iterator = fieldTermVector . iterator ( ) ; final boolean useDocsAndPos = positions | | offsets | | payloads ; while ( iterator . next ( ) ! = null ) { BytesRef termBytesRef = iterator . term ( ) ; Term term = new Term ( field , termBytesRef ) ; if ( hasScores & & ! termVectorsFilter . hasScoreTerm ( term ) ) { continue ; } startTerm ( termBytesRef ) ; if ( flags . contains ( Flag . TermStatistics ) ) { if ( dfs ! = null ) { final TermStatistics statistics = dfs . termStatistics ( ) . get ( term ) ; writeTermStatistics ( statistics = = null ? new TermStatistics ( termBytesRef , <int> , <int> ) : statistics ) ; } else { boolean foundTerm = topLevelIterator . seekExact ( termBytesRef ) ; if ( foundTerm ) { writeTermStatistics ( topLevelIterator ) ; } else { writeTermStatistics ( new TermStatistics ( termBytesRef , <int> , <int> ) ) ; } } } if ( useDocsAndPos ) { docsAndPosEnum = writeTermWithDocsAndPos ( iterator , docsAndPosEnum , positions , offsets , payloads ) ; } else { docsEnum = writeTermWithDocsOnly ( iterator , docsEnum ) ; } if ( hasScores ) { writeScoreTerm ( termVectorsFilter . getScoreTerm ( term ) ) ; } } numFieldsWritten + + ; } response . setTermVectorsField ( output ) ; response . setHeader ( writeHeader ( numFieldsWritten , flags . contains ( Flag . TermStatistics ) , flags . contains ( Flag . FieldStatistics ) , hasScores ) ) ; } private BytesReference writeHeader ( int numFieldsWritten , boolean getTermStatistics , boolean getFieldStatistics , boolean scores ) throws IOException { BytesStreamOutput header = new BytesStreamOutput ( ) ; header . writeString ( HEADER ) ; header . writeInt ( CURRENT_VERSION ) ; header . writeBoolean ( getTermStatistics ) ; header . writeBoolean ( getFieldStatistics ) ; header . writeBoolean ( scores ) ; header . writeVInt ( numFieldsWritten ) ; for ( int i = <int> ; i < fields . size ( ) ; i + + ) { header . writeString ( fields . get ( i ) ) ; header . writeVLong ( fieldOffset . get ( i ) . longValue ( ) ) ; } header . close ( ) ; return header . bytes ( ) ; } private PostingsEnum writeTermWithDocsOnly ( TermsEnum iterator , PostingsEnum docsEnum ) throws IOException { docsEnum = iterator . postings ( docsEnum ) ; int nextDoc = docsEnum . nextDoc ( ) ; assert nextDoc ! = DocIdSetIterator . NO_MORE_DOCS ; writeFreq ( docsEnum . freq ( ) ) ; nextDoc = docsEnum . nextDoc ( ) ; assert nextDoc = = DocIdSetIterator . NO_MORE_DOCS ; return docsEnum ; } private PostingsEnum writeTermWithDocsAndPos ( TermsEnum iterator , PostingsEnum docsAndPosEnum , boolean positions , boolean offsets , boolean payloads ) throws IOException { docsAndPosEnum = iterator . postings ( docsAndPosEnum , PostingsEnum . ALL ) ; int nextDoc = docsAndPosEnum . nextDoc ( ) ; assert nextDoc ! = DocIdSetIterator . NO_MORE_DOCS ; final int freq = docsAndPosEnum . freq ( ) ; writeFreq ( freq ) ; for ( int j = <int> ; j < freq ; j + + ) { int curPos = docsAndPosEnum . nextPosition ( ) ; if ( positions ) { writePosition ( curPos ) ; } if ( offsets ) { writeOffsets ( docsAndPosEnum . startOffset ( ) , docsAndPosEnum . endOffset ( ) ) ; } if ( payloads ) { writePayload ( docsAndPosEnum . getPayload ( ) ) ; } } nextDoc = docsAndPosEnum . nextDoc ( ) ; assert nextDoc = = DocIdSetIterator . NO_MORE_DOCS ; return docsAndPosEnum ; } private void writePayload ( BytesRef payload ) throws IOException { if ( payload ! = null ) { output . writeVInt ( payload . length ) ; output . writeBytes ( payload . bytes , payload . offset , payload . length ) ; } else { output . writeVInt ( <int> ) ; } } private void writeFreq ( int termFreq ) throws IOException { writePotentiallyNegativeVInt ( termFreq ) ; } private void writeOffsets ( int startOffset , int endOffset ) throws IOException { assert ( startOffset > = <int> ) ; assert ( endOffset > = <int> ) ; if ( ( startOffset > = <int> ) & & ( endOffset > = <int> ) ) { output . writeVInt ( startOffset ) ; output . writeVInt ( endOffset ) ; } } private void writePosition ( int pos ) throws IOException { assert ( pos > = <int> ) ; if ( pos > = <int> ) { output . writeVInt ( pos ) ; } } private void startField ( String fieldName , long termsSize , boolean writePositions , boolean writeOffsets , boolean writePayloads ) throws IOException { fields . add ( fieldName ) ; fieldOffset . add ( output . position ( ) ) ; output . writeVLong ( termsSize ) ; output . writeBoolean ( writePositions ) ; output . writeBoolean ( writeOffsets ) ; output . writeBoolean ( writePayloads ) ; } private void startTerm ( BytesRef term ) throws IOException { output . writeVInt ( term . length ) ; output . writeBytes ( term . bytes , term . offset , term . length ) ; } private void writeTermStatistics ( TermsEnum topLevelIterator ) throws IOException { int docFreq = topLevelIterator . docFreq ( ) ; assert ( docFreq > = - <int> ) ; writePotentiallyNegativeVInt ( docFreq ) ; long ttf = topLevelIterator . totalTermFreq ( ) ; assert ( ttf > = - <int> ) ; writePotentiallyNegativeVLong ( ttf ) ; } private void writeTermStatistics ( TermStatistics termStatistics ) throws IOException { int docFreq = ( int ) termStatistics . docFreq ( ) ; assert ( docFreq > = - <int> ) ; writePotentiallyNegativeVInt ( docFreq ) ; long ttf = termStatistics . totalTermFreq ( ) ; assert ( ttf > = - <int> ) ; writePotentiallyNegativeVLong ( ttf ) ; } private void writeFieldStatistics ( Terms topLevelTerms ) throws IOException { long sttf = topLevelTerms . getSumTotalTermFreq ( ) ; assert ( sttf > = - <int> ) ; writePotentiallyNegativeVLong ( sttf ) ; long sdf = topLevelTerms . getSumDocFreq ( ) ; assert ( sdf > = - <int> ) ; writePotentiallyNegativeVLong ( sdf ) ; int dc = topLevelTerms . getDocCount ( ) ; assert ( dc > = - <int> ) ; writePotentiallyNegativeVInt ( dc ) ; } private void writeFieldStatistics ( CollectionStatistics fieldStats ) throws IOException { long sttf = fieldStats . sumTotalTermFreq ( ) ; assert ( sttf > = - <int> ) ; writePotentiallyNegativeVLong ( sttf ) ; long sdf = fieldStats . sumDocFreq ( ) ; assert ( sdf > = - <int> ) ; writePotentiallyNegativeVLong ( sdf ) ; int dc = ( int ) fieldStats . docCount ( ) ; assert ( dc > = - <int> ) ; writePotentiallyNegativeVInt ( dc ) ; } private void writeScoreTerm ( TermVectorsFilter . ScoreTerm scoreTerm ) throws IOException { output . writeFloat ( Math . max ( <int> , scoreTerm . score ) ) ; } private void writePotentiallyNegativeVInt ( int value ) throws IOException { output . writeVInt ( Math . max ( <int> , value + <int> ) ) ; } private void writePotentiallyNegativeVLong ( long value ) throws IOException { output . writeVLong ( Math . max ( <int> , value + <int> ) ) ; } } 
