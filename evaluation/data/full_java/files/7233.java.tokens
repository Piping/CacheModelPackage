package org . elasticsearch . search . aggregations . bucket . significant ; import org . apache . lucene . index . IndexReader ; import org . apache . lucene . index . LeafReaderContext ; import org . apache . lucene . util . BytesRef ; import org . elasticsearch . common . lease . Releasables ; import org . elasticsearch . common . util . LongHash ; import org . elasticsearch . search . aggregations . Aggregator ; import org . elasticsearch . search . aggregations . AggregatorFactories ; import org . elasticsearch . search . aggregations . LeafBucketCollector ; import org . elasticsearch . search . aggregations . LeafBucketCollectorBase ; import org . elasticsearch . search . aggregations . bucket . terms . GlobalOrdinalsStringTermsAggregator ; import org . elasticsearch . search . aggregations . bucket . terms . support . IncludeExclude ; import org . elasticsearch . search . aggregations . pipeline . PipelineAggregator ; import org . elasticsearch . search . aggregations . support . AggregationContext ; import org . elasticsearch . search . aggregations . support . ValuesSource ; import org . elasticsearch . search . internal . ContextIndexSearcher ; import java . io . IOException ; import java . util . Arrays ; import java . util . Collections ; import java . util . List ; import java . util . Map ; public class GlobalOrdinalsSignificantTermsAggregator extends GlobalOrdinalsStringTermsAggregator { protected long numCollectedDocs ; protected final SignificantTermsAggregatorFactory termsAggFactory ; public GlobalOrdinalsSignificantTermsAggregator ( String name , AggregatorFactories factories , ValuesSource . Bytes . WithOrdinals . FieldData valuesSource , BucketCountThresholds bucketCountThresholds , IncludeExclude . OrdinalsFilter includeExclude , AggregationContext aggregationContext , Aggregator parent , SignificantTermsAggregatorFactory termsAggFactory , List < PipelineAggregator > pipelineAggregators , Map < String , Object > metaData ) throws IOException { super ( name , factories , valuesSource , null , bucketCountThresholds , includeExclude , aggregationContext , parent , SubAggCollectionMode . DEPTH_FIRST , false , pipelineAggregators , metaData ) ; this . termsAggFactory = termsAggFactory ; } @Override public LeafBucketCollector getLeafCollector ( LeafReaderContext ctx , final LeafBucketCollector sub ) throws IOException { return new LeafBucketCollectorBase ( super . getLeafCollector ( ctx , sub ) , null ) { @Override public void collect ( int doc , long bucket ) throws IOException { super . collect ( doc , bucket ) ; numCollectedDocs + + ; } } ; } @Override public SignificantStringTerms buildAggregation ( long owningBucketOrdinal ) throws IOException { assert owningBucketOrdinal = = <int> ; if ( globalOrds = = null ) { return buildEmptyAggregation ( ) ; } final int size ; if ( bucketCountThresholds . getMinDocCount ( ) = = <int> ) { size = ( int ) Math . min ( globalOrds . getValueCount ( ) , bucketCountThresholds . getShardSize ( ) ) ; } else { size = ( int ) Math . min ( maxBucketOrd ( ) , bucketCountThresholds . getShardSize ( ) ) ; } long supersetSize = termsAggFactory . prepareBackground ( context ) ; long subsetSize = numCollectedDocs ; BucketSignificancePriorityQueue ordered = new BucketSignificancePriorityQueue ( size ) ; SignificantStringTerms . Bucket spare = null ; for ( long globalTermOrd = <int> ; globalTermOrd < globalOrds . getValueCount ( ) ; + + globalTermOrd ) { if ( includeExclude ! = null & & ! acceptedGlobalOrdinals . get ( globalTermOrd ) ) { continue ; } final long bucketOrd = getBucketOrd ( globalTermOrd ) ; final int bucketDocCount = bucketOrd < <int> ? <int> : bucketDocCount ( bucketOrd ) ; if ( bucketCountThresholds . getMinDocCount ( ) > <int> & & bucketDocCount = = <int> ) { continue ; } if ( bucketDocCount < bucketCountThresholds . getShardMinDocCount ( ) ) { continue ; } if ( spare = = null ) { spare = new SignificantStringTerms . Bucket ( new BytesRef ( ) , <int> , <int> , <int> , <int> , null ) ; } spare . bucketOrd = bucketOrd ; copy ( globalOrds . lookupOrd ( globalTermOrd ) , spare . termBytes ) ; spare . subsetDf = bucketDocCount ; spare . subsetSize = subsetSize ; spare . supersetDf = termsAggFactory . getBackgroundFrequency ( spare . termBytes ) ; spare . supersetSize = supersetSize ; spare . updateScore ( termsAggFactory . getSignificanceHeuristic ( ) ) ; spare = ( SignificantStringTerms . Bucket ) ordered . insertWithOverflow ( spare ) ; } final InternalSignificantTerms . Bucket [ ] list = new InternalSignificantTerms . Bucket [ ordered . size ( ) ] ; for ( int i = ordered . size ( ) - <int> ; i > = <int> ; i - - ) { final SignificantStringTerms . Bucket bucket = ( SignificantStringTerms . Bucket ) ordered . pop ( ) ; bucket . termBytes = BytesRef . deepCopyOf ( bucket . termBytes ) ; bucket . aggregations = bucketAggregations ( bucket . bucketOrd ) ; list [ i ] = bucket ; } return new SignificantStringTerms ( subsetSize , supersetSize , name , bucketCountThresholds . getRequiredSize ( ) , bucketCountThresholds . getMinDocCount ( ) , termsAggFactory . getSignificanceHeuristic ( ) , Arrays . asList ( list ) , pipelineAggregators ( ) , metaData ( ) ) ; } @Override public SignificantStringTerms buildEmptyAggregation ( ) { ContextIndexSearcher searcher = context . searchContext ( ) . searcher ( ) ; IndexReader topReader = searcher . getIndexReader ( ) ; int supersetSize = topReader . numDocs ( ) ; return new SignificantStringTerms ( <int> , supersetSize , name , bucketCountThresholds . getRequiredSize ( ) , bucketCountThresholds . getMinDocCount ( ) , termsAggFactory . getSignificanceHeuristic ( ) , Collections . < InternalSignificantTerms . Bucket > emptyList ( ) , pipelineAggregators ( ) , metaData ( ) ) ; } @Override protected void doClose ( ) { Releasables . close ( termsAggFactory ) ; } public static class WithHash extends GlobalOrdinalsSignificantTermsAggregator { private final LongHash bucketOrds ; public WithHash ( String name , AggregatorFactories factories , ValuesSource . Bytes . WithOrdinals . FieldData valuesSource , BucketCountThresholds bucketCountThresholds , IncludeExclude . OrdinalsFilter includeExclude , AggregationContext aggregationContext , Aggregator parent , SignificantTermsAggregatorFactory termsAggFactory , List < PipelineAggregator > pipelineAggregators , Map < String , Object > metaData ) throws IOException { super ( name , factories , valuesSource , bucketCountThresholds , includeExclude , aggregationContext , parent , termsAggFactory , pipelineAggregators , metaData ) ; bucketOrds = new LongHash ( <int> , aggregationContext . bigArrays ( ) ) ; } @Override public LeafBucketCollector getLeafCollector ( LeafReaderContext ctx , final LeafBucketCollector sub ) throws IOException { return new LeafBucketCollectorBase ( super . getLeafCollector ( ctx , sub ) , null ) { @Override public void collect ( int doc , long bucket ) throws IOException { assert bucket = = <int> ; numCollectedDocs + + ; globalOrds . setDocument ( doc ) ; final int numOrds = globalOrds . cardinality ( ) ; for ( int i = <int> ; i < numOrds ; i + + ) { final long globalOrd = globalOrds . ordAt ( i ) ; long bucketOrd = bucketOrds . add ( globalOrd ) ; if ( bucketOrd < <int> ) { bucketOrd = - <int> - bucketOrd ; collectExistingBucket ( sub , doc , bucketOrd ) ; } else { collectBucket ( sub , doc , bucketOrd ) ; } } } } ; } @Override protected long getBucketOrd ( long termOrd ) { return bucketOrds . find ( termOrd ) ; } @Override protected void doClose ( ) { Releasables . close ( termsAggFactory , bucketOrds ) ; } } } 
