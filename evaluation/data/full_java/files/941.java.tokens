package org . apache . cassandra . service ; import java . net . InetAddress ; import java . util . * ; import java . util . concurrent . TimeoutException ; import org . apache . cassandra . concurrent . Stage ; import org . apache . cassandra . concurrent . StageManager ; import org . apache . cassandra . config . CFMetaData ; import org . apache . cassandra . config . ColumnDefinition ; import org . apache . cassandra . config . DatabaseDescriptor ; import org . apache . cassandra . db . * ; import org . apache . cassandra . db . filter . ClusteringIndexFilter ; import org . apache . cassandra . db . filter . DataLimits ; import org . apache . cassandra . db . partitions . * ; import org . apache . cassandra . db . rows . * ; import org . apache . cassandra . db . transform . MoreRows ; import org . apache . cassandra . db . transform . Transformation ; import org . apache . cassandra . exceptions . ReadTimeoutException ; import org . apache . cassandra . net . * ; import org . apache . cassandra . tracing . Tracing ; import org . apache . cassandra . utils . FBUtilities ; public class DataResolver extends ResponseResolver { private final List < AsyncOneResponse > repairResults = Collections . synchronizedList ( new ArrayList < > ( ) ) ; public DataResolver ( Keyspace keyspace , ReadCommand command , ConsistencyLevel consistency , int maxResponseCount ) { super ( keyspace , command , consistency , maxResponseCount ) ; } public PartitionIterator getData ( ) { ReadResponse response = responses . iterator ( ) . next ( ) . payload ; return UnfilteredPartitionIterators . filter ( response . makeIterator ( command . metadata ( ) , command ) , command . nowInSec ( ) ) ; } public PartitionIterator resolve ( ) { int count = responses . size ( ) ; List < UnfilteredPartitionIterator > iters = new ArrayList < > ( count ) ; InetAddress [ ] sources = new InetAddress [ count ] ; for ( int i = <int> ; i < count ; i + + ) { MessageIn < ReadResponse > msg = responses . get ( i ) ; iters . add ( msg . payload . makeIterator ( command . metadata ( ) , command ) ) ; sources [ i ] = msg . from ; } DataLimits . Counter counter = command . limits ( ) . newCounter ( command . nowInSec ( ) , true ) ; return counter . applyTo ( mergeWithShortReadProtection ( iters , sources , counter ) ) ; } private PartitionIterator mergeWithShortReadProtection ( List < UnfilteredPartitionIterator > results , InetAddress [ ] sources , DataLimits . Counter resultCounter ) { if ( results . size ( ) = = <int> ) return UnfilteredPartitionIterators . filter ( results . get ( <int> ) , command . nowInSec ( ) ) ; UnfilteredPartitionIterators . MergeListener listener = new RepairMergeListener ( sources ) ; if ( ! command . limits ( ) . isUnlimited ( ) ) { for ( int i = <int> ; i < results . size ( ) ; i + + ) results . set ( i , Transformation . apply ( results . get ( i ) , new ShortReadProtection ( sources [ i ] , resultCounter ) ) ) ; } return UnfilteredPartitionIterators . mergeAndFilter ( results , command . nowInSec ( ) , listener ) ; } private class RepairMergeListener implements UnfilteredPartitionIterators . MergeListener { private final InetAddress [ ] sources ; public RepairMergeListener ( InetAddress [ ] sources ) { this . sources = sources ; } public UnfilteredRowIterators . MergeListener getRowMergeListener ( DecoratedKey partitionKey , List < UnfilteredRowIterator > versions ) { return new MergeListener ( partitionKey , columns ( versions ) , isReversed ( versions ) ) ; } private PartitionColumns columns ( List < UnfilteredRowIterator > versions ) { Columns statics = Columns . NONE ; Columns regulars = Columns . NONE ; for ( UnfilteredRowIterator iter : versions ) { if ( iter = = null ) continue ; PartitionColumns cols = iter . columns ( ) ; statics = statics . mergeTo ( cols . statics ) ; regulars = regulars . mergeTo ( cols . regulars ) ; } return new PartitionColumns ( statics , regulars ) ; } private boolean isReversed ( List < UnfilteredRowIterator > versions ) { for ( UnfilteredRowIterator iter : versions ) { if ( iter = = null ) continue ; return iter . isReverseOrder ( ) ; } assert false : <str> ; return false ; } public void close ( ) { try { FBUtilities . waitOnFutures ( repairResults , DatabaseDescriptor . getWriteRpcTimeout ( ) ) ; } catch ( TimeoutException ex ) { int blockFor = consistency . blockFor ( keyspace ) ; if ( Tracing . isTracing ( ) ) Tracing . trace ( <str> , blockFor ) ; else logger . debug ( <str> , blockFor ) ; throw new ReadTimeoutException ( consistency , blockFor - <int> , blockFor , true ) ; } } private class MergeListener implements UnfilteredRowIterators . MergeListener { private final DecoratedKey partitionKey ; private final PartitionColumns columns ; private final boolean isReversed ; private final PartitionUpdate [ ] repairs = new PartitionUpdate [ sources . length ] ; private final Row . Builder [ ] currentRows = new Row . Builder [ sources . length ] ; private final RowDiffListener diffListener ; private final Slice . Bound [ ] markerOpen = new Slice . Bound [ sources . length ] ; private final DeletionTime [ ] markerTime = new DeletionTime [ sources . length ] ; public MergeListener ( DecoratedKey partitionKey , PartitionColumns columns , boolean isReversed ) { this . partitionKey = partitionKey ; this . columns = columns ; this . isReversed = isReversed ; this . diffListener = new RowDiffListener ( ) { public void onPrimaryKeyLivenessInfo ( int i , Clustering clustering , LivenessInfo merged , LivenessInfo original ) { if ( merged ! = null & & ! merged . equals ( original ) ) currentRow ( i , clustering ) . addPrimaryKeyLivenessInfo ( merged ) ; } public void onDeletion ( int i , Clustering clustering , Row . Deletion merged , Row . Deletion original ) { if ( merged ! = null & & ! merged . equals ( original ) ) currentRow ( i , clustering ) . addRowDeletion ( merged ) ; } public void onComplexDeletion ( int i , Clustering clustering , ColumnDefinition column , DeletionTime merged , DeletionTime original ) { if ( merged ! = null & & ! merged . equals ( original ) ) currentRow ( i , clustering ) . addComplexDeletion ( column , merged ) ; } public void onCell ( int i , Clustering clustering , Cell merged , Cell original ) { if ( merged ! = null & & ! merged . equals ( original ) ) currentRow ( i , clustering ) . addCell ( merged ) ; } } ; } private PartitionUpdate update ( int i ) { if ( repairs [ i ] = = null ) repairs [ i ] = new PartitionUpdate ( command . metadata ( ) , partitionKey , columns , <int> ) ; return repairs [ i ] ; } private Row . Builder currentRow ( int i , Clustering clustering ) { if ( currentRows [ i ] = = null ) { currentRows [ i ] = BTreeRow . sortedBuilder ( ) ; currentRows [ i ] . newRow ( clustering ) ; } return currentRows [ i ] ; } public void onMergedPartitionLevelDeletion ( DeletionTime mergedDeletion , DeletionTime [ ] versions ) { for ( int i = <int> ; i < versions . length ; i + + ) { if ( mergedDeletion . supersedes ( versions [ i ] ) ) update ( i ) . addPartitionDeletion ( mergedDeletion ) ; } } public void onMergedRows ( Row merged , Row [ ] versions ) { if ( merged . isEmpty ( ) ) return ; Rows . diff ( diffListener , merged , versions ) ; for ( int i = <int> ; i < currentRows . length ; i + + ) { if ( currentRows [ i ] ! = null ) update ( i ) . add ( currentRows [ i ] . build ( ) ) ; } Arrays . fill ( currentRows , null ) ; } public void onMergedRangeTombstoneMarkers ( RangeTombstoneMarker merged , RangeTombstoneMarker [ ] versions ) { for ( int i = <int> ; i < versions . length ; i + + ) { RangeTombstoneMarker marker = versions [ i ] ; if ( merged . isClose ( isReversed ) & & markerOpen [ i ] ! = null ) { Slice . Bound open = markerOpen [ i ] ; Slice . Bound close = merged . closeBound ( isReversed ) ; update ( i ) . add ( new RangeTombstone ( Slice . make ( isReversed ? close : open , isReversed ? open : close ) , markerTime [ i ] ) ) ; } if ( merged . isOpen ( isReversed ) & & ( marker = = null | | merged . openDeletionTime ( isReversed ) . supersedes ( marker . openDeletionTime ( isReversed ) ) ) ) { markerOpen [ i ] = merged . openBound ( isReversed ) ; markerTime [ i ] = merged . openDeletionTime ( isReversed ) ; } } } public void close ( ) { for ( int i = <int> ; i < repairs . length ; i + + ) { if ( repairs [ i ] = = null ) continue ; Tracing . trace ( <str> , sources [ i ] ) ; MessageOut < Mutation > msg = new Mutation ( repairs [ i ] ) . createMessage ( MessagingService . Verb . READ_REPAIR ) ; repairResults . add ( MessagingService . instance ( ) . sendRR ( msg , sources [ i ] ) ) ; } } } } private class ShortReadProtection extends Transformation < UnfilteredRowIterator > { private final InetAddress source ; private final DataLimits . Counter counter ; private final DataLimits . Counter postReconciliationCounter ; private ShortReadProtection ( InetAddress source , DataLimits . Counter postReconciliationCounter ) { this . source = source ; this . counter = command . limits ( ) . newCounter ( command . nowInSec ( ) , false ) . onlyCount ( ) ; this . postReconciliationCounter = postReconciliationCounter ; } @Override public UnfilteredRowIterator applyToPartition ( UnfilteredRowIterator partition ) { partition = Transformation . apply ( partition , counter ) ; ShortReadRowProtection protection = new ShortReadRowProtection ( partition . metadata ( ) , partition . partitionKey ( ) ) ; partition = MoreRows . extend ( partition , protection ) ; partition = Transformation . apply ( partition , protection ) ; return partition ; } private class ShortReadRowProtection extends Transformation implements MoreRows < UnfilteredRowIterator > { final CFMetaData metadata ; final DecoratedKey partitionKey ; Clustering lastClustering ; int lastCount = <int> ; private ShortReadRowProtection ( CFMetaData metadata , DecoratedKey partitionKey ) { this . metadata = metadata ; this . partitionKey = partitionKey ; } @Override public Row applyToRow ( Row row ) { lastClustering = row . clustering ( ) ; return row ; } @Override public UnfilteredRowIterator moreContents ( ) { if ( lastCount = = counter . counted ( ) | | ! counter . isDoneForPartition ( ) ) return null ; lastCount = counter . counted ( ) ; assert ! postReconciliationCounter . isDoneForPartition ( ) ; int n = postReconciliationCounter . countedInCurrentPartition ( ) ; int x = counter . countedInCurrentPartition ( ) ; int toQuery = Math . max ( ( ( n * n ) / x ) - n , <int> ) ; DataLimits retryLimits = command . limits ( ) . forShortReadRetry ( toQuery ) ; ClusteringIndexFilter filter = command . clusteringIndexFilter ( partitionKey ) ; ClusteringIndexFilter retryFilter = lastClustering = = null ? filter : filter . forPaging ( metadata . comparator , lastClustering , false ) ; SinglePartitionReadCommand cmd = SinglePartitionReadCommand . create ( command . metadata ( ) , command . nowInSec ( ) , command . columnFilter ( ) , command . rowFilter ( ) , retryLimits , partitionKey , retryFilter ) ; return doShortReadRetry ( cmd ) ; } private UnfilteredRowIterator doShortReadRetry ( SinglePartitionReadCommand retryCommand ) { DataResolver resolver = new DataResolver ( keyspace , retryCommand , ConsistencyLevel . ONE , <int> ) ; ReadCallback handler = new ReadCallback ( resolver , ConsistencyLevel . ONE , retryCommand , Collections . singletonList ( source ) ) ; if ( StorageProxy . canDoLocalRequest ( source ) ) StageManager . getStage ( Stage . READ ) . maybeExecuteImmediately ( new StorageProxy . LocalReadRunnable ( retryCommand , handler ) ) ; else MessagingService . instance ( ) . sendRRWithFailure ( retryCommand . createMessage ( MessagingService . current_version ) , source , handler ) ; handler . awaitResults ( ) ; assert resolver . responses . size ( ) = = <int> ; return UnfilteredPartitionIterators . getOnlyElement ( resolver . responses . get ( <int> ) . payload . makeIterator ( command . metadata ( ) , command ) , retryCommand ) ; } } } public boolean isDataPresent ( ) { return ! responses . isEmpty ( ) ; } } 
