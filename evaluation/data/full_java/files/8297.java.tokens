package org . elasticsearch . index . shard ; import org . apache . lucene . document . Document ; import org . apache . lucene . document . StringField ; import org . apache . lucene . index . * ; import org . apache . lucene . store . BaseDirectoryWrapper ; import org . apache . lucene . util . IOUtils ; import org . elasticsearch . common . lucene . index . ElasticsearchDirectoryReader ; import org . elasticsearch . test . ESTestCase ; import java . io . IOException ; public class ShardUtilsTests extends ESTestCase { public void testExtractShardId ( ) throws IOException { BaseDirectoryWrapper dir = newDirectory ( ) ; IndexWriter writer = new IndexWriter ( dir , newIndexWriterConfig ( ) ) ; writer . commit ( ) ; ShardId id = new ShardId ( <str> , random ( ) . nextInt ( ) ) ; try ( DirectoryReader reader = DirectoryReader . open ( writer , random ( ) . nextBoolean ( ) ) ) { ElasticsearchDirectoryReader wrap = ElasticsearchDirectoryReader . wrap ( reader , id ) ; assertEquals ( id , ShardUtils . extractShardId ( wrap ) ) ; } final int numDocs = <int> + random ( ) . nextInt ( <int> ) ; for ( int i = <int> ; i < numDocs ; i + + ) { Document d = new Document ( ) ; d . add ( newField ( <str> , <str> , StringField . TYPE_STORED ) ) ; writer . addDocument ( d ) ; if ( random ( ) . nextBoolean ( ) ) { writer . commit ( ) ; } } try ( DirectoryReader reader = DirectoryReader . open ( writer , random ( ) . nextBoolean ( ) ) ) { ElasticsearchDirectoryReader wrap = ElasticsearchDirectoryReader . wrap ( reader , id ) ; assertEquals ( id , ShardUtils . extractShardId ( wrap ) ) ; CompositeReaderContext context = wrap . getContext ( ) ; for ( LeafReaderContext leaf : context . leaves ( ) ) { assertEquals ( id , ShardUtils . extractShardId ( leaf . reader ( ) ) ) ; } } IOUtils . close ( writer , dir ) ; } } 
