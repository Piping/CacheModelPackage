package org . elasticsearch . recovery ; import com . carrotsearch . hppc . IntHashSet ; import com . carrotsearch . hppc . procedures . IntProcedure ; import org . apache . lucene . index . IndexFileNames ; import org . elasticsearch . action . admin . cluster . health . ClusterHealthResponse ; import org . elasticsearch . action . index . IndexRequestBuilder ; import org . elasticsearch . action . search . SearchPhaseExecutionException ; import org . elasticsearch . action . search . SearchResponse ; import org . elasticsearch . client . Client ; import org . elasticsearch . cluster . ClusterService ; import org . elasticsearch . cluster . ClusterState ; import org . elasticsearch . cluster . metadata . IndexMetaData ; import org . elasticsearch . cluster . node . DiscoveryNode ; import org . elasticsearch . cluster . routing . ShardRoutingState ; import org . elasticsearch . cluster . routing . allocation . command . MoveAllocationCommand ; import org . elasticsearch . cluster . routing . allocation . decider . EnableAllocationDecider ; import org . elasticsearch . common . Nullable ; import org . elasticsearch . common . Priority ; import org . elasticsearch . common . settings . Settings ; import org . elasticsearch . common . unit . TimeValue ; import org . elasticsearch . env . NodeEnvironment ; import org . elasticsearch . index . shard . IndexEventListener ; import org . elasticsearch . index . shard . IndexShard ; import org . elasticsearch . index . shard . IndexShardState ; import org . elasticsearch . index . shard . ShardId ; import org . elasticsearch . indices . recovery . RecoveryFileChunkRequest ; import org . elasticsearch . indices . recovery . RecoveryTarget ; import org . elasticsearch . plugins . Plugin ; import org . elasticsearch . search . SearchHit ; import org . elasticsearch . search . SearchHits ; import org . elasticsearch . test . BackgroundIndexer ; import org . elasticsearch . test . ESIntegTestCase ; import org . elasticsearch . test . ESIntegTestCase . ClusterScope ; import org . elasticsearch . test . ESIntegTestCase . Scope ; import org . elasticsearch . test . MockIndexEventListener ; import org . elasticsearch . test . junit . annotations . TestLogging ; import org . elasticsearch . test . transport . MockTransportService ; import org . elasticsearch . transport . Transport ; import org . elasticsearch . transport . TransportException ; import org . elasticsearch . transport . TransportRequest ; import org . elasticsearch . transport . TransportRequestOptions ; import org . elasticsearch . transport . TransportService ; import java . io . IOException ; import java . nio . file . FileVisitResult ; import java . nio . file . Files ; import java . nio . file . Path ; import java . nio . file . SimpleFileVisitor ; import java . nio . file . attribute . BasicFileAttributes ; import java . util . ArrayList ; import java . util . Collection ; import java . util . List ; import java . util . concurrent . CountDownLatch ; import java . util . concurrent . Semaphore ; import java . util . concurrent . TimeUnit ; import static org . elasticsearch . common . settings . Settings . settingsBuilder ; import static org . elasticsearch . index . query . QueryBuilders . matchAllQuery ; import static org . elasticsearch . test . hamcrest . ElasticsearchAssertions . assertAcked ; import static org . elasticsearch . test . hamcrest . ElasticsearchAssertions . assertNoFailures ; import static org . hamcrest . Matchers . equalTo ; import static org . hamcrest . Matchers . not ; import static org . hamcrest . Matchers . startsWith ; @ClusterScope ( scope = Scope . TEST , numDataNodes = <int> ) @TestLogging ( <str> ) public class RelocationIT extends ESIntegTestCase { private final TimeValue ACCEPTABLE_RELOCATION_TIME = new TimeValue ( <int> , TimeUnit . MINUTES ) ; @Override protected Collection < Class < ? extends Plugin > > nodePlugins ( ) { return pluginList ( MockTransportService . TestPlugin . class , MockIndexEventListener . TestPlugin . class ) ; } public void testSimpleRelocationNoIndexing ( ) { logger . info ( <str> ) ; final String node_1 = internalCluster ( ) . startNode ( ) ; logger . info ( <str> ) ; client ( ) . admin ( ) . indices ( ) . prepareCreate ( <str> ) . setSettings ( Settings . settingsBuilder ( ) . put ( <str> , <int> ) . put ( <str> , <int> ) ) . execute ( ) . actionGet ( ) ; logger . info ( <str> ) ; for ( int i = <int> ; i < <int> ; i + + ) { client ( ) . prepareIndex ( <str> , <str> , Integer . toString ( i ) ) . setSource ( <str> , <str> + i ) . execute ( ) . actionGet ( ) ; } logger . info ( <str> ) ; client ( ) . admin ( ) . indices ( ) . prepareFlush ( ) . execute ( ) . actionGet ( ) ; logger . info ( <str> ) ; for ( int i = <int> ; i < <int> ; i + + ) { client ( ) . prepareIndex ( <str> , <str> , Integer . toString ( i ) ) . setSource ( <str> , <str> + i ) . execute ( ) . actionGet ( ) ; } logger . info ( <str> ) ; client ( ) . admin ( ) . indices ( ) . prepareRefresh ( ) . execute ( ) . actionGet ( ) ; assertThat ( client ( ) . prepareSearch ( <str> ) . setSize ( <int> ) . execute ( ) . actionGet ( ) . getHits ( ) . totalHits ( ) , equalTo ( <int> ) ) ; logger . info ( <str> ) ; final String node_2 = internalCluster ( ) . startNode ( ) ; ClusterHealthResponse clusterHealthResponse = client ( ) . admin ( ) . cluster ( ) . prepareHealth ( ) . setWaitForEvents ( Priority . LANGUID ) . setWaitForNodes ( <str> ) . execute ( ) . actionGet ( ) ; assertThat ( clusterHealthResponse . isTimedOut ( ) , equalTo ( false ) ) ; logger . info ( <str> ) ; client ( ) . admin ( ) . cluster ( ) . prepareReroute ( ) . add ( new MoveAllocationCommand ( new ShardId ( <str> , <int> ) , node_1 , node_2 ) ) . execute ( ) . actionGet ( ) ; clusterHealthResponse = client ( ) . admin ( ) . cluster ( ) . prepareHealth ( ) . setWaitForEvents ( Priority . LANGUID ) . setWaitForRelocatingShards ( <int> ) . setTimeout ( ACCEPTABLE_RELOCATION_TIME ) . execute ( ) . actionGet ( ) ; assertThat ( clusterHealthResponse . isTimedOut ( ) , equalTo ( false ) ) ; clusterHealthResponse = client ( ) . admin ( ) . cluster ( ) . prepareHealth ( ) . setWaitForEvents ( Priority . LANGUID ) . setWaitForRelocatingShards ( <int> ) . setTimeout ( ACCEPTABLE_RELOCATION_TIME ) . execute ( ) . actionGet ( ) ; assertThat ( clusterHealthResponse . isTimedOut ( ) , equalTo ( false ) ) ; logger . info ( <str> ) ; client ( ) . admin ( ) . indices ( ) . prepareRefresh ( ) . execute ( ) . actionGet ( ) ; assertThat ( client ( ) . prepareSearch ( <str> ) . setSize ( <int> ) . execute ( ) . actionGet ( ) . getHits ( ) . totalHits ( ) , equalTo ( <int> ) ) ; } public void testRelocationWhileIndexingRandom ( ) throws Exception { int numberOfRelocations = scaledRandomIntBetween ( <int> , rarely ( ) ? <int> : <int> ) ; int numberOfReplicas = randomBoolean ( ) ? <int> : <int> ; int numberOfNodes = numberOfReplicas = = <int> ? <int> : <int> ; logger . info ( <str> , numberOfRelocations , numberOfReplicas , numberOfNodes ) ; String [ ] nodes = new String [ numberOfNodes ] ; logger . info ( <str> ) ; nodes [ <int> ] = internalCluster ( ) . startNode ( ) ; logger . info ( <str> ) ; client ( ) . admin ( ) . indices ( ) . prepareCreate ( <str> ) . setSettings ( settingsBuilder ( ) . put ( <str> , <int> ) . put ( <str> , numberOfReplicas ) ) . execute ( ) . actionGet ( ) ; for ( int i = <int> ; i < numberOfNodes ; i + + ) { logger . info ( <str> , i + <int> ) ; nodes [ i ] = internalCluster ( ) . startNode ( ) ; if ( i ! = numberOfNodes - <int> ) { ClusterHealthResponse healthResponse = client ( ) . admin ( ) . cluster ( ) . prepareHealth ( ) . setWaitForEvents ( Priority . LANGUID ) . setWaitForNodes ( Integer . toString ( i + <int> ) ) . setWaitForGreenStatus ( ) . execute ( ) . actionGet ( ) ; assertThat ( healthResponse . isTimedOut ( ) , equalTo ( false ) ) ; } } int numDocs = scaledRandomIntBetween ( <int> , <int> ) ; try ( BackgroundIndexer indexer = new BackgroundIndexer ( <str> , <str> , client ( ) , numDocs ) ) { logger . info ( <str> , numDocs ) ; waitForDocs ( numDocs , indexer ) ; logger . info ( <str> , numDocs ) ; logger . info ( <str> ) ; int nodeShiftBased = numberOfReplicas ; for ( int i = <int> ; i < numberOfRelocations ; i + + ) { int fromNode = ( i % <int> ) ; int toNode = fromNode = = <int> ? <int> : <int> ; fromNode + = nodeShiftBased ; toNode + = nodeShiftBased ; numDocs = scaledRandomIntBetween ( <int> , <int> ) ; logger . debug ( <str> , numDocs ) ; indexer . continueIndexing ( numDocs ) ; logger . info ( <str> , nodes [ fromNode ] , nodes [ toNode ] ) ; client ( ) . admin ( ) . cluster ( ) . prepareReroute ( ) . add ( new MoveAllocationCommand ( new ShardId ( <str> , <int> ) , nodes [ fromNode ] , nodes [ toNode ] ) ) . get ( ) ; if ( rarely ( ) ) { logger . debug ( <str> ) ; client ( ) . admin ( ) . indices ( ) . prepareFlush ( ) . get ( ) ; } ClusterHealthResponse clusterHealthResponse = client ( ) . admin ( ) . cluster ( ) . prepareHealth ( ) . setWaitForEvents ( Priority . LANGUID ) . setWaitForRelocatingShards ( <int> ) . setTimeout ( ACCEPTABLE_RELOCATION_TIME ) . execute ( ) . actionGet ( ) ; assertThat ( clusterHealthResponse . isTimedOut ( ) , equalTo ( false ) ) ; clusterHealthResponse = client ( ) . admin ( ) . cluster ( ) . prepareHealth ( ) . setWaitForEvents ( Priority . LANGUID ) . setWaitForRelocatingShards ( <int> ) . setTimeout ( ACCEPTABLE_RELOCATION_TIME ) . execute ( ) . actionGet ( ) ; assertThat ( clusterHealthResponse . isTimedOut ( ) , equalTo ( false ) ) ; indexer . pauseIndexing ( ) ; logger . info ( <str> , fromNode , toNode ) ; } logger . info ( <str> ) ; logger . info ( <str> ) ; indexer . stop ( ) ; logger . info ( <str> ) ; logger . info ( <str> ) ; client ( ) . admin ( ) . indices ( ) . prepareRefresh ( <str> ) . execute ( ) . actionGet ( ) ; logger . info ( <str> ) ; boolean ranOnce = false ; for ( int i = <int> ; i < <int> ; i + + ) { try { logger . info ( <str> , i + <int> ) ; SearchHits hits = client ( ) . prepareSearch ( <str> ) . setQuery ( matchAllQuery ( ) ) . setSize ( ( int ) indexer . totalIndexedDocs ( ) ) . setNoFields ( ) . execute ( ) . actionGet ( ) . getHits ( ) ; ranOnce = true ; if ( hits . totalHits ( ) ! = indexer . totalIndexedDocs ( ) ) { int [ ] hitIds = new int [ ( int ) indexer . totalIndexedDocs ( ) ] ; for ( int hit = <int> ; hit < indexer . totalIndexedDocs ( ) ; hit + + ) { hitIds [ hit ] = hit + <int> ; } IntHashSet set = IntHashSet . from ( hitIds ) ; for ( SearchHit hit : hits . hits ( ) ) { int id = Integer . parseInt ( hit . id ( ) ) ; if ( ! set . remove ( id ) ) { logger . error ( <str> , id ) ; } } set . forEach ( new IntProcedure ( ) { @Override public void apply ( int value ) { logger . error ( <str> , value ) ; } } ) ; } assertThat ( hits . totalHits ( ) , equalTo ( indexer . totalIndexedDocs ( ) ) ) ; logger . info ( <str> , i + <int> ) ; } catch ( SearchPhaseExecutionException ex ) { logger . warn ( <str> , ex ) ; } } if ( ! ranOnce ) { fail ( ) ; } } } public void testRelocationWhileRefreshing ( ) throws Exception { int numberOfRelocations = scaledRandomIntBetween ( <int> , rarely ( ) ? <int> : <int> ) ; int numberOfReplicas = randomBoolean ( ) ? <int> : <int> ; int numberOfNodes = numberOfReplicas = = <int> ? <int> : <int> ; logger . info ( <str> , numberOfRelocations , numberOfReplicas , numberOfNodes ) ; String [ ] nodes = new String [ numberOfNodes ] ; logger . info ( <str> ) ; nodes [ <int> ] = internalCluster ( ) . startNode ( ) ; logger . info ( <str> ) ; client ( ) . admin ( ) . indices ( ) . prepareCreate ( <str> ) . setSettings ( settingsBuilder ( ) . put ( <str> , <int> ) . put ( <str> , numberOfReplicas ) . put ( <str> , - <int> ) ) . execute ( ) . actionGet ( ) ; ensureYellow ( ) ; for ( int i = <int> ; i < numberOfNodes ; i + + ) { logger . info ( <str> , i ) ; nodes [ i ] = internalCluster ( ) . startNode ( ) ; if ( i ! = numberOfNodes - <int> ) { ClusterHealthResponse healthResponse = client ( ) . admin ( ) . cluster ( ) . prepareHealth ( ) . setWaitForEvents ( Priority . LANGUID ) . setWaitForNodes ( Integer . toString ( i + <int> ) ) . setWaitForGreenStatus ( ) . execute ( ) . actionGet ( ) ; assertThat ( healthResponse . isTimedOut ( ) , equalTo ( false ) ) ; } } final Semaphore postRecoveryShards = new Semaphore ( <int> ) ; final IndexEventListener listener = new IndexEventListener ( ) { @Override public void indexShardStateChanged ( IndexShard indexShard , @Nullable IndexShardState previousState , IndexShardState currentState , @Nullable String reason ) { if ( currentState = = IndexShardState . POST_RECOVERY ) { postRecoveryShards . release ( ) ; } } } ; for ( MockIndexEventListener . TestEventListener eventListener : internalCluster ( ) . getInstances ( MockIndexEventListener . TestEventListener . class ) ) { eventListener . setNewDelegate ( listener ) ; } logger . info ( <str> ) ; int nodeShiftBased = numberOfReplicas ; for ( int i = <int> ; i < numberOfRelocations ; i + + ) { int fromNode = ( i % <int> ) ; int toNode = fromNode = = <int> ? <int> : <int> ; fromNode + = nodeShiftBased ; toNode + = nodeShiftBased ; List < IndexRequestBuilder > builders1 = new ArrayList < > ( ) ; for ( int numDocs = randomIntBetween ( <int> , <int> ) ; numDocs > <int> ; numDocs - - ) { builders1 . add ( client ( ) . prepareIndex ( <str> , <str> ) . setSource ( <str> ) ) ; } List < IndexRequestBuilder > builders2 = new ArrayList < > ( ) ; for ( int numDocs = randomIntBetween ( <int> , <int> ) ; numDocs > <int> ; numDocs - - ) { builders2 . add ( client ( ) . prepareIndex ( <str> , <str> ) . setSource ( <str> ) ) ; } logger . info ( <str> , nodes [ fromNode ] , nodes [ toNode ] ) ; client ( ) . admin ( ) . cluster ( ) . prepareReroute ( ) . add ( new MoveAllocationCommand ( new ShardId ( <str> , <int> ) , nodes [ fromNode ] , nodes [ toNode ] ) ) . get ( ) ; logger . debug ( <str> , builders1 . size ( ) ) ; indexRandom ( false , true , builders1 ) ; postRecoveryShards . acquire ( <int> ) ; logger . debug ( <str> , builders2 . size ( ) ) ; indexRandom ( true , true , builders2 ) ; assertFalse ( client ( ) . admin ( ) . cluster ( ) . prepareHealth ( ) . setWaitForRelocatingShards ( <int> ) . setWaitForEvents ( Priority . LANGUID ) . setTimeout ( <str> ) . get ( ) . isTimedOut ( ) ) ; logger . info ( <str> , fromNode , toNode ) ; logger . debug ( <str> ) ; long expectedCount = - <int> ; for ( Client client : clients ( ) ) { SearchResponse response = client . prepareSearch ( <str> ) . setPreference ( <str> ) . setSize ( <int> ) . get ( ) ; assertNoFailures ( response ) ; if ( expectedCount < <int> ) { expectedCount = response . getHits ( ) . totalHits ( ) ; } else { assertEquals ( expectedCount , response . getHits ( ) . totalHits ( ) ) ; } } } } public void testCancellationCleansTempFiles ( ) throws Exception { final String indexName = <str> ; final String p_node = internalCluster ( ) . startNode ( ) ; client ( ) . admin ( ) . indices ( ) . prepareCreate ( indexName ) . setSettings ( Settings . builder ( ) . put ( IndexMetaData . SETTING_NUMBER_OF_SHARDS , <int> , IndexMetaData . SETTING_NUMBER_OF_REPLICAS , <int> ) ) . get ( ) ; internalCluster ( ) . startNodesAsync ( <int> ) . get ( ) ; List < IndexRequestBuilder > requests = new ArrayList < > ( ) ; int numDocs = scaledRandomIntBetween ( <int> , <int> ) ; for ( int i = <int> ; i < numDocs ; i + + ) { requests . add ( client ( ) . prepareIndex ( indexName , <str> ) . setCreate ( true ) . setSource ( <str> ) ) ; } indexRandom ( true , requests ) ; assertFalse ( client ( ) . admin ( ) . cluster ( ) . prepareHealth ( ) . setWaitForNodes ( <str> ) . setWaitForGreenStatus ( ) . get ( ) . isTimedOut ( ) ) ; flush ( ) ; int allowedFailures = randomIntBetween ( <int> , <int> ) ; logger . info ( <str> , allowedFailures ) ; CountDownLatch corruptionCount = new CountDownLatch ( allowedFailures ) ; ClusterService clusterService = internalCluster ( ) . getInstance ( ClusterService . class , p_node ) ; MockTransportService mockTransportService = ( MockTransportService ) internalCluster ( ) . getInstance ( TransportService . class , p_node ) ; for ( DiscoveryNode node : clusterService . state ( ) . nodes ( ) ) { if ( ! node . equals ( clusterService . localNode ( ) ) ) { mockTransportService . addDelegate ( internalCluster ( ) . getInstance ( TransportService . class , node . getName ( ) ) , new RecoveryCorruption ( mockTransportService . original ( ) , corruptionCount ) ) ; } } client ( ) . admin ( ) . indices ( ) . prepareUpdateSettings ( indexName ) . setSettings ( Settings . builder ( ) . put ( IndexMetaData . SETTING_NUMBER_OF_REPLICAS , <int> ) ) . get ( ) ; corruptionCount . await ( ) ; logger . info ( <str> ) ; assertAcked ( client ( ) . admin ( ) . cluster ( ) . prepareUpdateSettings ( ) . setTransientSettings ( Settings . builder ( ) . put ( EnableAllocationDecider . CLUSTER_ROUTING_ALLOCATION_ENABLE , <str> ) ) ) ; logger . info ( <str> ) ; assertBusy ( new Runnable ( ) { @Override public void run ( ) { for ( String node : internalCluster ( ) . getNodeNames ( ) ) { if ( node . equals ( p_node ) ) { continue ; } ClusterState state = client ( node ) . admin ( ) . cluster ( ) . prepareState ( ) . setLocal ( true ) . get ( ) . getState ( ) ; assertThat ( node + <str> , state . getRoutingTable ( ) . index ( indexName ) . shardsWithState ( ShardRoutingState . UNASSIGNED ) . size ( ) , equalTo ( <int> ) ) ; } } } ) ; logger . info ( <str> ) ; for ( String node : internalCluster ( ) . getNodeNames ( ) ) { NodeEnvironment nodeEnvironment = internalCluster ( ) . getInstance ( NodeEnvironment . class , node ) ; for ( final Path shardLoc : nodeEnvironment . availableShardPaths ( new ShardId ( indexName , <int> ) ) ) { if ( Files . exists ( shardLoc ) ) { assertBusy ( new Runnable ( ) { @Override public void run ( ) { try { Files . walkFileTree ( shardLoc , new SimpleFileVisitor < Path > ( ) { @Override public FileVisitResult visitFile ( Path file , BasicFileAttributes attrs ) throws IOException { assertThat ( <str> + file , file . getFileName ( ) . toString ( ) , not ( startsWith ( <str> ) ) ) ; return FileVisitResult . CONTINUE ; } } ) ; } catch ( IOException e ) { throw new AssertionError ( <str> + shardLoc + <str> , e ) ; } } } ) ; } } } } class RecoveryCorruption extends MockTransportService . DelegateTransport { private final CountDownLatch corruptionCount ; public RecoveryCorruption ( Transport transport , CountDownLatch corruptionCount ) { super ( transport ) ; this . corruptionCount = corruptionCount ; } @Override public void sendRequest ( DiscoveryNode node , long requestId , String action , TransportRequest request , TransportRequestOptions options ) throws IOException , TransportException { if ( action . equals ( RecoveryTarget . Actions . FILE_CHUNK ) ) { RecoveryFileChunkRequest chunkRequest = ( RecoveryFileChunkRequest ) request ; if ( chunkRequest . name ( ) . startsWith ( IndexFileNames . SEGMENTS ) ) { logger . debug ( <str> , action , node , chunkRequest . name ( ) ) ; byte [ ] array = chunkRequest . content ( ) . array ( ) ; array [ <int> ] = ( byte ) ~ array [ <int> ] ; corruptionCount . countDown ( ) ; } transport . sendRequest ( node , requestId , action , request , options ) ; } else { transport . sendRequest ( node , requestId , action , request , options ) ; } } } } 
