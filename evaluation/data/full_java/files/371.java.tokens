package org . apache . cassandra . db . commitlog ; import java . io . File ; import java . io . IOException ; import java . nio . ByteBuffer ; import java . nio . channels . FileChannel ; import java . nio . file . StandardOpenOption ; import java . util . ArrayList ; import java . util . Collection ; import java . util . Comparator ; import java . util . Iterator ; import java . util . List ; import java . util . Map ; import java . util . UUID ; import java . util . concurrent . ConcurrentHashMap ; import java . util . concurrent . ConcurrentMap ; import java . util . concurrent . atomic . AtomicInteger ; import java . util . zip . CRC32 ; import com . codahale . metrics . Timer ; import org . cliffc . high_scale_lib . NonBlockingHashMap ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; import org . apache . cassandra . config . CFMetaData ; import org . apache . cassandra . config . DatabaseDescriptor ; import org . apache . cassandra . config . Schema ; import org . apache . cassandra . db . Mutation ; import org . apache . cassandra . db . partitions . PartitionUpdate ; import org . apache . cassandra . io . FSWriteError ; import org . apache . cassandra . io . util . FileUtils ; import org . apache . cassandra . utils . CLibrary ; import org . apache . cassandra . utils . concurrent . OpOrder ; import org . apache . cassandra . utils . concurrent . WaitQueue ; import static org . apache . cassandra . utils . FBUtilities . updateChecksumInt ; public abstract class CommitLogSegment { private static final Logger logger = LoggerFactory . getLogger ( CommitLogSegment . class ) ; private final static long idBase ; private final static AtomicInteger nextId = new AtomicInteger ( <int> ) ; static { long maxId = Long . MIN_VALUE ; for ( File file : new File ( DatabaseDescriptor . getCommitLogLocation ( ) ) . listFiles ( ) ) { if ( CommitLogDescriptor . isValid ( file . getName ( ) ) ) maxId = Math . max ( CommitLogDescriptor . fromFileName ( file . getName ( ) ) . id , maxId ) ; } idBase = Math . max ( System . currentTimeMillis ( ) , maxId + <int> ) ; } public static final int ENTRY_OVERHEAD_SIZE = <int> + <int> + <int> ; static final int SYNC_MARKER_SIZE = <int> + <int> ; private final OpOrder appendOrder = new OpOrder ( ) ; private final AtomicInteger allocatePosition = new AtomicInteger ( ) ; private volatile int lastSyncedOffset ; private int endOfBuffer ; private final WaitQueue syncComplete = new WaitQueue ( ) ; private final NonBlockingHashMap < UUID , AtomicInteger > cfDirty = new NonBlockingHashMap < > ( <int> ) ; private final ConcurrentHashMap < UUID , AtomicInteger > cfClean = new ConcurrentHashMap < > ( ) ; public final long id ; final File logFile ; final FileChannel channel ; final int fd ; ByteBuffer buffer ; final CommitLog commitLog ; public final CommitLogDescriptor descriptor ; static CommitLogSegment createSegment ( CommitLog commitLog ) { return commitLog . compressor ! = null ? new CompressedSegment ( commitLog ) : new MemoryMappedSegment ( commitLog ) ; } static long getNextId ( ) { return idBase + nextId . getAndIncrement ( ) ; } CommitLogSegment ( CommitLog commitLog ) { this . commitLog = commitLog ; id = getNextId ( ) ; descriptor = new CommitLogDescriptor ( id , commitLog . compressorClass ) ; logFile = new File ( commitLog . location , descriptor . fileName ( ) ) ; try { channel = FileChannel . open ( logFile . toPath ( ) , StandardOpenOption . WRITE , StandardOpenOption . READ , StandardOpenOption . CREATE ) ; fd = CLibrary . getfd ( channel ) ; } catch ( IOException e ) { throw new FSWriteError ( e , logFile ) ; } buffer = createBuffer ( commitLog ) ; CommitLogDescriptor . writeHeader ( buffer , descriptor ) ; endOfBuffer = buffer . capacity ( ) ; lastSyncedOffset = buffer . position ( ) ; allocatePosition . set ( lastSyncedOffset + SYNC_MARKER_SIZE ) ; } abstract ByteBuffer createBuffer ( CommitLog commitLog ) ; @SuppressWarnings ( <str> ) Allocation allocate ( Mutation mutation , int size ) { final OpOrder . Group opGroup = appendOrder . start ( ) ; try { int position = allocate ( size ) ; if ( position < <int> ) { opGroup . close ( ) ; return null ; } markDirty ( mutation , position ) ; return new Allocation ( this , opGroup , position , ( ByteBuffer ) buffer . duplicate ( ) . position ( position ) . limit ( position + size ) ) ; } catch ( Throwable t ) { opGroup . close ( ) ; throw t ; } } private int allocate ( int size ) { while ( true ) { int prev = allocatePosition . get ( ) ; int next = prev + size ; if ( next > = endOfBuffer ) return - <int> ; if ( allocatePosition . compareAndSet ( prev , next ) ) { assert buffer ! = null ; return prev ; } } } void discardUnusedTail ( ) { try ( OpOrder . Group group = appendOrder . start ( ) ) { while ( true ) { int prev = allocatePosition . get ( ) ; int next = endOfBuffer + <int> ; if ( prev > = next ) { assert buffer = = null | | prev = = buffer . capacity ( ) + <int> ; return ; } if ( allocatePosition . compareAndSet ( prev , next ) ) { endOfBuffer = prev ; assert buffer ! = null & & next = = buffer . capacity ( ) + <int> ; return ; } } } } void waitForModifications ( ) { appendOrder . awaitNewBarrier ( ) ; } synchronized void sync ( ) { boolean close = false ; if ( allocatePosition . get ( ) < = lastSyncedOffset + SYNC_MARKER_SIZE ) return ; assert buffer ! = null ; int startMarker = lastSyncedOffset ; int nextMarker = allocate ( SYNC_MARKER_SIZE ) ; if ( nextMarker < <int> ) { discardUnusedTail ( ) ; close = true ; nextMarker = buffer . capacity ( ) ; } waitForModifications ( ) ; int sectionEnd = close ? endOfBuffer : nextMarker ; write ( startMarker , sectionEnd ) ; lastSyncedOffset = nextMarker ; if ( close ) internalClose ( ) ; syncComplete . signalAll ( ) ; } protected void writeSyncMarker ( ByteBuffer buffer , int offset , int filePos , int nextMarker ) { CRC32 crc = new CRC32 ( ) ; updateChecksumInt ( crc , ( int ) ( id & <hex> ) ) ; updateChecksumInt ( crc , ( int ) ( id > > > <int> ) ) ; updateChecksumInt ( crc , filePos ) ; buffer . putInt ( offset , nextMarker ) ; buffer . putInt ( offset + <int> , ( int ) crc . getValue ( ) ) ; } abstract void write ( int lastSyncedOffset , int nextMarker ) ; public boolean isStillAllocating ( ) { return allocatePosition . get ( ) < endOfBuffer ; } void discard ( boolean deleteFile ) { close ( ) ; if ( deleteFile ) FileUtils . deleteWithConfirm ( logFile ) ; commitLog . allocator . addSize ( - onDiskSize ( ) ) ; } public ReplayPosition getContext ( ) { return new ReplayPosition ( id , allocatePosition . get ( ) ) ; } public String getPath ( ) { return logFile . getPath ( ) ; } public String getName ( ) { return logFile . getName ( ) ; } void waitForFinalSync ( ) { while ( true ) { WaitQueue . Signal signal = syncComplete . register ( ) ; if ( lastSyncedOffset < endOfBuffer ) { signal . awaitUninterruptibly ( ) ; } else { signal . cancel ( ) ; break ; } } } void waitForSync ( int position , Timer waitingOnCommit ) { while ( lastSyncedOffset < position ) { WaitQueue . Signal signal = waitingOnCommit ! = null ? syncComplete . register ( waitingOnCommit . time ( ) ) : syncComplete . register ( ) ; if ( lastSyncedOffset < position ) signal . awaitUninterruptibly ( ) ; else signal . cancel ( ) ; } } synchronized void close ( ) { discardUnusedTail ( ) ; sync ( ) ; assert buffer = = null ; } protected void internalClose ( ) { try { channel . close ( ) ; buffer = null ; } catch ( IOException e ) { throw new FSWriteError ( e , getPath ( ) ) ; } } void markDirty ( Mutation mutation , int allocatedPosition ) { for ( PartitionUpdate update : mutation . getPartitionUpdates ( ) ) ensureAtleast ( cfDirty , update . metadata ( ) . cfId , allocatedPosition ) ; } public synchronized void markClean ( UUID cfId , ReplayPosition context ) { if ( ! cfDirty . containsKey ( cfId ) ) return ; if ( context . segment = = id ) markClean ( cfId , context . position ) ; else if ( context . segment > id ) markClean ( cfId , Integer . MAX_VALUE ) ; } private void markClean ( UUID cfId , int position ) { ensureAtleast ( cfClean , cfId , position ) ; removeCleanFromDirty ( ) ; } private static void ensureAtleast ( ConcurrentMap < UUID , AtomicInteger > map , UUID cfId , int value ) { AtomicInteger i = map . get ( cfId ) ; if ( i = = null ) { AtomicInteger i2 = map . putIfAbsent ( cfId , i = new AtomicInteger ( ) ) ; if ( i2 ! = null ) i = i2 ; } while ( true ) { int cur = i . get ( ) ; if ( cur > value ) break ; if ( i . compareAndSet ( cur , value ) ) break ; } } private void removeCleanFromDirty ( ) { if ( isStillAllocating ( ) ) return ; Iterator < Map . Entry < UUID , AtomicInteger > > iter = cfClean . entrySet ( ) . iterator ( ) ; while ( iter . hasNext ( ) ) { Map . Entry < UUID , AtomicInteger > clean = iter . next ( ) ; UUID cfId = clean . getKey ( ) ; AtomicInteger cleanPos = clean . getValue ( ) ; AtomicInteger dirtyPos = cfDirty . get ( cfId ) ; if ( dirtyPos ! = null & & dirtyPos . intValue ( ) < = cleanPos . intValue ( ) ) { cfDirty . remove ( cfId ) ; iter . remove ( ) ; } } } public synchronized Collection < UUID > getDirtyCFIDs ( ) { if ( cfClean . isEmpty ( ) | | cfDirty . isEmpty ( ) ) return cfDirty . keySet ( ) ; List < UUID > r = new ArrayList < > ( cfDirty . size ( ) ) ; for ( Map . Entry < UUID , AtomicInteger > dirty : cfDirty . entrySet ( ) ) { UUID cfId = dirty . getKey ( ) ; AtomicInteger dirtyPos = dirty . getValue ( ) ; AtomicInteger cleanPos = cfClean . get ( cfId ) ; if ( cleanPos = = null | | cleanPos . intValue ( ) < dirtyPos . intValue ( ) ) r . add ( dirty . getKey ( ) ) ; } return r ; } public synchronized boolean isUnused ( ) { if ( isStillAllocating ( ) ) return false ; removeCleanFromDirty ( ) ; return cfDirty . isEmpty ( ) ; } public boolean contains ( ReplayPosition context ) { return context . segment = = id ; } public String dirtyString ( ) { StringBuilder sb = new StringBuilder ( ) ; for ( UUID cfId : getDirtyCFIDs ( ) ) { CFMetaData m = Schema . instance . getCFMetaData ( cfId ) ; sb . append ( m = = null ? <str> : m . cfName ) . append ( <str> ) . append ( cfId ) . append ( <str> ) ; } return sb . toString ( ) ; } abstract public long onDiskSize ( ) ; public long contentSize ( ) { return lastSyncedOffset ; } @Override public String toString ( ) { return <str> + getPath ( ) + <str> ; } public static class CommitLogSegmentFileComparator implements Comparator < File > { public int compare ( File f , File f2 ) { CommitLogDescriptor desc = CommitLogDescriptor . fromFileName ( f . getName ( ) ) ; CommitLogDescriptor desc2 = CommitLogDescriptor . fromFileName ( f2 . getName ( ) ) ; return Long . compare ( desc . id , desc2 . id ) ; } } static class Allocation { private final CommitLogSegment segment ; private final OpOrder . Group appendOp ; private final int position ; private final ByteBuffer buffer ; Allocation ( CommitLogSegment segment , OpOrder . Group appendOp , int position , ByteBuffer buffer ) { this . segment = segment ; this . appendOp = appendOp ; this . position = position ; this . buffer = buffer ; } CommitLogSegment getSegment ( ) { return segment ; } ByteBuffer getBuffer ( ) { return buffer ; } void markWritten ( ) { appendOp . close ( ) ; } void awaitDiskSync ( Timer waitingOnCommit ) { segment . waitForSync ( position , waitingOnCommit ) ; } public ReplayPosition getReplayPosition ( ) { return new ReplayPosition ( segment . id , buffer . limit ( ) ) ; } } } 
