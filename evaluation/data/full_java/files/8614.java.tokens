package org . elasticsearch . messy . tests ; import com . carrotsearch . hppc . IntHashSet ; import org . elasticsearch . action . index . IndexRequestBuilder ; import org . elasticsearch . action . search . SearchRequestBuilder ; import org . elasticsearch . action . search . SearchResponse ; import org . elasticsearch . action . support . IndicesOptions ; import org . elasticsearch . common . xcontent . XContentBuilder ; import org . elasticsearch . index . query . QueryBuilders ; import org . elasticsearch . index . query . RangeQueryBuilder ; import org . elasticsearch . plugins . Plugin ; import org . elasticsearch . script . Script ; import org . elasticsearch . script . ScriptService . ScriptType ; import org . elasticsearch . script . groovy . GroovyPlugin ; import org . elasticsearch . search . aggregations . Aggregator . SubAggCollectionMode ; import org . elasticsearch . search . aggregations . bucket . filter . Filter ; import org . elasticsearch . search . aggregations . bucket . histogram . Histogram ; import org . elasticsearch . search . aggregations . bucket . range . Range ; import org . elasticsearch . search . aggregations . bucket . range . Range . Bucket ; import org . elasticsearch . search . aggregations . bucket . range . RangeBuilder ; import org . elasticsearch . search . aggregations . bucket . terms . Terms ; import org . elasticsearch . search . aggregations . bucket . terms . TermsAggregatorFactory ; import org . elasticsearch . search . aggregations . metrics . sum . Sum ; import org . elasticsearch . test . ESIntegTestCase ; import java . util . ArrayList ; import java . util . Collection ; import java . util . Collections ; import java . util . HashMap ; import java . util . Iterator ; import java . util . List ; import java . util . Map ; import static org . elasticsearch . common . xcontent . XContentFactory . jsonBuilder ; import static org . elasticsearch . search . aggregations . AggregationBuilders . extendedStats ; import static org . elasticsearch . search . aggregations . AggregationBuilders . filter ; import static org . elasticsearch . search . aggregations . AggregationBuilders . histogram ; import static org . elasticsearch . search . aggregations . AggregationBuilders . max ; import static org . elasticsearch . search . aggregations . AggregationBuilders . min ; import static org . elasticsearch . search . aggregations . AggregationBuilders . percentiles ; import static org . elasticsearch . search . aggregations . AggregationBuilders . range ; import static org . elasticsearch . search . aggregations . AggregationBuilders . stats ; import static org . elasticsearch . search . aggregations . AggregationBuilders . sum ; import static org . elasticsearch . search . aggregations . AggregationBuilders . terms ; import static org . elasticsearch . test . hamcrest . ElasticsearchAssertions . assertAllSuccessful ; import static org . elasticsearch . test . hamcrest . ElasticsearchAssertions . assertNoFailures ; import static org . elasticsearch . test . hamcrest . ElasticsearchAssertions . assertSearchResponse ; import static org . hamcrest . Matchers . equalTo ; import static org . hamcrest . core . IsNull . notNullValue ; public class EquivalenceTests extends ESIntegTestCase { @Override protected Collection < Class < ? extends Plugin > > nodePlugins ( ) { return Collections . singleton ( GroovyPlugin . class ) ; } public void testRandomRanges ( ) throws Exception { final int numDocs = scaledRandomIntBetween ( <int> , <int> ) ; final double [ ] [ ] docs = new double [ numDocs ] [ ] ; for ( int i = <int> ; i < numDocs ; + + i ) { final int numValues = randomInt ( <int> ) ; docs [ i ] = new double [ numValues ] ; for ( int j = <int> ; j < numValues ; + + j ) { docs [ i ] [ j ] = randomDouble ( ) * <int> ; } } createIndex ( <str> ) ; for ( int i = <int> ; i < docs . length ; + + i ) { XContentBuilder source = jsonBuilder ( ) . startObject ( ) . startArray ( <str> ) ; for ( int j = <int> ; j < docs [ i ] . length ; + + j ) { source = source . value ( docs [ i ] [ j ] ) ; } source = source . endArray ( ) . endObject ( ) ; client ( ) . prepareIndex ( <str> , <str> ) . setSource ( source ) . execute ( ) . actionGet ( ) ; } assertNoFailures ( client ( ) . admin ( ) . indices ( ) . prepareRefresh ( <str> ) . setIndicesOptions ( IndicesOptions . lenientExpandOpen ( ) ) . execute ( ) . get ( ) ) ; final int numRanges = randomIntBetween ( <int> , <int> ) ; final double [ ] [ ] ranges = new double [ numRanges ] [ ] ; for ( int i = <int> ; i < ranges . length ; + + i ) { switch ( randomInt ( <int> ) ) { case <int> : ranges [ i ] = new double [ ] { Double . NEGATIVE_INFINITY , randomInt ( <int> ) } ; break ; case <int> : ranges [ i ] = new double [ ] { randomInt ( <int> ) , Double . POSITIVE_INFINITY } ; break ; case <int> : ranges [ i ] = new double [ ] { randomInt ( <int> ) , randomInt ( <int> ) } ; break ; default : throw new AssertionError ( ) ; } } RangeBuilder query = range ( <str> ) . field ( <str> ) ; for ( int i = <int> ; i < ranges . length ; + + i ) { String key = Integer . toString ( i ) ; if ( ranges [ i ] [ <int> ] = = Double . NEGATIVE_INFINITY ) { query . addUnboundedTo ( key , ranges [ i ] [ <int> ] ) ; } else if ( ranges [ i ] [ <int> ] = = Double . POSITIVE_INFINITY ) { query . addUnboundedFrom ( key , ranges [ i ] [ <int> ] ) ; } else { query . addRange ( key , ranges [ i ] [ <int> ] , ranges [ i ] [ <int> ] ) ; } } SearchRequestBuilder reqBuilder = client ( ) . prepareSearch ( <str> ) . addAggregation ( query ) ; for ( int i = <int> ; i < ranges . length ; + + i ) { RangeQueryBuilder filter = QueryBuilders . rangeQuery ( <str> ) ; if ( ranges [ i ] [ <int> ] ! = Double . NEGATIVE_INFINITY ) { filter = filter . from ( ranges [ i ] [ <int> ] ) ; } if ( ranges [ i ] [ <int> ] ! = Double . POSITIVE_INFINITY ) { filter = filter . to ( ranges [ i ] [ <int> ] ) ; } reqBuilder = reqBuilder . addAggregation ( filter ( <str> + i ) . filter ( filter ) ) ; } SearchResponse resp = reqBuilder . execute ( ) . actionGet ( ) ; Range range = resp . getAggregations ( ) . get ( <str> ) ; List < ? extends Bucket > buckets = range . getBuckets ( ) ; HashMap < String , Bucket > bucketMap = new HashMap < > ( buckets . size ( ) ) ; for ( Bucket bucket : buckets ) { bucketMap . put ( bucket . getKeyAsString ( ) , bucket ) ; } for ( int i = <int> ; i < ranges . length ; + + i ) { long count = <int> ; for ( double [ ] values : docs ) { for ( double value : values ) { if ( value > = ranges [ i ] [ <int> ] & & value < ranges [ i ] [ <int> ] ) { + + count ; break ; } } } final Range . Bucket bucket = bucketMap . get ( Integer . toString ( i ) ) ; assertEquals ( bucket . getKeyAsString ( ) , Integer . toString ( i ) , bucket . getKeyAsString ( ) ) ; assertEquals ( bucket . getKeyAsString ( ) , count , bucket . getDocCount ( ) ) ; final Filter filter = resp . getAggregations ( ) . get ( <str> + i ) ; assertThat ( filter . getDocCount ( ) , equalTo ( count ) ) ; } } public void testDuelTerms ( ) throws Exception { final int numDocs = scaledRandomIntBetween ( <int> , <int> ) ; final int maxNumTerms = randomIntBetween ( <int> , <int> ) ; final IntHashSet valuesSet = new IntHashSet ( ) ; cluster ( ) . wipeIndices ( <str> ) ; prepareCreate ( <str> ) . addMapping ( <str> , jsonBuilder ( ) . startObject ( ) . startObject ( <str> ) . startObject ( <str> ) . startObject ( <str> ) . field ( <str> , <str> ) . field ( <str> , <str> ) . startObject ( <str> ) . startObject ( <str> ) . field ( <str> , <str> ) . field ( <str> , <str> ) . startObject ( <str> ) . field ( <str> , <str> ) . endObject ( ) . endObject ( ) . endObject ( ) . endObject ( ) . startObject ( <str> ) . field ( <str> , <str> ) . endObject ( ) . startObject ( <str> ) . field ( <str> , <str> ) . endObject ( ) . endObject ( ) . endObject ( ) ) . execute ( ) . actionGet ( ) ; List < IndexRequestBuilder > indexingRequests = new ArrayList < > ( ) ; for ( int i = <int> ; i < numDocs ; + + i ) { final int [ ] values = new int [ randomInt ( <int> ) ] ; for ( int j = <int> ; j < values . length ; + + j ) { values [ j ] = randomInt ( maxNumTerms - <int> ) - <int> ; valuesSet . add ( values [ j ] ) ; } XContentBuilder source = jsonBuilder ( ) . startObject ( ) . field ( <str> , randomDouble ( ) ) . startArray ( <str> ) ; for ( int j = <int> ; j < values . length ; + + j ) { source = source . value ( values [ j ] ) ; } source = source . endArray ( ) . startArray ( <str> ) ; for ( int j = <int> ; j < values . length ; + + j ) { source = source . value ( ( double ) values [ j ] ) ; } source = source . endArray ( ) . startArray ( <str> ) ; for ( int j = <int> ; j < values . length ; + + j ) { source = source . value ( Integer . toString ( values [ j ] ) ) ; } source = source . endArray ( ) . endObject ( ) ; indexingRequests . add ( client ( ) . prepareIndex ( <str> , <str> ) . setSource ( source ) ) ; } indexRandom ( true , indexingRequests ) ; assertNoFailures ( client ( ) . admin ( ) . indices ( ) . prepareRefresh ( <str> ) . setIndicesOptions ( IndicesOptions . lenientExpandOpen ( ) ) . execute ( ) . get ( ) ) ; TermsAggregatorFactory . ExecutionMode [ ] globalOrdinalModes = new TermsAggregatorFactory . ExecutionMode [ ] { TermsAggregatorFactory . ExecutionMode . GLOBAL_ORDINALS_HASH , TermsAggregatorFactory . ExecutionMode . GLOBAL_ORDINALS } ; SearchResponse resp = client ( ) . prepareSearch ( <str> ) . addAggregation ( terms ( <str> ) . field ( <str> ) . size ( maxNumTerms ) . collectMode ( randomFrom ( SubAggCollectionMode . values ( ) ) ) . subAggregation ( min ( <str> ) . field ( <str> ) ) ) . addAggregation ( terms ( <str> ) . field ( <str> ) . size ( maxNumTerms ) . collectMode ( randomFrom ( SubAggCollectionMode . values ( ) ) ) . subAggregation ( max ( <str> ) . field ( <str> ) ) ) . addAggregation ( terms ( <str> ) . field ( <str> ) . collectMode ( randomFrom ( SubAggCollectionMode . values ( ) ) ) . executionHint ( TermsAggregatorFactory . ExecutionMode . MAP . toString ( ) ) . size ( maxNumTerms ) . subAggregation ( stats ( <str> ) . field ( <str> ) ) ) . addAggregation ( terms ( <str> ) . field ( <str> ) . collectMode ( randomFrom ( SubAggCollectionMode . values ( ) ) ) . executionHint ( globalOrdinalModes [ randomInt ( globalOrdinalModes . length - <int> ) ] . toString ( ) ) . size ( maxNumTerms ) . subAggregation ( extendedStats ( <str> ) . field ( <str> ) ) ) . addAggregation ( terms ( <str> ) . field ( <str> ) . collectMode ( randomFrom ( SubAggCollectionMode . values ( ) ) ) . executionHint ( globalOrdinalModes [ randomInt ( globalOrdinalModes . length - <int> ) ] . toString ( ) ) . size ( maxNumTerms ) . subAggregation ( extendedStats ( <str> ) . field ( <str> ) ) ) . execute ( ) . actionGet ( ) ; assertAllSuccessful ( resp ) ; assertEquals ( numDocs , resp . getHits ( ) . getTotalHits ( ) ) ; final Terms longTerms = resp . getAggregations ( ) . get ( <str> ) ; final Terms doubleTerms = resp . getAggregations ( ) . get ( <str> ) ; final Terms stringMapTerms = resp . getAggregations ( ) . get ( <str> ) ; final Terms stringGlobalOrdinalsTerms = resp . getAggregations ( ) . get ( <str> ) ; final Terms stringGlobalOrdinalsDVTerms = resp . getAggregations ( ) . get ( <str> ) ; assertEquals ( valuesSet . size ( ) , longTerms . getBuckets ( ) . size ( ) ) ; assertEquals ( valuesSet . size ( ) , doubleTerms . getBuckets ( ) . size ( ) ) ; assertEquals ( valuesSet . size ( ) , stringMapTerms . getBuckets ( ) . size ( ) ) ; assertEquals ( valuesSet . size ( ) , stringGlobalOrdinalsTerms . getBuckets ( ) . size ( ) ) ; assertEquals ( valuesSet . size ( ) , stringGlobalOrdinalsDVTerms . getBuckets ( ) . size ( ) ) ; for ( Terms . Bucket bucket : longTerms . getBuckets ( ) ) { final Terms . Bucket doubleBucket = doubleTerms . getBucketByKey ( Double . toString ( Long . parseLong ( bucket . getKeyAsString ( ) ) ) ) ; final Terms . Bucket stringMapBucket = stringMapTerms . getBucketByKey ( bucket . getKeyAsString ( ) ) ; final Terms . Bucket stringGlobalOrdinalsBucket = stringGlobalOrdinalsTerms . getBucketByKey ( bucket . getKeyAsString ( ) ) ; final Terms . Bucket stringGlobalOrdinalsDVBucket = stringGlobalOrdinalsDVTerms . getBucketByKey ( bucket . getKeyAsString ( ) ) ; assertNotNull ( doubleBucket ) ; assertNotNull ( stringMapBucket ) ; assertNotNull ( stringGlobalOrdinalsBucket ) ; assertNotNull ( stringGlobalOrdinalsDVBucket ) ; assertEquals ( bucket . getDocCount ( ) , doubleBucket . getDocCount ( ) ) ; assertEquals ( bucket . getDocCount ( ) , stringMapBucket . getDocCount ( ) ) ; assertEquals ( bucket . getDocCount ( ) , stringGlobalOrdinalsBucket . getDocCount ( ) ) ; assertEquals ( bucket . getDocCount ( ) , stringGlobalOrdinalsDVBucket . getDocCount ( ) ) ; } } public void testDuelTermsHistogram ( ) throws Exception { createIndex ( <str> ) ; final int numDocs = scaledRandomIntBetween ( <int> , <int> ) ; final int maxNumTerms = randomIntBetween ( <int> , <int> ) ; final int interval = randomIntBetween ( <int> , <int> ) ; final Integer [ ] values = new Integer [ maxNumTerms ] ; for ( int i = <int> ; i < values . length ; + + i ) { values [ i ] = randomInt ( maxNumTerms * <int> ) - maxNumTerms ; } for ( int i = <int> ; i < numDocs ; + + i ) { XContentBuilder source = jsonBuilder ( ) . startObject ( ) . field ( <str> , randomDouble ( ) ) . startArray ( <str> ) ; final int numValues = randomInt ( <int> ) ; for ( int j = <int> ; j < numValues ; + + j ) { source = source . value ( randomFrom ( values ) ) ; } source = source . endArray ( ) . endObject ( ) ; client ( ) . prepareIndex ( <str> , <str> ) . setSource ( source ) . execute ( ) . actionGet ( ) ; } assertNoFailures ( client ( ) . admin ( ) . indices ( ) . prepareRefresh ( <str> ) . setIndicesOptions ( IndicesOptions . lenientExpandOpen ( ) ) . execute ( ) . get ( ) ) ; Map < String , Object > params = new HashMap < > ( ) ; params . put ( <str> , interval ) ; SearchResponse resp = client ( ) . prepareSearch ( <str> ) . addAggregation ( terms ( <str> ) . field ( <str> ) . collectMode ( randomFrom ( SubAggCollectionMode . values ( ) ) ) . script ( new Script ( <str> , ScriptType . INLINE , null , params ) ) . size ( maxNumTerms ) ) . addAggregation ( histogram ( <str> ) . field ( <str> ) . interval ( interval ) . minDocCount ( <int> ) ) . execute ( ) . actionGet ( ) ; assertSearchResponse ( resp ) ; Terms terms = resp . getAggregations ( ) . get ( <str> ) ; assertThat ( terms , notNullValue ( ) ) ; Histogram histo = resp . getAggregations ( ) . get ( <str> ) ; assertThat ( histo , notNullValue ( ) ) ; assertThat ( terms . getBuckets ( ) . size ( ) , equalTo ( histo . getBuckets ( ) . size ( ) ) ) ; for ( Histogram . Bucket bucket : histo . getBuckets ( ) ) { final double key = ( ( Number ) bucket . getKey ( ) ) . doubleValue ( ) / interval ; final Terms . Bucket termsBucket = terms . getBucketByKey ( String . valueOf ( key ) ) ; assertEquals ( bucket . getDocCount ( ) , termsBucket . getDocCount ( ) ) ; } } public void testLargeNumbersOfPercentileBuckets ( ) throws Exception { createIndex ( <str> ) ; final int numDocs = scaledRandomIntBetween ( <int> , <int> ) ; logger . info ( <str> + numDocs + <str> ) ; List < IndexRequestBuilder > indexingRequests = new ArrayList < > ( ) ; for ( int i = <int> ; i < numDocs ; + + i ) { indexingRequests . add ( client ( ) . prepareIndex ( <str> , <str> , Integer . toString ( i ) ) . setSource ( <str> , randomDouble ( ) ) ) ; } indexRandom ( true , indexingRequests ) ; SearchResponse response = client ( ) . prepareSearch ( <str> ) . addAggregation ( terms ( <str> ) . field ( <str> ) . collectMode ( randomFrom ( SubAggCollectionMode . values ( ) ) ) . subAggregation ( percentiles ( <str> ) . field ( <str> ) ) ) . execute ( ) . actionGet ( ) ; assertAllSuccessful ( response ) ; assertEquals ( numDocs , response . getHits ( ) . getTotalHits ( ) ) ; } public void testReduce ( ) throws Exception { createIndex ( <str> ) ; final int value = randomIntBetween ( <int> , <int> ) ; indexRandom ( true , client ( ) . prepareIndex ( <str> , <str> ) . setSource ( <str> , value ) ) ; ensureYellow ( <str> ) ; SearchResponse response = client ( ) . prepareSearch ( <str> ) . addAggregation ( filter ( <str> ) . filter ( QueryBuilders . matchAllQuery ( ) ) . subAggregation ( range ( <str> ) . field ( <str> ) . addUnboundedTo ( <int> ) . addUnboundedFrom ( <int> ) . subAggregation ( sum ( <str> ) . field ( <str> ) ) ) ) . execute ( ) . actionGet ( ) ; assertSearchResponse ( response ) ; Filter filter = response . getAggregations ( ) . get ( <str> ) ; assertNotNull ( filter ) ; assertEquals ( <int> , filter . getDocCount ( ) ) ; Range range = filter . getAggregations ( ) . get ( <str> ) ; assertThat ( range , notNullValue ( ) ) ; assertThat ( range . getName ( ) , equalTo ( <str> ) ) ; List < ? extends Bucket > buckets = range . getBuckets ( ) ; assertThat ( buckets . size ( ) , equalTo ( <int> ) ) ; Range . Bucket bucket = buckets . get ( <int> ) ; assertThat ( bucket , notNullValue ( ) ) ; assertThat ( ( String ) bucket . getKey ( ) , equalTo ( <str> ) ) ; assertThat ( ( ( Number ) bucket . getFrom ( ) ) . doubleValue ( ) , equalTo ( Double . NEGATIVE_INFINITY ) ) ; assertThat ( ( ( Number ) bucket . getTo ( ) ) . doubleValue ( ) , equalTo ( <float> ) ) ; assertThat ( bucket . getDocCount ( ) , equalTo ( value < <int> ? <int> : <int> L ) ) ; Sum sum = bucket . getAggregations ( ) . get ( <str> ) ; assertEquals ( value < <int> ? value : <int> , sum . getValue ( ) , <float> ) ; bucket = buckets . get ( <int> ) ; assertThat ( bucket , notNullValue ( ) ) ; assertThat ( ( String ) bucket . getKey ( ) , equalTo ( <str> ) ) ; assertThat ( ( ( Number ) bucket . getFrom ( ) ) . doubleValue ( ) , equalTo ( <float> ) ) ; assertThat ( ( ( Number ) bucket . getTo ( ) ) . doubleValue ( ) , equalTo ( Double . POSITIVE_INFINITY ) ) ; assertThat ( bucket . getDocCount ( ) , equalTo ( value > = <int> ? <int> : <int> L ) ) ; sum = bucket . getAggregations ( ) . get ( <str> ) ; assertEquals ( value > = <int> ? value : <int> , sum . getValue ( ) , <float> ) ; } private void assertEquals ( Terms t1 , Terms t2 ) { List < Terms . Bucket > t1Buckets = t1 . getBuckets ( ) ; List < Terms . Bucket > t2Buckets = t1 . getBuckets ( ) ; assertEquals ( t1Buckets . size ( ) , t2Buckets . size ( ) ) ; for ( Iterator < Terms . Bucket > it1 = t1Buckets . iterator ( ) , it2 = t2Buckets . iterator ( ) ; it1 . hasNext ( ) ; ) { final Terms . Bucket b1 = it1 . next ( ) ; final Terms . Bucket b2 = it2 . next ( ) ; assertEquals ( b1 . getDocCount ( ) , b2 . getDocCount ( ) ) ; assertEquals ( b1 . getKey ( ) , b2 . getKey ( ) ) ; } } public void testDuelDepthBreadthFirst ( ) throws Exception { createIndex ( <str> ) ; final int numDocs = randomIntBetween ( <int> , <int> ) ; List < IndexRequestBuilder > reqs = new ArrayList < > ( ) ; for ( int i = <int> ; i < numDocs ; + + i ) { final int v1 = randomInt ( <int> < < randomInt ( <int> ) ) ; final int v2 = randomInt ( <int> < < randomInt ( <int> ) ) ; final int v3 = randomInt ( <int> < < randomInt ( <int> ) ) ; reqs . add ( client ( ) . prepareIndex ( <str> , <str> ) . setSource ( <str> , v1 , <str> , v2 , <str> , v3 ) ) ; } indexRandom ( true , reqs ) ; final SearchResponse r1 = client ( ) . prepareSearch ( <str> ) . addAggregation ( terms ( <str> ) . field ( <str> ) . collectMode ( SubAggCollectionMode . DEPTH_FIRST ) . subAggregation ( terms ( <str> ) . field ( <str> ) . collectMode ( SubAggCollectionMode . DEPTH_FIRST ) . subAggregation ( terms ( <str> ) . field ( <str> ) . collectMode ( SubAggCollectionMode . DEPTH_FIRST ) ) ) ) . get ( ) ; assertSearchResponse ( r1 ) ; final SearchResponse r2 = client ( ) . prepareSearch ( <str> ) . addAggregation ( terms ( <str> ) . field ( <str> ) . collectMode ( SubAggCollectionMode . BREADTH_FIRST ) . subAggregation ( terms ( <str> ) . field ( <str> ) . collectMode ( SubAggCollectionMode . BREADTH_FIRST ) . subAggregation ( terms ( <str> ) . field ( <str> ) . collectMode ( SubAggCollectionMode . BREADTH_FIRST ) ) ) ) . get ( ) ; assertSearchResponse ( r2 ) ; final Terms t1 = r1 . getAggregations ( ) . get ( <str> ) ; final Terms t2 = r2 . getAggregations ( ) . get ( <str> ) ; assertEquals ( t1 , t2 ) ; for ( Terms . Bucket b1 : t1 . getBuckets ( ) ) { final Terms . Bucket b2 = t2 . getBucketByKey ( b1 . getKeyAsString ( ) ) ; final Terms sub1 = b1 . getAggregations ( ) . get ( <str> ) ; final Terms sub2 = b2 . getAggregations ( ) . get ( <str> ) ; assertEquals ( sub1 , sub2 ) ; for ( Terms . Bucket subB1 : sub1 . getBuckets ( ) ) { final Terms . Bucket subB2 = sub2 . getBucketByKey ( subB1 . getKeyAsString ( ) ) ; final Terms subSub1 = subB1 . getAggregations ( ) . get ( <str> ) ; final Terms subSub2 = subB2 . getAggregations ( ) . get ( <str> ) ; assertEquals ( subSub1 , subSub2 ) ; } } } } 
