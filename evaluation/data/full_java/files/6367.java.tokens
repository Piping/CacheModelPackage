package org . elasticsearch . index . analysis ; import org . apache . lucene . analysis . Tokenizer ; import org . apache . lucene . analysis . TokenStream ; import org . apache . lucene . analysis . core . LowerCaseFilter ; import org . apache . lucene . analysis . core . StopAnalyzer ; import org . apache . lucene . analysis . core . StopFilter ; import org . apache . lucene . analysis . standard . StandardFilter ; import org . apache . lucene . analysis . standard . StandardTokenizer ; import org . apache . lucene . analysis . standard . std40 . StandardTokenizer40 ; import org . apache . lucene . analysis . util . CharArraySet ; import org . apache . lucene . analysis . util . StopwordAnalyzerBase ; import org . apache . lucene . util . Version ; public class StandardHtmlStripAnalyzer extends StopwordAnalyzerBase { @Deprecated public StandardHtmlStripAnalyzer ( ) { super ( StopAnalyzer . ENGLISH_STOP_WORDS_SET ) ; } public StandardHtmlStripAnalyzer ( CharArraySet stopwords ) { super ( stopwords ) ; } @Override protected TokenStreamComponents createComponents ( final String fieldName ) { final Tokenizer src ; if ( getVersion ( ) . onOrAfter ( Version . LUCENE_4_7_0 ) ) { src = new StandardTokenizer ( ) ; } else { src = new StandardTokenizer40 ( ) ; } TokenStream tok = new StandardFilter ( src ) ; tok = new LowerCaseFilter ( tok ) ; if ( ! stopwords . isEmpty ( ) ) { tok = new StopFilter ( tok , stopwords ) ; } return new TokenStreamComponents ( src , tok ) ; } } 
