package org . apache . cassandra . schema ; import java . nio . ByteBuffer ; import java . util . * ; import java . util . stream . Collectors ; import com . google . common . collect . HashMultimap ; import com . google . common . collect . ImmutableList ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; import org . apache . cassandra . config . * ; import org . apache . cassandra . cql3 . ColumnIdentifier ; import org . apache . cassandra . cql3 . QueryProcessor ; import org . apache . cassandra . cql3 . UntypedResultSet ; import org . apache . cassandra . cql3 . functions . FunctionName ; import org . apache . cassandra . cql3 . functions . UDAggregate ; import org . apache . cassandra . cql3 . functions . UDFunction ; import org . apache . cassandra . db . * ; import org . apache . cassandra . db . compaction . AbstractCompactionStrategy ; import org . apache . cassandra . db . marshal . * ; import org . apache . cassandra . db . rows . RowIterator ; import org . apache . cassandra . db . rows . UnfilteredRowIterators ; import org . apache . cassandra . exceptions . InvalidRequestException ; import org . apache . cassandra . utils . ByteBufferUtil ; import org . apache . cassandra . utils . FBUtilities ; import org . apache . cassandra . utils . concurrent . OpOrder ; import static java . lang . String . format ; import static org . apache . cassandra . utils . ByteBufferUtil . bytes ; import static org . apache . cassandra . utils . FBUtilities . fromJsonMap ; @SuppressWarnings ( <str> ) public final class LegacySchemaMigrator { private LegacySchemaMigrator ( ) { } private static final Logger logger = LoggerFactory . getLogger ( LegacySchemaMigrator . class ) ; static final List < CFMetaData > LegacySchemaTables = ImmutableList . of ( SystemKeyspace . LegacyKeyspaces , SystemKeyspace . LegacyColumnfamilies , SystemKeyspace . LegacyColumns , SystemKeyspace . LegacyTriggers , SystemKeyspace . LegacyUsertypes , SystemKeyspace . LegacyFunctions , SystemKeyspace . LegacyAggregates ) ; public static void migrate ( ) { Collection < Keyspace > keyspaces = readSchema ( ) ; if ( keyspaces . isEmpty ( ) ) { unloadLegacySchemaTables ( ) ; return ; } logger . info ( <str> , keyspaces . size ( ) , SchemaKeyspace . NAME ) ; keyspaces . forEach ( LegacySchemaMigrator : : storeKeyspaceInNewSchemaTables ) ; SchemaKeyspace . flush ( ) ; logger . info ( <str> ) ; truncateLegacySchemaTables ( ) ; unloadLegacySchemaTables ( ) ; logger . info ( <str> ) ; } static void unloadLegacySchemaTables ( ) { KeyspaceMetadata systemKeyspace = Schema . instance . getKSMetaData ( SystemKeyspace . NAME ) ; Tables systemTables = systemKeyspace . tables ; for ( CFMetaData table : LegacySchemaTables ) systemTables = systemTables . without ( table . cfName ) ; LegacySchemaTables . forEach ( Schema . instance : : unload ) ; Schema . instance . setKeyspaceMetadata ( systemKeyspace . withSwapped ( systemTables ) ) ; } private static void truncateLegacySchemaTables ( ) { LegacySchemaTables . forEach ( table - > Schema . instance . getColumnFamilyStoreInstance ( table . cfId ) . truncateBlocking ( ) ) ; } private static void storeKeyspaceInNewSchemaTables ( Keyspace keyspace ) { logger . info ( <str> , keyspace ) ; Mutation mutation = SchemaKeyspace . makeCreateKeyspaceMutation ( keyspace . name , keyspace . params , keyspace . timestamp ) ; for ( Table table : keyspace . tables ) SchemaKeyspace . addTableToSchemaMutation ( table . metadata , table . timestamp , true , mutation ) ; for ( Type type : keyspace . types ) SchemaKeyspace . addTypeToSchemaMutation ( type . metadata , type . timestamp , mutation ) ; for ( Function function : keyspace . functions ) SchemaKeyspace . addFunctionToSchemaMutation ( function . metadata , function . timestamp , mutation ) ; for ( Aggregate aggregate : keyspace . aggregates ) SchemaKeyspace . addAggregateToSchemaMutation ( aggregate . metadata , aggregate . timestamp , mutation ) ; mutation . apply ( ) ; } private static Collection < Keyspace > readSchema ( ) { String query = format ( <str> , SystemKeyspace . NAME , SystemKeyspace . LEGACY_KEYSPACES ) ; Collection < String > keyspaceNames = new ArrayList < > ( ) ; query ( query ) . forEach ( row - > keyspaceNames . add ( row . getString ( <str> ) ) ) ; keyspaceNames . removeAll ( Schema . SYSTEM_KEYSPACE_NAMES ) ; Collection < Keyspace > keyspaces = new ArrayList < > ( ) ; keyspaceNames . forEach ( name - > keyspaces . add ( readKeyspace ( name ) ) ) ; return keyspaces ; } private static Keyspace readKeyspace ( String keyspaceName ) { long timestamp = readKeyspaceTimestamp ( keyspaceName ) ; KeyspaceParams params = readKeyspaceParams ( keyspaceName ) ; Collection < Table > tables = readTables ( keyspaceName ) ; Collection < Type > types = readTypes ( keyspaceName ) ; Collection < Function > functions = readFunctions ( keyspaceName ) ; Functions . Builder functionsBuilder = Functions . builder ( ) ; functions . forEach ( udf - > functionsBuilder . add ( udf . metadata ) ) ; Collection < Aggregate > aggregates = readAggregates ( functionsBuilder . build ( ) , keyspaceName ) ; return new Keyspace ( timestamp , keyspaceName , params , tables , types , functions , aggregates ) ; } private static long readKeyspaceTimestamp ( String keyspaceName ) { String query = format ( <str> , SystemKeyspace . NAME , SystemKeyspace . LEGACY_KEYSPACES ) ; return query ( query , keyspaceName ) . one ( ) . getLong ( <str> ) ; } private static KeyspaceParams readKeyspaceParams ( String keyspaceName ) { String query = format ( <str> , SystemKeyspace . NAME , SystemKeyspace . LEGACY_KEYSPACES ) ; UntypedResultSet . Row row = query ( query , keyspaceName ) . one ( ) ; boolean durableWrites = row . getBoolean ( <str> ) ; Map < String , String > replication = new HashMap < > ( ) ; replication . putAll ( fromJsonMap ( row . getString ( <str> ) ) ) ; replication . put ( ReplicationParams . CLASS , row . getString ( <str> ) ) ; return KeyspaceParams . create ( durableWrites , replication ) ; } private static Collection < Table > readTables ( String keyspaceName ) { String query = format ( <str> , SystemKeyspace . NAME , SystemKeyspace . LEGACY_COLUMNFAMILIES ) ; Collection < String > tableNames = new ArrayList < > ( ) ; query ( query , keyspaceName ) . forEach ( row - > tableNames . add ( row . getString ( <str> ) ) ) ; Collection < Table > tables = new ArrayList < > ( ) ; tableNames . forEach ( name - > tables . add ( readTable ( keyspaceName , name ) ) ) ; return tables ; } private static Table readTable ( String keyspaceName , String tableName ) { long timestamp = readTableTimestamp ( keyspaceName , tableName ) ; CFMetaData metadata = readTableMetadata ( keyspaceName , tableName ) ; return new Table ( timestamp , metadata ) ; } private static long readTableTimestamp ( String keyspaceName , String tableName ) { String query = format ( <str> , SystemKeyspace . NAME , SystemKeyspace . LEGACY_COLUMNFAMILIES ) ; return query ( query , keyspaceName , tableName ) . one ( ) . getLong ( <str> ) ; } private static CFMetaData readTableMetadata ( String keyspaceName , String tableName ) { String tableQuery = format ( <str> , SystemKeyspace . NAME , SystemKeyspace . LEGACY_COLUMNFAMILIES ) ; UntypedResultSet . Row tableRow = query ( tableQuery , keyspaceName , tableName ) . one ( ) ; String columnsQuery = format ( <str> , SystemKeyspace . NAME , SystemKeyspace . LEGACY_COLUMNS ) ; UntypedResultSet columnRows = query ( columnsQuery , keyspaceName , tableName ) ; String triggersQuery = format ( <str> , SystemKeyspace . NAME , SystemKeyspace . LEGACY_TRIGGERS ) ; UntypedResultSet triggerRows = query ( triggersQuery , keyspaceName , tableName ) ; return decodeTableMetadata ( tableRow , columnRows , triggerRows ) ; } private static CFMetaData decodeTableMetadata ( UntypedResultSet . Row tableRow , UntypedResultSet columnRows , UntypedResultSet triggerRows ) { String ksName = tableRow . getString ( <str> ) ; String cfName = tableRow . getString ( <str> ) ; AbstractType < ? > rawComparator = TypeParser . parse ( tableRow . getString ( <str> ) ) ; AbstractType < ? > subComparator = tableRow . has ( <str> ) ? TypeParser . parse ( tableRow . getString ( <str> ) ) : null ; boolean isSuper = <str> . equals ( tableRow . getString ( <str> ) . toLowerCase ( ) ) ; boolean isDense = tableRow . getBoolean ( <str> ) ; boolean isCompound = rawComparator instanceof CompositeType ; AbstractType < ? > defaultValidator = TypeParser . parse ( tableRow . getString ( <str> ) ) ; boolean isCounter = defaultValidator instanceof CounterColumnType ; UUID cfId = tableRow . has ( <str> ) ? tableRow . getUUID ( <str> ) : CFMetaData . generateLegacyCfId ( ksName , cfName ) ; boolean isCQLTable = ! isSuper & & ! isDense & & isCompound ; boolean isStaticCompactTable = ! isDense & & ! isCompound ; boolean needsUpgrade = ! isCQLTable & & checkNeedsUpgrade ( columnRows , isSuper , isStaticCompactTable ) ; List < ColumnDefinition > columnDefs = createColumnsFromColumnRows ( columnRows , ksName , cfName , rawComparator , subComparator , isSuper , isCQLTable , isStaticCompactTable , needsUpgrade ) ; if ( needsUpgrade ) { addDefinitionForUpgrade ( columnDefs , ksName , cfName , isStaticCompactTable , isSuper , rawComparator , subComparator , defaultValidator ) ; } CFMetaData cfm = CFMetaData . create ( ksName , cfName , cfId , isDense , isCompound , isSuper , isCounter , false , columnDefs , DatabaseDescriptor . getPartitioner ( ) ) ; Indexes indexes = createIndexesFromColumnRows ( cfm , columnRows , ksName , cfName , rawComparator , subComparator , isSuper , isCQLTable , isStaticCompactTable , needsUpgrade ) ; cfm . indexes ( indexes ) ; if ( tableRow . has ( <str> ) ) addDroppedColumns ( cfm , rawComparator , tableRow . getMap ( <str> , UTF8Type . instance , LongType . instance ) ) ; return cfm . params ( decodeTableParams ( tableRow ) ) . triggers ( createTriggersFromTriggerRows ( triggerRows ) ) ; } private static TableParams decodeTableParams ( UntypedResultSet . Row row ) { TableParams . Builder params = TableParams . builder ( ) ; params . readRepairChance ( row . getDouble ( <str> ) ) . dcLocalReadRepairChance ( row . getDouble ( <str> ) ) . gcGraceSeconds ( row . getInt ( <str> ) ) ; if ( row . has ( <str> ) ) params . comment ( row . getString ( <str> ) ) ; if ( row . has ( <str> ) ) params . memtableFlushPeriodInMs ( row . getInt ( <str> ) ) ; params . caching ( CachingParams . fromMap ( fromJsonMap ( row . getString ( <str> ) ) ) ) ; if ( row . has ( <str> ) ) params . defaultTimeToLive ( row . getInt ( <str> ) ) ; if ( row . has ( <str> ) ) params . speculativeRetry ( SpeculativeRetryParam . fromString ( row . getString ( <str> ) ) ) ; Map < String , String > compressionParameters = fromJsonMap ( row . getString ( <str> ) ) ; String crcCheckChance = compressionParameters . remove ( <str> ) ; if ( crcCheckChance ! = null ) params . crcCheckChance ( Double . parseDouble ( crcCheckChance ) ) ; params . compression ( CompressionParams . fromMap ( compressionParameters ) ) ; params . compaction ( compactionFromRow ( row ) ) ; if ( row . has ( <str> ) ) params . minIndexInterval ( row . getInt ( <str> ) ) ; if ( row . has ( <str> ) ) params . maxIndexInterval ( row . getInt ( <str> ) ) ; if ( row . has ( <str> ) ) params . bloomFilterFpChance ( row . getDouble ( <str> ) ) ; return params . build ( ) ; } @SuppressWarnings ( <str> ) private static CompactionParams compactionFromRow ( UntypedResultSet . Row row ) { Class < ? extends AbstractCompactionStrategy > klass = CFMetaData . createCompactionStrategy ( row . getString ( <str> ) ) ; Map < String , String > options = fromJsonMap ( row . getString ( <str> ) ) ; int minThreshold = row . getInt ( <str> ) ; int maxThreshold = row . getInt ( <str> ) ; Map < String , String > optionsWithThresholds = new HashMap < > ( options ) ; optionsWithThresholds . putIfAbsent ( CompactionParams . Option . MIN_THRESHOLD . toString ( ) , Integer . toString ( minThreshold ) ) ; optionsWithThresholds . putIfAbsent ( CompactionParams . Option . MAX_THRESHOLD . toString ( ) , Integer . toString ( maxThreshold ) ) ; try { Map < String , String > unrecognizedOptions = ( Map < String , String > ) klass . getMethod ( <str> , Map . class ) . invoke ( null , optionsWithThresholds ) ; if ( unrecognizedOptions . isEmpty ( ) ) options = optionsWithThresholds ; } catch ( Exception e ) { throw new RuntimeException ( e ) ; } return CompactionParams . create ( klass , options ) ; } private static boolean checkNeedsUpgrade ( UntypedResultSet defs , boolean isSuper , boolean isStaticCompactTable ) { if ( isSuper ) { for ( UntypedResultSet . Row row : defs ) if ( row . getString ( <str> ) . isEmpty ( ) ) return false ; return true ; } if ( isStaticCompactTable ) return ! hasKind ( defs , ColumnDefinition . Kind . STATIC ) ; return ! hasRegularColumns ( defs ) ; } private static boolean hasRegularColumns ( UntypedResultSet columnRows ) { for ( UntypedResultSet . Row row : columnRows ) { if ( isEmptyCompactValueColumn ( row ) ) return false ; if ( deserializeKind ( row . getString ( <str> ) ) = = ColumnDefinition . Kind . REGULAR ) return true ; } return false ; } private static boolean isEmptyCompactValueColumn ( UntypedResultSet . Row row ) { return <str> . equals ( row . getString ( <str> ) ) & & row . getString ( <str> ) . isEmpty ( ) ; } private static void addDefinitionForUpgrade ( List < ColumnDefinition > defs , String ksName , String cfName , boolean isStaticCompactTable , boolean isSuper , AbstractType < ? > rawComparator , AbstractType < ? > subComparator , AbstractType < ? > defaultValidator ) { CompactTables . DefaultNames names = CompactTables . defaultNameGenerator ( defs ) ; if ( isSuper ) { defs . add ( ColumnDefinition . regularDef ( ksName , cfName , CompactTables . SUPER_COLUMN_MAP_COLUMN_STR , MapType . getInstance ( subComparator , defaultValidator , true ) ) ) ; } else if ( isStaticCompactTable ) { defs . add ( ColumnDefinition . clusteringDef ( ksName , cfName , names . defaultClusteringName ( ) , rawComparator , <int> ) ) ; defs . add ( ColumnDefinition . regularDef ( ksName , cfName , names . defaultCompactValueName ( ) , defaultValidator ) ) ; } else { defs . add ( ColumnDefinition . regularDef ( ksName , cfName , names . defaultCompactValueName ( ) , EmptyType . instance ) ) ; } } private static boolean hasKind ( UntypedResultSet defs , ColumnDefinition . Kind kind ) { for ( UntypedResultSet . Row row : defs ) if ( deserializeKind ( row . getString ( <str> ) ) = = kind ) return true ; return false ; } private static void addDroppedColumns ( CFMetaData cfm , AbstractType < ? > comparator , Map < String , Long > droppedTimes ) { AbstractType < ? > last = comparator . getComponents ( ) . get ( comparator . componentsCount ( ) - <int> ) ; Map < ByteBuffer , CollectionType > collections = last instanceof ColumnToCollectionType ? ( ( ColumnToCollectionType ) last ) . defined : Collections . emptyMap ( ) ; for ( Map . Entry < String , Long > entry : droppedTimes . entrySet ( ) ) { String name = entry . getKey ( ) ; ByteBuffer nameBytes = UTF8Type . instance . decompose ( name ) ; long time = entry . getValue ( ) ; AbstractType < ? > type = collections . containsKey ( nameBytes ) ? collections . get ( nameBytes ) : BytesType . instance ; cfm . getDroppedColumns ( ) . put ( nameBytes , new CFMetaData . DroppedColumn ( name , type , time ) ) ; } } private static List < ColumnDefinition > createColumnsFromColumnRows ( UntypedResultSet rows , String keyspace , String table , AbstractType < ? > rawComparator , AbstractType < ? > rawSubComparator , boolean isSuper , boolean isCQLTable , boolean isStaticCompactTable , boolean needsUpgrade ) { List < ColumnDefinition > columns = new ArrayList < > ( ) ; for ( UntypedResultSet . Row row : rows ) { if ( isEmptyCompactValueColumn ( row ) ) continue ; columns . add ( createColumnFromColumnRow ( row , keyspace , table , rawComparator , rawSubComparator , isSuper , isCQLTable , isStaticCompactTable , needsUpgrade ) ) ; } return columns ; } private static ColumnDefinition createColumnFromColumnRow ( UntypedResultSet . Row row , String keyspace , String table , AbstractType < ? > rawComparator , AbstractType < ? > rawSubComparator , boolean isSuper , boolean isCQLTable , boolean isStaticCompactTable , boolean needsUpgrade ) { ColumnDefinition . Kind kind = deserializeKind ( row . getString ( <str> ) ) ; if ( needsUpgrade & & isStaticCompactTable & & kind = = ColumnDefinition . Kind . REGULAR ) kind = ColumnDefinition . Kind . STATIC ; int componentIndex = ColumnDefinition . NO_POSITION ; if ( kind . isPrimaryKeyKind ( ) ) componentIndex = row . has ( <str> ) ? row . getInt ( <str> ) : <int> ; AbstractType < ? > comparator = isCQLTable ? UTF8Type . instance : CompactTables . columnDefinitionComparator ( kind , isSuper , rawComparator , rawSubComparator ) ; ColumnIdentifier name = ColumnIdentifier . getInterned ( comparator . fromString ( row . getString ( <str> ) ) , comparator ) ; AbstractType < ? > validator = parseType ( row . getString ( <str> ) ) ; return new ColumnDefinition ( keyspace , table , name , validator , componentIndex , kind ) ; } private static Indexes createIndexesFromColumnRows ( CFMetaData cfm , UntypedResultSet rows , String keyspace , String table , AbstractType < ? > rawComparator , AbstractType < ? > rawSubComparator , boolean isSuper , boolean isCQLTable , boolean isStaticCompactTable , boolean needsUpgrade ) { Indexes . Builder indexes = Indexes . builder ( ) ; for ( UntypedResultSet . Row row : rows ) { IndexMetadata . Kind kind = null ; if ( row . has ( <str> ) ) kind = IndexMetadata . Kind . valueOf ( row . getString ( <str> ) ) ; if ( kind = = null ) continue ; Map < String , String > indexOptions = null ; if ( row . has ( <str> ) ) indexOptions = fromJsonMap ( row . getString ( <str> ) ) ; String indexName = null ; if ( row . has ( <str> ) ) indexName = row . getString ( <str> ) ; ColumnDefinition column = createColumnFromColumnRow ( row , keyspace , table , rawComparator , rawSubComparator , isSuper , isCQLTable , isStaticCompactTable , needsUpgrade ) ; indexes . add ( IndexMetadata . fromLegacyMetadata ( cfm , column , indexName , kind , indexOptions ) ) ; } return indexes . build ( ) ; } private static ColumnDefinition . Kind deserializeKind ( String kind ) { if ( <str> . equalsIgnoreCase ( kind ) ) return ColumnDefinition . Kind . CLUSTERING ; if ( <str> . equalsIgnoreCase ( kind ) ) return ColumnDefinition . Kind . REGULAR ; return Enum . valueOf ( ColumnDefinition . Kind . class , kind . toUpperCase ( ) ) ; } private static Triggers createTriggersFromTriggerRows ( UntypedResultSet rows ) { Triggers . Builder triggers = org . apache . cassandra . schema . Triggers . builder ( ) ; rows . forEach ( row - > triggers . add ( createTriggerFromTriggerRow ( row ) ) ) ; return triggers . build ( ) ; } private static TriggerMetadata createTriggerFromTriggerRow ( UntypedResultSet . Row row ) { String name = row . getString ( <str> ) ; String classOption = row . getTextMap ( <str> ) . get ( <str> ) ; return new TriggerMetadata ( name , classOption ) ; } private static Collection < Type > readTypes ( String keyspaceName ) { String query = format ( <str> , SystemKeyspace . NAME , SystemKeyspace . LEGACY_USERTYPES ) ; Collection < String > typeNames = new ArrayList < > ( ) ; query ( query , keyspaceName ) . forEach ( row - > typeNames . add ( row . getString ( <str> ) ) ) ; Collection < Type > types = new ArrayList < > ( ) ; typeNames . forEach ( name - > types . add ( readType ( keyspaceName , name ) ) ) ; return types ; } private static Type readType ( String keyspaceName , String typeName ) { long timestamp = readTypeTimestamp ( keyspaceName , typeName ) ; UserType metadata = readTypeMetadata ( keyspaceName , typeName ) ; return new Type ( timestamp , metadata ) ; } private static long readTypeTimestamp ( String keyspaceName , String typeName ) { ColumnFamilyStore store = org . apache . cassandra . db . Keyspace . open ( SystemKeyspace . NAME ) . getColumnFamilyStore ( SystemKeyspace . LEGACY_USERTYPES ) ; ClusteringComparator comparator = store . metadata . comparator ; Slices slices = Slices . with ( comparator , Slice . make ( comparator , typeName ) ) ; int nowInSec = FBUtilities . nowInSeconds ( ) ; DecoratedKey key = store . metadata . decorateKey ( AsciiType . instance . fromString ( keyspaceName ) ) ; SinglePartitionReadCommand command = SinglePartitionReadCommand . create ( store . metadata , nowInSec , key , slices ) ; try ( OpOrder . Group op = store . readOrdering . start ( ) ; RowIterator partition = UnfilteredRowIterators . filter ( command . queryMemtableAndDisk ( store , op ) , nowInSec ) ) { return partition . next ( ) . primaryKeyLivenessInfo ( ) . timestamp ( ) ; } } private static UserType readTypeMetadata ( String keyspaceName , String typeName ) { String query = format ( <str> , SystemKeyspace . NAME , SystemKeyspace . LEGACY_USERTYPES ) ; UntypedResultSet . Row row = query ( query , keyspaceName , typeName ) . one ( ) ; List < ByteBuffer > names = row . getList ( <str> , UTF8Type . instance ) . stream ( ) . map ( ByteBufferUtil : : bytes ) . collect ( Collectors . toList ( ) ) ; List < AbstractType < ? > > types = row . getList ( <str> , UTF8Type . instance ) . stream ( ) . map ( LegacySchemaMigrator : : parseType ) . collect ( Collectors . toList ( ) ) ; return new UserType ( keyspaceName , bytes ( typeName ) , names , types ) ; } private static Collection < Function > readFunctions ( String keyspaceName ) { String query = format ( <str> , SystemKeyspace . NAME , SystemKeyspace . LEGACY_FUNCTIONS ) ; HashMultimap < String , List < String > > functionSignatures = HashMultimap . create ( ) ; query ( query , keyspaceName ) . forEach ( row - > functionSignatures . put ( row . getString ( <str> ) , row . getList ( <str> , UTF8Type . instance ) ) ) ; Collection < Function > functions = new ArrayList < > ( ) ; functionSignatures . entries ( ) . forEach ( pair - > functions . add ( readFunction ( keyspaceName , pair . getKey ( ) , pair . getValue ( ) ) ) ) ; return functions ; } private static Function readFunction ( String keyspaceName , String functionName , List < String > signature ) { long timestamp = readFunctionTimestamp ( keyspaceName , functionName , signature ) ; UDFunction metadata = readFunctionMetadata ( keyspaceName , functionName , signature ) ; return new Function ( timestamp , metadata ) ; } private static long readFunctionTimestamp ( String keyspaceName , String functionName , List < String > signature ) { String query = format ( <str> + <str> + <str> , SystemKeyspace . NAME , SystemKeyspace . LEGACY_FUNCTIONS ) ; return query ( query , keyspaceName , functionName , signature ) . one ( ) . getLong ( <str> ) ; } private static UDFunction readFunctionMetadata ( String keyspaceName , String functionName , List < String > signature ) { String query = format ( <str> , SystemKeyspace . NAME , SystemKeyspace . LEGACY_FUNCTIONS ) ; UntypedResultSet . Row row = query ( query , keyspaceName , functionName , signature ) . one ( ) ; FunctionName name = new FunctionName ( keyspaceName , functionName ) ; List < ColumnIdentifier > argNames = new ArrayList < > ( ) ; if ( row . has ( <str> ) ) for ( String arg : row . getList ( <str> , UTF8Type . instance ) ) argNames . add ( new ColumnIdentifier ( arg , true ) ) ; List < AbstractType < ? > > argTypes = new ArrayList < > ( ) ; if ( row . has ( <str> ) ) for ( String type : row . getList ( <str> , UTF8Type . instance ) ) argTypes . add ( parseType ( type ) ) ; AbstractType < ? > returnType = parseType ( row . getString ( <str> ) ) ; String language = row . getString ( <str> ) ; String body = row . getString ( <str> ) ; boolean calledOnNullInput = row . getBoolean ( <str> ) ; try { return UDFunction . create ( name , argNames , argTypes , returnType , calledOnNullInput , language , body ) ; } catch ( InvalidRequestException e ) { return UDFunction . createBrokenFunction ( name , argNames , argTypes , returnType , calledOnNullInput , language , body , e ) ; } } private static Collection < Aggregate > readAggregates ( Functions functions , String keyspaceName ) { String query = format ( <str> , SystemKeyspace . NAME , SystemKeyspace . LEGACY_AGGREGATES ) ; HashMultimap < String , List < String > > aggregateSignatures = HashMultimap . create ( ) ; query ( query , keyspaceName ) . forEach ( row - > aggregateSignatures . put ( row . getString ( <str> ) , row . getList ( <str> , UTF8Type . instance ) ) ) ; Collection < Aggregate > aggregates = new ArrayList < > ( ) ; aggregateSignatures . entries ( ) . forEach ( pair - > aggregates . add ( readAggregate ( functions , keyspaceName , pair . getKey ( ) , pair . getValue ( ) ) ) ) ; return aggregates ; } private static Aggregate readAggregate ( Functions functions , String keyspaceName , String aggregateName , List < String > signature ) { long timestamp = readAggregateTimestamp ( keyspaceName , aggregateName , signature ) ; UDAggregate metadata = readAggregateMetadata ( functions , keyspaceName , aggregateName , signature ) ; return new Aggregate ( timestamp , metadata ) ; } private static long readAggregateTimestamp ( String keyspaceName , String aggregateName , List < String > signature ) { String query = format ( <str> + <str> + <str> , SystemKeyspace . NAME , SystemKeyspace . LEGACY_AGGREGATES ) ; return query ( query , keyspaceName , aggregateName , signature ) . one ( ) . getLong ( <str> ) ; } private static UDAggregate readAggregateMetadata ( Functions functions , String keyspaceName , String functionName , List < String > signature ) { String query = format ( <str> , SystemKeyspace . NAME , SystemKeyspace . LEGACY_AGGREGATES ) ; UntypedResultSet . Row row = query ( query , keyspaceName , functionName , signature ) . one ( ) ; FunctionName name = new FunctionName ( keyspaceName , functionName ) ; List < String > types = row . getList ( <str> , UTF8Type . instance ) ; List < AbstractType < ? > > argTypes = new ArrayList < > ( ) ; if ( types ! = null ) { argTypes = new ArrayList < > ( types . size ( ) ) ; for ( String type : types ) argTypes . add ( parseType ( type ) ) ; } AbstractType < ? > returnType = parseType ( row . getString ( <str> ) ) ; FunctionName stateFunc = new FunctionName ( keyspaceName , row . getString ( <str> ) ) ; AbstractType < ? > stateType = parseType ( row . getString ( <str> ) ) ; FunctionName finalFunc = row . has ( <str> ) ? new FunctionName ( keyspaceName , row . getString ( <str> ) ) : null ; ByteBuffer initcond = row . has ( <str> ) ? row . getBytes ( <str> ) : null ; try { return UDAggregate . create ( functions , name , argTypes , returnType , stateFunc , finalFunc , stateType , initcond ) ; } catch ( InvalidRequestException reason ) { return UDAggregate . createBroken ( name , argTypes , returnType , initcond , reason ) ; } } private static UntypedResultSet query ( String query , Object . . . values ) { return QueryProcessor . executeOnceInternal ( query , values ) ; } private static AbstractType < ? > parseType ( String str ) { return TypeParser . parse ( str ) ; } private static final class Keyspace { final long timestamp ; final String name ; final KeyspaceParams params ; final Collection < Table > tables ; final Collection < Type > types ; final Collection < Function > functions ; final Collection < Aggregate > aggregates ; Keyspace ( long timestamp , String name , KeyspaceParams params , Collection < Table > tables , Collection < Type > types , Collection < Function > functions , Collection < Aggregate > aggregates ) { this . timestamp = timestamp ; this . name = name ; this . params = params ; this . tables = tables ; this . types = types ; this . functions = functions ; this . aggregates = aggregates ; } } private static final class Table { final long timestamp ; final CFMetaData metadata ; Table ( long timestamp , CFMetaData metadata ) { this . timestamp = timestamp ; this . metadata = metadata ; } } private static final class Type { final long timestamp ; final UserType metadata ; Type ( long timestamp , UserType metadata ) { this . timestamp = timestamp ; this . metadata = metadata ; } } private static final class Function { final long timestamp ; final UDFunction metadata ; Function ( long timestamp , UDFunction metadata ) { this . timestamp = timestamp ; this . metadata = metadata ; } } private static final class Aggregate { final long timestamp ; final UDAggregate metadata ; Aggregate ( long timestamp , UDAggregate metadata ) { this . timestamp = timestamp ; this . metadata = metadata ; } } } 
