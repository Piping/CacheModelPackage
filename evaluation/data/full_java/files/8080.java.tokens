package org . elasticsearch . index . analysis ; import org . apache . lucene . analysis . Tokenizer ; import org . apache . lucene . analysis . standard . StandardTokenizer ; import org . elasticsearch . test . ESTokenStreamTestCase ; import java . io . IOException ; import java . io . StringReader ; public class CJKFilterFactoryTests extends ESTokenStreamTestCase { private static final String RESOURCE = <str> ; public void testDefault ( ) throws IOException { AnalysisService analysisService = AnalysisTestsHelper . createAnalysisServiceFromClassPath ( createTempDir ( ) , RESOURCE ) ; TokenFilterFactory tokenFilter = analysisService . tokenFilter ( <str> ) ; String source = <str> ; String [ ] expected = new String [ ] { <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> } ; Tokenizer tokenizer = new StandardTokenizer ( ) ; tokenizer . setReader ( new StringReader ( source ) ) ; assertTokenStreamContents ( tokenFilter . create ( tokenizer ) , expected ) ; } public void testNoFlags ( ) throws IOException { AnalysisService analysisService = AnalysisTestsHelper . createAnalysisServiceFromClassPath ( createTempDir ( ) , RESOURCE ) ; TokenFilterFactory tokenFilter = analysisService . tokenFilter ( <str> ) ; String source = <str> ; String [ ] expected = new String [ ] { <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> } ; Tokenizer tokenizer = new StandardTokenizer ( ) ; tokenizer . setReader ( new StringReader ( source ) ) ; assertTokenStreamContents ( tokenFilter . create ( tokenizer ) , expected ) ; } public void testHanOnly ( ) throws IOException { AnalysisService analysisService = AnalysisTestsHelper . createAnalysisServiceFromClassPath ( createTempDir ( ) , RESOURCE ) ; TokenFilterFactory tokenFilter = analysisService . tokenFilter ( <str> ) ; String source = <str> ; String [ ] expected = new String [ ] { <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> } ; Tokenizer tokenizer = new StandardTokenizer ( ) ; tokenizer . setReader ( new StringReader ( source ) ) ; assertTokenStreamContents ( tokenFilter . create ( tokenizer ) , expected ) ; } public void testHanUnigramOnly ( ) throws IOException { AnalysisService analysisService = AnalysisTestsHelper . createAnalysisServiceFromClassPath ( createTempDir ( ) , RESOURCE ) ; TokenFilterFactory tokenFilter = analysisService . tokenFilter ( <str> ) ; String source = <str> ; String [ ] expected = new String [ ] { <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> } ; Tokenizer tokenizer = new StandardTokenizer ( ) ; tokenizer . setReader ( new StringReader ( source ) ) ; assertTokenStreamContents ( tokenFilter . create ( tokenizer ) , expected ) ; } } 
