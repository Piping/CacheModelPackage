package org . apache . cassandra . db ; import java . io . IOException ; import java . nio . ByteBuffer ; import java . util . * ; import com . google . common . collect . Iterables ; import com . google . common . collect . Sets ; import org . apache . cassandra . cache . IRowCacheEntry ; import org . apache . cassandra . cache . RowCacheKey ; import org . apache . cassandra . cache . RowCacheSentinel ; import org . apache . cassandra . concurrent . Stage ; import org . apache . cassandra . concurrent . StageManager ; import org . apache . cassandra . config . CFMetaData ; import org . apache . cassandra . config . ColumnDefinition ; import org . apache . cassandra . config . DatabaseDescriptor ; import org . apache . cassandra . db . lifecycle . * ; import org . apache . cassandra . db . filter . * ; import org . apache . cassandra . db . partitions . * ; import org . apache . cassandra . db . rows . * ; import org . apache . cassandra . exceptions . RequestExecutionException ; import org . apache . cassandra . io . sstable . format . SSTableReader ; import org . apache . cassandra . io . util . DataInputPlus ; import org . apache . cassandra . io . util . DataOutputPlus ; import org . apache . cassandra . metrics . TableMetrics ; import org . apache . cassandra . net . MessageOut ; import org . apache . cassandra . net . MessagingService ; import org . apache . cassandra . schema . IndexMetadata ; import org . apache . cassandra . service . CacheService ; import org . apache . cassandra . service . ClientState ; import org . apache . cassandra . service . StorageProxy ; import org . apache . cassandra . service . pager . * ; import org . apache . cassandra . thrift . ThriftResultsMerger ; import org . apache . cassandra . tracing . Tracing ; import org . apache . cassandra . utils . FBUtilities ; import org . apache . cassandra . utils . SearchIterator ; import org . apache . cassandra . utils . btree . BTreeSet ; import org . apache . cassandra . utils . concurrent . OpOrder ; import org . apache . cassandra . utils . memory . HeapAllocator ; public class SinglePartitionReadCommand extends ReadCommand { protected static final SelectionDeserializer selectionDeserializer = new Deserializer ( ) ; private final DecoratedKey partitionKey ; private final ClusteringIndexFilter clusteringIndexFilter ; private int oldestUnrepairedTombstone = Integer . MAX_VALUE ; public SinglePartitionReadCommand ( boolean isDigest , int digestVersion , boolean isForThrift , CFMetaData metadata , int nowInSec , ColumnFilter columnFilter , RowFilter rowFilter , DataLimits limits , DecoratedKey partitionKey , ClusteringIndexFilter clusteringIndexFilter ) { super ( Kind . SINGLE_PARTITION , isDigest , digestVersion , isForThrift , metadata , nowInSec , columnFilter , rowFilter , limits ) ; assert partitionKey . getPartitioner ( ) = = metadata . partitioner ; this . partitionKey = partitionKey ; this . clusteringIndexFilter = clusteringIndexFilter ; } public static SinglePartitionReadCommand create ( CFMetaData metadata , int nowInSec , ColumnFilter columnFilter , RowFilter rowFilter , DataLimits limits , DecoratedKey partitionKey , ClusteringIndexFilter clusteringIndexFilter ) { return create ( false , metadata , nowInSec , columnFilter , rowFilter , limits , partitionKey , clusteringIndexFilter ) ; } public static SinglePartitionReadCommand create ( boolean isForThrift , CFMetaData metadata , int nowInSec , ColumnFilter columnFilter , RowFilter rowFilter , DataLimits limits , DecoratedKey partitionKey , ClusteringIndexFilter clusteringIndexFilter ) { return new SinglePartitionReadCommand ( false , <int> , isForThrift , metadata , nowInSec , columnFilter , rowFilter , limits , partitionKey , clusteringIndexFilter ) ; } public static SinglePartitionReadCommand create ( CFMetaData metadata , int nowInSec , DecoratedKey key , ColumnFilter columnFilter , ClusteringIndexFilter filter ) { return create ( metadata , nowInSec , columnFilter , RowFilter . NONE , DataLimits . NONE , key , filter ) ; } public static SinglePartitionReadCommand fullPartitionRead ( CFMetaData metadata , int nowInSec , DecoratedKey key ) { return SinglePartitionReadCommand . create ( metadata , nowInSec , key , Slices . ALL ) ; } public static SinglePartitionReadCommand fullPartitionRead ( CFMetaData metadata , int nowInSec , ByteBuffer key ) { return SinglePartitionReadCommand . create ( metadata , nowInSec , metadata . decorateKey ( key ) , Slices . ALL ) ; } public static SinglePartitionReadCommand create ( CFMetaData metadata , int nowInSec , DecoratedKey key , Slice slice ) { return create ( metadata , nowInSec , key , Slices . with ( metadata . comparator , slice ) ) ; } public static SinglePartitionReadCommand create ( CFMetaData metadata , int nowInSec , DecoratedKey key , Slices slices ) { ClusteringIndexSliceFilter filter = new ClusteringIndexSliceFilter ( slices , false ) ; return SinglePartitionReadCommand . create ( metadata , nowInSec , ColumnFilter . all ( metadata ) , RowFilter . NONE , DataLimits . NONE , key , filter ) ; } public static SinglePartitionReadCommand create ( CFMetaData metadata , int nowInSec , ByteBuffer key , Slices slices ) { return create ( metadata , nowInSec , metadata . decorateKey ( key ) , slices ) ; } public SinglePartitionReadCommand copy ( ) { return new SinglePartitionReadCommand ( isDigestQuery ( ) , digestVersion ( ) , isForThrift ( ) , metadata ( ) , nowInSec ( ) , columnFilter ( ) , rowFilter ( ) , limits ( ) , partitionKey ( ) , clusteringIndexFilter ( ) ) ; } public DecoratedKey partitionKey ( ) { return partitionKey ; } public ClusteringIndexFilter clusteringIndexFilter ( ) { return clusteringIndexFilter ; } public ClusteringIndexFilter clusteringIndexFilter ( DecoratedKey key ) { return clusteringIndexFilter ; } public long getTimeout ( ) { return DatabaseDescriptor . getReadRpcTimeout ( ) ; } public boolean selectsKey ( DecoratedKey key ) { if ( ! this . partitionKey ( ) . equals ( key ) ) return false ; return rowFilter ( ) . partitionKeyRestrictionsAreSatisfiedBy ( key , metadata ( ) . getKeyValidator ( ) ) ; } public boolean selectsClustering ( DecoratedKey key , Clustering clustering ) { if ( clustering = = Clustering . STATIC_CLUSTERING ) return ! columnFilter ( ) . fetchedColumns ( ) . statics . isEmpty ( ) ; if ( ! clusteringIndexFilter ( ) . selects ( clustering ) ) return false ; return rowFilter ( ) . clusteringKeyRestrictionsAreSatisfiedBy ( clustering ) ; } public SinglePartitionReadCommand forPaging ( Clustering lastReturned , int pageSize ) { assert ! isDigestQuery ( ) ; return create ( isForThrift ( ) , metadata ( ) , nowInSec ( ) , columnFilter ( ) , rowFilter ( ) , limits ( ) . forPaging ( pageSize ) , partitionKey ( ) , lastReturned = = null ? clusteringIndexFilter ( ) : clusteringIndexFilter . forPaging ( metadata ( ) . comparator , lastReturned , false ) ) ; } public PartitionIterator execute ( ConsistencyLevel consistency , ClientState clientState ) throws RequestExecutionException { return StorageProxy . read ( Group . one ( this ) , consistency , clientState ) ; } public SinglePartitionPager getPager ( PagingState pagingState , int protocolVersion ) { return getPager ( this , pagingState , protocolVersion ) ; } private static SinglePartitionPager getPager ( SinglePartitionReadCommand command , PagingState pagingState , int protocolVersion ) { return new SinglePartitionPager ( command , pagingState , protocolVersion ) ; } protected void recordLatency ( TableMetrics metric , long latencyNanos ) { metric . readLatency . addNano ( latencyNanos ) ; } @SuppressWarnings ( <str> ) protected UnfilteredPartitionIterator queryStorage ( final ColumnFamilyStore cfs , ReadExecutionController executionController ) { UnfilteredRowIterator partition = cfs . isRowCacheEnabled ( ) ? getThroughCache ( cfs , executionController ) : queryMemtableAndDisk ( cfs , executionController ) ; return new SingletonUnfilteredPartitionIterator ( partition , isForThrift ( ) ) ; } private UnfilteredRowIterator getThroughCache ( ColumnFamilyStore cfs , ReadExecutionController executionController ) { assert ! cfs . isIndex ( ) ; assert cfs . isRowCacheEnabled ( ) : String . format ( <str> , cfs . name ) ; RowCacheKey key = new RowCacheKey ( metadata ( ) . ksAndCFName , partitionKey ( ) ) ; IRowCacheEntry cached = CacheService . instance . rowCache . get ( key ) ; if ( cached ! = null ) { if ( cached instanceof RowCacheSentinel ) { Tracing . trace ( <str> ) ; cfs . metric . rowCacheMiss . inc ( ) ; return queryMemtableAndDisk ( cfs , executionController ) ; } CachedPartition cachedPartition = ( CachedPartition ) cached ; if ( cfs . isFilterFullyCoveredBy ( clusteringIndexFilter ( ) , limits ( ) , cachedPartition , nowInSec ( ) ) ) { cfs . metric . rowCacheHit . inc ( ) ; Tracing . trace ( <str> ) ; UnfilteredRowIterator unfilteredRowIterator = clusteringIndexFilter ( ) . getUnfilteredRowIterator ( columnFilter ( ) , cachedPartition ) ; cfs . metric . updateSSTableIterated ( <int> ) ; return unfilteredRowIterator ; } cfs . metric . rowCacheHitOutOfRange . inc ( ) ; Tracing . trace ( <str> ) ; return queryMemtableAndDisk ( cfs , executionController ) ; } cfs . metric . rowCacheMiss . inc ( ) ; Tracing . trace ( <str> ) ; boolean cacheFullPartitions = metadata ( ) . params . caching . cacheAllRows ( ) ; if ( cacheFullPartitions | | clusteringIndexFilter ( ) . isHeadFilter ( ) ) { RowCacheSentinel sentinel = new RowCacheSentinel ( ) ; boolean sentinelSuccess = CacheService . instance . rowCache . putIfAbsent ( key , sentinel ) ; boolean sentinelReplaced = false ; try { int rowsToCache = metadata ( ) . params . caching . rowsPerPartitionToCache ( ) ; @SuppressWarnings ( <str> ) UnfilteredRowIterator iter = SinglePartitionReadCommand . fullPartitionRead ( metadata ( ) , nowInSec ( ) , partitionKey ( ) ) . queryMemtableAndDisk ( cfs , executionController ) ; try { CachedPartition toCache = CachedBTreePartition . create ( DataLimits . cqlLimits ( rowsToCache ) . filter ( iter , nowInSec ( ) ) , nowInSec ( ) ) ; if ( sentinelSuccess & & ! toCache . isEmpty ( ) ) { Tracing . trace ( <str> , toCache . rowCount ( ) ) ; CacheService . instance . rowCache . replace ( key , sentinel , toCache ) ; sentinelReplaced = true ; } UnfilteredRowIterator cacheIterator = clusteringIndexFilter ( ) . getUnfilteredRowIterator ( columnFilter ( ) , toCache ) ; if ( cacheFullPartitions ) { assert ! iter . hasNext ( ) ; iter . close ( ) ; return cacheIterator ; } return UnfilteredRowIterators . concat ( cacheIterator , clusteringIndexFilter ( ) . filterNotIndexed ( columnFilter ( ) , iter ) ) ; } catch ( RuntimeException | Error e ) { iter . close ( ) ; throw e ; } } finally { if ( sentinelSuccess & & ! sentinelReplaced ) cfs . invalidateCachedPartition ( key ) ; } } Tracing . trace ( <str> ) ; return queryMemtableAndDisk ( cfs , executionController ) ; } public UnfilteredRowIterator queryMemtableAndDisk ( ColumnFamilyStore cfs , OpOrder . Group readOp ) { return queryMemtableAndDisk ( cfs , ReadExecutionController . forReadOp ( readOp ) ) ; } public UnfilteredRowIterator queryMemtableAndDisk ( ColumnFamilyStore cfs , ReadExecutionController executionController ) { Tracing . trace ( <str> , cfs . name ) ; boolean copyOnHeap = Memtable . MEMORY_POOL . needToCopyOnHeap ( ) ; return queryMemtableAndDiskInternal ( cfs , copyOnHeap ) ; } @Override protected int oldestUnrepairedTombstone ( ) { return oldestUnrepairedTombstone ; } private UnfilteredRowIterator queryMemtableAndDiskInternal ( ColumnFamilyStore cfs , boolean copyOnHeap ) { if ( clusteringIndexFilter ( ) instanceof ClusteringIndexNamesFilter & & queryNeitherCountersNorCollections ( ) ) return queryMemtableAndSSTablesInTimestampOrder ( cfs , copyOnHeap , ( ClusteringIndexNamesFilter ) clusteringIndexFilter ( ) ) ; Tracing . trace ( <str> ) ; ColumnFamilyStore . ViewFragment view = cfs . select ( View . select ( SSTableSet . LIVE , partitionKey ( ) ) ) ; List < UnfilteredRowIterator > iterators = new ArrayList < > ( Iterables . size ( view . memtables ) + view . sstables . size ( ) ) ; ClusteringIndexFilter filter = clusteringIndexFilter ( ) ; try { for ( Memtable memtable : view . memtables ) { Partition partition = memtable . getPartition ( partitionKey ( ) ) ; if ( partition = = null ) continue ; @SuppressWarnings ( <str> ) UnfilteredRowIterator iter = filter . getUnfilteredRowIterator ( columnFilter ( ) , partition ) ; @SuppressWarnings ( <str> ) UnfilteredRowIterator maybeCopied = copyOnHeap ? UnfilteredRowIterators . cloningIterator ( iter , HeapAllocator . instance ) : iter ; oldestUnrepairedTombstone = Math . min ( oldestUnrepairedTombstone , partition . stats ( ) . minLocalDeletionTime ) ; iterators . add ( isForThrift ( ) ? ThriftResultsMerger . maybeWrap ( maybeCopied , nowInSec ( ) ) : maybeCopied ) ; } int sstablesIterated = <int> ; Collections . sort ( view . sstables , SSTableReader . maxTimestampComparator ) ; List < SSTableReader > skippedSSTables = null ; long mostRecentPartitionTombstone = Long . MIN_VALUE ; long minTimestamp = Long . MAX_VALUE ; int nonIntersectingSSTables = <int> ; for ( SSTableReader sstable : view . sstables ) { minTimestamp = Math . min ( minTimestamp , sstable . getMinTimestamp ( ) ) ; if ( sstable . getMaxTimestamp ( ) < mostRecentPartitionTombstone ) break ; if ( ! shouldInclude ( sstable ) ) { nonIntersectingSSTables + + ; if ( sstable . getSSTableMetadata ( ) . maxLocalDeletionTime ! = Integer . MAX_VALUE ) { if ( skippedSSTables = = null ) skippedSSTables = new ArrayList < > ( ) ; skippedSSTables . add ( sstable ) ; } continue ; } sstable . incrementReadCount ( ) ; @SuppressWarnings ( <str> ) UnfilteredRowIterator iter = filter . filter ( sstable . iterator ( partitionKey ( ) , columnFilter ( ) , filter . isReversed ( ) , isForThrift ( ) ) ) ; if ( ! sstable . isRepaired ( ) ) oldestUnrepairedTombstone = Math . min ( oldestUnrepairedTombstone , sstable . getMinLocalDeletionTime ( ) ) ; iterators . add ( isForThrift ( ) ? ThriftResultsMerger . maybeWrap ( iter , nowInSec ( ) ) : iter ) ; mostRecentPartitionTombstone = Math . max ( mostRecentPartitionTombstone , iter . partitionLevelDeletion ( ) . markedForDeleteAt ( ) ) ; sstablesIterated + + ; } int includedDueToTombstones = <int> ; if ( skippedSSTables ! = null ) { for ( SSTableReader sstable : skippedSSTables ) { if ( sstable . getMaxTimestamp ( ) < = minTimestamp ) continue ; sstable . incrementReadCount ( ) ; @SuppressWarnings ( <str> ) UnfilteredRowIterator iter = filter . filter ( sstable . iterator ( partitionKey ( ) , columnFilter ( ) , filter . isReversed ( ) , isForThrift ( ) ) ) ; if ( iter . partitionLevelDeletion ( ) . markedForDeleteAt ( ) > minTimestamp ) { iterators . add ( iter ) ; if ( ! sstable . isRepaired ( ) ) oldestUnrepairedTombstone = Math . min ( oldestUnrepairedTombstone , sstable . getMinLocalDeletionTime ( ) ) ; includedDueToTombstones + + ; sstablesIterated + + ; } else { iter . close ( ) ; } } } if ( Tracing . isTracing ( ) ) Tracing . trace ( <str> , nonIntersectingSSTables , view . sstables . size ( ) , includedDueToTombstones ) ; cfs . metric . updateSSTableIterated ( sstablesIterated ) ; if ( iterators . isEmpty ( ) ) return EmptyIterators . unfilteredRow ( cfs . metadata , partitionKey ( ) , filter . isReversed ( ) ) ; Tracing . trace ( <str> , sstablesIterated ) ; @SuppressWarnings ( <str> ) UnfilteredRowIterator merged = UnfilteredRowIterators . merge ( iterators , nowInSec ( ) ) ; if ( ! merged . isEmpty ( ) ) { DecoratedKey key = merged . partitionKey ( ) ; cfs . metric . samplers . get ( TableMetrics . Sampler . READS ) . addSample ( key . getKey ( ) , key . hashCode ( ) , <int> ) ; } return withStateTracking ( merged ) ; } catch ( RuntimeException | Error e ) { try { FBUtilities . closeAll ( iterators ) ; } catch ( Exception suppressed ) { e . addSuppressed ( suppressed ) ; } throw e ; } } private boolean shouldInclude ( SSTableReader sstable ) { if ( ! columnFilter ( ) . fetchedColumns ( ) . statics . isEmpty ( ) ) return true ; return clusteringIndexFilter ( ) . shouldInclude ( sstable ) ; } private boolean queryNeitherCountersNorCollections ( ) { for ( ColumnDefinition column : columnFilter ( ) . fetchedColumns ( ) ) { if ( column . type . isCollection ( ) | | column . type . isCounter ( ) ) return false ; } return true ; } private UnfilteredRowIterator queryMemtableAndSSTablesInTimestampOrder ( ColumnFamilyStore cfs , boolean copyOnHeap , ClusteringIndexNamesFilter filter ) { Tracing . trace ( <str> ) ; ColumnFamilyStore . ViewFragment view = cfs . select ( View . select ( SSTableSet . LIVE , partitionKey ( ) ) ) ; ImmutableBTreePartition result = null ; Tracing . trace ( <str> ) ; for ( Memtable memtable : view . memtables ) { Partition partition = memtable . getPartition ( partitionKey ( ) ) ; if ( partition = = null ) continue ; try ( UnfilteredRowIterator iter = filter . getUnfilteredRowIterator ( columnFilter ( ) , partition ) ) { if ( iter . isEmpty ( ) ) continue ; UnfilteredRowIterator clonedFilter = copyOnHeap ? UnfilteredRowIterators . cloningIterator ( iter , HeapAllocator . instance ) : iter ; result = add ( isForThrift ( ) ? ThriftResultsMerger . maybeWrap ( clonedFilter , nowInSec ( ) ) : clonedFilter , result , filter , false ) ; } } Collections . sort ( view . sstables , SSTableReader . maxTimestampComparator ) ; int sstablesIterated = <int> ; for ( SSTableReader sstable : view . sstables ) { if ( result ! = null & & sstable . getMaxTimestamp ( ) < result . partitionLevelDeletion ( ) . markedForDeleteAt ( ) ) break ; long currentMaxTs = sstable . getMaxTimestamp ( ) ; filter = reduceFilter ( filter , result , currentMaxTs ) ; if ( filter = = null ) break ; if ( ! shouldInclude ( sstable ) ) { if ( sstable . getSSTableMetadata ( ) . maxLocalDeletionTime = = Integer . MAX_VALUE ) continue ; sstable . incrementReadCount ( ) ; try ( UnfilteredRowIterator iter = sstable . iterator ( partitionKey ( ) , columnFilter ( ) , filter . isReversed ( ) , isForThrift ( ) ) ) { if ( iter . partitionLevelDeletion ( ) . isLive ( ) ) { sstablesIterated + + ; result = add ( UnfilteredRowIterators . noRowsIterator ( iter . metadata ( ) , iter . partitionKey ( ) , Rows . EMPTY_STATIC_ROW , iter . partitionLevelDeletion ( ) , filter . isReversed ( ) ) , result , filter , sstable . isRepaired ( ) ) ; } } continue ; } Tracing . trace ( <str> , sstable . descriptor . generation ) ; sstable . incrementReadCount ( ) ; try ( UnfilteredRowIterator iter = filter . filter ( sstable . iterator ( partitionKey ( ) , columnFilter ( ) , filter . isReversed ( ) , isForThrift ( ) ) ) ) { if ( iter . isEmpty ( ) ) continue ; sstablesIterated + + ; result = add ( isForThrift ( ) ? ThriftResultsMerger . maybeWrap ( iter , nowInSec ( ) ) : iter , result , filter , sstable . isRepaired ( ) ) ; } } cfs . metric . updateSSTableIterated ( sstablesIterated ) ; if ( result = = null | | result . isEmpty ( ) ) return EmptyIterators . unfilteredRow ( metadata ( ) , partitionKey ( ) , false ) ; DecoratedKey key = result . partitionKey ( ) ; cfs . metric . samplers . get ( TableMetrics . Sampler . READS ) . addSample ( key . getKey ( ) , key . hashCode ( ) , <int> ) ; if ( sstablesIterated > cfs . getMinimumCompactionThreshold ( ) & & ! cfs . isAutoCompactionDisabled ( ) & & cfs . getCompactionStrategyManager ( ) . shouldDefragment ( ) ) { Tracing . trace ( <str> ) ; try ( UnfilteredRowIterator iter = result . unfilteredIterator ( columnFilter ( ) , Slices . ALL , false ) ) { final Mutation mutation = new Mutation ( PartitionUpdate . fromIterator ( iter ) ) ; StageManager . getStage ( Stage . MUTATION ) . execute ( new Runnable ( ) { public void run ( ) { Keyspace . open ( mutation . getKeyspaceName ( ) ) . apply ( mutation , false , false ) ; } } ) ; } } return withStateTracking ( result . unfilteredIterator ( columnFilter ( ) , Slices . ALL , clusteringIndexFilter ( ) . isReversed ( ) ) ) ; } private ImmutableBTreePartition add ( UnfilteredRowIterator iter , ImmutableBTreePartition result , ClusteringIndexNamesFilter filter , boolean isRepaired ) { if ( ! isRepaired ) oldestUnrepairedTombstone = Math . min ( oldestUnrepairedTombstone , iter . stats ( ) . minLocalDeletionTime ) ; int maxRows = Math . max ( filter . requestedRows ( ) . size ( ) , <int> ) ; if ( result = = null ) return ImmutableBTreePartition . create ( iter , maxRows ) ; try ( UnfilteredRowIterator merged = UnfilteredRowIterators . merge ( Arrays . asList ( iter , result . unfilteredIterator ( columnFilter ( ) , Slices . ALL , filter . isReversed ( ) ) ) , nowInSec ( ) ) ) { return ImmutableBTreePartition . create ( merged , maxRows ) ; } } private ClusteringIndexNamesFilter reduceFilter ( ClusteringIndexNamesFilter filter , Partition result , long sstableTimestamp ) { if ( result = = null ) return filter ; SearchIterator < Clustering , Row > searchIter = result . searchIterator ( columnFilter ( ) , false ) ; PartitionColumns columns = columnFilter ( ) . fetchedColumns ( ) ; NavigableSet < Clustering > clusterings = filter . requestedRows ( ) ; boolean removeStatic = false ; if ( ! columns . statics . isEmpty ( ) ) { Row staticRow = searchIter . next ( Clustering . STATIC_CLUSTERING ) ; removeStatic = staticRow ! = null & & canRemoveRow ( staticRow , columns . statics , sstableTimestamp ) ; } NavigableSet < Clustering > toRemove = null ; for ( Clustering clustering : clusterings ) { if ( ! searchIter . hasNext ( ) ) break ; Row row = searchIter . next ( clustering ) ; if ( row = = null | | ! canRemoveRow ( row , columns . regulars , sstableTimestamp ) ) continue ; if ( toRemove = = null ) toRemove = new TreeSet < > ( result . metadata ( ) . comparator ) ; toRemove . add ( clustering ) ; } if ( ! removeStatic & & toRemove = = null ) return filter ; boolean hasNoMoreStatic = columns . statics . isEmpty ( ) | | removeStatic ; boolean hasNoMoreClusterings = clusterings . isEmpty ( ) | | ( toRemove ! = null & & toRemove . size ( ) = = clusterings . size ( ) ) ; if ( hasNoMoreStatic & & hasNoMoreClusterings ) return null ; if ( toRemove ! = null ) { BTreeSet . Builder < Clustering > newClusterings = BTreeSet . builder ( result . metadata ( ) . comparator ) ; newClusterings . addAll ( Sets . difference ( clusterings , toRemove ) ) ; clusterings = newClusterings . build ( ) ; } return new ClusteringIndexNamesFilter ( clusterings , filter . isReversed ( ) ) ; } private boolean canRemoveRow ( Row row , Columns requestedColumns , long sstableTimestamp ) { if ( row . primaryKeyLivenessInfo ( ) . isEmpty ( ) | | row . primaryKeyLivenessInfo ( ) . timestamp ( ) < = sstableTimestamp ) return false ; for ( ColumnDefinition column : requestedColumns ) { Cell cell = row . getCell ( column ) ; if ( cell = = null | | cell . timestamp ( ) < = sstableTimestamp ) return false ; } return true ; } @Override public String toString ( ) { return String . format ( <str> , metadata ( ) . ksName , metadata ( ) . cfName , columnFilter ( ) , rowFilter ( ) , limits ( ) , metadata ( ) . getKeyValidator ( ) . getString ( partitionKey ( ) . getKey ( ) ) , clusteringIndexFilter . toString ( metadata ( ) ) , nowInSec ( ) ) ; } public MessageOut < ReadCommand > createMessage ( int version ) { return new MessageOut < > ( MessagingService . Verb . READ , this , version < MessagingService . VERSION_30 ? legacyReadCommandSerializer : serializer ) ; } protected void appendCQLWhereClause ( StringBuilder sb ) { sb . append ( <str> ) ; sb . append ( ColumnDefinition . toCQLString ( metadata ( ) . partitionKeyColumns ( ) ) ) . append ( <str> ) ; DataRange . appendKeyString ( sb , metadata ( ) . getKeyValidator ( ) , partitionKey ( ) . getKey ( ) ) ; if ( ! rowFilter ( ) . isEmpty ( ) ) sb . append ( <str> ) . append ( rowFilter ( ) ) ; String filterString = clusteringIndexFilter ( ) . toCQLString ( metadata ( ) ) ; if ( ! filterString . isEmpty ( ) ) sb . append ( <str> ) . append ( filterString ) ; } protected void serializeSelection ( DataOutputPlus out , int version ) throws IOException { metadata ( ) . getKeyValidator ( ) . writeValue ( partitionKey ( ) . getKey ( ) , out ) ; ClusteringIndexFilter . serializer . serialize ( clusteringIndexFilter ( ) , out , version ) ; } protected long selectionSerializedSize ( int version ) { return metadata ( ) . getKeyValidator ( ) . writtenLength ( partitionKey ( ) . getKey ( ) ) + ClusteringIndexFilter . serializer . serializedSize ( clusteringIndexFilter ( ) , version ) ; } public static class Group implements ReadQuery { public final List < SinglePartitionReadCommand > commands ; private final DataLimits limits ; private final int nowInSec ; public Group ( List < SinglePartitionReadCommand > commands , DataLimits limits ) { assert ! commands . isEmpty ( ) ; this . commands = commands ; this . limits = limits ; this . nowInSec = commands . get ( <int> ) . nowInSec ( ) ; for ( int i = <int> ; i < commands . size ( ) ; i + + ) assert commands . get ( i ) . nowInSec ( ) = = nowInSec ; } public static Group one ( SinglePartitionReadCommand command ) { return new Group ( Collections . < SinglePartitionReadCommand > singletonList ( command ) , command . limits ( ) ) ; } public PartitionIterator execute ( ConsistencyLevel consistency , ClientState clientState ) throws RequestExecutionException { return StorageProxy . read ( this , consistency , clientState ) ; } public int nowInSec ( ) { return nowInSec ; } public DataLimits limits ( ) { return limits ; } public CFMetaData metadata ( ) { return commands . get ( <int> ) . metadata ( ) ; } public ReadExecutionController executionController ( ) { return commands . get ( <int> ) . executionController ( ) ; } public PartitionIterator executeInternal ( ReadExecutionController controller ) { List < PartitionIterator > partitions = new ArrayList < > ( commands . size ( ) ) ; for ( SinglePartitionReadCommand cmd : commands ) partitions . add ( cmd . executeInternal ( controller ) ) ; return limits . filter ( PartitionIterators . concat ( partitions ) , nowInSec ) ; } public QueryPager getPager ( PagingState pagingState , int protocolVersion ) { if ( commands . size ( ) = = <int> ) return SinglePartitionReadCommand . getPager ( commands . get ( <int> ) , pagingState , protocolVersion ) ; return new MultiPartitionPager ( this , pagingState , protocolVersion ) ; } public boolean selectsKey ( DecoratedKey key ) { return Iterables . any ( commands , c - > c . selectsKey ( key ) ) ; } public boolean selectsClustering ( DecoratedKey key , Clustering clustering ) { return Iterables . any ( commands , c - > c . selectsClustering ( key , clustering ) ) ; } @Override public String toString ( ) { return commands . toString ( ) ; } } private static class Deserializer extends SelectionDeserializer { public ReadCommand deserialize ( DataInputPlus in , int version , boolean isDigest , int digestVersion , boolean isForThrift , CFMetaData metadata , int nowInSec , ColumnFilter columnFilter , RowFilter rowFilter , DataLimits limits , Optional < IndexMetadata > index ) throws IOException { DecoratedKey key = metadata . decorateKey ( metadata . getKeyValidator ( ) . readValue ( in ) ) ; ClusteringIndexFilter filter = ClusteringIndexFilter . serializer . deserialize ( in , version , metadata ) ; return new SinglePartitionReadCommand ( isDigest , digestVersion , isForThrift , metadata , nowInSec , columnFilter , rowFilter , limits , key , filter ) ; } } } 
