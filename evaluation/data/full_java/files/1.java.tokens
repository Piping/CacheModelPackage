import java . io . IOException ; import java . nio . ByteBuffer ; import java . nio . charset . CharacterCodingException ; import java . util . * ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; import org . apache . cassandra . hadoop . cql3 . CqlConfigHelper ; import org . apache . cassandra . hadoop . cql3 . CqlInputFormat ; import org . apache . hadoop . conf . Configuration ; import org . apache . hadoop . conf . Configured ; import org . apache . hadoop . fs . Path ; import org . apache . hadoop . io . Text ; import org . apache . hadoop . io . LongWritable ; import org . apache . hadoop . mapreduce . Job ; import org . apache . hadoop . mapreduce . Mapper ; import org . apache . hadoop . mapreduce . Reducer ; import org . apache . hadoop . mapreduce . lib . output . FileOutputFormat ; import org . apache . hadoop . util . Tool ; import org . apache . hadoop . util . ToolRunner ; import com . datastax . driver . core . Row ; import org . apache . cassandra . hadoop . ConfigHelper ; import org . apache . cassandra . utils . ByteBufferUtil ; public class WordCountCounters extends Configured implements Tool { private static final Logger logger = LoggerFactory . getLogger ( WordCountCounters . class ) ; static final String INPUT_MAPPER_VAR = <str> ; static final String COUNTER_COLUMN_FAMILY = <str> ; private static final String OUTPUT_PATH_PREFIX = <str> ; public static void main ( String [ ] args ) throws Exception { ToolRunner . run ( new Configuration ( ) , new WordCountCounters ( ) , args ) ; System . exit ( <int> ) ; } public static class SumNativeMapper extends Mapper < Long , Row , Text , LongWritable > { long sum = - <int> ; public void map ( Long key , Row row , Context context ) throws IOException , InterruptedException { if ( sum < <int> ) sum = <int> ; logger . debug ( <str> + key + <str> + context . getInputSplit ( ) ) ; sum + = Long . valueOf ( row . getString ( <str> ) ) ; } protected void cleanup ( Context context ) throws IOException , InterruptedException { if ( sum > <int> ) context . write ( new Text ( <str> ) , new LongWritable ( sum ) ) ; } } public static class SumMapper extends Mapper < Map < String , ByteBuffer > , Map < String , ByteBuffer > , Text , LongWritable > { long sum = - <int> ; public void map ( Map < String , ByteBuffer > key , Map < String , ByteBuffer > columns , Context context ) throws IOException , InterruptedException { if ( sum < <int> ) sum = <int> ; logger . debug ( <str> + toString ( key ) + <str> + context . getInputSplit ( ) ) ; sum + = Long . valueOf ( ByteBufferUtil . string ( columns . get ( <str> ) ) ) ; } protected void cleanup ( Context context ) throws IOException , InterruptedException { if ( sum > <int> ) context . write ( new Text ( <str> ) , new LongWritable ( sum ) ) ; } private String toString ( Map < String , ByteBuffer > keys ) { String result = <str> ; try { for ( ByteBuffer key : keys . values ( ) ) result = result + ByteBufferUtil . string ( key ) + <str> ; } catch ( CharacterCodingException e ) { logger . error ( <str> , e ) ; } return result ; } } public static class ReducerToFilesystem extends Reducer < Text , LongWritable , Text , LongWritable > { long sum = <int> ; public void reduce ( Text key , Iterable < LongWritable > values , Context context ) throws IOException , InterruptedException { for ( LongWritable val : values ) sum + = val . get ( ) ; context . write ( key , new LongWritable ( sum ) ) ; } } public int run ( String [ ] args ) throws Exception { String inputMapperType = <str> ; if ( args ! = null & & args [ <int> ] . startsWith ( INPUT_MAPPER_VAR ) ) { String [ ] arg0 = args [ <int> ] . split ( <str> ) ; if ( arg0 ! = null & & arg0 . length = = <int> ) inputMapperType = arg0 [ <int> ] ; } Job job = new Job ( getConf ( ) , <str> ) ; job . setCombinerClass ( ReducerToFilesystem . class ) ; job . setReducerClass ( ReducerToFilesystem . class ) ; job . setJarByClass ( WordCountCounters . class ) ; ConfigHelper . setInputInitialAddress ( job . getConfiguration ( ) , <str> ) ; ConfigHelper . setInputPartitioner ( job . getConfiguration ( ) , <str> ) ; ConfigHelper . setInputColumnFamily ( job . getConfiguration ( ) , WordCount . KEYSPACE , WordCount . OUTPUT_COLUMN_FAMILY ) ; CqlConfigHelper . setInputCQLPageRowSize ( job . getConfiguration ( ) , <str> ) ; if ( <str> . equals ( inputMapperType ) ) { job . setMapperClass ( SumNativeMapper . class ) ; job . setInputFormatClass ( CqlInputFormat . class ) ; CqlConfigHelper . setInputCql ( job . getConfiguration ( ) , <str> + WordCount . OUTPUT_COLUMN_FAMILY + <str> ) ; } else { job . setMapperClass ( SumMapper . class ) ; job . setInputFormatClass ( CqlInputFormat . class ) ; ConfigHelper . setInputRpcPort ( job . getConfiguration ( ) , <str> ) ; } job . setOutputKeyClass ( Text . class ) ; job . setOutputValueClass ( LongWritable . class ) ; FileOutputFormat . setOutputPath ( job , new Path ( OUTPUT_PATH_PREFIX ) ) ; job . waitForCompletion ( true ) ; return <int> ; } } 
