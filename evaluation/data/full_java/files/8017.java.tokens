package org . elasticsearch . deps . lucene ; import org . apache . lucene . document . Document ; import org . apache . lucene . document . Field ; import org . apache . lucene . document . FieldType ; import org . apache . lucene . document . IntField ; import org . apache . lucene . document . SortedDocValuesField ; import org . apache . lucene . document . TextField ; import org . apache . lucene . index . DirectoryReader ; import org . apache . lucene . index . FieldInfo ; import org . apache . lucene . index . IndexOptions ; import org . apache . lucene . index . IndexReader ; import org . apache . lucene . index . IndexWriter ; import org . apache . lucene . index . IndexWriterConfig ; import org . apache . lucene . index . IndexableField ; import org . apache . lucene . index . LeafReader ; import org . apache . lucene . index . PostingsEnum ; import org . apache . lucene . index . SlowCompositeReaderWrapper ; import org . apache . lucene . index . StoredFieldVisitor ; import org . apache . lucene . index . Term ; import org . apache . lucene . index . Terms ; import org . apache . lucene . index . TermsEnum ; import org . apache . lucene . search . FieldDoc ; import org . apache . lucene . search . IndexSearcher ; import org . apache . lucene . search . MatchAllDocsQuery ; import org . apache . lucene . search . Sort ; import org . apache . lucene . search . SortField ; import org . apache . lucene . search . TermQuery ; import org . apache . lucene . search . TopDocs ; import org . apache . lucene . search . TopFieldDocs ; import org . apache . lucene . store . Directory ; import org . apache . lucene . store . RAMDirectory ; import org . apache . lucene . util . BytesRef ; import org . apache . lucene . util . BytesRefBuilder ; import org . apache . lucene . util . NumericUtils ; import org . elasticsearch . common . lucene . Lucene ; import org . elasticsearch . test . ESTestCase ; import java . io . IOException ; import java . util . ArrayList ; import static org . hamcrest . Matchers . equalTo ; public class SimpleLuceneTests extends ESTestCase { public void testSortValues ( ) throws Exception { Directory dir = new RAMDirectory ( ) ; IndexWriter indexWriter = new IndexWriter ( dir , new IndexWriterConfig ( Lucene . STANDARD_ANALYZER ) ) ; for ( int i = <int> ; i < <int> ; i + + ) { Document document = new Document ( ) ; String text = new String ( new char [ ] { ( char ) ( <int> + i ) , ( char ) ( <int> + i ) } ) ; document . add ( new TextField ( <str> , text , Field . Store . YES ) ) ; document . add ( new SortedDocValuesField ( <str> , new BytesRef ( text ) ) ) ; indexWriter . addDocument ( document ) ; } IndexReader reader = SlowCompositeReaderWrapper . wrap ( DirectoryReader . open ( indexWriter , true ) ) ; IndexSearcher searcher = new IndexSearcher ( reader ) ; TopFieldDocs docs = searcher . search ( new MatchAllDocsQuery ( ) , null , <int> , new Sort ( new SortField ( <str> , SortField . Type . STRING ) ) ) ; for ( int i = <int> ; i < <int> ; i + + ) { FieldDoc fieldDoc = ( FieldDoc ) docs . scoreDocs [ i ] ; assertThat ( ( BytesRef ) fieldDoc . fields [ <int> ] , equalTo ( new BytesRef ( new String ( new char [ ] { ( char ) ( <int> + i ) , ( char ) ( <int> + i ) } ) ) ) ) ; } } public void testSimpleNumericOps ( ) throws Exception { Directory dir = new RAMDirectory ( ) ; IndexWriter indexWriter = new IndexWriter ( dir , new IndexWriterConfig ( Lucene . STANDARD_ANALYZER ) ) ; Document document = new Document ( ) ; document . add ( new TextField ( <str> , <str> , Field . Store . YES ) ) ; document . add ( new IntField ( <str> , <int> , IntField . TYPE_STORED ) ) ; indexWriter . addDocument ( document ) ; IndexReader reader = DirectoryReader . open ( indexWriter , true ) ; IndexSearcher searcher = new IndexSearcher ( reader ) ; TopDocs topDocs = searcher . search ( new TermQuery ( new Term ( <str> , <str> ) ) , <int> ) ; Document doc = searcher . doc ( topDocs . scoreDocs [ <int> ] . doc ) ; IndexableField f = doc . getField ( <str> ) ; assertThat ( f . stringValue ( ) , equalTo ( <str> ) ) ; BytesRefBuilder bytes = new BytesRefBuilder ( ) ; NumericUtils . intToPrefixCoded ( <int> , <int> , bytes ) ; topDocs = searcher . search ( new TermQuery ( new Term ( <str> , bytes . get ( ) ) ) , <int> ) ; doc = searcher . doc ( topDocs . scoreDocs [ <int> ] . doc ) ; f = doc . getField ( <str> ) ; assertThat ( f . stringValue ( ) , equalTo ( <str> ) ) ; indexWriter . close ( ) ; } public void testOrdering ( ) throws Exception { Directory dir = new RAMDirectory ( ) ; IndexWriter indexWriter = new IndexWriter ( dir , new IndexWriterConfig ( Lucene . STANDARD_ANALYZER ) ) ; Document document = new Document ( ) ; document . add ( new TextField ( <str> , <str> , Field . Store . YES ) ) ; document . add ( new TextField ( <str> , <str> , Field . Store . YES ) ) ; indexWriter . addDocument ( document ) ; IndexReader reader = DirectoryReader . open ( indexWriter , true ) ; IndexSearcher searcher = new IndexSearcher ( reader ) ; TopDocs topDocs = searcher . search ( new TermQuery ( new Term ( <str> , <str> ) ) , <int> ) ; final ArrayList < String > fieldsOrder = new ArrayList < > ( ) ; searcher . doc ( topDocs . scoreDocs [ <int> ] . doc , new StoredFieldVisitor ( ) { @Override public Status needsField ( FieldInfo fieldInfo ) throws IOException { fieldsOrder . add ( fieldInfo . name ) ; return Status . YES ; } } ) ; assertThat ( fieldsOrder . size ( ) , equalTo ( <int> ) ) ; assertThat ( fieldsOrder . get ( <int> ) , equalTo ( <str> ) ) ; assertThat ( fieldsOrder . get ( <int> ) , equalTo ( <str> ) ) ; indexWriter . close ( ) ; } public void testBoost ( ) throws Exception { Directory dir = new RAMDirectory ( ) ; IndexWriter indexWriter = new IndexWriter ( dir , new IndexWriterConfig ( Lucene . STANDARD_ANALYZER ) ) ; for ( int i = <int> ; i < <int> ; i + + ) { StringBuilder value = new StringBuilder ( ) . append ( <str> ) ; for ( int j = <int> ; j < i ; j + + ) { value . append ( <str> ) . append ( <str> ) ; } Document document = new Document ( ) ; TextField textField = new TextField ( <str> , Integer . toString ( i ) , Field . Store . YES ) ; textField . setBoost ( i ) ; document . add ( textField ) ; textField = new TextField ( <str> , value . toString ( ) , Field . Store . YES ) ; textField . setBoost ( i ) ; document . add ( textField ) ; indexWriter . addDocument ( document ) ; } IndexReader reader = DirectoryReader . open ( indexWriter , true ) ; IndexSearcher searcher = new IndexSearcher ( reader ) ; TermQuery query = new TermQuery ( new Term ( <str> , <str> ) ) ; TopDocs topDocs = searcher . search ( query , <int> ) ; assertThat ( <int> , equalTo ( topDocs . totalHits ) ) ; for ( int i = <int> ; i < topDocs . scoreDocs . length ; i + + ) { Document doc = searcher . doc ( topDocs . scoreDocs [ i ] . doc ) ; assertThat ( doc . get ( <str> ) , equalTo ( Integer . toString ( <int> - i - <int> ) ) ) ; } indexWriter . close ( ) ; } public void testNRTSearchOnClosedWriter ( ) throws Exception { Directory dir = new RAMDirectory ( ) ; IndexWriter indexWriter = new IndexWriter ( dir , new IndexWriterConfig ( Lucene . STANDARD_ANALYZER ) ) ; DirectoryReader reader = DirectoryReader . open ( indexWriter , true ) ; for ( int i = <int> ; i < <int> ; i + + ) { Document document = new Document ( ) ; TextField field = new TextField ( <str> , Integer . toString ( i ) , Field . Store . YES ) ; field . setBoost ( i ) ; document . add ( field ) ; indexWriter . addDocument ( document ) ; } reader = refreshReader ( reader ) ; indexWriter . close ( ) ; TermsEnum termDocs = SlowCompositeReaderWrapper . wrap ( reader ) . terms ( <str> ) . iterator ( ) ; termDocs . next ( ) ; } public void testNumericTermDocsFreqs ( ) throws Exception { Directory dir = new RAMDirectory ( ) ; IndexWriter indexWriter = new IndexWriter ( dir , new IndexWriterConfig ( Lucene . STANDARD_ANALYZER ) ) ; Document doc = new Document ( ) ; FieldType type = IntField . TYPE_NOT_STORED ; IntField field = new IntField ( <str> , <int> , type ) ; doc . add ( field ) ; type = new FieldType ( IntField . TYPE_NOT_STORED ) ; type . setIndexOptions ( IndexOptions . DOCS_AND_FREQS ) ; type . freeze ( ) ; field = new IntField ( <str> , <int> , type ) ; doc . add ( field ) ; field = new IntField ( <str> , <int> , type ) ; doc . add ( field ) ; field = new IntField ( <str> , <int> , type ) ; doc . add ( field ) ; indexWriter . addDocument ( doc ) ; IndexReader reader = DirectoryReader . open ( indexWriter , true ) ; LeafReader atomicReader = SlowCompositeReaderWrapper . wrap ( reader ) ; Terms terms = atomicReader . terms ( <str> ) ; TermsEnum termsEnum = terms . iterator ( ) ; termsEnum . next ( ) ; PostingsEnum termDocs = termsEnum . postings ( null ) ; assertThat ( termDocs . nextDoc ( ) , equalTo ( <int> ) ) ; assertThat ( termDocs . docID ( ) , equalTo ( <int> ) ) ; assertThat ( termDocs . freq ( ) , equalTo ( <int> ) ) ; terms = atomicReader . terms ( <str> ) ; termsEnum = terms . iterator ( ) ; termsEnum . next ( ) ; termDocs = termsEnum . postings ( termDocs ) ; assertThat ( termDocs . nextDoc ( ) , equalTo ( <int> ) ) ; assertThat ( termDocs . docID ( ) , equalTo ( <int> ) ) ; assertThat ( termDocs . freq ( ) , equalTo ( <int> ) ) ; reader . close ( ) ; indexWriter . close ( ) ; } private DirectoryReader refreshReader ( DirectoryReader reader ) throws IOException { DirectoryReader oldReader = reader ; reader = DirectoryReader . openIfChanged ( reader ) ; if ( reader ! = oldReader ) { oldReader . close ( ) ; } return reader ; } } 
