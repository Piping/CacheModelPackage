package org . apache . cassandra . utils ; import java . io . DataInputStream ; import java . io . IOException ; import org . junit . Assert ; import org . junit . Test ; import org . apache . cassandra . AbstractSerializationsTester ; import org . apache . cassandra . Util ; import org . apache . cassandra . db . DecoratedKey ; import org . apache . cassandra . db . marshal . Int32Type ; import org . apache . cassandra . io . util . DataInputPlus . DataInputStreamPlus ; import org . apache . cassandra . io . util . DataOutputStreamPlus ; import org . apache . cassandra . dht . IPartitioner ; import org . apache . cassandra . dht . Murmur3Partitioner ; import java . io . File ; import java . io . FileInputStream ; public class SerializationsTest extends AbstractSerializationsTester { private static void testBloomFilterWrite ( boolean offheap , boolean oldBfHashOrder ) throws IOException { IPartitioner partitioner = Util . testPartitioner ( ) ; try ( IFilter bf = FilterFactory . getFilter ( <int> , <float> , offheap , oldBfHashOrder ) ) { for ( int i = <int> ; i < <int> ; i + + ) bf . add ( partitioner . decorateKey ( partitioner . getTokenFactory ( ) . toByteArray ( partitioner . getRandomToken ( ) ) ) ) ; try ( DataOutputStreamPlus out = getOutput ( oldBfHashOrder ? <str> : <str> , <str> ) ) { FilterFactory . serialize ( bf , out ) ; } } } private static void testBloomFilterWrite1000 ( boolean offheap , boolean oldBfHashOrder ) throws IOException { try ( IFilter bf = FilterFactory . getFilter ( <int> , <float> , offheap , oldBfHashOrder ) ) { for ( int i = <int> ; i < <int> ; i + + ) bf . add ( Util . dk ( Int32Type . instance . decompose ( i ) ) ) ; try ( DataOutputStreamPlus out = getOutput ( oldBfHashOrder ? <str> : <str> , <str> ) ) { FilterFactory . serialize ( bf , out ) ; } } } @Test public void testBloomFilterRead1000 ( ) throws IOException { if ( EXECUTE_WRITES ) { testBloomFilterWrite1000 ( true , false ) ; testBloomFilterWrite1000 ( true , true ) ; } try ( DataInputStream in = getInput ( <str> , <str> ) ; IFilter filter = FilterFactory . deserialize ( in , true , false ) ) { boolean present ; for ( int i = <int> ; i < <int> ; i + + ) { present = filter . isPresent ( Util . dk ( Int32Type . instance . decompose ( i ) ) ) ; Assert . assertTrue ( present ) ; } for ( int i = <int> ; i < <int> ; i + + ) { present = filter . isPresent ( Util . dk ( Int32Type . instance . decompose ( i ) ) ) ; Assert . assertFalse ( present ) ; } } try ( DataInputStream in = getInput ( <str> , <str> ) ; IFilter filter = FilterFactory . deserialize ( in , true , true ) ) { boolean present ; for ( int i = <int> ; i < <int> ; i + + ) { present = filter . isPresent ( Util . dk ( Int32Type . instance . decompose ( i ) ) ) ; Assert . assertTrue ( present ) ; } for ( int i = <int> ; i < <int> ; i + + ) { present = filter . isPresent ( Util . dk ( Int32Type . instance . decompose ( i ) ) ) ; Assert . assertFalse ( present ) ; } } int falsePositive = <int> ; int falseNegative = <int> ; try ( DataInputStream in = getInput ( <str> , <str> ) ; IFilter filter = FilterFactory . deserialize ( in , true , false ) ) { boolean present ; for ( int i = <int> ; i < <int> ; i + + ) { present = filter . isPresent ( Util . dk ( Int32Type . instance . decompose ( i ) ) ) ; if ( ! present ) falseNegative + + ; } for ( int i = <int> ; i < <int> ; i + + ) { present = filter . isPresent ( Util . dk ( Int32Type . instance . decompose ( i ) ) ) ; if ( present ) falsePositive + + ; } } Assert . assertEquals ( <int> , falseNegative ) ; Assert . assertEquals ( <int> , falsePositive ) ; } @Test public void testBloomFilterTable ( ) throws Exception { testBloomFilterTable ( <str> , true ) ; testBloomFilterTable ( <str> , false ) ; } private static void testBloomFilterTable ( String file , boolean oldBfHashOrder ) throws Exception { Murmur3Partitioner partitioner = new Murmur3Partitioner ( ) ; try ( DataInputStream in = new DataInputStream ( new FileInputStream ( new File ( file ) ) ) ; IFilter filter = FilterFactory . deserialize ( in , true , oldBfHashOrder ) ) { for ( int i = <int> ; i < = <int> ; i + + ) { DecoratedKey decoratedKey = partitioner . decorateKey ( Int32Type . instance . decompose ( i ) ) ; boolean present = filter . isPresent ( decoratedKey ) ; Assert . assertTrue ( present ) ; } int positives = <int> ; for ( int i = <int> ; i < = <int> ; i + + ) { DecoratedKey decoratedKey = partitioner . decorateKey ( Int32Type . instance . decompose ( i ) ) ; boolean present = filter . isPresent ( decoratedKey ) ; if ( present ) positives + + ; } double fpr = positives ; fpr / = <int> ; Assert . assertTrue ( fpr < = <float> ) ; } } @Test public void testBloomFilterReadMURMUR3 ( ) throws IOException { if ( EXECUTE_WRITES ) testBloomFilterWrite ( true , true ) ; try ( DataInputStream in = getInput ( <str> , <str> ) ; IFilter filter = FilterFactory . deserialize ( in , true , true ) ) { Assert . assertNotNull ( filter ) ; } } @Test public void testBloomFilterReadMURMUR3pre30 ( ) throws IOException { if ( EXECUTE_WRITES ) testBloomFilterWrite ( true , false ) ; try ( DataInputStream in = getInput ( <str> , <str> ) ; IFilter filter = FilterFactory . deserialize ( in , true , false ) ) { Assert . assertNotNull ( filter ) ; } } private static void testEstimatedHistogramWrite ( ) throws IOException { EstimatedHistogram hist0 = new EstimatedHistogram ( ) ; EstimatedHistogram hist1 = new EstimatedHistogram ( <int> ) ; long [ ] offsets = new long [ <int> ] ; long [ ] data = new long [ offsets . length + <int> ] ; for ( int i = <int> ; i < offsets . length ; i + + ) { offsets [ i ] = i ; data [ i ] = <int> * i ; } data [ offsets . length ] = <int> ; EstimatedHistogram hist2 = new EstimatedHistogram ( offsets , data ) ; try ( DataOutputStreamPlus out = getOutput ( <str> ) ) { EstimatedHistogram . serializer . serialize ( hist0 , out ) ; EstimatedHistogram . serializer . serialize ( hist1 , out ) ; EstimatedHistogram . serializer . serialize ( hist2 , out ) ; } } @Test public void testEstimatedHistogramRead ( ) throws IOException { if ( EXECUTE_WRITES ) testEstimatedHistogramWrite ( ) ; try ( DataInputStreamPlus in = getInput ( <str> ) ) { Assert . assertNotNull ( EstimatedHistogram . serializer . deserialize ( in ) ) ; Assert . assertNotNull ( EstimatedHistogram . serializer . deserialize ( in ) ) ; Assert . assertNotNull ( EstimatedHistogram . serializer . deserialize ( in ) ) ; } } } 
