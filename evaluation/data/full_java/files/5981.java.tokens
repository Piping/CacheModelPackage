package org . elasticsearch . common . lucene . all ; import org . apache . lucene . analysis . Analyzer ; import org . apache . lucene . analysis . TokenFilter ; import org . apache . lucene . analysis . TokenStream ; import org . apache . lucene . analysis . tokenattributes . OffsetAttribute ; import org . apache . lucene . analysis . tokenattributes . PayloadAttribute ; import org . apache . lucene . util . BytesRef ; import java . io . IOException ; import static org . apache . lucene . analysis . payloads . PayloadHelper . encodeFloat ; public final class AllTokenStream extends TokenFilter { public static TokenStream allTokenStream ( String allFieldName , AllEntries allEntries , Analyzer analyzer ) throws IOException { return new AllTokenStream ( analyzer . tokenStream ( allFieldName , allEntries ) , allEntries ) ; } private final BytesRef payloadSpare = new BytesRef ( new byte [ <int> ] ) ; private final AllEntries allEntries ; private final OffsetAttribute offsetAttribute ; private final PayloadAttribute payloadAttribute ; AllTokenStream ( TokenStream input , AllEntries allEntries ) { super ( input ) ; this . allEntries = allEntries ; offsetAttribute = addAttribute ( OffsetAttribute . class ) ; payloadAttribute = addAttribute ( PayloadAttribute . class ) ; } public AllEntries allEntries ( ) { return allEntries ; } @Override public final boolean incrementToken ( ) throws IOException { if ( ! input . incrementToken ( ) ) { return false ; } final float boost = allEntries . boost ( offsetAttribute . startOffset ( ) ) ; if ( boost ! = <float> ) { encodeFloat ( boost , payloadSpare . bytes , payloadSpare . offset ) ; payloadAttribute . setPayload ( payloadSpare ) ; } else { payloadAttribute . setPayload ( null ) ; } return true ; } @Override public String toString ( ) { return allEntries . toString ( ) ; } } 
