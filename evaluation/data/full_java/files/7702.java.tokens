package org . apache . lucene . analysis . miscellaneous ; import org . apache . lucene . analysis . Analyzer ; import org . apache . lucene . analysis . MockTokenizer ; import org . apache . lucene . analysis . TokenStream ; import org . apache . lucene . analysis . Tokenizer ; import org . apache . lucene . analysis . tokenattributes . CharTermAttribute ; import org . elasticsearch . test . ESTestCase ; import java . io . IOException ; import static org . hamcrest . Matchers . equalTo ; public class UniqueTokenFilterTests extends ESTestCase { public void testSimple ( ) throws IOException { Analyzer analyzer = new Analyzer ( ) { @Override protected TokenStreamComponents createComponents ( String fieldName ) { Tokenizer t = new MockTokenizer ( MockTokenizer . WHITESPACE , false ) ; return new TokenStreamComponents ( t , new UniqueTokenFilter ( t ) ) ; } } ; TokenStream test = analyzer . tokenStream ( <str> , <str> ) ; test . reset ( ) ; CharTermAttribute termAttribute = test . addAttribute ( CharTermAttribute . class ) ; assertThat ( test . incrementToken ( ) , equalTo ( true ) ) ; assertThat ( termAttribute . toString ( ) , equalTo ( <str> ) ) ; assertThat ( test . incrementToken ( ) , equalTo ( true ) ) ; assertThat ( termAttribute . toString ( ) , equalTo ( <str> ) ) ; assertThat ( test . incrementToken ( ) , equalTo ( true ) ) ; assertThat ( termAttribute . toString ( ) , equalTo ( <str> ) ) ; assertThat ( test . incrementToken ( ) , equalTo ( false ) ) ; } } 
