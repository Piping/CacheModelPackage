package org . nd4j . linalg . lossfunctions ; import lombok . Builder ; import lombok . Data ; import org . nd4j . linalg . api . ndarray . INDArray ; import org . nd4j . linalg . api . ops . impl . transforms . LogSoftMax ; import org . nd4j . linalg . factory . Nd4j ; import org . nd4j . linalg . indexing . BooleanIndexing ; import org . nd4j . linalg . indexing . conditions . Conditions ; import org . nd4j . linalg . indexing . conditions . Or ; import org . nd4j . linalg . indexing . functions . StableNumber ; import org . nd4j . linalg . indexing . functions . Value ; import static org . nd4j . linalg . ops . transforms . Transforms . log ; import static org . nd4j . linalg . ops . transforms . Transforms . pow ; import static org . nd4j . linalg . ops . transforms . Transforms . sqrt ; public @Data @Builder class LossCalculation { private INDArray labels ; private INDArray z ; private double l1 , l2 ; private LossFunctions . LossFunction lossFunction ; private boolean useRegularization ; private boolean miniBatch = false ; private int miniBatchSize ; private String activationFn ; private INDArray preOut ; public double score ( ) { double ret = <float> ; switch ( lossFunction ) { case CUSTOM : throw new IllegalStateException ( <str> ) ; case RECONSTRUCTION_CROSSENTROPY : INDArray xEntLogZ2 = logZ ( z ) ; INDArray xEntOneMinusLabelsOut2 = labels . rsub ( <int> ) ; INDArray xEntOneMinusLogOneMinusZ2 = xEntLogZ2 . rsubi ( <int> ) ; ret = - labels . mul ( xEntLogZ2 ) . add ( xEntOneMinusLabelsOut2 ) . muli ( xEntOneMinusLogOneMinusZ2 ) . sumNumber ( ) . doubleValue ( ) ; break ; case NEGATIVELOGLIKELIHOOD : case MCXENT : if ( preOut ! = null & & <str> . equals ( activationFn ) ) { INDArray logsoftmax = Nd4j . getExecutioner ( ) . execAndReturn ( new LogSoftMax ( preOut . dup ( ) ) , <int> ) ; INDArray sums = labels . mul ( logsoftmax ) ; ret = - sums . sumNumber ( ) . doubleValue ( ) ; } else { INDArray sums = labels . mul ( logZ ( z ) ) ; ret = - sums . sumNumber ( ) . doubleValue ( ) ; } break ; case XENT : INDArray xEntLogZ = logZ ( z ) ; INDArray xEntOneMinusLabelsOut = labels . rsub ( <int> ) ; INDArray xEntOneMinusLogOneMinusZ = xEntLogZ . dup ( ) . rsubi ( <int> ) ; ret = labels . mul ( xEntLogZ ) . add ( xEntOneMinusLabelsOut ) . muli ( xEntOneMinusLogOneMinusZ ) . sum ( <int> ) . sumNumber ( ) . doubleValue ( ) ; break ; case RMSE_XENT : INDArray rmseXentDiff = labels . sub ( z ) ; INDArray squaredrmseXentDiff = pow ( rmseXentDiff , <float> ) ; INDArray sqrt = sqrt ( squaredrmseXentDiff ) ; ret = sqrt . sumNumber ( ) . doubleValue ( ) ; break ; case MSE : INDArray mseDelta = labels . sub ( z ) ; ret = <float> * pow ( mseDelta , <int> ) . sum ( <int> ) . sumNumber ( ) . doubleValue ( ) ; break ; case EXPLL : INDArray expLLLogZ = logZ ( z ) ; ret = z . sub ( labels . mul ( expLLLogZ ) ) . sumNumber ( ) . doubleValue ( ) ; break ; case SQUARED_LOSS : ret = pow ( labels . sub ( z ) , <int> ) . sumNumber ( ) . doubleValue ( ) ; break ; } if ( useRegularization ) { ret + = l1 + l2 ; } if ( miniBatch ) ret / = ( double ) miniBatchSize ; return ret ; } private static INDArray logZ ( INDArray z ) { INDArray log = log ( z , true ) ; switch ( log . data ( ) . dataType ( ) ) { case FLOAT : BooleanIndexing . applyWhere ( log , new Or ( Conditions . isNan ( ) , Conditions . isInfinite ( ) ) , new StableNumber ( StableNumber . Type . FLOAT ) ) ; break ; case DOUBLE : BooleanIndexing . applyWhere ( log , new Or ( Conditions . isNan ( ) , Conditions . isInfinite ( ) ) , new StableNumber ( StableNumber . Type . DOUBLE ) ) ; break ; case INT : BooleanIndexing . applyWhere ( log , new Or ( Conditions . isNan ( ) , Conditions . isInfinite ( ) ) , new Value ( - Integer . MAX_VALUE ) ) ; break ; default : throw new RuntimeException ( <str> + log . data ( ) . dataType ( ) ) ; } return log ; } } 
