package org . elasticsearch . common . lucene . search ; import com . carrotsearch . hppc . ObjectHashSet ; import org . apache . lucene . index . * ; import org . apache . lucene . search . MatchNoDocsQuery ; import org . apache . lucene . search . MultiPhraseQuery ; import org . apache . lucene . search . Query ; import org . apache . lucene . util . BytesRef ; import org . apache . lucene . util . StringHelper ; import org . apache . lucene . util . ToStringUtils ; import java . io . IOException ; import java . util . * ; public class MultiPhrasePrefixQuery extends Query { private String field ; private ArrayList < Term [ ] > termArrays = new ArrayList < > ( ) ; private ArrayList < Integer > positions = new ArrayList < > ( ) ; private int maxExpansions = Integer . MAX_VALUE ; private int slop = <int> ; public void setSlop ( int s ) { slop = s ; } public void setMaxExpansions ( int maxExpansions ) { this . maxExpansions = maxExpansions ; } public int getSlop ( ) { return slop ; } public void add ( Term term ) { add ( new Term [ ] { term } ) ; } public void add ( Term [ ] terms ) { int position = <int> ; if ( positions . size ( ) > <int> ) position = positions . get ( positions . size ( ) - <int> ) + <int> ; add ( terms , position ) ; } public void add ( Term [ ] terms , int position ) { if ( termArrays . size ( ) = = <int> ) field = terms [ <int> ] . field ( ) ; for ( int i = <int> ; i < terms . length ; i + + ) { if ( terms [ i ] . field ( ) ! = field ) { throw new IllegalArgumentException ( <str> + field + <str> + terms [ i ] ) ; } } termArrays . add ( terms ) ; positions . add ( position ) ; } public int [ ] getPositions ( ) { int [ ] result = new int [ positions . size ( ) ] ; for ( int i = <int> ; i < positions . size ( ) ; i + + ) result [ i ] = positions . get ( i ) ; return result ; } @Override public Query rewrite ( IndexReader reader ) throws IOException { Query rewritten = super . rewrite ( reader ) ; if ( rewritten ! = this ) { return rewritten ; } if ( termArrays . isEmpty ( ) ) { return new MatchNoDocsQuery ( ) ; } MultiPhraseQuery query = new MultiPhraseQuery ( ) ; query . setSlop ( slop ) ; int sizeMinus1 = termArrays . size ( ) - <int> ; for ( int i = <int> ; i < sizeMinus1 ; i + + ) { query . add ( termArrays . get ( i ) , positions . get ( i ) ) ; } Term [ ] suffixTerms = termArrays . get ( sizeMinus1 ) ; int position = positions . get ( sizeMinus1 ) ; ObjectHashSet < Term > terms = new ObjectHashSet < > ( ) ; for ( Term term : suffixTerms ) { getPrefixTerms ( terms , term , reader ) ; if ( terms . size ( ) > maxExpansions ) { break ; } } if ( terms . isEmpty ( ) ) { return Queries . newMatchNoDocsQuery ( ) ; } query . add ( terms . toArray ( Term . class ) , position ) ; return query . rewrite ( reader ) ; } private void getPrefixTerms ( ObjectHashSet < Term > terms , final Term prefix , final IndexReader reader ) throws IOException { List < LeafReaderContext > leaves = reader . leaves ( ) ; for ( LeafReaderContext leaf : leaves ) { Terms _terms = leaf . reader ( ) . terms ( field ) ; if ( _terms = = null ) { continue ; } TermsEnum termsEnum = _terms . iterator ( ) ; TermsEnum . SeekStatus seekStatus = termsEnum . seekCeil ( prefix . bytes ( ) ) ; if ( TermsEnum . SeekStatus . END = = seekStatus ) { continue ; } for ( BytesRef term = termsEnum . term ( ) ; term ! = null ; term = termsEnum . next ( ) ) { if ( ! StringHelper . startsWith ( term , prefix . bytes ( ) ) ) { break ; } terms . add ( new Term ( field , BytesRef . deepCopyOf ( term ) ) ) ; if ( terms . size ( ) > = maxExpansions ) { return ; } } } } @Override public final String toString ( String f ) { StringBuilder buffer = new StringBuilder ( ) ; if ( field = = null | | ! field . equals ( f ) ) { buffer . append ( field ) ; buffer . append ( <str> ) ; } buffer . append ( <str> ) ; Iterator < Term [ ] > i = termArrays . iterator ( ) ; while ( i . hasNext ( ) ) { Term [ ] terms = i . next ( ) ; if ( terms . length > <int> ) { buffer . append ( <str> ) ; for ( int j = <int> ; j < terms . length ; j + + ) { buffer . append ( terms [ j ] . text ( ) ) ; if ( j < terms . length - <int> ) { if ( i . hasNext ( ) ) { buffer . append ( <str> ) ; } else { buffer . append ( <str> ) ; } } } if ( i . hasNext ( ) ) { buffer . append ( <str> ) ; } else { buffer . append ( <str> ) ; } } else { buffer . append ( terms [ <int> ] . text ( ) ) ; if ( i . hasNext ( ) ) { buffer . append ( <str> ) ; } else { buffer . append ( <str> ) ; } } } buffer . append ( <str> ) ; if ( slop ! = <int> ) { buffer . append ( <str> ) ; buffer . append ( slop ) ; } buffer . append ( ToStringUtils . boost ( getBoost ( ) ) ) ; return buffer . toString ( ) ; } @Override public boolean equals ( Object o ) { if ( super . equals ( o ) = = false ) { return false ; } MultiPhrasePrefixQuery other = ( MultiPhrasePrefixQuery ) o ; return this . slop = = other . slop & & termArraysEquals ( this . termArrays , other . termArrays ) & & this . positions . equals ( other . positions ) ; } @Override public int hashCode ( ) { return super . hashCode ( ) ^ slop ^ termArraysHashCode ( ) ^ positions . hashCode ( ) ; } private int termArraysHashCode ( ) { int hashCode = <int> ; for ( final Term [ ] termArray : termArrays ) { hashCode = <int> * hashCode + ( termArray = = null ? <int> : Arrays . hashCode ( termArray ) ) ; } return hashCode ; } private boolean termArraysEquals ( List < Term [ ] > termArrays1 , List < Term [ ] > termArrays2 ) { if ( termArrays1 . size ( ) ! = termArrays2 . size ( ) ) { return false ; } ListIterator < Term [ ] > iterator1 = termArrays1 . listIterator ( ) ; ListIterator < Term [ ] > iterator2 = termArrays2 . listIterator ( ) ; while ( iterator1 . hasNext ( ) ) { Term [ ] termArray1 = iterator1 . next ( ) ; Term [ ] termArray2 = iterator2 . next ( ) ; if ( ! ( termArray1 = = null ? termArray2 = = null : Arrays . equals ( termArray1 , termArray2 ) ) ) { return false ; } } return true ; } public String getField ( ) { return field ; } } 
