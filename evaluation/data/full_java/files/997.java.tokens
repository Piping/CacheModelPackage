package org . apache . cassandra . streaming ; import java . io . File ; import java . io . IOError ; import java . io . IOException ; import java . util . ArrayList ; import java . util . Collection ; import java . util . List ; import java . util . Set ; import java . util . UUID ; import java . util . concurrent . ExecutorService ; import java . util . concurrent . Executors ; import com . google . common . collect . Iterables ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; import org . apache . cassandra . concurrent . NamedThreadFactory ; import org . apache . cassandra . config . Schema ; import org . apache . cassandra . db . ColumnFamilyStore ; import org . apache . cassandra . db . Keyspace ; import org . apache . cassandra . db . Mutation ; import org . apache . cassandra . db . compaction . OperationType ; import org . apache . cassandra . db . lifecycle . LifecycleTransaction ; import org . apache . cassandra . db . partitions . PartitionUpdate ; import org . apache . cassandra . db . rows . UnfilteredRowIterator ; import org . apache . cassandra . db . view . View ; import org . apache . cassandra . dht . Bounds ; import org . apache . cassandra . dht . Token ; import org . apache . cassandra . io . sstable . ISSTableScanner ; import org . apache . cassandra . io . sstable . SSTableMultiWriter ; import org . apache . cassandra . io . sstable . format . SSTableReader ; import org . apache . cassandra . utils . JVMStabilityInspector ; import org . apache . cassandra . utils . Pair ; import org . apache . cassandra . utils . concurrent . Refs ; public class StreamReceiveTask extends StreamTask { private static final Logger logger = LoggerFactory . getLogger ( StreamReceiveTask . class ) ; private static final ExecutorService executor = Executors . newCachedThreadPool ( new NamedThreadFactory ( <str> ) ) ; private final int totalFiles ; private final long totalSize ; public final LifecycleTransaction txn ; private boolean done = false ; protected Collection < SSTableMultiWriter > sstables ; public StreamReceiveTask ( StreamSession session , UUID cfId , int totalFiles , long totalSize ) { super ( session , cfId ) ; this . totalFiles = totalFiles ; this . totalSize = totalSize ; this . txn = LifecycleTransaction . offline ( OperationType . STREAM ) ; this . sstables = new ArrayList < > ( totalFiles ) ; } public synchronized void received ( SSTableMultiWriter sstable ) { if ( done ) return ; assert cfId . equals ( sstable . getCfId ( ) ) ; sstables . add ( sstable ) ; if ( sstables . size ( ) = = totalFiles ) { done = true ; executor . submit ( new OnCompletionRunnable ( this ) ) ; } } public int getTotalNumberOfFiles ( ) { return totalFiles ; } public long getTotalSize ( ) { return totalSize ; } private static class OnCompletionRunnable implements Runnable { private final StreamReceiveTask task ; public OnCompletionRunnable ( StreamReceiveTask task ) { this . task = task ; } public void run ( ) { boolean hasViews = false ; ColumnFamilyStore cfs = null ; try { Pair < String , String > kscf = Schema . instance . getCF ( task . cfId ) ; if ( kscf = = null ) { task . sstables . forEach ( SSTableMultiWriter : : abortOrDie ) ; task . sstables . clear ( ) ; task . txn . abort ( ) ; task . session . taskCompleted ( task ) ; return ; } cfs = Keyspace . open ( kscf . left ) . getColumnFamilyStore ( kscf . right ) ; hasViews = ! Iterables . isEmpty ( View . findAll ( kscf . left , kscf . right ) ) ; List < SSTableReader > readers = new ArrayList < > ( ) ; for ( SSTableMultiWriter writer : task . sstables ) { Collection < SSTableReader > newReaders = writer . finish ( true ) ; readers . addAll ( newReaders ) ; task . txn . update ( newReaders , false ) ; } task . sstables . clear ( ) ; try ( Refs < SSTableReader > refs = Refs . ref ( readers ) ) { if ( hasViews ) { for ( SSTableReader reader : readers ) { try ( ISSTableScanner scanner = reader . getScanner ( ) ) { while ( scanner . hasNext ( ) ) { try ( UnfilteredRowIterator rowIterator = scanner . next ( ) ) { new Mutation ( PartitionUpdate . fromIterator ( rowIterator ) ) . applyUnsafe ( ) ; } } } } } else { task . txn . finish ( ) ; cfs . addSSTables ( readers ) ; cfs . indexManager . buildAllIndexesBlocking ( readers ) ; if ( cfs . isRowCacheEnabled ( ) | | cfs . metadata . isCounter ( ) ) { List < Bounds < Token > > boundsToInvalidate = new ArrayList < > ( readers . size ( ) ) ; readers . forEach ( sstable - > boundsToInvalidate . add ( new Bounds < Token > ( sstable . first . getToken ( ) , sstable . last . getToken ( ) ) ) ) ; Set < Bounds < Token > > nonOverlappingBounds = Bounds . getNonOverlappingBounds ( boundsToInvalidate ) ; if ( cfs . isRowCacheEnabled ( ) ) { int invalidatedKeys = cfs . invalidateRowCache ( nonOverlappingBounds ) ; if ( invalidatedKeys > <int> ) logger . debug ( <str> + <str> , task . session . planId ( ) , invalidatedKeys , cfs . keyspace . getName ( ) , cfs . getTableName ( ) ) ; } if ( cfs . metadata . isCounter ( ) ) { int invalidatedKeys = cfs . invalidateCounterCache ( nonOverlappingBounds ) ; if ( invalidatedKeys > <int> ) logger . debug ( <str> + <str> , task . session . planId ( ) , invalidatedKeys , cfs . keyspace . getName ( ) , cfs . getTableName ( ) ) ; } } } } task . session . taskCompleted ( task ) ; } catch ( Throwable t ) { logger . error ( <str> , t ) ; JVMStabilityInspector . inspectThrowable ( t ) ; task . session . onError ( t ) ; } finally { if ( hasViews ) { if ( cfs ! = null ) cfs . forceBlockingFlush ( ) ; task . txn . abort ( ) ; } } } } public synchronized void abort ( ) { if ( done ) return ; done = true ; sstables . forEach ( SSTableMultiWriter : : abortOrDie ) ; txn . abort ( ) ; sstables . clear ( ) ; } } 
