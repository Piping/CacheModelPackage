package org . apache . cassandra . db . columniterator ; import java . io . IOException ; import java . util . * ; import org . apache . cassandra . config . CFMetaData ; import org . apache . cassandra . db . * ; import org . apache . cassandra . db . filter . ColumnFilter ; import org . apache . cassandra . db . partitions . ImmutableBTreePartition ; import org . apache . cassandra . db . rows . * ; import org . apache . cassandra . io . sstable . format . SSTableReader ; import org . apache . cassandra . io . util . FileDataInput ; import org . apache . cassandra . utils . btree . BTree ; public class SSTableReversedIterator extends AbstractSSTableIterator { public SSTableReversedIterator ( SSTableReader sstable , DecoratedKey key , ColumnFilter columns , boolean isForThrift ) { this ( sstable , null , key , sstable . getPosition ( key , SSTableReader . Operator . EQ ) , columns , isForThrift ) ; } public SSTableReversedIterator ( SSTableReader sstable , FileDataInput file , DecoratedKey key , RowIndexEntry indexEntry , ColumnFilter columns , boolean isForThrift ) { super ( sstable , file , key , indexEntry , columns , isForThrift ) ; } protected Reader createReader ( RowIndexEntry indexEntry , FileDataInput file , boolean isAtPartitionStart , boolean shouldCloseFile ) { return indexEntry . isIndexed ( ) ? new ReverseIndexedReader ( indexEntry , file , isAtPartitionStart , shouldCloseFile ) : new ReverseReader ( file , isAtPartitionStart , shouldCloseFile ) ; } public boolean isReverseOrder ( ) { return true ; } private class ReverseReader extends Reader { protected ReusablePartitionData buffer ; protected Iterator < Unfiltered > iterator ; private ReverseReader ( FileDataInput file , boolean isAtPartitionStart , boolean shouldCloseFile ) { super ( file , isAtPartitionStart , shouldCloseFile ) ; } protected ReusablePartitionData createBuffer ( int blocksCount ) { int estimatedRowCount = <int> ; int columnCount = metadata ( ) . partitionColumns ( ) . regulars . size ( ) ; if ( columnCount = = <int> | | metadata ( ) . clusteringColumns ( ) . isEmpty ( ) ) { estimatedRowCount = <int> ; } else { try { int estimatedRowsPerPartition = ( int ) ( sstable . getEstimatedColumnCount ( ) . percentile ( <float> ) / columnCount ) ; estimatedRowCount = Math . max ( estimatedRowsPerPartition / blocksCount , <int> ) ; } catch ( IllegalStateException e ) { } } return new ReusablePartitionData ( metadata ( ) , partitionKey ( ) , columns ( ) , estimatedRowCount ) ; } protected void init ( ) throws IOException { throw new IllegalStateException ( ) ; } public void setForSlice ( Slice slice ) throws IOException { if ( buffer = = null ) { buffer = createBuffer ( <int> ) ; loadFromDisk ( null , slice . end ( ) , true ) ; } setIterator ( slice ) ; } protected void setIterator ( Slice slice ) { assert buffer ! = null ; iterator = buffer . built . unfilteredIterator ( columns , Slices . with ( metadata ( ) . comparator , slice ) , true ) ; } protected boolean hasNextInternal ( ) throws IOException { if ( iterator = = null ) setForSlice ( Slice . ALL ) ; return iterator . hasNext ( ) ; } protected Unfiltered nextInternal ( ) throws IOException { if ( ! hasNext ( ) ) throw new NoSuchElementException ( ) ; return iterator . next ( ) ; } protected boolean stopReadingDisk ( ) { return false ; } protected void loadFromDisk ( Slice . Bound start , Slice . Bound end , boolean includeFirst ) throws IOException { buffer . reset ( ) ; boolean isFirst = true ; if ( start ! = null ) { while ( deserializer . hasNext ( ) & & deserializer . compareNextTo ( start ) < = <int> & & ! stopReadingDisk ( ) ) { isFirst = false ; if ( deserializer . nextIsRow ( ) ) deserializer . skipNext ( ) ; else updateOpenMarker ( ( RangeTombstoneMarker ) deserializer . readNext ( ) ) ; } } if ( openMarker ! = null ) { RangeTombstone . Bound markerStart = start = = null ? RangeTombstone . Bound . BOTTOM : RangeTombstone . Bound . fromSliceBound ( start ) ; buffer . add ( new RangeTombstoneBoundMarker ( markerStart , openMarker ) ) ; } while ( deserializer . hasNext ( ) & & ( end = = null | | deserializer . compareNextTo ( end ) < = <int> ) & & ! stopReadingDisk ( ) ) { Unfiltered unfiltered = deserializer . readNext ( ) ; if ( ! isFirst | | includeFirst ) buffer . add ( unfiltered ) ; isFirst = false ; if ( unfiltered . isRangeTombstoneMarker ( ) ) updateOpenMarker ( ( RangeTombstoneMarker ) unfiltered ) ; } if ( openMarker ! = null ) { RangeTombstone . Bound markerEnd = end = = null ? RangeTombstone . Bound . TOP : RangeTombstone . Bound . fromSliceBound ( end ) ; buffer . add ( new RangeTombstoneBoundMarker ( markerEnd , getAndClearOpenMarker ( ) ) ) ; } buffer . build ( ) ; } } private class ReverseIndexedReader extends ReverseReader { private final IndexState indexState ; private Slice slice ; private int lastBlockIdx ; private ReverseIndexedReader ( RowIndexEntry indexEntry , FileDataInput file , boolean isAtPartitionStart , boolean shouldCloseFile ) { super ( file , isAtPartitionStart , shouldCloseFile ) ; this . indexState = new IndexState ( this , sstable . metadata . comparator , indexEntry , true ) ; } protected void init ( ) throws IOException { } @Override public void setForSlice ( Slice slice ) throws IOException { this . slice = slice ; isInit = true ; if ( indexState . isDone ( ) ) { iterator = Collections . emptyIterator ( ) ; return ; } int startIdx = indexState . findBlockIndex ( slice . end ( ) , indexState . currentBlockIdx ( ) ) ; if ( startIdx < <int> ) { iterator = Collections . emptyIterator ( ) ; return ; } lastBlockIdx = indexState . findBlockIndex ( slice . start ( ) , startIdx ) ; if ( lastBlockIdx > = indexState . blocksCount ( ) ) { assert startIdx > = indexState . blocksCount ( ) ; iterator = Collections . emptyIterator ( ) ; return ; } if ( startIdx > = indexState . blocksCount ( ) ) startIdx = indexState . blocksCount ( ) - <int> ; if ( startIdx ! = indexState . currentBlockIdx ( ) ) { indexState . setToBlock ( startIdx ) ; readCurrentBlock ( true ) ; } setIterator ( slice ) ; } @Override protected boolean hasNextInternal ( ) throws IOException { if ( super . hasNextInternal ( ) ) return true ; int previousBlockIdx = indexState . currentBlockIdx ( ) - <int> ; if ( previousBlockIdx < <int> | | previousBlockIdx < lastBlockIdx ) return false ; indexState . setToBlock ( previousBlockIdx ) ; readCurrentBlock ( false ) ; setIterator ( slice ) ; return iterator . hasNext ( ) ; } private void readCurrentBlock ( boolean canIncludeSliceEnd ) throws IOException { if ( buffer = = null ) buffer = createBuffer ( indexState . blocksCount ( ) ) ; int currentBlock = indexState . currentBlockIdx ( ) ; boolean canIncludeSliceStart = currentBlock = = lastBlockIdx ; boolean includeFirst = true ; if ( ! sstable . descriptor . version . storeRows ( ) & & currentBlock > <int> ) { ClusteringPrefix lastOfPrevious = indexState . index ( currentBlock - <int> ) . lastName ; ClusteringPrefix firstOfCurrent = indexState . index ( currentBlock ) . firstName ; includeFirst = metadata ( ) . comparator . compare ( lastOfPrevious , firstOfCurrent ) ! = <int> ; } loadFromDisk ( canIncludeSliceStart ? slice . start ( ) : null , canIncludeSliceEnd ? slice . end ( ) : null , includeFirst ) ; } @Override protected boolean stopReadingDisk ( ) { return indexState . isPastCurrentBlock ( ) ; } } private class ReusablePartitionData { private final CFMetaData metadata ; private final DecoratedKey partitionKey ; private final PartitionColumns columns ; private MutableDeletionInfo . Builder deletionBuilder ; private MutableDeletionInfo deletionInfo ; private BTree . Builder < Row > rowBuilder ; private ImmutableBTreePartition built ; private ReusablePartitionData ( CFMetaData metadata , DecoratedKey partitionKey , PartitionColumns columns , int initialRowCapacity ) { this . metadata = metadata ; this . partitionKey = partitionKey ; this . columns = columns ; this . rowBuilder = BTree . builder ( metadata . comparator , initialRowCapacity ) ; } public void add ( Unfiltered unfiltered ) { if ( unfiltered . isRow ( ) ) rowBuilder . add ( ( Row ) unfiltered ) ; else deletionBuilder . add ( ( RangeTombstoneMarker ) unfiltered ) ; } public void reset ( ) { built = null ; rowBuilder . reuse ( ) ; deletionBuilder = MutableDeletionInfo . builder ( partitionLevelDeletion , metadata ( ) . comparator , false ) ; } public void build ( ) { deletionInfo = deletionBuilder . build ( ) ; built = new ImmutableBTreePartition ( metadata , partitionKey , columns , Rows . EMPTY_STATIC_ROW , rowBuilder . build ( ) , DeletionInfo . LIVE , EncodingStats . NO_STATS ) ; deletionBuilder = null ; } } } 
