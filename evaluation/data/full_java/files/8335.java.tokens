package org . elasticsearch . indices . flush ; import com . carrotsearch . hppc . ObjectIntHashMap ; import com . carrotsearch . hppc . ObjectIntMap ; import org . elasticsearch . cluster . routing . ShardRouting ; import org . elasticsearch . cluster . routing . ShardRoutingState ; import org . elasticsearch . cluster . routing . TestShardRouting ; import org . elasticsearch . index . shard . ShardId ; import org . elasticsearch . indices . flush . IndicesSyncedFlushResult . ShardCounts ; import org . elasticsearch . indices . flush . SyncedFlushService . SyncedFlushResponse ; import org . elasticsearch . rest . RestStatus ; import org . elasticsearch . test . ESTestCase ; import java . io . IOException ; import java . util . ArrayList ; import java . util . HashMap ; import java . util . List ; import java . util . Map ; import static org . elasticsearch . test . XContentTestUtils . convertToMap ; import static org . hamcrest . Matchers . equalTo ; import static org . hamcrest . Matchers . hasSize ; public class SyncedFlushUnitTests extends ESTestCase { private static class TestPlan { public ShardCounts totalCounts ; public Map < String , ShardCounts > countsPerIndex = new HashMap < > ( ) ; public ObjectIntMap < String > expectedFailuresPerIndex = new ObjectIntHashMap < > ( ) ; public IndicesSyncedFlushResult result ; } public void testIndicesSyncedFlushResult ( ) throws IOException { final TestPlan testPlan = createTestPlan ( ) ; assertThat ( testPlan . result . totalShards ( ) , equalTo ( testPlan . totalCounts . total ) ) ; assertThat ( testPlan . result . successfulShards ( ) , equalTo ( testPlan . totalCounts . successful ) ) ; assertThat ( testPlan . result . failedShards ( ) , equalTo ( testPlan . totalCounts . failed ) ) ; assertThat ( testPlan . result . restStatus ( ) , equalTo ( testPlan . totalCounts . failed > <int> ? RestStatus . CONFLICT : RestStatus . OK ) ) ; Map < String , Object > asMap = convertToMap ( testPlan . result ) ; assertShardCount ( <str> , ( Map < String , Object > ) asMap . get ( <str> ) , testPlan . totalCounts ) ; assertThat ( <str> , asMap . size ( ) , equalTo ( <int> + testPlan . countsPerIndex . size ( ) ) ) ; for ( String index : testPlan . countsPerIndex . keySet ( ) ) { Map < String , Object > indexMap = ( Map < String , Object > ) asMap . get ( index ) ; assertShardCount ( index , indexMap , testPlan . countsPerIndex . get ( index ) ) ; List < Map < String , Object > > failureList = ( List < Map < String , Object > > ) indexMap . get ( <str> ) ; final int expectedFailures = testPlan . expectedFailuresPerIndex . get ( index ) ; if ( expectedFailures = = <int> ) { assertNull ( index + <str> , failureList ) ; } else { assertNotNull ( index + <str> , failureList ) ; assertThat ( failureList , hasSize ( expectedFailures ) ) ; } } } private void assertShardCount ( String name , Map < String , Object > header , ShardCounts expectedCounts ) { assertThat ( name + <str> , ( Integer ) header . get ( <str> ) , equalTo ( expectedCounts . total ) ) ; assertThat ( name + <str> , ( Integer ) header . get ( <str> ) , equalTo ( expectedCounts . successful ) ) ; assertThat ( name + <str> , ( Integer ) header . get ( <str> ) , equalTo ( expectedCounts . failed ) ) ; } protected TestPlan createTestPlan ( ) { final TestPlan testPlan = new TestPlan ( ) ; final Map < String , List < ShardsSyncedFlushResult > > indicesResults = new HashMap < > ( ) ; final int indexCount = randomIntBetween ( <int> , <int> ) ; int totalShards = <int> ; int totalSuccesful = <int> ; int totalFailed = <int> ; for ( int i = <int> ; i < indexCount ; i + + ) { final String index = <str> + i ; int shards = randomIntBetween ( <int> , <int> ) ; int replicas = randomIntBetween ( <int> , <int> ) ; int successful = <int> ; int failed = <int> ; int failures = <int> ; List < ShardsSyncedFlushResult > shardsResults = new ArrayList < > ( ) ; for ( int shard = <int> ; shard < shards ; shard + + ) { final ShardId shardId = new ShardId ( index , shard ) ; if ( randomInt ( <int> ) < <int> ) { failed + = replicas + <int> ; failures + + ; shardsResults . add ( new ShardsSyncedFlushResult ( shardId , replicas + <int> , <str> ) ) ; } else { Map < ShardRouting , SyncedFlushResponse > shardResponses = new HashMap < > ( ) ; for ( int copy = <int> ; copy < replicas + <int> ; copy + + ) { final ShardRouting shardRouting = TestShardRouting . newShardRouting ( index , shard , <str> + shardId + <str> + copy , null , copy = = <int> , ShardRoutingState . STARTED , <int> ) ; if ( randomInt ( <int> ) < <int> ) { failed + + ; failures + + ; shardResponses . put ( shardRouting , new SyncedFlushResponse ( <str> + shardId ) ) ; } else { successful + + ; shardResponses . put ( shardRouting , new SyncedFlushResponse ( ) ) ; } } shardsResults . add ( new ShardsSyncedFlushResult ( shardId , <str> + shard , replicas + <int> , shardResponses ) ) ; } } indicesResults . put ( index , shardsResults ) ; testPlan . countsPerIndex . put ( index , new ShardCounts ( shards * ( replicas + <int> ) , successful , failed ) ) ; testPlan . expectedFailuresPerIndex . put ( index , failures ) ; totalFailed + = failed ; totalShards + = shards * ( replicas + <int> ) ; totalSuccesful + = successful ; } testPlan . result = new IndicesSyncedFlushResult ( indicesResults ) ; testPlan . totalCounts = new ShardCounts ( totalShards , totalSuccesful , totalFailed ) ; return testPlan ; } } 
