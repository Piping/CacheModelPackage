package org . elasticsearch . common . lucene . uid ; import org . apache . lucene . analysis . Analyzer ; import org . apache . lucene . analysis . TokenStream ; import org . apache . lucene . analysis . core . KeywordAnalyzer ; import org . apache . lucene . analysis . tokenattributes . CharTermAttribute ; import org . apache . lucene . analysis . tokenattributes . PayloadAttribute ; import org . apache . lucene . document . Document ; import org . apache . lucene . document . Field ; import org . apache . lucene . document . Field . Store ; import org . apache . lucene . document . FieldType ; import org . apache . lucene . document . NumericDocValuesField ; import org . apache . lucene . document . StringField ; import org . apache . lucene . index . DirectoryReader ; import org . apache . lucene . index . IndexOptions ; import org . apache . lucene . index . IndexWriter ; import org . apache . lucene . index . IndexWriterConfig ; import org . apache . lucene . index . LeafReader ; import org . apache . lucene . index . NumericDocValues ; import org . apache . lucene . index . SlowCompositeReaderWrapper ; import org . apache . lucene . index . Term ; import org . apache . lucene . store . Directory ; import org . apache . lucene . util . BytesRef ; import org . elasticsearch . common . Numbers ; import org . elasticsearch . common . lucene . Lucene ; import org . elasticsearch . common . lucene . index . ElasticsearchDirectoryReader ; import org . elasticsearch . index . mapper . internal . UidFieldMapper ; import org . elasticsearch . index . mapper . internal . VersionFieldMapper ; import org . elasticsearch . index . shard . ElasticsearchMergePolicy ; import org . elasticsearch . index . shard . ShardId ; import org . elasticsearch . test . ESTestCase ; import org . hamcrest . MatcherAssert ; import java . io . IOException ; import java . util . ArrayList ; import java . util . HashMap ; import java . util . List ; import java . util . Map ; import static org . hamcrest . Matchers . equalTo ; import static org . hamcrest . Matchers . is ; import static org . hamcrest . Matchers . notNullValue ; import static org . hamcrest . Matchers . nullValue ; public class VersionsTests extends ESTestCase { public static DirectoryReader reopen ( DirectoryReader reader ) throws IOException { return reopen ( reader , true ) ; } public static DirectoryReader reopen ( DirectoryReader reader , boolean newReaderExpected ) throws IOException { DirectoryReader newReader = DirectoryReader . openIfChanged ( reader ) ; if ( newReader ! = null ) { reader . close ( ) ; } else { assertFalse ( newReaderExpected ) ; } return newReader ; } public void testVersions ( ) throws Exception { Directory dir = newDirectory ( ) ; IndexWriter writer = new IndexWriter ( dir , new IndexWriterConfig ( Lucene . STANDARD_ANALYZER ) ) ; DirectoryReader directoryReader = ElasticsearchDirectoryReader . wrap ( DirectoryReader . open ( writer , true ) , new ShardId ( <str> , <int> ) ) ; MatcherAssert . assertThat ( Versions . loadVersion ( directoryReader , new Term ( UidFieldMapper . NAME , <str> ) ) , equalTo ( Versions . NOT_FOUND ) ) ; Document doc = new Document ( ) ; doc . add ( new Field ( UidFieldMapper . NAME , <str> , UidFieldMapper . Defaults . FIELD_TYPE ) ) ; writer . addDocument ( doc ) ; directoryReader = reopen ( directoryReader ) ; assertThat ( Versions . loadVersion ( directoryReader , new Term ( UidFieldMapper . NAME , <str> ) ) , equalTo ( Versions . NOT_SET ) ) ; assertThat ( Versions . loadDocIdAndVersion ( directoryReader , new Term ( UidFieldMapper . NAME , <str> ) ) . version , equalTo ( Versions . NOT_SET ) ) ; doc = new Document ( ) ; doc . add ( new Field ( UidFieldMapper . NAME , <str> , UidFieldMapper . Defaults . FIELD_TYPE ) ) ; doc . add ( new NumericDocValuesField ( VersionFieldMapper . NAME , <int> ) ) ; writer . updateDocument ( new Term ( UidFieldMapper . NAME , <str> ) , doc ) ; directoryReader = reopen ( directoryReader ) ; assertThat ( Versions . loadVersion ( directoryReader , new Term ( UidFieldMapper . NAME , <str> ) ) , equalTo ( <int> ) ) ; assertThat ( Versions . loadDocIdAndVersion ( directoryReader , new Term ( UidFieldMapper . NAME , <str> ) ) . version , equalTo ( <int> ) ) ; doc = new Document ( ) ; Field uid = new Field ( UidFieldMapper . NAME , <str> , UidFieldMapper . Defaults . FIELD_TYPE ) ; Field version = new NumericDocValuesField ( VersionFieldMapper . NAME , <int> ) ; doc . add ( uid ) ; doc . add ( version ) ; writer . updateDocument ( new Term ( UidFieldMapper . NAME , <str> ) , doc ) ; directoryReader = reopen ( directoryReader ) ; assertThat ( Versions . loadVersion ( directoryReader , new Term ( UidFieldMapper . NAME , <str> ) ) , equalTo ( <int> ) ) ; assertThat ( Versions . loadDocIdAndVersion ( directoryReader , new Term ( UidFieldMapper . NAME , <str> ) ) . version , equalTo ( <int> ) ) ; doc = new Document ( ) ; version . setLongValue ( <int> ) ; doc . add ( uid ) ; doc . add ( version ) ; writer . updateDocument ( new Term ( UidFieldMapper . NAME , <str> ) , doc ) ; directoryReader = reopen ( directoryReader ) ; assertThat ( Versions . loadVersion ( directoryReader , new Term ( UidFieldMapper . NAME , <str> ) ) , equalTo ( <int> ) ) ; assertThat ( Versions . loadDocIdAndVersion ( directoryReader , new Term ( UidFieldMapper . NAME , <str> ) ) . version , equalTo ( <int> ) ) ; writer . deleteDocuments ( new Term ( UidFieldMapper . NAME , <str> ) ) ; directoryReader = reopen ( directoryReader ) ; assertThat ( Versions . loadVersion ( directoryReader , new Term ( UidFieldMapper . NAME , <str> ) ) , equalTo ( Versions . NOT_FOUND ) ) ; assertThat ( Versions . loadDocIdAndVersion ( directoryReader , new Term ( UidFieldMapper . NAME , <str> ) ) , nullValue ( ) ) ; directoryReader . close ( ) ; writer . close ( ) ; dir . close ( ) ; } public void testNestedDocuments ( ) throws IOException { Directory dir = newDirectory ( ) ; IndexWriter writer = new IndexWriter ( dir , new IndexWriterConfig ( Lucene . STANDARD_ANALYZER ) ) ; List < Document > docs = new ArrayList < > ( ) ; for ( int i = <int> ; i < <int> ; + + i ) { Document doc = new Document ( ) ; doc . add ( new Field ( UidFieldMapper . NAME , <str> , UidFieldMapper . Defaults . NESTED_FIELD_TYPE ) ) ; docs . add ( doc ) ; } Document doc = new Document ( ) ; doc . add ( new Field ( UidFieldMapper . NAME , <str> , UidFieldMapper . Defaults . FIELD_TYPE ) ) ; NumericDocValuesField version = new NumericDocValuesField ( VersionFieldMapper . NAME , <int> ) ; doc . add ( version ) ; docs . add ( doc ) ; writer . updateDocuments ( new Term ( UidFieldMapper . NAME , <str> ) , docs ) ; DirectoryReader directoryReader = ElasticsearchDirectoryReader . wrap ( DirectoryReader . open ( writer , true ) , new ShardId ( <str> , <int> ) ) ; assertThat ( Versions . loadVersion ( directoryReader , new Term ( UidFieldMapper . NAME , <str> ) ) , equalTo ( <int> ) ) ; assertThat ( Versions . loadDocIdAndVersion ( directoryReader , new Term ( UidFieldMapper . NAME , <str> ) ) . version , equalTo ( <int> ) ) ; version . setLongValue ( <int> ) ; writer . updateDocuments ( new Term ( UidFieldMapper . NAME , <str> ) , docs ) ; version . setLongValue ( <int> ) ; writer . updateDocuments ( new Term ( UidFieldMapper . NAME , <str> ) , docs ) ; directoryReader = reopen ( directoryReader ) ; assertThat ( Versions . loadVersion ( directoryReader , new Term ( UidFieldMapper . NAME , <str> ) ) , equalTo ( <int> ) ) ; assertThat ( Versions . loadDocIdAndVersion ( directoryReader , new Term ( UidFieldMapper . NAME , <str> ) ) . version , equalTo ( <int> ) ) ; writer . deleteDocuments ( new Term ( UidFieldMapper . NAME , <str> ) ) ; directoryReader = reopen ( directoryReader ) ; assertThat ( Versions . loadVersion ( directoryReader , new Term ( UidFieldMapper . NAME , <str> ) ) , equalTo ( Versions . NOT_FOUND ) ) ; assertThat ( Versions . loadDocIdAndVersion ( directoryReader , new Term ( UidFieldMapper . NAME , <str> ) ) , nullValue ( ) ) ; directoryReader . close ( ) ; writer . close ( ) ; dir . close ( ) ; } public void testBackwardCompatibility ( ) throws IOException { Directory dir = newDirectory ( ) ; IndexWriter writer = new IndexWriter ( dir , new IndexWriterConfig ( Lucene . STANDARD_ANALYZER ) ) ; DirectoryReader directoryReader = ElasticsearchDirectoryReader . wrap ( DirectoryReader . open ( writer , true ) , new ShardId ( <str> , <int> ) ) ; MatcherAssert . assertThat ( Versions . loadVersion ( directoryReader , new Term ( UidFieldMapper . NAME , <str> ) ) , equalTo ( Versions . NOT_FOUND ) ) ; Document doc = new Document ( ) ; UidField uidAndVersion = new UidField ( <str> , <int> ) ; doc . add ( uidAndVersion ) ; writer . addDocument ( doc ) ; uidAndVersion . uid = <str> ; uidAndVersion . version = <int> ; writer . addDocument ( doc ) ; writer . commit ( ) ; directoryReader = reopen ( directoryReader ) ; assertThat ( Versions . loadVersion ( directoryReader , new Term ( UidFieldMapper . NAME , <str> ) ) , equalTo ( <int> ) ) ; assertThat ( Versions . loadVersion ( directoryReader , new Term ( UidFieldMapper . NAME , <str> ) ) , equalTo ( <int> ) ) ; assertThat ( Versions . loadVersion ( directoryReader , new Term ( UidFieldMapper . NAME , <str> ) ) , equalTo ( Versions . NOT_FOUND ) ) ; directoryReader . close ( ) ; writer . close ( ) ; dir . close ( ) ; } private static class UidField extends Field { private static final FieldType FIELD_TYPE = new FieldType ( ) ; static { FIELD_TYPE . setTokenized ( true ) ; FIELD_TYPE . setIndexOptions ( IndexOptions . DOCS_AND_FREQS_AND_POSITIONS ) ; FIELD_TYPE . setStored ( true ) ; FIELD_TYPE . freeze ( ) ; } String uid ; long version ; UidField ( String uid , long version ) { super ( UidFieldMapper . NAME , uid , FIELD_TYPE ) ; this . uid = uid ; this . version = version ; } @Override public TokenStream tokenStream ( Analyzer analyzer , TokenStream reuse ) throws IOException { return new TokenStream ( ) { boolean finished = true ; final CharTermAttribute term = addAttribute ( CharTermAttribute . class ) ; final PayloadAttribute payload = addAttribute ( PayloadAttribute . class ) ; @Override public boolean incrementToken ( ) throws IOException { if ( finished ) { return false ; } term . setEmpty ( ) . append ( uid ) ; payload . setPayload ( new BytesRef ( Numbers . longToBytes ( version ) ) ) ; finished = true ; return true ; } @Override public void reset ( ) throws IOException { finished = false ; } } ; } } public void testMergingOldIndices ( ) throws Exception { final IndexWriterConfig iwConf = new IndexWriterConfig ( new KeywordAnalyzer ( ) ) ; iwConf . setMergePolicy ( new ElasticsearchMergePolicy ( iwConf . getMergePolicy ( ) ) ) ; final Directory dir = newDirectory ( ) ; final IndexWriter iw = new IndexWriter ( dir , iwConf ) ; Document document = new Document ( ) ; document . add ( new StringField ( <str> , <str> , Store . NO ) ) ; StringField uid = new StringField ( UidFieldMapper . NAME , <str> , Store . YES ) ; document . add ( uid ) ; iw . addDocument ( document ) ; uid . setStringValue ( <str> ) ; iw . addDocument ( document ) ; iw . commit ( ) ; document = new Document ( ) ; UidField uidAndVersion = new UidField ( <str> , <int> ) ; document . add ( uidAndVersion ) ; iw . addDocument ( document ) ; uidAndVersion . uid = <str> ; uidAndVersion . version = <int> ; iw . addDocument ( document ) ; iw . commit ( ) ; document = new Document ( ) ; uid . setStringValue ( <str> ) ; Field version = new NumericDocValuesField ( VersionFieldMapper . NAME , <int> ) ; document . add ( uid ) ; document . add ( version ) ; iw . addDocument ( document ) ; uid . setStringValue ( <str> ) ; version . setLongValue ( <int> ) ; iw . addDocument ( document ) ; iw . commit ( ) ; Map < String , Long > expectedVersions = new HashMap < > ( ) ; expectedVersions . put ( <str> , <int> L ) ; expectedVersions . put ( <str> , <int> L ) ; expectedVersions . put ( <str> , <int> L ) ; expectedVersions . put ( <str> , <int> ) ; expectedVersions . put ( <str> , <int> ) ; expectedVersions . put ( <str> , <int> ) ; iw . forceMerge ( <int> , true ) ; final LeafReader ir = SlowCompositeReaderWrapper . wrap ( ElasticsearchDirectoryReader . wrap ( DirectoryReader . open ( iw . getDirectory ( ) ) , new ShardId ( <str> , <int> ) ) ) ; final NumericDocValues versions = ir . getNumericDocValues ( VersionFieldMapper . NAME ) ; assertThat ( versions , notNullValue ( ) ) ; for ( int i = <int> ; i < ir . maxDoc ( ) ; + + i ) { final String uidValue = ir . document ( i ) . get ( UidFieldMapper . NAME ) ; final long expectedVersion = expectedVersions . get ( uidValue ) ; assertThat ( versions . get ( i ) , equalTo ( expectedVersion ) ) ; } iw . close ( ) ; assertThat ( IndexWriter . isLocked ( iw . getDirectory ( ) ) , is ( false ) ) ; ir . close ( ) ; dir . close ( ) ; } public void testCache ( ) throws Exception { int size = Versions . lookupStates . size ( ) ; Directory dir = newDirectory ( ) ; IndexWriter writer = new IndexWriter ( dir , new IndexWriterConfig ( Lucene . STANDARD_ANALYZER ) ) ; Document doc = new Document ( ) ; doc . add ( new Field ( UidFieldMapper . NAME , <str> , UidFieldMapper . Defaults . FIELD_TYPE ) ) ; doc . add ( new NumericDocValuesField ( VersionFieldMapper . NAME , <int> ) ) ; writer . addDocument ( doc ) ; DirectoryReader reader = DirectoryReader . open ( writer , false ) ; assertEquals ( <int> , Versions . loadVersion ( reader , new Term ( UidFieldMapper . NAME , <str> ) ) ) ; assertEquals ( size + <int> , Versions . lookupStates . size ( ) ) ; assertEquals ( <int> , Versions . loadVersion ( reader , new Term ( UidFieldMapper . NAME , <str> ) ) ) ; assertEquals ( size + <int> , Versions . lookupStates . size ( ) ) ; reader . close ( ) ; writer . close ( ) ; assertEquals ( size , Versions . lookupStates . size ( ) ) ; dir . close ( ) ; } public void testCacheFilterReader ( ) throws Exception { int size = Versions . lookupStates . size ( ) ; Directory dir = newDirectory ( ) ; IndexWriter writer = new IndexWriter ( dir , new IndexWriterConfig ( Lucene . STANDARD_ANALYZER ) ) ; Document doc = new Document ( ) ; doc . add ( new Field ( UidFieldMapper . NAME , <str> , UidFieldMapper . Defaults . FIELD_TYPE ) ) ; doc . add ( new NumericDocValuesField ( VersionFieldMapper . NAME , <int> ) ) ; writer . addDocument ( doc ) ; DirectoryReader reader = DirectoryReader . open ( writer , false ) ; assertEquals ( <int> , Versions . loadVersion ( reader , new Term ( UidFieldMapper . NAME , <str> ) ) ) ; assertEquals ( size + <int> , Versions . lookupStates . size ( ) ) ; DirectoryReader wrapped = ElasticsearchDirectoryReader . wrap ( reader , new ShardId ( <str> , <int> ) ) ; assertEquals ( <int> , Versions . loadVersion ( wrapped , new Term ( UidFieldMapper . NAME , <str> ) ) ) ; assertEquals ( size + <int> , Versions . lookupStates . size ( ) ) ; reader . close ( ) ; writer . close ( ) ; assertEquals ( size , Versions . lookupStates . size ( ) ) ; dir . close ( ) ; } } 
