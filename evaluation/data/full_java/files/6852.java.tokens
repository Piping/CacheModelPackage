package org . elasticsearch . indices . cache . request ; import com . carrotsearch . hppc . ObjectHashSet ; import com . carrotsearch . hppc . ObjectSet ; import org . apache . lucene . index . DirectoryReader ; import org . apache . lucene . index . IndexReader ; import org . apache . lucene . util . Accountable ; import org . apache . lucene . util . RamUsageEstimator ; import org . elasticsearch . action . search . SearchType ; import org . elasticsearch . cluster . ClusterService ; import org . elasticsearch . cluster . metadata . IndexMetaData ; import org . elasticsearch . common . bytes . BytesReference ; import org . elasticsearch . common . cache . * ; import org . elasticsearch . common . component . AbstractComponent ; import org . elasticsearch . common . inject . Inject ; import org . elasticsearch . common . io . stream . BytesStreamOutput ; import org . elasticsearch . common . lucene . index . ElasticsearchDirectoryReader ; import org . elasticsearch . common . settings . Settings ; import org . elasticsearch . common . unit . MemorySizeValue ; import org . elasticsearch . common . unit . TimeValue ; import org . elasticsearch . common . util . concurrent . ConcurrentCollections ; import org . elasticsearch . common . util . concurrent . EsRejectedExecutionException ; import org . elasticsearch . index . shard . IndexShard ; import org . elasticsearch . index . shard . IndexShardState ; import org . elasticsearch . search . internal . SearchContext ; import org . elasticsearch . search . internal . ShardSearchRequest ; import org . elasticsearch . search . query . QueryPhase ; import org . elasticsearch . search . query . QuerySearchResult ; import org . elasticsearch . threadpool . ThreadPool ; import java . util . * ; import java . util . concurrent . ConcurrentMap ; import java . util . concurrent . TimeUnit ; public class IndicesRequestCache extends AbstractComponent implements RemovalListener < IndicesRequestCache . Key , IndicesRequestCache . Value > { public static final String INDEX_CACHE_REQUEST_ENABLED = <str> ; @Deprecated public static final String DEPRECATED_INDEX_CACHE_REQUEST_ENABLED = <str> ; public static final String INDICES_CACHE_REQUEST_CLEAN_INTERVAL = <str> ; public static final String INDICES_CACHE_QUERY_SIZE = <str> ; @Deprecated public static final String DEPRECATED_INDICES_CACHE_QUERY_SIZE = <str> ; public static final String INDICES_CACHE_QUERY_EXPIRE = <str> ; private static final Set < SearchType > CACHEABLE_SEARCH_TYPES = EnumSet . of ( SearchType . QUERY_THEN_FETCH , SearchType . QUERY_AND_FETCH ) ; private final ThreadPool threadPool ; private final ClusterService clusterService ; private final TimeValue cleanInterval ; private final Reaper reaper ; final ConcurrentMap < CleanupKey , Boolean > registeredClosedListeners = ConcurrentCollections . newConcurrentMap ( ) ; final Set < CleanupKey > keysToClean = ConcurrentCollections . newConcurrentSet ( ) ; private final String size ; private final TimeValue expire ; private volatile Cache < Key , Value > cache ; @Inject public IndicesRequestCache ( Settings settings , ClusterService clusterService , ThreadPool threadPool ) { super ( settings ) ; this . clusterService = clusterService ; this . threadPool = threadPool ; this . cleanInterval = settings . getAsTime ( INDICES_CACHE_REQUEST_CLEAN_INTERVAL , TimeValue . timeValueSeconds ( <int> ) ) ; String size = settings . get ( INDICES_CACHE_QUERY_SIZE ) ; if ( size = = null ) { size = settings . get ( DEPRECATED_INDICES_CACHE_QUERY_SIZE ) ; if ( size ! = null ) { deprecationLogger . deprecated ( <str> + DEPRECATED_INDICES_CACHE_QUERY_SIZE + <str> + INDICES_CACHE_QUERY_SIZE + <str> ) ; } } if ( size = = null ) { size = <str> ; } this . size = size ; this . expire = settings . getAsTime ( INDICES_CACHE_QUERY_EXPIRE , null ) ; buildCache ( ) ; this . reaper = new Reaper ( ) ; threadPool . schedule ( cleanInterval , ThreadPool . Names . SAME , reaper ) ; } private boolean isCacheEnabled ( Settings settings , boolean defaultEnable ) { Boolean enable = settings . getAsBoolean ( INDEX_CACHE_REQUEST_ENABLED , null ) ; if ( enable = = null ) { enable = settings . getAsBoolean ( DEPRECATED_INDEX_CACHE_REQUEST_ENABLED , null ) ; if ( enable ! = null ) { deprecationLogger . deprecated ( <str> + DEPRECATED_INDEX_CACHE_REQUEST_ENABLED + <str> + INDEX_CACHE_REQUEST_ENABLED + <str> ) ; } } if ( enable = = null ) { enable = defaultEnable ; } return enable ; } private void buildCache ( ) { long sizeInBytes = MemorySizeValue . parseBytesSizeValueOrHeapRatio ( size , INDICES_CACHE_QUERY_SIZE ) . bytes ( ) ; CacheBuilder < Key , Value > cacheBuilder = CacheBuilder . < Key , Value > builder ( ) . setMaximumWeight ( sizeInBytes ) . weigher ( ( k , v ) - > k . ramBytesUsed ( ) + v . ramBytesUsed ( ) ) . removalListener ( this ) ; if ( expire ! = null ) { cacheBuilder . setExpireAfterAccess ( TimeUnit . MILLISECONDS . toNanos ( expire . millis ( ) ) ) ; } cache = cacheBuilder . build ( ) ; } public void close ( ) { reaper . close ( ) ; cache . invalidateAll ( ) ; } public void clear ( IndexShard shard ) { if ( shard = = null ) { return ; } keysToClean . add ( new CleanupKey ( shard , - <int> ) ) ; logger . trace ( <str> , shard . shardId ( ) ) ; reaper . reap ( ) ; } @Override public void onRemoval ( RemovalNotification < Key , Value > notification ) { notification . getKey ( ) . shard . requestCache ( ) . onRemoval ( notification ) ; } public boolean canCache ( ShardSearchRequest request , SearchContext context ) { if ( request . template ( ) ! = null ) { return false ; } if ( context . size ( ) ! = <int> ) { return false ; } if ( ! CACHEABLE_SEARCH_TYPES . contains ( context . searchType ( ) ) ) { return false ; } IndexMetaData index = clusterService . state ( ) . getMetaData ( ) . index ( request . index ( ) ) ; if ( index = = null ) { return false ; } if ( request . requestCache ( ) = = null ) { if ( ! isCacheEnabled ( index . getSettings ( ) , Boolean . FALSE ) ) { return false ; } } else if ( ! request . requestCache ( ) ) { return false ; } if ( ! ( context . searcher ( ) . getIndexReader ( ) instanceof DirectoryReader ) ) { return false ; } if ( context . nowInMillisUsed ( ) ) { return false ; } return true ; } public void loadIntoContext ( final ShardSearchRequest request , final SearchContext context , final QueryPhase queryPhase ) throws Exception { assert canCache ( request , context ) ; Key key = buildKey ( request , context ) ; Loader loader = new Loader ( queryPhase , context ) ; Value value = cache . computeIfAbsent ( key , loader ) ; if ( loader . isLoaded ( ) ) { key . shard . requestCache ( ) . onMiss ( ) ; CleanupKey cleanupKey = new CleanupKey ( context . indexShard ( ) , ( ( DirectoryReader ) context . searcher ( ) . getIndexReader ( ) ) . getVersion ( ) ) ; if ( ! registeredClosedListeners . containsKey ( cleanupKey ) ) { Boolean previous = registeredClosedListeners . putIfAbsent ( cleanupKey , Boolean . TRUE ) ; if ( previous = = null ) { ElasticsearchDirectoryReader . addReaderCloseListener ( context . searcher ( ) . getDirectoryReader ( ) , cleanupKey ) ; } } } else { key . shard . requestCache ( ) . onHit ( ) ; final QuerySearchResult result = context . queryResult ( ) ; result . readFromWithId ( context . id ( ) , value . reference . streamInput ( ) ) ; result . shardTarget ( context . shardTarget ( ) ) ; } } private static class Loader implements CacheLoader < Key , Value > { private final QueryPhase queryPhase ; private final SearchContext context ; private boolean loaded ; Loader ( QueryPhase queryPhase , SearchContext context ) { this . queryPhase = queryPhase ; this . context = context ; } public boolean isLoaded ( ) { return this . loaded ; } @Override public Value load ( Key key ) throws Exception { queryPhase . execute ( context ) ; final int expectedSizeInBytes = <int> ; try ( BytesStreamOutput out = new BytesStreamOutput ( expectedSizeInBytes ) ) { context . queryResult ( ) . writeToNoId ( out ) ; final BytesReference reference = out . bytes ( ) ; loaded = true ; Value value = new Value ( reference , out . ramBytesUsed ( ) ) ; key . shard . requestCache ( ) . onCached ( key , value ) ; return value ; } } } public static class Value implements Accountable { final BytesReference reference ; final long ramBytesUsed ; public Value ( BytesReference reference , long ramBytesUsed ) { this . reference = reference ; this . ramBytesUsed = ramBytesUsed ; } @Override public long ramBytesUsed ( ) { return ramBytesUsed ; } @Override public Collection < Accountable > getChildResources ( ) { return Collections . emptyList ( ) ; } } public static class Key implements Accountable { public final IndexShard shard ; public final long readerVersion ; public final BytesReference value ; Key ( IndexShard shard , long readerVersion , BytesReference value ) { this . shard = shard ; this . readerVersion = readerVersion ; this . value = value ; } @Override public long ramBytesUsed ( ) { return RamUsageEstimator . NUM_BYTES_OBJECT_REF + RamUsageEstimator . NUM_BYTES_LONG + value . length ( ) ; } @Override public Collection < Accountable > getChildResources ( ) { return Collections . emptyList ( ) ; } @Override public boolean equals ( Object o ) { if ( this = = o ) return true ; Key key = ( Key ) o ; if ( readerVersion ! = key . readerVersion ) return false ; if ( ! shard . equals ( key . shard ) ) return false ; if ( ! value . equals ( key . value ) ) return false ; return true ; } @Override public int hashCode ( ) { int result = shard . hashCode ( ) ; result = <int> * result + Long . hashCode ( readerVersion ) ; result = <int> * result + value . hashCode ( ) ; return result ; } } private class CleanupKey implements IndexReader . ReaderClosedListener { IndexShard indexShard ; long readerVersion ; private CleanupKey ( IndexShard indexShard , long readerVersion ) { this . indexShard = indexShard ; this . readerVersion = readerVersion ; } @Override public void onClose ( IndexReader reader ) { Boolean remove = registeredClosedListeners . remove ( this ) ; if ( remove ! = null ) { keysToClean . add ( this ) ; } } @Override public boolean equals ( Object o ) { if ( this = = o ) return true ; CleanupKey that = ( CleanupKey ) o ; if ( readerVersion ! = that . readerVersion ) return false ; if ( ! indexShard . equals ( that . indexShard ) ) return false ; return true ; } @Override public int hashCode ( ) { int result = indexShard . hashCode ( ) ; result = <int> * result + Long . hashCode ( readerVersion ) ; return result ; } } private class Reaper implements Runnable { private final ObjectSet < CleanupKey > currentKeysToClean = new ObjectHashSet < > ( ) ; private final ObjectSet < IndexShard > currentFullClean = new ObjectHashSet < > ( ) ; private volatile boolean closed ; void close ( ) { closed = true ; } @Override public void run ( ) { if ( closed ) { return ; } if ( keysToClean . isEmpty ( ) ) { schedule ( ) ; return ; } try { threadPool . executor ( ThreadPool . Names . GENERIC ) . execute ( new Runnable ( ) { @Override public void run ( ) { reap ( ) ; schedule ( ) ; } } ) ; } catch ( EsRejectedExecutionException ex ) { logger . debug ( <str> , ex ) ; } } private void schedule ( ) { try { threadPool . schedule ( cleanInterval , ThreadPool . Names . SAME , this ) ; } catch ( EsRejectedExecutionException ex ) { logger . debug ( <str> , ex ) ; } } synchronized void reap ( ) { currentKeysToClean . clear ( ) ; currentFullClean . clear ( ) ; for ( Iterator < CleanupKey > iterator = keysToClean . iterator ( ) ; iterator . hasNext ( ) ; ) { CleanupKey cleanupKey = iterator . next ( ) ; iterator . remove ( ) ; if ( cleanupKey . readerVersion = = - <int> | | cleanupKey . indexShard . state ( ) = = IndexShardState . CLOSED ) { currentFullClean . add ( cleanupKey . indexShard ) ; } else { currentKeysToClean . add ( cleanupKey ) ; } } if ( ! currentKeysToClean . isEmpty ( ) | | ! currentFullClean . isEmpty ( ) ) { CleanupKey lookupKey = new CleanupKey ( null , - <int> ) ; for ( Iterator < Key > iterator = cache . keys ( ) . iterator ( ) ; iterator . hasNext ( ) ; ) { Key key = iterator . next ( ) ; if ( currentFullClean . contains ( key . shard ) ) { iterator . remove ( ) ; } else { lookupKey . indexShard = key . shard ; lookupKey . readerVersion = key . readerVersion ; if ( currentKeysToClean . contains ( lookupKey ) ) { iterator . remove ( ) ; } } } } cache . refresh ( ) ; currentKeysToClean . clear ( ) ; currentFullClean . clear ( ) ; } } private static Key buildKey ( ShardSearchRequest request , SearchContext context ) throws Exception { return new Key ( context . indexShard ( ) , ( ( DirectoryReader ) context . searcher ( ) . getIndexReader ( ) ) . getVersion ( ) , request . cacheKey ( ) ) ; } } 
