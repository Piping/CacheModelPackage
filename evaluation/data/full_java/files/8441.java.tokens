package org . elasticsearch . search . aggregations . bucket ; import org . elasticsearch . Version ; import org . elasticsearch . action . index . IndexRequestBuilder ; import org . elasticsearch . action . search . SearchResponse ; import org . elasticsearch . common . settings . Settings ; import org . elasticsearch . index . mapper . core . DateFieldMapper ; import org . elasticsearch . search . aggregations . bucket . histogram . DateHistogramInterval ; import org . elasticsearch . search . aggregations . bucket . histogram . Histogram ; import org . elasticsearch . test . ESIntegTestCase ; import org . elasticsearch . test . transport . AssertingLocalTransport ; import org . joda . time . DateTime ; import org . joda . time . DateTimeZone ; import org . junit . After ; import org . junit . Before ; import java . io . IOException ; import java . util . List ; import java . util . concurrent . ExecutionException ; import static org . elasticsearch . common . xcontent . XContentFactory . jsonBuilder ; import static org . elasticsearch . index . query . QueryBuilders . matchAllQuery ; import static org . elasticsearch . search . aggregations . AggregationBuilders . dateHistogram ; import static org . hamcrest . Matchers . equalTo ; import static org . hamcrest . core . IsNull . notNullValue ; @ESIntegTestCase.SuiteScopeTestCase @ESIntegTestCase.ClusterScope ( scope = ESIntegTestCase . Scope . SUITE ) public class DateHistogramOffsetIT extends ESIntegTestCase { private static final String DATE_FORMAT = <str> ; private DateTime date ( String date ) { return DateFieldMapper . Defaults . DATE_TIME_FORMATTER . parser ( ) . parseDateTime ( date ) ; } @Override protected Settings nodeSettings ( int nodeOrdinal ) { return Settings . builder ( ) . put ( super . nodeSettings ( nodeOrdinal ) ) . put ( AssertingLocalTransport . ASSERTING_TRANSPORT_MIN_VERSION_KEY , Version . V_1_4_0_Beta1 ) . build ( ) ; } @Before public void beforeEachTest ( ) throws IOException { prepareCreate ( <str> ) . addMapping ( <str> , <str> , <str> ) . execute ( ) . actionGet ( ) ; } @After public void afterEachTest ( ) throws IOException { internalCluster ( ) . wipeIndices ( <str> ) ; } private void prepareIndex ( DateTime date , int numHours , int stepSizeHours , int idxIdStart ) throws IOException , InterruptedException , ExecutionException { IndexRequestBuilder [ ] reqs = new IndexRequestBuilder [ numHours ] ; for ( int i = idxIdStart ; i < idxIdStart + reqs . length ; i + + ) { reqs [ i - idxIdStart ] = client ( ) . prepareIndex ( <str> , <str> , <str> + i ) . setSource ( jsonBuilder ( ) . startObject ( ) . field ( <str> , date ) . endObject ( ) ) ; date = date . plusHours ( stepSizeHours ) ; } indexRandom ( true , reqs ) ; } public void testSingleValueWithPositiveOffset ( ) throws Exception { prepareIndex ( date ( <str> ) , <int> , <int> , <int> ) ; SearchResponse response = client ( ) . prepareSearch ( <str> ) . setQuery ( matchAllQuery ( ) ) . addAggregation ( dateHistogram ( <str> ) . field ( <str> ) . offset ( <str> ) . format ( DATE_FORMAT ) . interval ( DateHistogramInterval . DAY ) ) . execute ( ) . actionGet ( ) ; assertThat ( response . getHits ( ) . getTotalHits ( ) , equalTo ( <int> ) ) ; Histogram histo = response . getAggregations ( ) . get ( <str> ) ; List < ? extends Histogram . Bucket > buckets = histo . getBuckets ( ) ; assertThat ( buckets . size ( ) , equalTo ( <int> ) ) ; checkBucketFor ( buckets . get ( <int> ) , new DateTime ( <int> , <int> , <int> , <int> , <int> , DateTimeZone . UTC ) , <int> ) ; checkBucketFor ( buckets . get ( <int> ) , new DateTime ( <int> , <int> , <int> , <int> , <int> , DateTimeZone . UTC ) , <int> ) ; } public void testSingleValueWithNegativeOffset ( ) throws Exception { prepareIndex ( date ( <str> ) , <int> , - <int> , <int> ) ; SearchResponse response = client ( ) . prepareSearch ( <str> ) . setQuery ( matchAllQuery ( ) ) . addAggregation ( dateHistogram ( <str> ) . field ( <str> ) . offset ( <str> ) . format ( DATE_FORMAT ) . interval ( DateHistogramInterval . DAY ) ) . execute ( ) . actionGet ( ) ; assertThat ( response . getHits ( ) . getTotalHits ( ) , equalTo ( <int> ) ) ; Histogram histo = response . getAggregations ( ) . get ( <str> ) ; List < ? extends Histogram . Bucket > buckets = histo . getBuckets ( ) ; assertThat ( buckets . size ( ) , equalTo ( <int> ) ) ; checkBucketFor ( buckets . get ( <int> ) , new DateTime ( <int> , <int> , <int> , <int> , <int> , DateTimeZone . UTC ) , <int> ) ; checkBucketFor ( buckets . get ( <int> ) , new DateTime ( <int> , <int> , <int> , <int> , <int> , DateTimeZone . UTC ) , <int> ) ; } public void testSingleValueWithOffsetMinDocCount ( ) throws Exception { prepareIndex ( date ( <str> ) , <int> , <int> , <int> ) ; prepareIndex ( date ( <str> ) , <int> , <int> , <int> ) ; SearchResponse response = client ( ) . prepareSearch ( <str> ) . setQuery ( matchAllQuery ( ) ) . addAggregation ( dateHistogram ( <str> ) . field ( <str> ) . offset ( <str> ) . minDocCount ( <int> ) . format ( DATE_FORMAT ) . interval ( DateHistogramInterval . DAY ) ) . execute ( ) . actionGet ( ) ; assertThat ( response . getHits ( ) . getTotalHits ( ) , equalTo ( <int> ) ) ; Histogram histo = response . getAggregations ( ) . get ( <str> ) ; List < ? extends Histogram . Bucket > buckets = histo . getBuckets ( ) ; assertThat ( buckets . size ( ) , equalTo ( <int> ) ) ; checkBucketFor ( buckets . get ( <int> ) , new DateTime ( <int> , <int> , <int> , <int> , <int> , DateTimeZone . UTC ) , <int> ) ; checkBucketFor ( buckets . get ( <int> ) , new DateTime ( <int> , <int> , <int> , <int> , <int> , DateTimeZone . UTC ) , <int> ) ; checkBucketFor ( buckets . get ( <int> ) , new DateTime ( <int> , <int> , <int> , <int> , <int> , DateTimeZone . UTC ) , <int> L ) ; checkBucketFor ( buckets . get ( <int> ) , new DateTime ( <int> , <int> , <int> , <int> , <int> , DateTimeZone . UTC ) , <int> ) ; checkBucketFor ( buckets . get ( <int> ) , new DateTime ( <int> , <int> , <int> , <int> , <int> , DateTimeZone . UTC ) , <int> ) ; } private static void checkBucketFor ( Histogram . Bucket bucket , DateTime key , long expectedSize ) { assertThat ( bucket , notNullValue ( ) ) ; assertThat ( bucket . getKeyAsString ( ) , equalTo ( key . toString ( DATE_FORMAT ) ) ) ; assertThat ( ( ( DateTime ) bucket . getKey ( ) ) , equalTo ( key ) ) ; assertThat ( bucket . getDocCount ( ) , equalTo ( expectedSize ) ) ; } } 
