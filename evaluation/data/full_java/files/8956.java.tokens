package org . elasticsearch . test ; import com . carrotsearch . randomizedtesting . RandomizedTest ; import com . carrotsearch . randomizedtesting . generators . RandomInts ; import com . carrotsearch . randomizedtesting . generators . RandomStrings ; import org . elasticsearch . ElasticsearchException ; import org . elasticsearch . action . bulk . BulkItemResponse ; import org . elasticsearch . action . bulk . BulkRequestBuilder ; import org . elasticsearch . action . bulk . BulkResponse ; import org . elasticsearch . client . Client ; import org . elasticsearch . common . logging . ESLogger ; import org . elasticsearch . common . logging . Loggers ; import org . elasticsearch . common . xcontent . XContentBuilder ; import org . elasticsearch . common . xcontent . XContentFactory ; import org . junit . Assert ; import java . io . IOException ; import java . util . Random ; import java . util . concurrent . CopyOnWriteArrayList ; import java . util . concurrent . CountDownLatch ; import java . util . concurrent . Semaphore ; import java . util . concurrent . TimeUnit ; import java . util . concurrent . atomic . AtomicBoolean ; import java . util . concurrent . atomic . AtomicLong ; import static org . hamcrest . Matchers . emptyIterable ; import static org . hamcrest . Matchers . equalTo ; public class BackgroundIndexer implements AutoCloseable { private final ESLogger logger = Loggers . getLogger ( getClass ( ) ) ; final Thread [ ] writers ; final CountDownLatch stopLatch ; final CopyOnWriteArrayList < Throwable > failures ; final AtomicBoolean stop = new AtomicBoolean ( false ) ; final AtomicLong idGenerator = new AtomicLong ( ) ; final AtomicLong indexCounter = new AtomicLong ( ) ; final CountDownLatch startLatch = new CountDownLatch ( <int> ) ; final AtomicBoolean hasBudget = new AtomicBoolean ( false ) ; final Semaphore availableBudget = new Semaphore ( <int> ) ; volatile int minFieldSize = <int> ; volatile int maxFieldSize = <int> ; public BackgroundIndexer ( String index , String type , Client client ) { this ( index , type , client , - <int> ) ; } public BackgroundIndexer ( String index , String type , Client client , int numOfDocs ) { this ( index , type , client , numOfDocs , RandomizedTest . scaledRandomIntBetween ( <int> , <int> ) ) ; } public BackgroundIndexer ( String index , String type , Client client , int numOfDocs , final int writerCount ) { this ( index , type , client , numOfDocs , writerCount , true , null ) ; } public BackgroundIndexer ( final String index , final String type , final Client client , final int numOfDocs , final int writerCount , boolean autoStart , Random random ) { if ( random = = null ) { random = RandomizedTest . getRandom ( ) ; } failures = new CopyOnWriteArrayList < > ( ) ; writers = new Thread [ writerCount ] ; stopLatch = new CountDownLatch ( writers . length ) ; logger . info ( <str> , writerCount , autoStart , numOfDocs ) ; for ( int i = <int> ; i < writers . length ; i + + ) { final int indexerId = i ; final boolean batch = random . nextBoolean ( ) ; final Random threadRandom = new Random ( random . nextLong ( ) ) ; writers [ i ] = new Thread ( ) { @Override public void run ( ) { long id = - <int> ; try { startLatch . await ( ) ; logger . info ( <str> , indexerId ) ; while ( ! stop . get ( ) ) { if ( batch ) { int batchSize = threadRandom . nextInt ( <int> ) + <int> ; if ( hasBudget . get ( ) ) { batchSize = Math . max ( Math . min ( batchSize , availableBudget . availablePermits ( ) ) , <int> ) ; if ( ! availableBudget . tryAcquire ( batchSize , <int> , TimeUnit . MILLISECONDS ) ) { continue ; } } BulkRequestBuilder bulkRequest = client . prepareBulk ( ) ; for ( int i = <int> ; i < batchSize ; i + + ) { id = idGenerator . incrementAndGet ( ) ; bulkRequest . add ( client . prepareIndex ( index , type , Long . toString ( id ) ) . setSource ( generateSource ( id , threadRandom ) ) ) ; } BulkResponse bulkResponse = bulkRequest . get ( ) ; for ( BulkItemResponse bulkItemResponse : bulkResponse ) { if ( ! bulkItemResponse . isFailed ( ) ) { indexCounter . incrementAndGet ( ) ; } else { throw new ElasticsearchException ( <str> + bulkItemResponse . getFailure ( ) . getId ( ) + <str> + bulkItemResponse . getFailure ( ) . getMessage ( ) ) ; } } } else { if ( hasBudget . get ( ) & & ! availableBudget . tryAcquire ( <int> , TimeUnit . MILLISECONDS ) ) { continue ; } id = idGenerator . incrementAndGet ( ) ; client . prepareIndex ( index , type , Long . toString ( id ) ) . setSource ( generateSource ( id , threadRandom ) ) . get ( ) ; indexCounter . incrementAndGet ( ) ; } } logger . info ( <str> , indexerId , stop . get ( ) , indexCounter . get ( ) ) ; } catch ( Throwable e ) { failures . add ( e ) ; logger . warn ( <str> , e , indexerId , id ) ; } finally { stopLatch . countDown ( ) ; } } } ; writers [ i ] . start ( ) ; } if ( autoStart ) { start ( numOfDocs ) ; } } private XContentBuilder generateSource ( long id , Random random ) throws IOException { int contentLength = RandomInts . randomIntBetween ( random , minFieldSize , maxFieldSize ) ; StringBuilder text = new StringBuilder ( contentLength ) ; while ( text . length ( ) < contentLength ) { int tokenLength = RandomInts . randomIntBetween ( random , <int> , Math . min ( contentLength - text . length ( ) , <int> ) ) ; text . append ( <str> ) . append ( RandomStrings . randomRealisticUnicodeOfCodepointLength ( random , tokenLength ) ) ; } XContentBuilder builder = XContentFactory . smileBuilder ( ) ; builder . startObject ( ) . field ( <str> , <str> + id ) . field ( <str> , text . toString ( ) ) . field ( <str> , id ) . endObject ( ) ; return builder ; } private void setBudget ( int numOfDocs ) { logger . debug ( <str> , numOfDocs ) ; if ( numOfDocs > = <int> ) { hasBudget . set ( true ) ; availableBudget . release ( numOfDocs ) ; } else { hasBudget . set ( false ) ; } } public void start ( ) { start ( - <int> ) ; } public void start ( int numOfDocs ) { assert ! stop . get ( ) : <str> ; setBudget ( numOfDocs ) ; startLatch . countDown ( ) ; } public void pauseIndexing ( ) { availableBudget . drainPermits ( ) ; setBudget ( <int> ) ; } public void continueIndexing ( ) { continueIndexing ( - <int> ) ; } public void continueIndexing ( int numOfDocs ) { setBudget ( numOfDocs ) ; } public void stop ( ) throws InterruptedException { if ( stop . get ( ) ) { return ; } stop . set ( true ) ; Assert . assertThat ( <str> , stopLatch . await ( <int> , TimeUnit . MINUTES ) , equalTo ( true ) ) ; assertNoFailures ( ) ; } public long totalIndexedDocs ( ) { return indexCounter . get ( ) ; } public Throwable [ ] getFailures ( ) { return failures . toArray ( new Throwable [ failures . size ( ) ] ) ; } public void assertNoFailures ( ) { Assert . assertThat ( failures , emptyIterable ( ) ) ; } public void setMinFieldSize ( int fieldSize ) { minFieldSize = fieldSize ; } public void setMaxFieldSize ( int fieldSize ) { maxFieldSize = fieldSize ; } @Override public void close ( ) throws Exception { stop ( ) ; } } 
