package org . apache . cassandra . utils ; import java . io . * ; import java . nio . ByteBuffer ; import java . util . ArrayList ; import java . util . HashSet ; import java . util . Iterator ; import java . util . List ; import java . util . Random ; import java . util . Set ; import org . junit . * ; import org . apache . cassandra . db . marshal . Int32Type ; import org . apache . cassandra . dht . IPartitioner ; import org . apache . cassandra . dht . Murmur3Partitioner ; import org . apache . cassandra . io . util . BufferedDataOutputStreamPlus ; import org . apache . cassandra . io . util . DataOutputBuffer ; import org . apache . cassandra . io . util . DataOutputStreamPlus ; import org . apache . cassandra . io . util . FileUtils ; import org . apache . cassandra . utils . IFilter . FilterKey ; import org . apache . cassandra . utils . KeyGenerator . RandomStringGenerator ; public class BloomFilterTest { public IFilter bfOldFormat ; public IFilter bfInvHashes ; public BloomFilterTest ( ) { } public static IFilter testSerialize ( IFilter f , boolean oldBfHashOrder ) throws IOException { f . add ( FilterTestHelper . bytes ( <str> ) ) ; DataOutputBuffer out = new DataOutputBuffer ( ) ; FilterFactory . serialize ( f , out ) ; ByteArrayInputStream in = new ByteArrayInputStream ( out . getData ( ) , <int> , out . getLength ( ) ) ; IFilter f2 = FilterFactory . deserialize ( new DataInputStream ( in ) , true , oldBfHashOrder ) ; assert f2 . isPresent ( FilterTestHelper . bytes ( <str> ) ) ; assert ! f2 . isPresent ( FilterTestHelper . bytes ( <str> ) ) ; return f2 ; } @Before public void setup ( ) { bfOldFormat = FilterFactory . getFilter ( <int> , FilterTestHelper . MAX_FAILURE_RATE , true , true ) ; bfInvHashes = FilterFactory . getFilter ( <int> , FilterTestHelper . MAX_FAILURE_RATE , true , false ) ; } @After public void destroy ( ) { bfOldFormat . close ( ) ; bfInvHashes . close ( ) ; } @Test ( expected = UnsupportedOperationException . class ) public void testBloomLimits1 ( ) { int maxBuckets = BloomCalculations . probs . length - <int> ; int maxK = BloomCalculations . probs [ maxBuckets ] . length - <int> ; BloomCalculations . computeBloomSpec ( maxBuckets , BloomCalculations . probs [ maxBuckets ] [ maxK ] ) ; BloomCalculations . computeBloomSpec ( maxBuckets , BloomCalculations . probs [ maxBuckets ] [ maxK ] / <int> ) ; } @Test public void testOne ( ) { bfOldFormat . add ( FilterTestHelper . bytes ( <str> ) ) ; assert bfOldFormat . isPresent ( FilterTestHelper . bytes ( <str> ) ) ; assert ! bfOldFormat . isPresent ( FilterTestHelper . bytes ( <str> ) ) ; bfInvHashes . add ( FilterTestHelper . bytes ( <str> ) ) ; assert bfInvHashes . isPresent ( FilterTestHelper . bytes ( <str> ) ) ; assert ! bfInvHashes . isPresent ( FilterTestHelper . bytes ( <str> ) ) ; } @Test public void testFalsePositivesInt ( ) { FilterTestHelper . testFalsePositives ( bfOldFormat , FilterTestHelper . intKeys ( ) , FilterTestHelper . randomKeys2 ( ) ) ; FilterTestHelper . testFalsePositives ( bfInvHashes , FilterTestHelper . intKeys ( ) , FilterTestHelper . randomKeys2 ( ) ) ; } @Test public void testFalsePositivesRandom ( ) { FilterTestHelper . testFalsePositives ( bfOldFormat , FilterTestHelper . randomKeys ( ) , FilterTestHelper . randomKeys2 ( ) ) ; FilterTestHelper . testFalsePositives ( bfInvHashes , FilterTestHelper . randomKeys ( ) , FilterTestHelper . randomKeys2 ( ) ) ; } @Test public void testWords ( ) { if ( KeyGenerator . WordGenerator . WORDS = = <int> ) { return ; } IFilter bf2 = FilterFactory . getFilter ( KeyGenerator . WordGenerator . WORDS / <int> , FilterTestHelper . MAX_FAILURE_RATE , true , false ) ; int skipEven = KeyGenerator . WordGenerator . WORDS % <int> = = <int> ? <int> : <int> ; FilterTestHelper . testFalsePositives ( bf2 , new KeyGenerator . WordGenerator ( skipEven , <int> ) , new KeyGenerator . WordGenerator ( <int> , <int> ) ) ; bf2 . close ( ) ; bf2 = FilterFactory . getFilter ( KeyGenerator . WordGenerator . WORDS / <int> , FilterTestHelper . MAX_FAILURE_RATE , true , true ) ; FilterTestHelper . testFalsePositives ( bf2 , new KeyGenerator . WordGenerator ( skipEven , <int> ) , new KeyGenerator . WordGenerator ( <int> , <int> ) ) ; bf2 . close ( ) ; } @Test public void testSerialize ( ) throws IOException { BloomFilterTest . testSerialize ( bfOldFormat , true ) . close ( ) ; BloomFilterTest . testSerialize ( bfInvHashes , false ) . close ( ) ; } @Test @Ignore public void testManyRandom ( ) { testManyRandom ( FilterTestHelper . randomKeys ( ) , false ) ; testManyRandom ( FilterTestHelper . randomKeys ( ) , true ) ; } private static void testManyRandom ( Iterator < ByteBuffer > keys , boolean oldBfHashOrder ) { int MAX_HASH_COUNT = <int> ; Set < Long > hashes = new HashSet < > ( ) ; long collisions = <int> ; while ( keys . hasNext ( ) ) { hashes . clear ( ) ; FilterKey buf = FilterTestHelper . wrap ( keys . next ( ) ) ; BloomFilter bf = ( BloomFilter ) FilterFactory . getFilter ( <int> , <int> , false , oldBfHashOrder ) ; for ( long hashIndex : bf . getHashBuckets ( buf , MAX_HASH_COUNT , <int> * <int> ) ) { hashes . add ( hashIndex ) ; } collisions + = ( MAX_HASH_COUNT - hashes . size ( ) ) ; bf . close ( ) ; } Assert . assertTrue ( <str> + collisions , collisions < = <int> ) ; } @Test ( expected = UnsupportedOperationException . class ) public void testOffHeapException ( ) { long numKeys = ( ( long ) Integer . MAX_VALUE ) * <int> + <int> ; FilterFactory . getFilter ( numKeys , <float> , true , true ) . close ( ) ; } @Test public void compareCachedKeyOldHashOrder ( ) { BloomFilter bf1 = ( BloomFilter ) FilterFactory . getFilter ( FilterTestHelper . ELEMENTS / <int> , FilterTestHelper . MAX_FAILURE_RATE , false , true ) ; BloomFilter bf2 = ( BloomFilter ) FilterFactory . getFilter ( FilterTestHelper . ELEMENTS / <int> , FilterTestHelper . MAX_FAILURE_RATE , false , true ) ; BloomFilter bf3 = ( BloomFilter ) FilterFactory . getFilter ( FilterTestHelper . ELEMENTS / <int> , FilterTestHelper . MAX_FAILURE_RATE , false , true ) ; RandomStringGenerator gen1 = new KeyGenerator . RandomStringGenerator ( new Random ( ) . nextInt ( ) , FilterTestHelper . ELEMENTS ) ; BitSetTest . compare ( bf1 . bitset , bf2 . bitset ) ; BitSetTest . compare ( bf1 . bitset , bf3 . bitset ) ; while ( gen1 . hasNext ( ) ) { ByteBuffer key = gen1 . next ( ) ; FilterKey cached = FilterTestHelper . wrapCached ( key ) ; bf1 . add ( FilterTestHelper . wrap ( key ) ) ; bf2 . add ( cached ) ; bf3 . add ( cached ) ; } BitSetTest . compare ( bf1 . bitset , bf2 . bitset ) ; BitSetTest . compare ( bf1 . bitset , bf3 . bitset ) ; } @Test public void compareCachedKeyNewHashOrder ( ) { try ( BloomFilter bf1 = ( BloomFilter ) FilterFactory . getFilter ( FilterTestHelper . ELEMENTS / <int> , FilterTestHelper . MAX_FAILURE_RATE , false , false ) ; BloomFilter bf2 = ( BloomFilter ) FilterFactory . getFilter ( FilterTestHelper . ELEMENTS / <int> , FilterTestHelper . MAX_FAILURE_RATE , false , false ) ; BloomFilter bf3 = ( BloomFilter ) FilterFactory . getFilter ( FilterTestHelper . ELEMENTS / <int> , FilterTestHelper . MAX_FAILURE_RATE , false , false ) ) { RandomStringGenerator gen1 = new KeyGenerator . RandomStringGenerator ( new Random ( ) . nextInt ( ) , FilterTestHelper . ELEMENTS ) ; BitSetTest . compare ( bf1 . bitset , bf2 . bitset ) ; BitSetTest . compare ( bf1 . bitset , bf3 . bitset ) ; while ( gen1 . hasNext ( ) ) { ByteBuffer key = gen1 . next ( ) ; FilterKey cached = FilterTestHelper . wrapCached ( key ) ; bf1 . add ( FilterTestHelper . wrap ( key ) ) ; bf2 . add ( cached ) ; bf3 . add ( cached ) ; } BitSetTest . compare ( bf1 . bitset , bf2 . bitset ) ; BitSetTest . compare ( bf1 . bitset , bf3 . bitset ) ; } } @Test @Ignore public void testHugeBFSerialization ( ) throws IOException { hugeBFSerialization ( false ) ; hugeBFSerialization ( true ) ; } static void hugeBFSerialization ( boolean oldBfHashOrder ) throws IOException { ByteBuffer test = ByteBuffer . wrap ( new byte [ ] { <int> , <int> } ) ; File file = FileUtils . createTempFile ( <str> , <str> ) ; BloomFilter filter = ( BloomFilter ) FilterFactory . getFilter ( ( ( long ) Integer . MAX_VALUE / <int> ) + <int> , <float> , true , oldBfHashOrder ) ; filter . add ( FilterTestHelper . wrap ( test ) ) ; DataOutputStreamPlus out = new BufferedDataOutputStreamPlus ( new FileOutputStream ( file ) ) ; FilterFactory . serialize ( filter , out ) ; filter . bitset . serialize ( out ) ; out . close ( ) ; filter . close ( ) ; DataInputStream in = new DataInputStream ( new FileInputStream ( file ) ) ; BloomFilter filter2 = ( BloomFilter ) FilterFactory . deserialize ( in , true , oldBfHashOrder ) ; Assert . assertTrue ( filter2 . isPresent ( FilterTestHelper . wrap ( test ) ) ) ; FileUtils . closeQuietly ( in ) ; filter2 . close ( ) ; } @Test public void testMurmur3FilterHash ( ) { IPartitioner partitioner = new Murmur3Partitioner ( ) ; Iterator < ByteBuffer > gen = new KeyGenerator . RandomStringGenerator ( new Random ( ) . nextInt ( ) , FilterTestHelper . ELEMENTS ) ; long [ ] expected = new long [ <int> ] ; long [ ] actual = new long [ <int> ] ; while ( gen . hasNext ( ) ) { expected [ <int> ] = <int> ; expected [ <int> ] = <int> ; actual [ <int> ] = <int> ; actual [ <int> ] = <int> ; ByteBuffer key = gen . next ( ) ; FilterKey expectedKey = FilterTestHelper . wrap ( key ) ; FilterKey actualKey = partitioner . decorateKey ( key ) ; actualKey . filterHash ( actual ) ; expectedKey . filterHash ( expected ) ; Assert . assertArrayEquals ( expected , actual ) ; } } } 
