package org . nd4j . linalg . ops . impl . transform ; import static org . junit . Assert . * ; import java . util . Arrays ; import java . util . Random ; import org . apache . commons . math3 . util . FastMath ; import org . junit . Test ; import org . nd4j . linalg . BaseNd4jTest ; import org . nd4j . linalg . api . buffer . DataBuffer ; import org . nd4j . linalg . api . ndarray . INDArray ; import org . nd4j . linalg . api . ops . impl . transforms . * ; import org . nd4j . linalg . factory . NDArrayFactory ; import org . nd4j . linalg . factory . Nd4j ; import org . nd4j . linalg . factory . Nd4jBackend ; public class TestDerivatives extends BaseNd4jTest { public static final double REL_ERROR_TOLERANCE = <float> ; public TestDerivatives ( ) { } public TestDerivatives ( Nd4jBackend backend ) { super ( backend ) ; } public TestDerivatives ( String name ) { super ( name ) ; } public TestDerivatives ( String name , Nd4jBackend backend ) { super ( name , backend ) ; } static { Nd4j . dtype = DataBuffer . Type . DOUBLE ; NDArrayFactory factory = Nd4j . factory ( ) ; factory . setDType ( DataBuffer . Type . DOUBLE ) ; } @Test public void testHardTanhDerivative ( ) { assertTrue ( Nd4j . getOpFactory ( ) . createTransform ( <str> , Nd4j . ones ( <int> ) ) . derivative ( ) instanceof HardTanhDerivative ) ; INDArray z = Nd4j . zeros ( <int> ) ; double [ ] expOut = new double [ <int> ] ; for ( int i = <int> ; i < <int> ; i + + ) { double x = <float> * ( i - <int> ) ; z . putScalar ( i , x ) ; expOut [ i ] = ( Math . abs ( x ) < = <float> ? <int> : <int> ) ; } INDArray zPrime = Nd4j . getExecutioner ( ) . execAndReturn ( Nd4j . getOpFactory ( ) . createTransform ( <str> , z ) . derivative ( ) ) ; for ( int i = <int> ; i < <int> ; i + + ) { assertEquals ( expOut [ i ] , zPrime . getDouble ( i ) , <float> ) ; } } @Test public void testRectifiedLinearDerivative ( ) { assertTrue ( Nd4j . getOpFactory ( ) . createTransform ( <str> , Nd4j . ones ( <int> ) ) . derivative ( ) instanceof Step ) ; INDArray z = Nd4j . zeros ( <int> ) ; double [ ] expOut = new double [ <int> ] ; for ( int i = <int> ; i < <int> ; i + + ) { double x = <float> * ( i - <int> ) ; z . putScalar ( i , x ) ; expOut [ i ] = ( x > <int> ? <int> : <int> ) ; } INDArray zPrime = Nd4j . getExecutioner ( ) . execAndReturn ( Nd4j . getOpFactory ( ) . createTransform ( <str> , z ) . derivative ( ) ) ; for ( int i = <int> ; i < <int> ; i + + ) { assertTrue ( expOut [ i ] = = zPrime . getDouble ( i ) ) ; } } @Test public void testSigmoidDerivative ( ) { assertTrue ( Nd4j . getOpFactory ( ) . createTransform ( <str> , Nd4j . ones ( <int> ) ) . derivative ( ) instanceof SigmoidDerivative ) ; INDArray z = Nd4j . zeros ( <int> ) ; double [ ] expOut = new double [ <int> ] ; for ( int i = <int> ; i < <int> ; i + + ) { double x = <float> * ( i - <int> ) ; z . putScalar ( i , x ) ; double sigmoid = <float> / ( FastMath . exp ( - x ) + <int> ) ; expOut [ i ] = sigmoid * ( <int> - sigmoid ) ; } INDArray zPrime = Nd4j . getExecutioner ( ) . execAndReturn ( Nd4j . getOpFactory ( ) . createTransform ( <str> , z ) . derivative ( ) ) ; for ( int i = <int> ; i < <int> ; i + + ) { double relError = Math . abs ( expOut [ i ] - zPrime . getDouble ( i ) ) / ( Math . abs ( expOut [ i ] ) + Math . abs ( zPrime . getDouble ( i ) ) ) ; assertTrue ( relError < REL_ERROR_TOLERANCE ) ; } } @Test public void testSoftMaxDerivative ( ) { assertTrue ( Nd4j . getOpFactory ( ) . createTransform ( <str> , Nd4j . ones ( <int> ) ) . derivative ( ) instanceof SoftMaxDerivative ) ; Random r = new Random ( <int> ) ; INDArray z = Nd4j . zeros ( <int> , <int> ) ; double [ ] [ ] in = new double [ <int> ] [ <int> ] ; double [ ] [ ] softmax = new double [ <int> ] [ <int> ] ; double [ ] [ ] expOut = new double [ <int> ] [ <int> ] ; for ( int i = <int> ; i < <int> ; i + + ) { double rowSumExp = <float> ; for ( int j = <int> ; j < <int> ; j + + ) { in [ i ] [ j ] = <int> * r . nextDouble ( ) ; z . putScalar ( new int [ ] { i , j } , in [ i ] [ j ] ) ; rowSumExp + = FastMath . exp ( in [ i ] [ j ] ) ; } for ( int j = <int> ; j < <int> ; j + + ) { softmax [ i ] [ j ] = FastMath . exp ( in [ i ] [ j ] ) / rowSumExp ; expOut [ i ] [ j ] = softmax [ i ] [ j ] * ( <float> - softmax [ i ] [ j ] ) ; } } INDArray sm = Nd4j . getExecutioner ( ) . execAndReturn ( Nd4j . getOpFactory ( ) . createTransform ( <str> , z . dup ( ) ) , <int> ) ; INDArray zPrime = Nd4j . getExecutioner ( ) . execAndReturn ( Nd4j . getOpFactory ( ) . createTransform ( <str> , z ) . derivative ( ) ) ; System . out . println ( Arrays . toString ( sm . data ( ) . asDouble ( ) ) ) ; System . out . println ( Arrays . toString ( zPrime . data ( ) . asDouble ( ) ) ) ; assertNotEquals ( sm , zPrime ) ; for ( int i = <int> ; i < <int> ; i + + ) { for ( int j = <int> ; j < <int> ; j + + ) { double relError = Math . abs ( expOut [ i ] [ j ] - zPrime . getDouble ( i , j ) ) / ( Math . abs ( expOut [ i ] [ j ] ) + Math . abs ( zPrime . getDouble ( i , j ) ) ) ; assertTrue ( relError < REL_ERROR_TOLERANCE ) ; } } } @Test public void testSoftPlusDerivative ( ) { assertTrue ( Nd4j . getOpFactory ( ) . createTransform ( <str> , Nd4j . ones ( <int> ) ) . derivative ( ) instanceof Sigmoid ) ; INDArray z = Nd4j . zeros ( <int> ) ; double [ ] expOut = new double [ <int> ] ; for ( int i = <int> ; i < <int> ; i + + ) { double x = <float> * ( i - <int> ) ; z . putScalar ( i , x ) ; expOut [ i ] = <float> / ( <float> + FastMath . exp ( - x ) ) ; } INDArray zPrime = Nd4j . getExecutioner ( ) . execAndReturn ( Nd4j . getOpFactory ( ) . createTransform ( <str> , z ) . derivative ( ) ) ; for ( int i = <int> ; i < <int> ; i + + ) { double relError = Math . abs ( expOut [ i ] - zPrime . getDouble ( i ) ) / ( Math . abs ( expOut [ i ] ) + Math . abs ( zPrime . getDouble ( i ) ) ) ; assertTrue ( relError < REL_ERROR_TOLERANCE ) ; } } @Test public void testTanhDerivative ( ) { assertTrue ( Nd4j . getOpFactory ( ) . createTransform ( <str> , Nd4j . ones ( <int> ) ) . derivative ( ) instanceof TanhDerivative ) ; INDArray z = Nd4j . zeros ( <int> ) ; double [ ] expOut = new double [ <int> ] ; for ( int i = <int> ; i < <int> ; i + + ) { double x = <float> * ( i - <int> ) ; z . putScalar ( i , x ) ; double tanh = FastMath . tanh ( x ) ; expOut [ i ] = <float> - tanh * tanh ; } INDArray zPrime = Nd4j . getExecutioner ( ) . execAndReturn ( Nd4j . getOpFactory ( ) . createTransform ( <str> , z ) . derivative ( ) ) ; for ( int i = <int> ; i < <int> ; i + + ) { double relError = Math . abs ( expOut [ i ] - zPrime . getDouble ( i ) ) / ( Math . abs ( expOut [ i ] ) + Math . abs ( zPrime . getDouble ( i ) ) ) ; assertTrue ( relError < REL_ERROR_TOLERANCE ) ; } } @Test public void testLeakyReLUDerivative ( ) { assertTrue ( Nd4j . getOpFactory ( ) . createTransform ( <str> , Nd4j . ones ( <int> ) ) . derivative ( ) instanceof LeakyReLUDerivative ) ; INDArray z = Nd4j . zeros ( <int> ) ; double [ ] expOut = new double [ <int> ] ; for ( int i = <int> ; i < <int> ; i + + ) { double x = <float> * ( i - <int> ) ; z . putScalar ( i , x ) ; expOut [ i ] = ( x > = <int> ? <int> : <float> ) ; } INDArray zPrime = Nd4j . getExecutioner ( ) . execAndReturn ( Nd4j . getOpFactory ( ) . createTransform ( <str> , z ) . derivative ( ) ) ; for ( int i = <int> ; i < <int> ; i + + ) { double relError = Math . abs ( expOut [ i ] - zPrime . getDouble ( i ) ) / ( Math . abs ( expOut [ i ] ) + Math . abs ( zPrime . getDouble ( i ) ) ) ; assertTrue ( relError < REL_ERROR_TOLERANCE ) ; } } @Test public void testSoftSignDerivative ( ) { assertTrue ( Nd4j . getOpFactory ( ) . createTransform ( <str> , Nd4j . ones ( <int> ) ) . derivative ( ) instanceof SoftSignDerivative ) ; INDArray z = Nd4j . zeros ( <int> ) ; double [ ] expOut = new double [ <int> ] ; for ( int i = <int> ; i < <int> ; i + + ) { double x = <float> * ( i - <int> ) ; z . putScalar ( i , x ) ; double temp = <int> + Math . abs ( x ) ; expOut [ i ] = <float> / ( temp * temp ) ; } INDArray zPrime = Nd4j . getExecutioner ( ) . execAndReturn ( Nd4j . getOpFactory ( ) . createTransform ( <str> , z ) . derivative ( ) ) ; for ( int i = <int> ; i < <int> ; i + + ) { double relError = Math . abs ( expOut [ i ] - zPrime . getDouble ( i ) ) / ( Math . abs ( expOut [ i ] ) + Math . abs ( zPrime . getDouble ( i ) ) ) ; assertTrue ( relError < REL_ERROR_TOLERANCE ) ; } } @Test public void testELUDerivative ( ) { assertTrue ( Nd4j . getOpFactory ( ) . createTransform ( <str> , Nd4j . ones ( <int> ) ) . derivative ( ) instanceof ELUDerivative ) ; INDArray z = Nd4j . zeros ( <int> ) ; double [ ] out = new double [ <int> ] ; double [ ] outDeriv = new double [ <int> ] ; for ( int i = <int> ; i < <int> ; i + + ) { double x = <float> * ( i - <int> ) ; z . putScalar ( i , x ) ; if ( x > = <int> ) { out [ i ] = x ; outDeriv [ i ] = <float> ; } else { out [ i ] = FastMath . exp ( x ) - <float> ; outDeriv [ i ] = FastMath . exp ( x ) ; } } INDArray act = Nd4j . getExecutioner ( ) . execAndReturn ( Nd4j . getOpFactory ( ) . createTransform ( <str> , z . dup ( ) ) ) ; INDArray actDeriv = Nd4j . getExecutioner ( ) . execAndReturn ( Nd4j . getOpFactory ( ) . createTransform ( <str> , z . dup ( ) ) . derivative ( ) ) ; System . out . println ( act ) ; for ( int i = <int> ; i < <int> ; i + + ) { double relError1 = Math . abs ( out [ i ] - act . getDouble ( i ) ) / ( Math . abs ( out [ i ] ) + Math . abs ( act . getDouble ( i ) ) ) ; if ( out [ i ] = = <float> & & act . getDouble ( i ) = = <float> ) relError1 = <float> ; double relError2 = Math . abs ( outDeriv [ i ] - actDeriv . getDouble ( i ) ) / ( Math . abs ( outDeriv [ i ] ) + Math . abs ( actDeriv . getDouble ( i ) ) ) ; if ( outDeriv [ i ] = = <float> & & actDeriv . getDouble ( i ) = = <float> ) relError2 = <float> ; assertTrue ( relError1 < REL_ERROR_TOLERANCE ) ; assertTrue ( relError2 < REL_ERROR_TOLERANCE ) ; } } @Override public char ordering ( ) { return <str> ; } } 
