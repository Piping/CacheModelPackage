package org . elasticsearch . cluster . metadata ; import com . carrotsearch . hppc . cursors . ObjectCursor ; import org . elasticsearch . action . ActionListener ; import org . elasticsearch . action . admin . indices . mapping . put . PutMappingClusterStateUpdateRequest ; import org . elasticsearch . cluster . * ; import org . elasticsearch . cluster . ack . ClusterStateUpdateResponse ; import org . elasticsearch . cluster . node . DiscoveryNode ; import org . elasticsearch . common . Nullable ; import org . elasticsearch . common . Priority ; import org . elasticsearch . common . component . AbstractComponent ; import org . elasticsearch . common . compress . CompressedXContent ; import org . elasticsearch . common . inject . Inject ; import org . elasticsearch . common . settings . Settings ; import org . elasticsearch . common . unit . TimeValue ; import org . elasticsearch . index . IndexNotFoundException ; import org . elasticsearch . index . IndexService ; import org . elasticsearch . index . NodeServicesProvider ; import org . elasticsearch . index . mapper . DocumentMapper ; import org . elasticsearch . index . mapper . MapperService ; import org . elasticsearch . index . mapper . MergeResult ; import org . elasticsearch . indices . IndicesService ; import org . elasticsearch . indices . InvalidTypeNameException ; import org . elasticsearch . percolator . PercolatorService ; import java . io . IOException ; import java . util . * ; public class MetaDataMappingService extends AbstractComponent { private final ClusterService clusterService ; private final IndicesService indicesService ; final ClusterStateTaskExecutor < RefreshTask > refreshExecutor = new RefreshTaskExecutor ( ) ; final ClusterStateTaskExecutor < PutMappingClusterStateUpdateRequest > putMappingExecutor = new PutMappingExecutor ( ) ; private final NodeServicesProvider nodeServicesProvider ; @Inject public MetaDataMappingService ( Settings settings , ClusterService clusterService , IndicesService indicesService , NodeServicesProvider nodeServicesProvider ) { super ( settings ) ; this . clusterService = clusterService ; this . indicesService = indicesService ; this . nodeServicesProvider = nodeServicesProvider ; } static class RefreshTask { final String index ; final String indexUUID ; RefreshTask ( String index , final String indexUUID ) { this . index = index ; this . indexUUID = indexUUID ; } } class RefreshTaskExecutor implements ClusterStateTaskExecutor < RefreshTask > { @Override public BatchResult < RefreshTask > execute ( ClusterState currentState , List < RefreshTask > tasks ) throws Exception { ClusterState newClusterState = executeRefresh ( currentState , tasks ) ; return BatchResult . < RefreshTask > builder ( ) . successes ( tasks ) . build ( newClusterState ) ; } } ClusterState executeRefresh ( final ClusterState currentState , final List < RefreshTask > allTasks ) throws Exception { Map < String , List < RefreshTask > > tasksPerIndex = new HashMap < > ( ) ; for ( RefreshTask task : allTasks ) { if ( task . index = = null ) { logger . debug ( <str> , task ) ; } tasksPerIndex . computeIfAbsent ( task . index , k - > new ArrayList < > ( ) ) . add ( task ) ; } boolean dirty = false ; MetaData . Builder mdBuilder = MetaData . builder ( currentState . metaData ( ) ) ; for ( Map . Entry < String , List < RefreshTask > > entry : tasksPerIndex . entrySet ( ) ) { String index = entry . getKey ( ) ; IndexMetaData indexMetaData = mdBuilder . get ( index ) ; if ( indexMetaData = = null ) { logger . debug ( <str> , index ) ; continue ; } List < RefreshTask > allIndexTasks = entry . getValue ( ) ; boolean hasTaskWithRightUUID = false ; for ( RefreshTask task : allIndexTasks ) { if ( indexMetaData . isSameUUID ( task . indexUUID ) ) { hasTaskWithRightUUID = true ; } else { logger . debug ( <str> , index , task ) ; } } if ( hasTaskWithRightUUID = = false ) { continue ; } boolean removeIndex = false ; IndexService indexService = indicesService . indexService ( index ) ; if ( indexService = = null ) { indexService = indicesService . createIndex ( nodeServicesProvider , indexMetaData , Collections . emptyList ( ) ) ; removeIndex = true ; for ( ObjectCursor < MappingMetaData > metaData : indexMetaData . getMappings ( ) . values ( ) ) { indexService . mapperService ( ) . merge ( metaData . value . type ( ) , metaData . value . source ( ) , false , true ) ; } } IndexMetaData . Builder builder = IndexMetaData . builder ( indexMetaData ) ; try { boolean indexDirty = refreshIndexMapping ( indexService , builder ) ; if ( indexDirty ) { mdBuilder . put ( builder ) ; dirty = true ; } } finally { if ( removeIndex ) { indicesService . removeIndex ( index , <str> ) ; } } } if ( ! dirty ) { return currentState ; } return ClusterState . builder ( currentState ) . metaData ( mdBuilder ) . build ( ) ; } private boolean refreshIndexMapping ( IndexService indexService , IndexMetaData . Builder builder ) { boolean dirty = false ; String index = indexService . index ( ) . name ( ) ; try { List < String > updatedTypes = new ArrayList < > ( ) ; for ( DocumentMapper mapper : indexService . mapperService ( ) . docMappers ( true ) ) { final String type = mapper . type ( ) ; if ( ! mapper . mappingSource ( ) . equals ( builder . mapping ( type ) . source ( ) ) ) { updatedTypes . add ( type ) ; } } if ( updatedTypes . isEmpty ( ) = = false ) { logger . warn ( <str> , index , updatedTypes ) ; dirty = true ; for ( DocumentMapper mapper : indexService . mapperService ( ) . docMappers ( true ) ) { builder . putMapping ( new MappingMetaData ( mapper ) ) ; } } } catch ( Throwable t ) { logger . warn ( <str> , t , index ) ; } return dirty ; } public void refreshMapping ( final String index , final String indexUUID ) { final RefreshTask refreshTask = new RefreshTask ( index , indexUUID ) ; clusterService . submitStateUpdateTask ( <str> + index + <str> , refreshTask , ClusterStateTaskConfig . build ( Priority . HIGH ) , refreshExecutor , ( source , t ) - > logger . warn ( <str> , t , source ) ) ; } class PutMappingExecutor implements ClusterStateTaskExecutor < PutMappingClusterStateUpdateRequest > { @Override public BatchResult < PutMappingClusterStateUpdateRequest > execute ( ClusterState currentState , List < PutMappingClusterStateUpdateRequest > tasks ) throws Exception { Set < String > indicesToClose = new HashSet < > ( ) ; BatchResult . Builder < PutMappingClusterStateUpdateRequest > builder = BatchResult . builder ( ) ; try { for ( PutMappingClusterStateUpdateRequest request : tasks ) { for ( String index : request . indices ( ) ) { final IndexMetaData indexMetaData = currentState . metaData ( ) . index ( index ) ; if ( indexMetaData ! = null & & indicesService . hasIndex ( index ) = = false ) { indicesToClose . add ( index ) ; IndexService indexService = indicesService . createIndex ( nodeServicesProvider , indexMetaData , Collections . emptyList ( ) ) ; for ( ObjectCursor < MappingMetaData > mapping : indexMetaData . getMappings ( ) . values ( ) ) { indexService . mapperService ( ) . merge ( mapping . value . type ( ) , mapping . value . source ( ) , false , request . updateAllTypes ( ) ) ; } } } } for ( PutMappingClusterStateUpdateRequest request : tasks ) { try { currentState = applyRequest ( currentState , request ) ; builder . success ( request ) ; } catch ( Throwable t ) { builder . failure ( request , t ) ; } } return builder . build ( currentState ) ; } finally { for ( String index : indicesToClose ) { indicesService . removeIndex ( index , <str> ) ; } } } private ClusterState applyRequest ( ClusterState currentState , PutMappingClusterStateUpdateRequest request ) throws IOException { Map < String , DocumentMapper > newMappers = new HashMap < > ( ) ; Map < String , DocumentMapper > existingMappers = new HashMap < > ( ) ; for ( String index : request . indices ( ) ) { IndexService indexService = indicesService . indexServiceSafe ( index ) ; DocumentMapper newMapper ; DocumentMapper existingMapper = indexService . mapperService ( ) . documentMapper ( request . type ( ) ) ; if ( MapperService . DEFAULT_MAPPING . equals ( request . type ( ) ) ) { newMapper = indexService . mapperService ( ) . parse ( request . type ( ) , new CompressedXContent ( request . source ( ) ) , false ) ; } else { newMapper = indexService . mapperService ( ) . parse ( request . type ( ) , new CompressedXContent ( request . source ( ) ) , existingMapper = = null ) ; if ( existingMapper ! = null ) { MergeResult mergeResult = existingMapper . merge ( newMapper . mapping ( ) , true , request . updateAllTypes ( ) ) ; if ( mergeResult . hasConflicts ( ) ) { throw new IllegalArgumentException ( <str> + Arrays . toString ( mergeResult . buildConflicts ( ) ) + <str> ) ; } } else { if ( newMapper . parentFieldMapper ( ) . active ( ) ) { IndexMetaData indexMetaData = currentState . metaData ( ) . index ( index ) ; for ( ObjectCursor < MappingMetaData > mapping : indexMetaData . getMappings ( ) . values ( ) ) { if ( newMapper . parentFieldMapper ( ) . type ( ) . equals ( mapping . value . type ( ) ) ) { throw new IllegalArgumentException ( <str> ) ; } } } } } newMappers . put ( index , newMapper ) ; if ( existingMapper ! = null ) { existingMappers . put ( index , existingMapper ) ; } } String mappingType = request . type ( ) ; if ( mappingType = = null ) { mappingType = newMappers . values ( ) . iterator ( ) . next ( ) . type ( ) ; } else if ( ! mappingType . equals ( newMappers . values ( ) . iterator ( ) . next ( ) . type ( ) ) ) { throw new InvalidTypeNameException ( <str> ) ; } if ( ! MapperService . DEFAULT_MAPPING . equals ( mappingType ) & & ! PercolatorService . TYPE_NAME . equals ( mappingType ) & & mappingType . charAt ( <int> ) = = <str> ) { throw new InvalidTypeNameException ( <str> ) ; } final Map < String , MappingMetaData > mappings = new HashMap < > ( ) ; for ( Map . Entry < String , DocumentMapper > entry : newMappers . entrySet ( ) ) { String index = entry . getKey ( ) ; DocumentMapper newMapper = entry . getValue ( ) ; IndexService indexService = indicesService . indexService ( index ) ; if ( indexService = = null ) { continue ; } CompressedXContent existingSource = null ; if ( existingMappers . containsKey ( entry . getKey ( ) ) ) { existingSource = existingMappers . get ( entry . getKey ( ) ) . mappingSource ( ) ; } DocumentMapper mergedMapper = indexService . mapperService ( ) . merge ( newMapper . type ( ) , newMapper . mappingSource ( ) , false , request . updateAllTypes ( ) ) ; CompressedXContent updatedSource = mergedMapper . mappingSource ( ) ; if ( existingSource ! = null ) { if ( existingSource . equals ( updatedSource ) ) { } else { mappings . put ( index , new MappingMetaData ( mergedMapper ) ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( <str> , index , mergedMapper . type ( ) , updatedSource ) ; } else if ( logger . isInfoEnabled ( ) ) { logger . info ( <str> , index , mergedMapper . type ( ) ) ; } } } else { mappings . put ( index , new MappingMetaData ( mergedMapper ) ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( <str> , index , newMapper . type ( ) , updatedSource ) ; } else if ( logger . isInfoEnabled ( ) ) { logger . info ( <str> , index , newMapper . type ( ) ) ; } } } if ( mappings . isEmpty ( ) ) { return currentState ; } MetaData . Builder builder = MetaData . builder ( currentState . metaData ( ) ) ; for ( String indexName : request . indices ( ) ) { IndexMetaData indexMetaData = currentState . metaData ( ) . index ( indexName ) ; if ( indexMetaData = = null ) { throw new IndexNotFoundException ( indexName ) ; } MappingMetaData mappingMd = mappings . get ( indexName ) ; if ( mappingMd ! = null ) { builder . put ( IndexMetaData . builder ( indexMetaData ) . putMapping ( mappingMd ) ) ; } } return ClusterState . builder ( currentState ) . metaData ( builder ) . build ( ) ; } } public void putMapping ( final PutMappingClusterStateUpdateRequest request , final ActionListener < ClusterStateUpdateResponse > listener ) { clusterService . submitStateUpdateTask ( <str> + request . type ( ) + <str> , request , ClusterStateTaskConfig . build ( Priority . HIGH , request . masterNodeTimeout ( ) ) , putMappingExecutor , new AckedClusterStateTaskListener ( ) { @Override public void onFailure ( String source , Throwable t ) { listener . onFailure ( t ) ; } @Override public boolean mustAck ( DiscoveryNode discoveryNode ) { return true ; } @Override public void onAllNodesAcked ( @Nullable Throwable t ) { listener . onResponse ( new ClusterStateUpdateResponse ( true ) ) ; } @Override public void onAckTimeout ( ) { listener . onResponse ( new ClusterStateUpdateResponse ( false ) ) ; } @Override public TimeValue ackTimeout ( ) { return request . ackTimeout ( ) ; } } ) ; } } 
