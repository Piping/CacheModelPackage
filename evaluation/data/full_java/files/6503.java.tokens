package org . elasticsearch . index . fielddata . plain ; import org . apache . lucene . codecs . blocktree . FieldReader ; import org . apache . lucene . codecs . blocktree . Stats ; import org . apache . lucene . index . * ; import org . apache . lucene . search . DocIdSetIterator ; import org . apache . lucene . util . BytesRef ; import org . apache . lucene . util . PagedBytes ; import org . apache . lucene . util . packed . PackedInts ; import org . apache . lucene . util . packed . PackedLongValues ; import org . elasticsearch . common . breaker . CircuitBreaker ; import org . elasticsearch . index . IndexSettings ; import org . elasticsearch . index . fielddata . * ; import org . elasticsearch . index . fielddata . ordinals . Ordinals ; import org . elasticsearch . index . fielddata . ordinals . OrdinalsBuilder ; import org . elasticsearch . index . mapper . MappedFieldType ; import org . elasticsearch . index . mapper . MapperService ; import org . elasticsearch . indices . breaker . CircuitBreakerService ; import java . io . IOException ; public class PagedBytesIndexFieldData extends AbstractIndexOrdinalsFieldData { public static class Builder implements IndexFieldData . Builder { @Override public IndexOrdinalsFieldData build ( IndexSettings indexSettings , MappedFieldType fieldType , IndexFieldDataCache cache , CircuitBreakerService breakerService , MapperService mapperService ) { return new PagedBytesIndexFieldData ( indexSettings , fieldType . names ( ) , fieldType . fieldDataType ( ) , cache , breakerService ) ; } } public PagedBytesIndexFieldData ( IndexSettings indexSettings , MappedFieldType . Names fieldNames , FieldDataType fieldDataType , IndexFieldDataCache cache , CircuitBreakerService breakerService ) { super ( indexSettings , fieldNames , fieldDataType , cache , breakerService ) ; } @Override public AtomicOrdinalsFieldData loadDirect ( LeafReaderContext context ) throws Exception { LeafReader reader = context . reader ( ) ; AtomicOrdinalsFieldData data = null ; PagedBytesEstimator estimator = new PagedBytesEstimator ( context , breakerService . getBreaker ( CircuitBreaker . FIELDDATA ) , getFieldNames ( ) . fullName ( ) ) ; Terms terms = reader . terms ( getFieldNames ( ) . indexName ( ) ) ; if ( terms = = null ) { data = AbstractAtomicOrdinalsFieldData . empty ( ) ; estimator . afterLoad ( null , data . ramBytesUsed ( ) ) ; return data ; } final PagedBytes bytes = new PagedBytes ( <int> ) ; final PackedLongValues . Builder termOrdToBytesOffset = PackedLongValues . monotonicBuilder ( PackedInts . COMPACT ) ; final long numTerms ; if ( regex = = null & & frequency = = null ) { numTerms = terms . size ( ) ; } else { numTerms = - <int> ; } final float acceptableTransientOverheadRatio = fieldDataType . getSettings ( ) . getAsFloat ( FilterSettingFields . ACCEPTABLE_TRANSIENT_OVERHEAD_RATIO , OrdinalsBuilder . DEFAULT_ACCEPTABLE_OVERHEAD_RATIO ) ; TermsEnum termsEnum = estimator . beforeLoad ( terms ) ; boolean success = false ; try ( OrdinalsBuilder builder = new OrdinalsBuilder ( numTerms , reader . maxDoc ( ) , acceptableTransientOverheadRatio ) ) { PostingsEnum docsEnum = null ; for ( BytesRef term = termsEnum . next ( ) ; term ! = null ; term = termsEnum . next ( ) ) { final long termOrd = builder . nextOrdinal ( ) ; assert termOrd = = termOrdToBytesOffset . size ( ) ; termOrdToBytesOffset . add ( bytes . copyUsingLengthPrefix ( term ) ) ; docsEnum = termsEnum . postings ( docsEnum , PostingsEnum . NONE ) ; for ( int docId = docsEnum . nextDoc ( ) ; docId ! = DocIdSetIterator . NO_MORE_DOCS ; docId = docsEnum . nextDoc ( ) ) { builder . addDoc ( docId ) ; } } PagedBytes . Reader bytesReader = bytes . freeze ( true ) ; final Ordinals ordinals = builder . build ( fieldDataType . getSettings ( ) ) ; data = new PagedBytesAtomicFieldData ( bytesReader , termOrdToBytesOffset . build ( ) , ordinals ) ; success = true ; return data ; } finally { if ( ! success ) { estimator . afterLoad ( termsEnum , <int> ) ; } else { estimator . afterLoad ( termsEnum , data . ramBytesUsed ( ) ) ; } } } public class PagedBytesEstimator implements PerValueEstimator { private final LeafReaderContext context ; private final CircuitBreaker breaker ; private final String fieldName ; private long estimatedBytes ; PagedBytesEstimator ( LeafReaderContext context , CircuitBreaker breaker , String fieldName ) { this . breaker = breaker ; this . context = context ; this . fieldName = fieldName ; } @Override public long bytesPerValue ( BytesRef term ) { if ( term = = null ) { return <int> ; } long bytes = term . length ; bytes + = <int> ; bytes = ( long ) ( ( double ) bytes / <float> ) + <int> ; return bytes ; } public long estimateStringFieldData ( ) { try { LeafReader reader = context . reader ( ) ; Terms terms = reader . terms ( getFieldNames ( ) . indexName ( ) ) ; Fields fields = reader . fields ( ) ; final Terms fieldTerms = fields . terms ( getFieldNames ( ) . indexName ( ) ) ; if ( fieldTerms instanceof FieldReader ) { final Stats stats = ( ( FieldReader ) fieldTerms ) . getStats ( ) ; long totalTermBytes = stats . totalTermBytes ; if ( logger . isTraceEnabled ( ) ) { logger . trace ( <str> , totalTermBytes , terms . size ( ) , terms . getSumDocFreq ( ) ) ; } long totalBytes = totalTermBytes + ( <int> * terms . size ( ) ) + ( <int> * terms . getSumDocFreq ( ) ) ; return totalBytes ; } } catch ( Exception e ) { logger . warn ( <str> , e ) ; } return <int> ; } @Override public TermsEnum beforeLoad ( Terms terms ) throws IOException { final float acceptableTransientOverheadRatio = fieldDataType . getSettings ( ) . getAsFloat ( FilterSettingFields . ACCEPTABLE_TRANSIENT_OVERHEAD_RATIO , OrdinalsBuilder . DEFAULT_ACCEPTABLE_OVERHEAD_RATIO ) ; LeafReader reader = context . reader ( ) ; if ( acceptableTransientOverheadRatio ! = OrdinalsBuilder . DEFAULT_ACCEPTABLE_OVERHEAD_RATIO | | fieldDataType . getSettings ( ) . getAsDouble ( FilterSettingFields . FREQUENCY_MIN , <float> ) ! = <float> | | fieldDataType . getSettings ( ) . getAsDouble ( FilterSettingFields . FREQUENCY_MAX , <float> ) ! = <float> | | fieldDataType . getSettings ( ) . getAsDouble ( FilterSettingFields . FREQUENCY_MIN_SEGMENT_SIZE , <float> ) ! = <float> | | fieldDataType . getSettings ( ) . get ( FilterSettingFields . REGEX_PATTERN ) ! = null ) { if ( logger . isTraceEnabled ( ) ) { logger . trace ( <str> ) ; } return new RamAccountingTermsEnum ( filter ( terms , reader ) , breaker , this , this . fieldName ) ; } else { estimatedBytes = this . estimateStringFieldData ( ) ; if ( estimatedBytes = = <int> ) { return new RamAccountingTermsEnum ( filter ( terms , reader ) , breaker , this , this . fieldName ) ; } breaker . addEstimateBytesAndMaybeBreak ( estimatedBytes , fieldName ) ; return filter ( terms , reader ) ; } } @Override public void afterLoad ( TermsEnum termsEnum , long actualUsed ) { if ( termsEnum instanceof RamAccountingTermsEnum ) { estimatedBytes = ( ( RamAccountingTermsEnum ) termsEnum ) . getTotalBytes ( ) ; } breaker . addWithoutBreaking ( - ( estimatedBytes - actualUsed ) ) ; } public void adjustForNoTerms ( long actualUsed ) { breaker . addWithoutBreaking ( actualUsed ) ; } } static final class FilterSettingFields { static final String ACCEPTABLE_TRANSIENT_OVERHEAD_RATIO = <str> ; static final String FREQUENCY_MIN = <str> ; static final String FREQUENCY_MAX = <str> ; static final String FREQUENCY_MIN_SEGMENT_SIZE = <str> ; static final String REGEX_PATTERN = <str> ; } } 
