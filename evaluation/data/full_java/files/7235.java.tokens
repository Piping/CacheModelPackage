package org . elasticsearch . search . aggregations . bucket . significant ; import org . elasticsearch . common . io . stream . StreamInput ; import org . elasticsearch . common . io . stream . StreamOutput ; import org . elasticsearch . common . xcontent . XContentBuilder ; import org . elasticsearch . search . aggregations . AggregationStreams ; import org . elasticsearch . search . aggregations . InternalAggregations ; import org . elasticsearch . search . aggregations . bucket . BucketStreamContext ; import org . elasticsearch . search . aggregations . bucket . BucketStreams ; import org . elasticsearch . search . aggregations . bucket . significant . heuristics . SignificanceHeuristic ; import org . elasticsearch . search . aggregations . bucket . significant . heuristics . SignificanceHeuristicStreams ; import org . elasticsearch . search . aggregations . pipeline . PipelineAggregator ; import org . elasticsearch . search . aggregations . support . format . ValueFormatter ; import org . elasticsearch . search . aggregations . support . format . ValueFormatterStreams ; import java . io . IOException ; import java . util . ArrayList ; import java . util . HashMap ; import java . util . List ; import java . util . Map ; public class SignificantLongTerms extends InternalSignificantTerms < SignificantLongTerms , SignificantLongTerms . Bucket > { public static final Type TYPE = new Type ( <str> , <str> ) ; public static final AggregationStreams . Stream STREAM = new AggregationStreams . Stream ( ) { @Override public SignificantLongTerms readResult ( StreamInput in ) throws IOException { SignificantLongTerms buckets = new SignificantLongTerms ( ) ; buckets . readFrom ( in ) ; return buckets ; } } ; private final static BucketStreams . Stream < Bucket > BUCKET_STREAM = new BucketStreams . Stream < Bucket > ( ) { @Override public Bucket readResult ( StreamInput in , BucketStreamContext context ) throws IOException { Bucket buckets = new Bucket ( ( long ) context . attributes ( ) . get ( <str> ) , ( long ) context . attributes ( ) . get ( <str> ) , context . formatter ( ) ) ; buckets . readFrom ( in ) ; return buckets ; } @Override public BucketStreamContext getBucketStreamContext ( Bucket bucket ) { BucketStreamContext context = new BucketStreamContext ( ) ; Map < String , Object > attributes = new HashMap < > ( ) ; attributes . put ( <str> , bucket . subsetSize ) ; attributes . put ( <str> , bucket . supersetSize ) ; context . attributes ( attributes ) ; context . formatter ( bucket . formatter ) ; return context ; } } ; public static void registerStreams ( ) { AggregationStreams . registerStream ( STREAM , TYPE . stream ( ) ) ; BucketStreams . registerStream ( BUCKET_STREAM , TYPE . stream ( ) ) ; } static class Bucket extends InternalSignificantTerms . Bucket { long term ; private transient final ValueFormatter formatter ; public Bucket ( long subsetSize , long supersetSize , ValueFormatter formatter ) { super ( subsetSize , supersetSize ) ; this . formatter = formatter ; } public Bucket ( long subsetDf , long subsetSize , long supersetDf , long supersetSize , long term , InternalAggregations aggregations , ValueFormatter formatter ) { super ( subsetDf , subsetSize , supersetDf , supersetSize , aggregations ) ; this . formatter = formatter ; this . term = term ; } public Bucket ( long subsetDf , long subsetSize , long supersetDf , long supersetSize , long term , InternalAggregations aggregations , double score ) { this ( subsetDf , subsetSize , supersetDf , supersetSize , term , aggregations , null ) ; this . score = score ; } @Override public Object getKey ( ) { return term ; } @Override int compareTerm ( SignificantTerms . Bucket other ) { return Long . compare ( term , ( ( Number ) other . getKey ( ) ) . longValue ( ) ) ; } @Override public String getKeyAsString ( ) { return Long . toString ( term ) ; } @Override public Number getKeyAsNumber ( ) { return term ; } @Override Bucket newBucket ( long subsetDf , long subsetSize , long supersetDf , long supersetSize , InternalAggregations aggregations ) { return new Bucket ( subsetDf , subsetSize , supersetDf , supersetSize , term , aggregations , formatter ) ; } @Override public void readFrom ( StreamInput in ) throws IOException { subsetDf = in . readVLong ( ) ; supersetDf = in . readVLong ( ) ; term = in . readLong ( ) ; score = in . readDouble ( ) ; aggregations = InternalAggregations . readAggregations ( in ) ; } @Override public void writeTo ( StreamOutput out ) throws IOException { out . writeVLong ( subsetDf ) ; out . writeVLong ( supersetDf ) ; out . writeLong ( term ) ; out . writeDouble ( getSignificanceScore ( ) ) ; aggregations . writeTo ( out ) ; } @Override public XContentBuilder toXContent ( XContentBuilder builder , Params params ) throws IOException { builder . startObject ( ) ; builder . field ( CommonFields . KEY , term ) ; if ( formatter ! = null ) { builder . field ( CommonFields . KEY_AS_STRING , formatter . format ( term ) ) ; } builder . field ( CommonFields . DOC_COUNT , getDocCount ( ) ) ; builder . field ( <str> , score ) ; builder . field ( <str> , supersetDf ) ; aggregations . toXContentInternal ( builder , params ) ; builder . endObject ( ) ; return builder ; } } private ValueFormatter formatter ; SignificantLongTerms ( ) { } public SignificantLongTerms ( long subsetSize , long supersetSize , String name , ValueFormatter formatter , int requiredSize , long minDocCount , SignificanceHeuristic significanceHeuristic , List < ? extends InternalSignificantTerms . Bucket > buckets , List < PipelineAggregator > pipelineAggregators , Map < String , Object > metaData ) { super ( subsetSize , supersetSize , name , requiredSize , minDocCount , significanceHeuristic , buckets , pipelineAggregators , metaData ) ; this . formatter = formatter ; } @Override public Type type ( ) { return TYPE ; } @Override public SignificantLongTerms create ( List < SignificantLongTerms . Bucket > buckets ) { return new SignificantLongTerms ( this . subsetSize , this . supersetSize , this . name , this . formatter , this . requiredSize , this . minDocCount , this . significanceHeuristic , buckets , this . pipelineAggregators ( ) , this . metaData ) ; } @Override public Bucket createBucket ( InternalAggregations aggregations , SignificantLongTerms . Bucket prototype ) { return new Bucket ( prototype . subsetDf , prototype . subsetSize , prototype . supersetDf , prototype . supersetSize , prototype . term , aggregations , prototype . formatter ) ; } @Override protected SignificantLongTerms create ( long subsetSize , long supersetSize , List < org . elasticsearch . search . aggregations . bucket . significant . InternalSignificantTerms . Bucket > buckets , InternalSignificantTerms prototype ) { return new SignificantLongTerms ( subsetSize , supersetSize , prototype . getName ( ) , ( ( SignificantLongTerms ) prototype ) . formatter , prototype . requiredSize , prototype . minDocCount , prototype . significanceHeuristic , buckets , prototype . pipelineAggregators ( ) , prototype . getMetaData ( ) ) ; } @Override protected void doReadFrom ( StreamInput in ) throws IOException { this . formatter = ValueFormatterStreams . readOptional ( in ) ; this . requiredSize = readSize ( in ) ; this . minDocCount = in . readVLong ( ) ; this . subsetSize = in . readVLong ( ) ; this . supersetSize = in . readVLong ( ) ; significanceHeuristic = SignificanceHeuristicStreams . read ( in ) ; int size = in . readVInt ( ) ; List < InternalSignificantTerms . Bucket > buckets = new ArrayList < > ( size ) ; for ( int i = <int> ; i < size ; i + + ) { Bucket bucket = new Bucket ( subsetSize , supersetSize , formatter ) ; bucket . readFrom ( in ) ; buckets . add ( bucket ) ; } this . buckets = buckets ; this . bucketMap = null ; } @Override protected void doWriteTo ( StreamOutput out ) throws IOException { ValueFormatterStreams . writeOptional ( formatter , out ) ; writeSize ( requiredSize , out ) ; out . writeVLong ( minDocCount ) ; out . writeVLong ( subsetSize ) ; out . writeVLong ( supersetSize ) ; significanceHeuristic . writeTo ( out ) ; out . writeVInt ( buckets . size ( ) ) ; for ( InternalSignificantTerms . Bucket bucket : buckets ) { bucket . writeTo ( out ) ; } } @Override public XContentBuilder doXContentBody ( XContentBuilder builder , Params params ) throws IOException { builder . field ( <str> , subsetSize ) ; builder . startArray ( CommonFields . BUCKETS ) ; for ( InternalSignificantTerms . Bucket bucket : buckets ) { bucket . toXContent ( builder , params ) ; } builder . endArray ( ) ; return builder ; } } 
