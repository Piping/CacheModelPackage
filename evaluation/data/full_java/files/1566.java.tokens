package org . apache . cassandra . io . sstable ; import java . io . File ; import java . io . IOException ; import java . util . * ; import org . apache . cassandra . config . CFMetaData ; import org . apache . cassandra . config . Schema ; import org . apache . cassandra . db . * ; import org . apache . cassandra . db . rows . * ; import org . apache . cassandra . db . partitions . * ; import org . apache . cassandra . io . sstable . format . SSTableReader ; import org . apache . cassandra . service . ActiveRepairService ; import org . apache . cassandra . Util ; import static org . junit . Assert . assertEquals ; public class SSTableUtils { public static String KEYSPACENAME = <str> ; public static String CFNAME = <str> ; public SSTableUtils ( String ksname , String cfname ) { KEYSPACENAME = ksname ; CFNAME = cfname ; } public static File tempSSTableFile ( String keyspaceName , String cfname , int generation ) throws IOException { File tempdir = File . createTempFile ( keyspaceName , cfname ) ; if ( ! tempdir . delete ( ) | | ! tempdir . mkdir ( ) ) throw new IOException ( <str> ) ; tempdir . deleteOnExit ( ) ; File cfDir = new File ( tempdir , keyspaceName + File . separator + cfname ) ; cfDir . mkdirs ( ) ; cfDir . deleteOnExit ( ) ; File datafile = new File ( new Descriptor ( cfDir , keyspaceName , cfname , generation ) . filenameFor ( Component . DATA ) ) ; if ( ! datafile . createNewFile ( ) ) throw new IOException ( <str> + datafile ) ; datafile . deleteOnExit ( ) ; return datafile ; } public static void assertContentEquals ( SSTableReader lhs , SSTableReader rhs ) throws Exception { try ( ISSTableScanner slhs = lhs . getScanner ( ) ; ISSTableScanner srhs = rhs . getScanner ( ) ) { while ( slhs . hasNext ( ) ) { UnfilteredRowIterator ilhs = slhs . next ( ) ; assert srhs . hasNext ( ) : <str> ; UnfilteredRowIterator irhs = srhs . next ( ) ; assertContentEquals ( ilhs , irhs ) ; } assert ! srhs . hasNext ( ) : <str> ; } } public static void assertContentEquals ( UnfilteredRowIterator lhs , UnfilteredRowIterator rhs ) { assertEquals ( lhs . partitionKey ( ) , rhs . partitionKey ( ) ) ; assertEquals ( lhs . partitionLevelDeletion ( ) , rhs . partitionLevelDeletion ( ) ) ; while ( lhs . hasNext ( ) ) { Unfiltered clhs = lhs . next ( ) ; assert rhs . hasNext ( ) : <str> + lhs . partitionKey ( ) ; Unfiltered crhs = rhs . next ( ) ; assertEquals ( <str> + lhs . partitionKey ( ) , clhs , crhs ) ; } assert ! rhs . hasNext ( ) : <str> + lhs . partitionKey ( ) ; } public static Context prepare ( ) { return new Context ( ) ; } public static class Context { private String ksname = KEYSPACENAME ; private String cfname = CFNAME ; private Descriptor dest = null ; private boolean cleanup = true ; private int generation = <int> ; Context ( ) { } public Context ks ( String ksname ) { this . ksname = ksname ; return this ; } public Context cf ( String cfname ) { this . cfname = cfname ; return this ; } public Context dest ( Descriptor dest ) { this . dest = dest ; this . cleanup = false ; return this ; } public Context generation ( int generation ) { this . generation = generation ; return this ; } public Collection < SSTableReader > write ( Set < String > keys ) throws IOException { Map < String , PartitionUpdate > map = new HashMap < > ( ) ; for ( String key : keys ) { RowUpdateBuilder builder = new RowUpdateBuilder ( Schema . instance . getCFMetaData ( ksname , cfname ) , <int> , key ) ; builder . clustering ( key ) . add ( <str> , key ) ; map . put ( key , builder . buildUpdate ( ) ) ; } return write ( map ) ; } public Collection < SSTableReader > write ( SortedMap < DecoratedKey , PartitionUpdate > sorted ) throws IOException { PartitionColumns . Builder builder = PartitionColumns . builder ( ) ; for ( PartitionUpdate update : sorted . values ( ) ) builder . addAll ( update . columns ( ) ) ; final Iterator < Map . Entry < DecoratedKey , PartitionUpdate > > iter = sorted . entrySet ( ) . iterator ( ) ; return write ( sorted . size ( ) , new Appender ( ) { public SerializationHeader header ( ) { return new SerializationHeader ( true , Schema . instance . getCFMetaData ( ksname , cfname ) , builder . build ( ) , EncodingStats . NO_STATS ) ; } @Override public boolean append ( SSTableTxnWriter writer ) throws IOException { if ( ! iter . hasNext ( ) ) return false ; writer . append ( iter . next ( ) . getValue ( ) . unfilteredIterator ( ) ) ; return true ; } } ) ; } public Collection < SSTableReader > write ( Map < String , PartitionUpdate > entries ) throws IOException { SortedMap < DecoratedKey , PartitionUpdate > sorted = new TreeMap < > ( ) ; for ( Map . Entry < String , PartitionUpdate > entry : entries . entrySet ( ) ) sorted . put ( Util . dk ( entry . getKey ( ) ) , entry . getValue ( ) ) ; return write ( sorted ) ; } public Collection < SSTableReader > write ( int expectedSize , Appender appender ) throws IOException { File datafile = ( dest = = null ) ? tempSSTableFile ( ksname , cfname , generation ) : new File ( dest . filenameFor ( Component . DATA ) ) ; CFMetaData cfm = Schema . instance . getCFMetaData ( ksname , cfname ) ; ColumnFamilyStore cfs = Schema . instance . getColumnFamilyStoreInstance ( cfm . cfId ) ; SerializationHeader header = appender . header ( ) ; SSTableTxnWriter writer = SSTableTxnWriter . create ( cfs , datafile . getAbsolutePath ( ) , expectedSize , ActiveRepairService . UNREPAIRED_SSTABLE , <int> , header ) ; while ( appender . append ( writer ) ) { } Collection < SSTableReader > readers = writer . finish ( true ) ; if ( cleanup ) for ( SSTableReader reader : readers ) for ( Component component : reader . components ) new File ( reader . descriptor . filenameFor ( component ) ) . deleteOnExit ( ) ; return readers ; } } public static abstract class Appender { public abstract SerializationHeader header ( ) ; public abstract boolean append ( SSTableTxnWriter writer ) throws IOException ; } } 
