package org . elasticsearch . index . analysis ; import org . apache . lucene . analysis . Analyzer ; import org . apache . lucene . analysis . TokenStream ; import org . apache . lucene . analysis . Tokenizer ; import org . apache . lucene . analysis . core . LowerCaseFilter ; import org . apache . lucene . analysis . core . WhitespaceTokenizer ; import org . apache . lucene . analysis . synonym . SolrSynonymParser ; import org . apache . lucene . analysis . synonym . SynonymFilter ; import org . apache . lucene . analysis . synonym . SynonymMap ; import org . apache . lucene . analysis . synonym . WordnetSynonymParser ; import org . elasticsearch . env . Environment ; import org . elasticsearch . common . io . FastStringReader ; import org . elasticsearch . common . settings . Settings ; import org . elasticsearch . index . IndexSettings ; import java . io . IOException ; import java . io . Reader ; import java . util . List ; import java . util . Map ; public class SynonymTokenFilterFactory extends AbstractTokenFilterFactory { private final SynonymMap synonymMap ; private final boolean ignoreCase ; public SynonymTokenFilterFactory ( IndexSettings indexSettings , Environment env , Map < String , TokenizerFactory > tokenizerFactories , String name , Settings settings ) throws IOException { super ( indexSettings , name , settings ) ; Reader rulesReader = null ; if ( settings . getAsArray ( <str> , null ) ! = null ) { List < String > rules = Analysis . getWordList ( env , settings , <str> ) ; StringBuilder sb = new StringBuilder ( ) ; for ( String line : rules ) { sb . append ( line ) . append ( System . getProperty ( <str> ) ) ; } rulesReader = new FastStringReader ( sb . toString ( ) ) ; } else if ( settings . get ( <str> ) ! = null ) { rulesReader = Analysis . getReaderFromFile ( env , settings , <str> ) ; } else { throw new IllegalArgumentException ( <str> ) ; } this . ignoreCase = settings . getAsBoolean ( <str> , false ) ; boolean expand = settings . getAsBoolean ( <str> , true ) ; String tokenizerName = settings . get ( <str> , <str> ) ; final TokenizerFactory tokenizerFactory = tokenizerFactories . get ( tokenizerName ) ; if ( tokenizerFactory = = null ) { throw new IllegalArgumentException ( <str> + tokenizerName + <str> ) ; } Analyzer analyzer = new Analyzer ( ) { @Override protected TokenStreamComponents createComponents ( String fieldName ) { Tokenizer tokenizer = tokenizerFactory = = null ? new WhitespaceTokenizer ( ) : tokenizerFactory . create ( ) ; TokenStream stream = ignoreCase ? new LowerCaseFilter ( tokenizer ) : tokenizer ; return new TokenStreamComponents ( tokenizer , stream ) ; } } ; try { SynonymMap . Builder parser = null ; if ( <str> . equalsIgnoreCase ( settings . get ( <str> ) ) ) { parser = new WordnetSynonymParser ( true , expand , analyzer ) ; ( ( WordnetSynonymParser ) parser ) . parse ( rulesReader ) ; } else { parser = new SolrSynonymParser ( true , expand , analyzer ) ; ( ( SolrSynonymParser ) parser ) . parse ( rulesReader ) ; } synonymMap = parser . build ( ) ; } catch ( Exception e ) { throw new IllegalArgumentException ( <str> , e ) ; } } @Override public TokenStream create ( TokenStream tokenStream ) { return synonymMap . fst = = null ? tokenStream : new SynonymFilter ( tokenStream , synonymMap , ignoreCase ) ; } } 
