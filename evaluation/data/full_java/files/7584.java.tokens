package org . elasticsearch . search . suggest ; import org . apache . lucene . analysis . Analyzer ; import org . apache . lucene . analysis . TokenStream ; import org . apache . lucene . analysis . tokenattributes . CharTermAttribute ; import org . apache . lucene . analysis . tokenattributes . OffsetAttribute ; import org . apache . lucene . analysis . tokenattributes . PositionIncrementAttribute ; import org . apache . lucene . search . spell . * ; import org . apache . lucene . util . BytesRef ; import org . apache . lucene . util . BytesRefBuilder ; import org . apache . lucene . util . CharsRef ; import org . apache . lucene . util . CharsRefBuilder ; import org . apache . lucene . util . IOUtils ; import org . apache . lucene . util . automaton . LevenshteinAutomata ; import org . elasticsearch . common . ParseField ; import org . elasticsearch . common . ParseFieldMatcher ; import org . elasticsearch . common . io . FastCharArrayReader ; import org . elasticsearch . common . xcontent . XContentParser ; import org . elasticsearch . index . analysis . CustomAnalyzer ; import org . elasticsearch . index . analysis . NamedAnalyzer ; import org . elasticsearch . index . analysis . ShingleTokenFilterFactory ; import org . elasticsearch . index . analysis . TokenFilterFactory ; import org . elasticsearch . index . mapper . MapperService ; import org . elasticsearch . search . suggest . SuggestionSearchContext . SuggestionContext ; import java . io . IOException ; import java . util . Comparator ; import java . util . Locale ; public final class SuggestUtils { public static final Comparator < SuggestWord > LUCENE_FREQUENCY = new SuggestWordFrequencyComparator ( ) ; public static final Comparator < SuggestWord > SCORE_COMPARATOR = SuggestWordQueue . DEFAULT_COMPARATOR ; private SuggestUtils ( ) { } public static DirectSpellChecker getDirectSpellChecker ( DirectSpellcheckerSettings suggestion ) { DirectSpellChecker directSpellChecker = new DirectSpellChecker ( ) ; directSpellChecker . setAccuracy ( suggestion . accuracy ( ) ) ; Comparator < SuggestWord > comparator ; switch ( suggestion . sort ( ) ) { case SCORE : comparator = SCORE_COMPARATOR ; break ; case FREQUENCY : comparator = LUCENE_FREQUENCY ; break ; default : throw new IllegalArgumentException ( <str> + suggestion . sort ( ) ) ; } directSpellChecker . setComparator ( comparator ) ; directSpellChecker . setDistance ( suggestion . stringDistance ( ) ) ; directSpellChecker . setMaxEdits ( suggestion . maxEdits ( ) ) ; directSpellChecker . setMaxInspections ( suggestion . maxInspections ( ) ) ; directSpellChecker . setMaxQueryFrequency ( suggestion . maxTermFreq ( ) ) ; directSpellChecker . setMinPrefix ( suggestion . prefixLength ( ) ) ; directSpellChecker . setMinQueryLength ( suggestion . minWordLength ( ) ) ; directSpellChecker . setThresholdFrequency ( suggestion . minDocFreq ( ) ) ; directSpellChecker . setLowerCaseTerms ( false ) ; return directSpellChecker ; } public static BytesRef join ( BytesRef separator , BytesRefBuilder result , BytesRef . . . toJoin ) { result . clear ( ) ; for ( int i = <int> ; i < toJoin . length - <int> ; i + + ) { result . append ( toJoin [ i ] ) ; result . append ( separator ) ; } result . append ( toJoin [ toJoin . length - <int> ] ) ; return result . get ( ) ; } public static abstract class TokenConsumer { protected CharTermAttribute charTermAttr ; protected PositionIncrementAttribute posIncAttr ; protected OffsetAttribute offsetAttr ; public void reset ( TokenStream stream ) { charTermAttr = stream . addAttribute ( CharTermAttribute . class ) ; posIncAttr = stream . addAttribute ( PositionIncrementAttribute . class ) ; offsetAttr = stream . addAttribute ( OffsetAttribute . class ) ; } protected BytesRef fillBytesRef ( BytesRefBuilder spare ) { spare . copyChars ( charTermAttr ) ; return spare . get ( ) ; } public abstract void nextToken ( ) throws IOException ; public void end ( ) { } } public static int analyze ( Analyzer analyzer , BytesRef toAnalyze , String field , TokenConsumer consumer , CharsRefBuilder spare ) throws IOException { spare . copyUTF8Bytes ( toAnalyze ) ; return analyze ( analyzer , spare . get ( ) , field , consumer ) ; } public static int analyze ( Analyzer analyzer , CharsRef toAnalyze , String field , TokenConsumer consumer ) throws IOException { try ( TokenStream ts = analyzer . tokenStream ( field , new FastCharArrayReader ( toAnalyze . chars , toAnalyze . offset , toAnalyze . length ) ) ) { return analyze ( ts , consumer ) ; } } public static int analyze ( TokenStream stream , TokenConsumer consumer ) throws IOException { int numTokens = <int> ; boolean success = false ; try { stream . reset ( ) ; consumer . reset ( stream ) ; while ( stream . incrementToken ( ) ) { consumer . nextToken ( ) ; numTokens + + ; } consumer . end ( ) ; } finally { if ( success ) { stream . close ( ) ; } else { IOUtils . closeWhileHandlingException ( stream ) ; } } return numTokens ; } public static SuggestMode resolveSuggestMode ( String suggestMode ) { suggestMode = suggestMode . toLowerCase ( Locale . US ) ; if ( <str> . equals ( suggestMode ) ) { return SuggestMode . SUGGEST_WHEN_NOT_IN_INDEX ; } else if ( <str> . equals ( suggestMode ) ) { return SuggestMode . SUGGEST_MORE_POPULAR ; } else if ( <str> . equals ( suggestMode ) ) { return SuggestMode . SUGGEST_ALWAYS ; } else { throw new IllegalArgumentException ( <str> + suggestMode ) ; } } public static Suggest . Suggestion . Sort resolveSort ( String sortVal ) { if ( <str> . equals ( sortVal ) ) { return Suggest . Suggestion . Sort . SCORE ; } else if ( <str> . equals ( sortVal ) ) { return Suggest . Suggestion . Sort . FREQUENCY ; } else { throw new IllegalArgumentException ( <str> + sortVal ) ; } } public static StringDistance resolveDistance ( String distanceVal ) { if ( <str> . equals ( distanceVal ) ) { return DirectSpellChecker . INTERNAL_LEVENSHTEIN ; } else if ( <str> . equals ( distanceVal ) | | <str> . equals ( distanceVal ) ) { return new LuceneLevenshteinDistance ( ) ; } else if ( <str> . equals ( distanceVal ) ) { return new LevensteinDistance ( ) ; } else if ( <str> . equals ( distanceVal ) ) { return new JaroWinklerDistance ( ) ; } else if ( <str> . equals ( distanceVal ) ) { return new NGramDistance ( ) ; } else { throw new IllegalArgumentException ( <str> + distanceVal ) ; } } public static class Fields { public static final ParseField STRING_DISTANCE = new ParseField ( <str> ) ; public static final ParseField SUGGEST_MODE = new ParseField ( <str> ) ; public static final ParseField MAX_EDITS = new ParseField ( <str> ) ; public static final ParseField MAX_INSPECTIONS = new ParseField ( <str> ) ; public static final ParseField MAX_TERM_FREQ = new ParseField ( <str> ) ; public static final ParseField PREFIX_LENGTH = new ParseField ( <str> , <str> ) ; public static final ParseField MIN_WORD_LENGTH = new ParseField ( <str> , <str> ) ; public static final ParseField MIN_DOC_FREQ = new ParseField ( <str> ) ; public static final ParseField SHARD_SIZE = new ParseField ( <str> ) ; } public static boolean parseDirectSpellcheckerSettings ( XContentParser parser , String fieldName , DirectSpellcheckerSettings suggestion , ParseFieldMatcher parseFieldMatcher ) throws IOException { if ( <str> . equals ( fieldName ) ) { suggestion . accuracy ( parser . floatValue ( ) ) ; } else if ( parseFieldMatcher . match ( fieldName , Fields . SUGGEST_MODE ) ) { suggestion . suggestMode ( SuggestUtils . resolveSuggestMode ( parser . text ( ) ) ) ; } else if ( <str> . equals ( fieldName ) ) { suggestion . sort ( SuggestUtils . resolveSort ( parser . text ( ) ) ) ; } else if ( parseFieldMatcher . match ( fieldName , Fields . STRING_DISTANCE ) ) { suggestion . stringDistance ( SuggestUtils . resolveDistance ( parser . text ( ) ) ) ; } else if ( parseFieldMatcher . match ( fieldName , Fields . MAX_EDITS ) ) { suggestion . maxEdits ( parser . intValue ( ) ) ; if ( suggestion . maxEdits ( ) < <int> | | suggestion . maxEdits ( ) > LevenshteinAutomata . MAXIMUM_SUPPORTED_DISTANCE ) { throw new IllegalArgumentException ( <str> + suggestion . maxEdits ( ) ) ; } } else if ( parseFieldMatcher . match ( fieldName , Fields . MAX_INSPECTIONS ) ) { suggestion . maxInspections ( parser . intValue ( ) ) ; } else if ( parseFieldMatcher . match ( fieldName , Fields . MAX_TERM_FREQ ) ) { suggestion . maxTermFreq ( parser . floatValue ( ) ) ; } else if ( parseFieldMatcher . match ( fieldName , Fields . PREFIX_LENGTH ) ) { suggestion . prefixLength ( parser . intValue ( ) ) ; } else if ( parseFieldMatcher . match ( fieldName , Fields . MIN_WORD_LENGTH ) ) { suggestion . minQueryLength ( parser . intValue ( ) ) ; } else if ( parseFieldMatcher . match ( fieldName , Fields . MIN_DOC_FREQ ) ) { suggestion . minDocFreq ( parser . floatValue ( ) ) ; } else { return false ; } return true ; } public static boolean parseSuggestContext ( XContentParser parser , MapperService mapperService , String fieldName , SuggestionSearchContext . SuggestionContext suggestion , ParseFieldMatcher parseFieldMatcher ) throws IOException { if ( <str> . equals ( fieldName ) ) { String analyzerName = parser . text ( ) ; Analyzer analyzer = mapperService . analysisService ( ) . analyzer ( analyzerName ) ; if ( analyzer = = null ) { throw new IllegalArgumentException ( <str> + analyzerName + <str> ) ; } suggestion . setAnalyzer ( analyzer ) ; } else if ( <str> . equals ( fieldName ) ) { suggestion . setField ( parser . text ( ) ) ; } else if ( <str> . equals ( fieldName ) ) { suggestion . setSize ( parser . intValue ( ) ) ; } else if ( parseFieldMatcher . match ( fieldName , Fields . SHARD_SIZE ) ) { suggestion . setShardSize ( parser . intValue ( ) ) ; } else { return false ; } return true ; } public static void verifySuggestion ( MapperService mapperService , BytesRef globalText , SuggestionContext suggestion ) { if ( suggestion . getField ( ) = = null ) { throw new IllegalArgumentException ( <str> ) ; } if ( suggestion . getText ( ) = = null ) { if ( globalText = = null ) { throw new IllegalArgumentException ( <str> ) ; } suggestion . setText ( globalText ) ; } if ( suggestion . getAnalyzer ( ) = = null ) { suggestion . setAnalyzer ( mapperService . searchAnalyzer ( ) ) ; } if ( suggestion . getShardSize ( ) = = - <int> ) { suggestion . setShardSize ( Math . max ( suggestion . getSize ( ) , <int> ) ) ; } } public static ShingleTokenFilterFactory . Factory getShingleFilterFactory ( Analyzer analyzer ) { if ( analyzer instanceof NamedAnalyzer ) { analyzer = ( ( NamedAnalyzer ) analyzer ) . analyzer ( ) ; } if ( analyzer instanceof CustomAnalyzer ) { final CustomAnalyzer a = ( CustomAnalyzer ) analyzer ; final TokenFilterFactory [ ] tokenFilters = a . tokenFilters ( ) ; for ( TokenFilterFactory tokenFilterFactory : tokenFilters ) { if ( tokenFilterFactory instanceof ShingleTokenFilterFactory ) { return ( ( ShingleTokenFilterFactory ) tokenFilterFactory ) . getInnerFactory ( ) ; } else if ( tokenFilterFactory instanceof ShingleTokenFilterFactory . Factory ) { return ( ShingleTokenFilterFactory . Factory ) tokenFilterFactory ; } } } return null ; } } 
