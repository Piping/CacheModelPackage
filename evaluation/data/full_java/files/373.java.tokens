package org . apache . cassandra . db . commitlog ; import java . io . IOException ; import java . nio . ByteBuffer ; import java . util . Queue ; import java . util . concurrent . ConcurrentLinkedQueue ; import org . apache . cassandra . config . DatabaseDescriptor ; import org . apache . cassandra . io . FSWriteError ; import org . apache . cassandra . io . compress . BufferType ; import org . apache . cassandra . io . compress . ICompressor ; import org . apache . cassandra . io . util . FileUtils ; import org . apache . cassandra . utils . SyncUtil ; public class CompressedSegment extends CommitLogSegment { private static final ThreadLocal < ByteBuffer > compressedBufferHolder = new ThreadLocal < ByteBuffer > ( ) { protected ByteBuffer initialValue ( ) { return ByteBuffer . allocate ( <int> ) ; } } ; static Queue < ByteBuffer > bufferPool = new ConcurrentLinkedQueue < > ( ) ; static final int MAX_BUFFERPOOL_SIZE = DatabaseDescriptor . getCommitLogMaxCompressionBuffersInPool ( ) ; static final int COMPRESSED_MARKER_SIZE = SYNC_MARKER_SIZE + <int> ; final ICompressor compressor ; volatile long lastWrittenPos = <int> ; CompressedSegment ( CommitLog commitLog ) { super ( commitLog ) ; this . compressor = commitLog . compressor ; try { channel . write ( ( ByteBuffer ) buffer . duplicate ( ) . flip ( ) ) ; commitLog . allocator . addSize ( lastWrittenPos = buffer . position ( ) ) ; } catch ( IOException e ) { throw new FSWriteError ( e , getPath ( ) ) ; } } ByteBuffer allocate ( int size ) { return compressor . preferredBufferType ( ) . allocate ( size ) ; } ByteBuffer createBuffer ( CommitLog commitLog ) { ByteBuffer buf = bufferPool . poll ( ) ; if ( buf = = null ) { buf = commitLog . compressor . preferredBufferType ( ) . allocate ( DatabaseDescriptor . getCommitLogSegmentSize ( ) ) ; } else buf . clear ( ) ; return buf ; } static long startMillis = System . currentTimeMillis ( ) ; @Override void write ( int startMarker , int nextMarker ) { int contentStart = startMarker + SYNC_MARKER_SIZE ; int length = nextMarker - contentStart ; assert length > <int> | | length = = <int> & & ! isStillAllocating ( ) ; try { int neededBufferSize = compressor . initialCompressedBufferLength ( length ) + COMPRESSED_MARKER_SIZE ; ByteBuffer compressedBuffer = compressedBufferHolder . get ( ) ; if ( compressor . preferredBufferType ( ) ! = BufferType . typeOf ( compressedBuffer ) | | compressedBuffer . capacity ( ) < neededBufferSize ) { FileUtils . clean ( compressedBuffer ) ; compressedBuffer = allocate ( neededBufferSize ) ; compressedBufferHolder . set ( compressedBuffer ) ; } ByteBuffer inputBuffer = buffer . duplicate ( ) ; inputBuffer . limit ( contentStart + length ) . position ( contentStart ) ; compressedBuffer . limit ( compressedBuffer . capacity ( ) ) . position ( COMPRESSED_MARKER_SIZE ) ; compressor . compress ( inputBuffer , compressedBuffer ) ; compressedBuffer . flip ( ) ; compressedBuffer . putInt ( SYNC_MARKER_SIZE , length ) ; writeSyncMarker ( compressedBuffer , <int> , ( int ) channel . position ( ) , ( int ) channel . position ( ) + compressedBuffer . remaining ( ) ) ; commitLog . allocator . addSize ( compressedBuffer . limit ( ) ) ; channel . write ( compressedBuffer ) ; assert channel . position ( ) - lastWrittenPos = = compressedBuffer . limit ( ) ; lastWrittenPos = channel . position ( ) ; SyncUtil . force ( channel , true ) ; } catch ( Exception e ) { throw new FSWriteError ( e , getPath ( ) ) ; } } @Override protected void internalClose ( ) { if ( bufferPool . size ( ) < MAX_BUFFERPOOL_SIZE ) bufferPool . add ( buffer ) ; else FileUtils . clean ( buffer ) ; super . internalClose ( ) ; } static void shutdown ( ) { bufferPool . clear ( ) ; } @Override public long onDiskSize ( ) { return lastWrittenPos ; } } 
