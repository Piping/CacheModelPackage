package org . elasticsearch . rest . action . admin . indices . analyze ; import org . elasticsearch . action . admin . indices . analyze . AnalyzeRequest ; import org . elasticsearch . action . admin . indices . analyze . AnalyzeResponse ; import org . elasticsearch . client . Client ; import org . elasticsearch . common . ParseField ; import org . elasticsearch . common . ParseFieldMatcher ; import org . elasticsearch . common . bytes . BytesReference ; import org . elasticsearch . common . inject . Inject ; import org . elasticsearch . common . settings . Settings ; import org . elasticsearch . common . xcontent . XContentHelper ; import org . elasticsearch . common . xcontent . XContentParser ; import org . elasticsearch . common . xcontent . XContentType ; import org . elasticsearch . rest . BaseRestHandler ; import org . elasticsearch . rest . RestChannel ; import org . elasticsearch . rest . RestController ; import org . elasticsearch . rest . RestRequest ; import org . elasticsearch . rest . action . support . RestActions ; import org . elasticsearch . rest . action . support . RestToXContentListener ; import java . io . IOException ; import java . util . ArrayList ; import java . util . List ; import static org . elasticsearch . rest . RestRequest . Method . GET ; import static org . elasticsearch . rest . RestRequest . Method . POST ; public class RestAnalyzeAction extends BaseRestHandler { public static class Fields { public static final ParseField ANALYZER = new ParseField ( <str> ) ; public static final ParseField TEXT = new ParseField ( <str> ) ; public static final ParseField FIELD = new ParseField ( <str> ) ; public static final ParseField TOKENIZER = new ParseField ( <str> ) ; public static final ParseField TOKEN_FILTERS = new ParseField ( <str> , <str> ) ; public static final ParseField CHAR_FILTERS = new ParseField ( <str> ) ; public static final ParseField EXPLAIN = new ParseField ( <str> ) ; public static final ParseField ATTRIBUTES = new ParseField ( <str> ) ; } @Inject public RestAnalyzeAction ( Settings settings , RestController controller , Client client ) { super ( settings , controller , client ) ; controller . registerHandler ( GET , <str> , this ) ; controller . registerHandler ( GET , <str> , this ) ; controller . registerHandler ( POST , <str> , this ) ; controller . registerHandler ( POST , <str> , this ) ; } @Override public void handleRequest ( final RestRequest request , final RestChannel channel , final Client client ) { String [ ] texts = request . paramAsStringArrayOrEmptyIfAll ( <str> ) ; AnalyzeRequest analyzeRequest = new AnalyzeRequest ( request . param ( <str> ) ) ; analyzeRequest . text ( texts ) ; analyzeRequest . analyzer ( request . param ( <str> ) ) ; analyzeRequest . field ( request . param ( <str> ) ) ; analyzeRequest . tokenizer ( request . param ( <str> ) ) ; analyzeRequest . tokenFilters ( request . paramAsStringArray ( <str> , request . paramAsStringArray ( <str> , analyzeRequest . tokenFilters ( ) ) ) ) ; analyzeRequest . charFilters ( request . paramAsStringArray ( <str> , analyzeRequest . charFilters ( ) ) ) ; analyzeRequest . explain ( request . paramAsBoolean ( <str> , false ) ) ; analyzeRequest . attributes ( request . paramAsStringArray ( <str> , analyzeRequest . attributes ( ) ) ) ; if ( RestActions . hasBodyContent ( request ) ) { XContentType type = RestActions . guessBodyContentType ( request ) ; if ( type = = null ) { if ( texts = = null | | texts . length = = <int> ) { texts = new String [ ] { RestActions . getRestContent ( request ) . toUtf8 ( ) } ; analyzeRequest . text ( texts ) ; } } else { buildFromContent ( RestActions . getRestContent ( request ) , analyzeRequest , parseFieldMatcher ) ; } } client . admin ( ) . indices ( ) . analyze ( analyzeRequest , new RestToXContentListener < AnalyzeResponse > ( channel ) ) ; } public static void buildFromContent ( BytesReference content , AnalyzeRequest analyzeRequest , ParseFieldMatcher parseFieldMatcher ) { try ( XContentParser parser = XContentHelper . createParser ( content ) ) { if ( parser . nextToken ( ) ! = XContentParser . Token . START_OBJECT ) { throw new IllegalArgumentException ( <str> ) ; } else { XContentParser . Token token ; String currentFieldName = null ; while ( ( token = parser . nextToken ( ) ) ! = XContentParser . Token . END_OBJECT ) { if ( token = = XContentParser . Token . FIELD_NAME ) { currentFieldName = parser . currentName ( ) ; } else if ( parseFieldMatcher . match ( currentFieldName , Fields . TEXT ) & & token = = XContentParser . Token . VALUE_STRING ) { analyzeRequest . text ( parser . text ( ) ) ; } else if ( parseFieldMatcher . match ( currentFieldName , Fields . TEXT ) & & token = = XContentParser . Token . START_ARRAY ) { List < String > texts = new ArrayList < > ( ) ; while ( ( token = parser . nextToken ( ) ) ! = XContentParser . Token . END_ARRAY ) { if ( token . isValue ( ) = = false ) { throw new IllegalArgumentException ( currentFieldName + <str> ) ; } texts . add ( parser . text ( ) ) ; } analyzeRequest . text ( texts . toArray ( new String [ texts . size ( ) ] ) ) ; } else if ( parseFieldMatcher . match ( currentFieldName , Fields . ANALYZER ) & & token = = XContentParser . Token . VALUE_STRING ) { analyzeRequest . analyzer ( parser . text ( ) ) ; } else if ( parseFieldMatcher . match ( currentFieldName , Fields . FIELD ) & & token = = XContentParser . Token . VALUE_STRING ) { analyzeRequest . field ( parser . text ( ) ) ; } else if ( parseFieldMatcher . match ( currentFieldName , Fields . TOKENIZER ) & & token = = XContentParser . Token . VALUE_STRING ) { analyzeRequest . tokenizer ( parser . text ( ) ) ; } else if ( parseFieldMatcher . match ( currentFieldName , Fields . TOKEN_FILTERS ) & & token = = XContentParser . Token . START_ARRAY ) { List < String > filters = new ArrayList < > ( ) ; while ( ( token = parser . nextToken ( ) ) ! = XContentParser . Token . END_ARRAY ) { if ( token . isValue ( ) = = false ) { throw new IllegalArgumentException ( currentFieldName + <str> ) ; } filters . add ( parser . text ( ) ) ; } analyzeRequest . tokenFilters ( filters . toArray ( new String [ filters . size ( ) ] ) ) ; } else if ( parseFieldMatcher . match ( currentFieldName , Fields . CHAR_FILTERS ) & & token = = XContentParser . Token . START_ARRAY ) { List < String > charFilters = new ArrayList < > ( ) ; while ( ( token = parser . nextToken ( ) ) ! = XContentParser . Token . END_ARRAY ) { if ( token . isValue ( ) = = false ) { throw new IllegalArgumentException ( currentFieldName + <str> ) ; } charFilters . add ( parser . text ( ) ) ; } analyzeRequest . charFilters ( charFilters . toArray ( new String [ charFilters . size ( ) ] ) ) ; } else if ( parseFieldMatcher . match ( currentFieldName , Fields . EXPLAIN ) & & token = = XContentParser . Token . VALUE_BOOLEAN ) { analyzeRequest . explain ( parser . booleanValue ( ) ) ; } else if ( parseFieldMatcher . match ( currentFieldName , Fields . ATTRIBUTES ) & & token = = XContentParser . Token . START_ARRAY ) { List < String > attributes = new ArrayList < > ( ) ; while ( ( token = parser . nextToken ( ) ) ! = XContentParser . Token . END_ARRAY ) { if ( token . isValue ( ) = = false ) { throw new IllegalArgumentException ( currentFieldName + <str> ) ; } attributes . add ( parser . text ( ) ) ; } analyzeRequest . attributes ( attributes . toArray ( new String [ attributes . size ( ) ] ) ) ; } else { throw new IllegalArgumentException ( <str> + currentFieldName + <str> + token + <str> ) ; } } } } catch ( IOException e ) { throw new IllegalArgumentException ( <str> , e ) ; } } } 
