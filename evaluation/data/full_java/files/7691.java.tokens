package org . elasticsearch . tribe ; import com . carrotsearch . hppc . cursors . ObjectObjectCursor ; import org . elasticsearch . ElasticsearchException ; import org . elasticsearch . action . support . master . TransportMasterNodeReadAction ; import org . elasticsearch . cluster . ClusterChangedEvent ; import org . elasticsearch . cluster . ClusterService ; import org . elasticsearch . cluster . ClusterState ; import org . elasticsearch . cluster . ClusterStateListener ; import org . elasticsearch . cluster . ClusterStateUpdateTask ; import org . elasticsearch . cluster . block . ClusterBlock ; import org . elasticsearch . cluster . block . ClusterBlockLevel ; import org . elasticsearch . cluster . block . ClusterBlocks ; import org . elasticsearch . cluster . metadata . IndexMetaData ; import org . elasticsearch . cluster . metadata . MetaData ; import org . elasticsearch . cluster . node . DiscoveryNode ; import org . elasticsearch . cluster . node . DiscoveryNodes ; import org . elasticsearch . cluster . routing . IndexRoutingTable ; import org . elasticsearch . cluster . routing . RoutingTable ; import org . elasticsearch . common . Strings ; import org . elasticsearch . common . component . AbstractLifecycleComponent ; import org . elasticsearch . common . inject . Inject ; import org . elasticsearch . common . regex . Regex ; import org . elasticsearch . common . settings . Settings ; import org . elasticsearch . common . util . concurrent . ConcurrentCollections ; import org . elasticsearch . discovery . DiscoveryService ; import org . elasticsearch . gateway . GatewayService ; import org . elasticsearch . node . Node ; import org . elasticsearch . rest . RestStatus ; import java . util . EnumSet ; import java . util . HashMap ; import java . util . List ; import java . util . Map ; import java . util . Set ; import java . util . concurrent . CopyOnWriteArrayList ; import static java . util . Collections . unmodifiableMap ; public class TribeService extends AbstractLifecycleComponent < TribeService > { public static final ClusterBlock TRIBE_METADATA_BLOCK = new ClusterBlock ( <int> , <str> , false , false , RestStatus . BAD_REQUEST , EnumSet . of ( ClusterBlockLevel . METADATA_READ , ClusterBlockLevel . METADATA_WRITE ) ) ; public static final ClusterBlock TRIBE_WRITE_BLOCK = new ClusterBlock ( <int> , <str> , false , false , RestStatus . BAD_REQUEST , EnumSet . of ( ClusterBlockLevel . WRITE ) ) ; public static Settings processSettings ( Settings settings ) { if ( settings . get ( TRIBE_NAME ) ! = null ) { Settings . Builder sb = Settings . builder ( ) . put ( settings ) ; for ( String s : settings . getAsMap ( ) . keySet ( ) ) { if ( s . startsWith ( <str> ) & & ! s . equals ( TRIBE_NAME ) ) { sb . remove ( s ) ; } } return sb . build ( ) ; } Map < String , Settings > nodesSettings = settings . getGroups ( <str> , true ) ; if ( nodesSettings . isEmpty ( ) ) { return settings ; } Settings . Builder sb = Settings . builder ( ) . put ( settings ) ; sb . put ( <str> , true ) ; sb . put ( <str> , <str> ) ; sb . put ( <str> , <int> ) ; if ( sb . get ( <str> ) = = null ) { sb . put ( <str> , <str> + Strings . randomBase64UUID ( ) ) ; } sb . put ( TransportMasterNodeReadAction . FORCE_LOCAL_SETTING , true ) ; return sb . build ( ) ; } public static final String TRIBE_NAME = <str> ; private final ClusterService clusterService ; private final String [ ] blockIndicesWrite ; private final String [ ] blockIndicesRead ; private final String [ ] blockIndicesMetadata ; private static final String ON_CONFLICT_ANY = <str> , ON_CONFLICT_DROP = <str> , ON_CONFLICT_PREFER = <str> ; private final String onConflict ; private final Set < String > droppedIndices = ConcurrentCollections . newConcurrentSet ( ) ; private final List < Node > nodes = new CopyOnWriteArrayList < > ( ) ; @Inject public TribeService ( Settings settings , ClusterService clusterService , DiscoveryService discoveryService ) { super ( settings ) ; this . clusterService = clusterService ; Map < String , Settings > nodesSettings = new HashMap < > ( settings . getGroups ( <str> , true ) ) ; nodesSettings . remove ( <str> ) ; nodesSettings . remove ( <str> ) ; for ( Map . Entry < String , Settings > entry : nodesSettings . entrySet ( ) ) { Settings . Builder sb = Settings . builder ( ) . put ( entry . getValue ( ) ) ; sb . put ( <str> , settings . get ( <str> ) + <str> + entry . getKey ( ) ) ; sb . put ( <str> , settings . get ( <str> ) ) ; sb . put ( TRIBE_NAME , entry . getKey ( ) ) ; if ( sb . get ( <str> ) = = null ) { sb . put ( <str> , false ) ; } sb . put ( <str> , true ) ; nodes . add ( new TribeClientNode ( sb . build ( ) ) ) ; } String [ ] blockIndicesWrite = Strings . EMPTY_ARRAY ; String [ ] blockIndicesRead = Strings . EMPTY_ARRAY ; String [ ] blockIndicesMetadata = Strings . EMPTY_ARRAY ; if ( ! nodes . isEmpty ( ) ) { clusterService . removeInitialStateBlock ( discoveryService . getNoMasterBlock ( ) ) ; clusterService . removeInitialStateBlock ( GatewayService . STATE_NOT_RECOVERED_BLOCK ) ; if ( settings . getAsBoolean ( <str> , false ) ) { clusterService . addInitialStateBlock ( TRIBE_WRITE_BLOCK ) ; } blockIndicesWrite = settings . getAsArray ( <str> , Strings . EMPTY_ARRAY ) ; if ( settings . getAsBoolean ( <str> , false ) ) { clusterService . addInitialStateBlock ( TRIBE_METADATA_BLOCK ) ; } blockIndicesMetadata = settings . getAsArray ( <str> , Strings . EMPTY_ARRAY ) ; blockIndicesRead = settings . getAsArray ( <str> , Strings . EMPTY_ARRAY ) ; for ( Node node : nodes ) { node . injector ( ) . getInstance ( ClusterService . class ) . add ( new TribeClusterStateListener ( node ) ) ; } } this . blockIndicesMetadata = blockIndicesMetadata ; this . blockIndicesRead = blockIndicesRead ; this . blockIndicesWrite = blockIndicesWrite ; this . onConflict = settings . get ( <str> , ON_CONFLICT_ANY ) ; } @Override protected void doStart ( ) { for ( Node node : nodes ) { try { node . start ( ) ; } catch ( Throwable e ) { for ( Node otherNode : nodes ) { try { otherNode . close ( ) ; } catch ( Throwable t ) { logger . warn ( <str> , otherNode , t ) ; } } if ( e instanceof RuntimeException ) { throw ( RuntimeException ) e ; } throw new ElasticsearchException ( e ) ; } } } @Override protected void doStop ( ) { doClose ( ) ; } @Override protected void doClose ( ) { for ( Node node : nodes ) { try { node . close ( ) ; } catch ( Throwable t ) { logger . warn ( <str> , t , node ) ; } } } class TribeClusterStateListener implements ClusterStateListener { private final String tribeName ; TribeClusterStateListener ( Node tribeNode ) { this . tribeName = tribeNode . settings ( ) . get ( TRIBE_NAME ) ; } @Override public void clusterChanged ( final ClusterChangedEvent event ) { logger . debug ( <str> , tribeName , event . source ( ) ) ; clusterService . submitStateUpdateTask ( <str> + tribeName + <str> + event . source ( ) , new ClusterStateUpdateTask ( ) { @Override public boolean runOnlyOnMaster ( ) { return false ; } @Override public ClusterState execute ( ClusterState currentState ) throws Exception { ClusterState tribeState = event . state ( ) ; DiscoveryNodes . Builder nodes = DiscoveryNodes . builder ( currentState . nodes ( ) ) ; for ( DiscoveryNode discoNode : currentState . nodes ( ) ) { String markedTribeName = discoNode . attributes ( ) . get ( TRIBE_NAME ) ; if ( markedTribeName ! = null & & markedTribeName . equals ( tribeName ) ) { if ( tribeState . nodes ( ) . get ( discoNode . id ( ) ) = = null ) { logger . info ( <str> , tribeName , discoNode ) ; nodes . remove ( discoNode . id ( ) ) ; } } } for ( DiscoveryNode tribe : tribeState . nodes ( ) ) { if ( currentState . nodes ( ) . get ( tribe . id ( ) ) = = null ) { Map < String , String > tribeAttr = new HashMap < > ( ) ; for ( ObjectObjectCursor < String , String > attr : tribe . attributes ( ) ) { tribeAttr . put ( attr . key , attr . value ) ; } tribeAttr . put ( TRIBE_NAME , tribeName ) ; DiscoveryNode discoNode = new DiscoveryNode ( tribe . name ( ) , tribe . id ( ) , tribe . getHostName ( ) , tribe . getHostAddress ( ) , tribe . address ( ) , unmodifiableMap ( tribeAttr ) , tribe . version ( ) ) ; logger . info ( <str> , tribeName , discoNode ) ; nodes . put ( discoNode ) ; } } ClusterBlocks . Builder blocks = ClusterBlocks . builder ( ) . blocks ( currentState . blocks ( ) ) ; MetaData . Builder metaData = MetaData . builder ( currentState . metaData ( ) ) ; RoutingTable . Builder routingTable = RoutingTable . builder ( currentState . routingTable ( ) ) ; for ( IndexMetaData index : currentState . metaData ( ) ) { String markedTribeName = index . getSettings ( ) . get ( TRIBE_NAME ) ; if ( markedTribeName ! = null & & markedTribeName . equals ( tribeName ) ) { IndexMetaData tribeIndex = tribeState . metaData ( ) . index ( index . getIndex ( ) ) ; if ( tribeIndex = = null | | tribeIndex . getState ( ) = = IndexMetaData . State . CLOSE ) { logger . info ( <str> , tribeName , index . getIndex ( ) ) ; removeIndex ( blocks , metaData , routingTable , index ) ; } else { routingTable . add ( tribeState . routingTable ( ) . index ( index . getIndex ( ) ) ) ; Settings tribeSettings = Settings . builder ( ) . put ( tribeIndex . getSettings ( ) ) . put ( TRIBE_NAME , tribeName ) . build ( ) ; metaData . put ( IndexMetaData . builder ( tribeIndex ) . settings ( tribeSettings ) ) ; } } } for ( IndexMetaData tribeIndex : tribeState . metaData ( ) ) { IndexRoutingTable table = tribeState . routingTable ( ) . index ( tribeIndex . getIndex ( ) ) ; if ( table = = null ) { continue ; } final IndexMetaData indexMetaData = currentState . metaData ( ) . index ( tribeIndex . getIndex ( ) ) ; if ( indexMetaData = = null ) { if ( ! droppedIndices . contains ( tribeIndex . getIndex ( ) ) ) { logger . info ( <str> , tribeName , tribeIndex . getIndex ( ) ) ; addNewIndex ( tribeState , blocks , metaData , routingTable , tribeIndex ) ; } } else { String existingFromTribe = indexMetaData . getSettings ( ) . get ( TRIBE_NAME ) ; if ( ! tribeName . equals ( existingFromTribe ) ) { if ( ON_CONFLICT_ANY . equals ( onConflict ) ) { } else if ( ON_CONFLICT_DROP . equals ( onConflict ) ) { logger . info ( <str> , tribeName , tribeIndex . getIndex ( ) , existingFromTribe ) ; removeIndex ( blocks , metaData , routingTable , tribeIndex ) ; droppedIndices . add ( tribeIndex . getIndex ( ) ) ; } else if ( onConflict . startsWith ( ON_CONFLICT_PREFER ) ) { String preferredTribeName = onConflict . substring ( ON_CONFLICT_PREFER . length ( ) ) ; if ( tribeName . equals ( preferredTribeName ) ) { logger . info ( <str> , tribeName , tribeIndex . getIndex ( ) , existingFromTribe ) ; removeIndex ( blocks , metaData , routingTable , tribeIndex ) ; addNewIndex ( tribeState , blocks , metaData , routingTable , tribeIndex ) ; } } } } } return ClusterState . builder ( currentState ) . incrementVersion ( ) . blocks ( blocks ) . nodes ( nodes ) . metaData ( metaData ) . routingTable ( routingTable . build ( ) ) . build ( ) ; } private void removeIndex ( ClusterBlocks . Builder blocks , MetaData . Builder metaData , RoutingTable . Builder routingTable , IndexMetaData index ) { metaData . remove ( index . getIndex ( ) ) ; routingTable . remove ( index . getIndex ( ) ) ; blocks . removeIndexBlocks ( index . getIndex ( ) ) ; } private void addNewIndex ( ClusterState tribeState , ClusterBlocks . Builder blocks , MetaData . Builder metaData , RoutingTable . Builder routingTable , IndexMetaData tribeIndex ) { Settings tribeSettings = Settings . builder ( ) . put ( tribeIndex . getSettings ( ) ) . put ( TRIBE_NAME , tribeName ) . build ( ) ; metaData . put ( IndexMetaData . builder ( tribeIndex ) . settings ( tribeSettings ) ) ; routingTable . add ( tribeState . routingTable ( ) . index ( tribeIndex . getIndex ( ) ) ) ; if ( Regex . simpleMatch ( blockIndicesMetadata , tribeIndex . getIndex ( ) ) ) { blocks . addIndexBlock ( tribeIndex . getIndex ( ) , IndexMetaData . INDEX_METADATA_BLOCK ) ; } if ( Regex . simpleMatch ( blockIndicesRead , tribeIndex . getIndex ( ) ) ) { blocks . addIndexBlock ( tribeIndex . getIndex ( ) , IndexMetaData . INDEX_READ_BLOCK ) ; } if ( Regex . simpleMatch ( blockIndicesWrite , tribeIndex . getIndex ( ) ) ) { blocks . addIndexBlock ( tribeIndex . getIndex ( ) , IndexMetaData . INDEX_WRITE_BLOCK ) ; } } @Override public void onFailure ( String source , Throwable t ) { logger . warn ( <str> , t , source ) ; } } ) ; } } } 
