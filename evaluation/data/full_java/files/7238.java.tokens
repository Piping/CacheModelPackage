package org . elasticsearch . search . aggregations . bucket . significant ; import org . apache . lucene . index . IndexReader ; import org . apache . lucene . index . LeafReaderContext ; import org . apache . lucene . util . BytesRef ; import org . elasticsearch . common . lease . Releasables ; import org . elasticsearch . search . aggregations . Aggregator ; import org . elasticsearch . search . aggregations . AggregatorFactories ; import org . elasticsearch . search . aggregations . LeafBucketCollector ; import org . elasticsearch . search . aggregations . LeafBucketCollectorBase ; import org . elasticsearch . search . aggregations . bucket . terms . StringTermsAggregator ; import org . elasticsearch . search . aggregations . bucket . terms . support . IncludeExclude ; import org . elasticsearch . search . aggregations . pipeline . PipelineAggregator ; import org . elasticsearch . search . aggregations . support . AggregationContext ; import org . elasticsearch . search . aggregations . support . ValuesSource ; import org . elasticsearch . search . internal . ContextIndexSearcher ; import java . io . IOException ; import java . util . Arrays ; import java . util . Collections ; import java . util . List ; import java . util . Map ; public class SignificantStringTermsAggregator extends StringTermsAggregator { protected long numCollectedDocs ; protected final SignificantTermsAggregatorFactory termsAggFactory ; public SignificantStringTermsAggregator ( String name , AggregatorFactories factories , ValuesSource valuesSource , BucketCountThresholds bucketCountThresholds , IncludeExclude . StringFilter includeExclude , AggregationContext aggregationContext , Aggregator parent , SignificantTermsAggregatorFactory termsAggFactory , List < PipelineAggregator > pipelineAggregators , Map < String , Object > metaData ) throws IOException { super ( name , factories , valuesSource , null , bucketCountThresholds , includeExclude , aggregationContext , parent , SubAggCollectionMode . DEPTH_FIRST , false , pipelineAggregators , metaData ) ; this . termsAggFactory = termsAggFactory ; } @Override public LeafBucketCollector getLeafCollector ( LeafReaderContext ctx , final LeafBucketCollector sub ) throws IOException { return new LeafBucketCollectorBase ( super . getLeafCollector ( ctx , sub ) , null ) { @Override public void collect ( int doc , long bucket ) throws IOException { super . collect ( doc , bucket ) ; numCollectedDocs + + ; } } ; } @Override public SignificantStringTerms buildAggregation ( long owningBucketOrdinal ) throws IOException { assert owningBucketOrdinal = = <int> ; final int size = ( int ) Math . min ( bucketOrds . size ( ) , bucketCountThresholds . getShardSize ( ) ) ; long supersetSize = termsAggFactory . prepareBackground ( context ) ; long subsetSize = numCollectedDocs ; BucketSignificancePriorityQueue ordered = new BucketSignificancePriorityQueue ( size ) ; SignificantStringTerms . Bucket spare = null ; for ( int i = <int> ; i < bucketOrds . size ( ) ; i + + ) { final int docCount = bucketDocCount ( i ) ; if ( docCount < bucketCountThresholds . getShardMinDocCount ( ) ) { continue ; } if ( spare = = null ) { spare = new SignificantStringTerms . Bucket ( new BytesRef ( ) , <int> , <int> , <int> , <int> , null ) ; } bucketOrds . get ( i , spare . termBytes ) ; spare . subsetDf = docCount ; spare . subsetSize = subsetSize ; spare . supersetDf = termsAggFactory . getBackgroundFrequency ( spare . termBytes ) ; spare . supersetSize = supersetSize ; spare . updateScore ( termsAggFactory . getSignificanceHeuristic ( ) ) ; spare . bucketOrd = i ; spare = ( SignificantStringTerms . Bucket ) ordered . insertWithOverflow ( spare ) ; } final InternalSignificantTerms . Bucket [ ] list = new InternalSignificantTerms . Bucket [ ordered . size ( ) ] ; for ( int i = ordered . size ( ) - <int> ; i > = <int> ; i - - ) { final SignificantStringTerms . Bucket bucket = ( SignificantStringTerms . Bucket ) ordered . pop ( ) ; bucket . termBytes = BytesRef . deepCopyOf ( bucket . termBytes ) ; bucket . aggregations = bucketAggregations ( bucket . bucketOrd ) ; list [ i ] = bucket ; } return new SignificantStringTerms ( subsetSize , supersetSize , name , bucketCountThresholds . getRequiredSize ( ) , bucketCountThresholds . getMinDocCount ( ) , termsAggFactory . getSignificanceHeuristic ( ) , Arrays . asList ( list ) , pipelineAggregators ( ) , metaData ( ) ) ; } @Override public SignificantStringTerms buildEmptyAggregation ( ) { ContextIndexSearcher searcher = context . searchContext ( ) . searcher ( ) ; IndexReader topReader = searcher . getIndexReader ( ) ; int supersetSize = topReader . numDocs ( ) ; return new SignificantStringTerms ( <int> , supersetSize , name , bucketCountThresholds . getRequiredSize ( ) , bucketCountThresholds . getMinDocCount ( ) , termsAggFactory . getSignificanceHeuristic ( ) , Collections . < InternalSignificantTerms . Bucket > emptyList ( ) , pipelineAggregators ( ) , metaData ( ) ) ; } @Override public void doClose ( ) { Releasables . close ( bucketOrds , termsAggFactory ) ; } } 
