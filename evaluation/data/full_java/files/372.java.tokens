package org . apache . cassandra . db . commitlog ; import java . io . File ; import java . util . ArrayList ; import java . util . Collection ; import java . util . Collections ; import java . util . HashSet ; import java . util . LinkedHashMap ; import java . util . List ; import java . util . Map ; import java . util . Set ; import java . util . UUID ; import java . util . concurrent . BlockingQueue ; import java . util . concurrent . ConcurrentLinkedQueue ; import java . util . concurrent . Future ; import java . util . concurrent . LinkedBlockingQueue ; import java . util . concurrent . TimeUnit ; import java . util . concurrent . atomic . AtomicLong ; import com . google . common . collect . Iterables ; import com . google . common . util . concurrent . * ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; import org . apache . cassandra . config . DatabaseDescriptor ; import org . apache . cassandra . config . Schema ; import org . apache . cassandra . db . ColumnFamilyStore ; import org . apache . cassandra . db . Keyspace ; import org . apache . cassandra . db . Mutation ; import org . apache . cassandra . io . util . FileUtils ; import org . apache . cassandra . utils . Pair ; import org . apache . cassandra . utils . concurrent . WaitQueue ; import org . apache . cassandra . utils . JVMStabilityInspector ; import org . apache . cassandra . utils . WrappedRunnable ; import static org . apache . cassandra . db . commitlog . CommitLogSegment . Allocation ; public class CommitLogSegmentManager { static final Logger logger = LoggerFactory . getLogger ( CommitLogSegmentManager . class ) ; private final BlockingQueue < Runnable > segmentManagementTasks = new LinkedBlockingQueue < > ( ) ; private final ConcurrentLinkedQueue < CommitLogSegment > availableSegments = new ConcurrentLinkedQueue < > ( ) ; private final ConcurrentLinkedQueue < CommitLogSegment > activeSegments = new ConcurrentLinkedQueue < > ( ) ; private volatile CommitLogSegment allocatingFrom = null ; private final WaitQueue hasAvailableSegments = new WaitQueue ( ) ; private final AtomicLong size = new AtomicLong ( ) ; volatile boolean createReserveSegments = false ; private Thread managerThread ; private volatile boolean run = true ; private final CommitLog commitLog ; CommitLogSegmentManager ( final CommitLog commitLog ) { this . commitLog = commitLog ; } void start ( ) { Runnable runnable = new WrappedRunnable ( ) { public void runMayThrow ( ) throws Exception { while ( run ) { try { Runnable task = segmentManagementTasks . poll ( ) ; if ( task = = null ) { if ( availableSegments . isEmpty ( ) & & ( activeSegments . isEmpty ( ) | | createReserveSegments ) ) { logger . trace ( <str> ) ; availableSegments . add ( CommitLogSegment . createSegment ( commitLog ) ) ; hasAvailableSegments . signalAll ( ) ; } long unused = unusedCapacity ( ) ; if ( unused < <int> ) { List < CommitLogSegment > segmentsToRecycle = new ArrayList < > ( ) ; long spaceToReclaim = <int> ; for ( CommitLogSegment segment : activeSegments ) { if ( segment = = allocatingFrom ) break ; segmentsToRecycle . add ( segment ) ; spaceToReclaim + = DatabaseDescriptor . getCommitLogSegmentSize ( ) ; if ( spaceToReclaim + unused > = <int> ) break ; } flushDataFrom ( segmentsToRecycle , false ) ; } try { task = segmentManagementTasks . take ( ) ; } catch ( InterruptedException e ) { throw new AssertionError ( ) ; } } task . run ( ) ; } catch ( Throwable t ) { JVMStabilityInspector . inspectThrowable ( t ) ; if ( ! CommitLog . handleCommitError ( <str> , t ) ) return ; Uninterruptibles . sleepUninterruptibly ( <int> , TimeUnit . SECONDS ) ; } } } } ; run = true ; managerThread = new Thread ( runnable , <str> ) ; managerThread . start ( ) ; } public Allocation allocate ( Mutation mutation , int size ) { CommitLogSegment segment = allocatingFrom ( ) ; Allocation alloc ; while ( null = = ( alloc = segment . allocate ( mutation , size ) ) ) { advanceAllocatingFrom ( segment ) ; segment = allocatingFrom ; } return alloc ; } CommitLogSegment allocatingFrom ( ) { CommitLogSegment r = allocatingFrom ; if ( r = = null ) { advanceAllocatingFrom ( null ) ; r = allocatingFrom ; } return r ; } private void advanceAllocatingFrom ( CommitLogSegment old ) { while ( true ) { CommitLogSegment next ; synchronized ( this ) { if ( allocatingFrom ! = old ) return ; next = availableSegments . poll ( ) ; if ( next ! = null ) { allocatingFrom = next ; activeSegments . add ( next ) ; } } if ( next ! = null ) { if ( old ! = null ) { commitLog . archiver . maybeArchive ( old ) ; old . discardUnusedTail ( ) ; } commitLog . requestExtraSync ( ) ; return ; } WaitQueue . Signal signal = hasAvailableSegments . register ( commitLog . metrics . waitingOnSegmentAllocation . time ( ) ) ; wakeManager ( ) ; if ( ! availableSegments . isEmpty ( ) | | allocatingFrom ! = old ) { signal . cancel ( ) ; if ( allocatingFrom ! = old ) return ; continue ; } signal . awaitUninterruptibly ( ) ; } } private void wakeManager ( ) { segmentManagementTasks . add ( Runnables . doNothing ( ) ) ; } void forceRecycleAll ( Iterable < UUID > droppedCfs ) { List < CommitLogSegment > segmentsToRecycle = new ArrayList < > ( activeSegments ) ; CommitLogSegment last = segmentsToRecycle . get ( segmentsToRecycle . size ( ) - <int> ) ; advanceAllocatingFrom ( last ) ; last . waitForModifications ( ) ; Set < Keyspace > keyspaces = new HashSet < > ( ) ; for ( UUID cfId : last . getDirtyCFIDs ( ) ) { ColumnFamilyStore cfs = Schema . instance . getColumnFamilyStoreInstance ( cfId ) ; if ( cfs ! = null ) keyspaces . add ( cfs . keyspace ) ; } Keyspace . writeOrder . awaitNewBarrier ( ) ; Future < ? > future = flushDataFrom ( segmentsToRecycle , true ) ; try { future . get ( ) ; for ( CommitLogSegment segment : activeSegments ) for ( UUID cfId : droppedCfs ) segment . markClean ( cfId , segment . getContext ( ) ) ; for ( CommitLogSegment segment : activeSegments ) if ( segment . isUnused ( ) ) recycleSegment ( segment ) ; CommitLogSegment first ; if ( ( first = activeSegments . peek ( ) ) ! = null & & first . id < = last . id ) logger . error ( <str> ) ; } catch ( Throwable t ) { logger . error ( <str> , t ) ; } } void recycleSegment ( final CommitLogSegment segment ) { boolean archiveSuccess = commitLog . archiver . maybeWaitForArchiving ( segment . getName ( ) ) ; if ( activeSegments . remove ( segment ) ) { discardSegment ( segment , archiveSuccess ) ; } else { logger . warn ( <str> , segment ) ; } } void recycleSegment ( final File file ) { logger . trace ( <str> , file ) ; FileUtils . deleteWithConfirm ( file ) ; } private void discardSegment ( final CommitLogSegment segment , final boolean deleteFile ) { logger . trace ( <str> , segment , deleteFile ? <str> : <str> ) ; segmentManagementTasks . add ( new Runnable ( ) { public void run ( ) { segment . discard ( deleteFile ) ; } } ) ; } void addSize ( long addedSize ) { size . addAndGet ( addedSize ) ; } public long onDiskSize ( ) { return size . get ( ) ; } private long unusedCapacity ( ) { long total = DatabaseDescriptor . getTotalCommitlogSpaceInMB ( ) * <int> * <int> ; long currentSize = size . get ( ) ; logger . trace ( <str> , currentSize , total ) ; return total - currentSize ; } public boolean manages ( String name ) { for ( CommitLogSegment segment : Iterables . concat ( activeSegments , availableSegments ) ) if ( segment . getName ( ) . equals ( name ) ) return true ; return false ; } void enableReserveSegmentCreation ( ) { createReserveSegments = true ; wakeManager ( ) ; } private Future < ? > flushDataFrom ( List < CommitLogSegment > segments , boolean force ) { if ( segments . isEmpty ( ) ) return Futures . immediateFuture ( null ) ; final ReplayPosition maxReplayPosition = segments . get ( segments . size ( ) - <int> ) . getContext ( ) ; final Map < UUID , ListenableFuture < ? > > flushes = new LinkedHashMap < > ( ) ; for ( CommitLogSegment segment : segments ) { for ( UUID dirtyCFId : segment . getDirtyCFIDs ( ) ) { Pair < String , String > pair = Schema . instance . getCF ( dirtyCFId ) ; if ( pair = = null ) { logger . trace ( <str> , dirtyCFId ) ; segment . markClean ( dirtyCFId , segment . getContext ( ) ) ; } else if ( ! flushes . containsKey ( dirtyCFId ) ) { String keyspace = pair . left ; final ColumnFamilyStore cfs = Keyspace . open ( keyspace ) . getColumnFamilyStore ( dirtyCFId ) ; flushes . put ( dirtyCFId , force ? cfs . forceFlush ( ) : cfs . forceFlush ( maxReplayPosition ) ) ; } } } return Futures . allAsList ( flushes . values ( ) ) ; } public void stopUnsafe ( boolean deleteSegments ) { logger . trace ( <str> ) ; createReserveSegments = false ; awaitManagementTasksCompletion ( ) ; shutdown ( ) ; try { awaitTermination ( ) ; } catch ( InterruptedException e ) { throw new RuntimeException ( e ) ; } for ( CommitLogSegment segment : activeSegments ) closeAndDeleteSegmentUnsafe ( segment , deleteSegments ) ; activeSegments . clear ( ) ; for ( CommitLogSegment segment : availableSegments ) closeAndDeleteSegmentUnsafe ( segment , deleteSegments ) ; availableSegments . clear ( ) ; allocatingFrom = null ; segmentManagementTasks . clear ( ) ; size . set ( <int> L ) ; logger . trace ( <str> ) ; } void awaitManagementTasksCompletion ( ) { while ( ! segmentManagementTasks . isEmpty ( ) ) Thread . yield ( ) ; Uninterruptibles . sleepUninterruptibly ( <int> , TimeUnit . MILLISECONDS ) ; } private static void closeAndDeleteSegmentUnsafe ( CommitLogSegment segment , boolean delete ) { try { segment . discard ( delete ) ; } catch ( AssertionError ignored ) { } } public void shutdown ( ) { run = false ; wakeManager ( ) ; } public void awaitTermination ( ) throws InterruptedException { managerThread . join ( ) ; for ( CommitLogSegment segment : activeSegments ) segment . close ( ) ; for ( CommitLogSegment segment : availableSegments ) segment . close ( ) ; CompressedSegment . shutdown ( ) ; } Collection < CommitLogSegment > getActiveSegments ( ) { return Collections . unmodifiableCollection ( activeSegments ) ; } } 
