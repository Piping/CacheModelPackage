package org . apache . cassandra . hadoop . cql3 ; import java . io . IOException ; import java . net . InetAddress ; import java . nio . ByteBuffer ; import java . util . * ; import java . util . concurrent . * ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; import com . datastax . driver . core . * ; import com . datastax . driver . core . exceptions . * ; import org . apache . cassandra . db . marshal . CompositeType ; import org . apache . cassandra . dht . IPartitioner ; import org . apache . cassandra . dht . Token ; import org . apache . cassandra . hadoop . ConfigHelper ; import org . apache . cassandra . hadoop . HadoopCompat ; import org . apache . cassandra . utils . FBUtilities ; import org . apache . hadoop . conf . Configuration ; import org . apache . hadoop . mapreduce . RecordWriter ; import org . apache . hadoop . mapreduce . TaskAttemptContext ; import org . apache . hadoop . util . Progressable ; class CqlRecordWriter extends RecordWriter < Map < String , ByteBuffer > , List < ByteBuffer > > implements org . apache . hadoop . mapred . RecordWriter < Map < String , ByteBuffer > , List < ByteBuffer > > , AutoCloseable { private static final Logger logger = LoggerFactory . getLogger ( CqlRecordWriter . class ) ; protected final Configuration conf ; protected final int queueSize ; protected final long batchThreshold ; protected Progressable progressable ; protected TaskAttemptContext context ; private final NativeRingCache ringCache ; protected final Map < InetAddress , RangeClient > clients ; protected final ConcurrentHashMap < Session , PreparedStatement > preparedStatements = new ConcurrentHashMap < Session , PreparedStatement > ( ) ; protected final String cql ; protected List < ColumnMetadata > partitionKeyColumns ; protected List < ColumnMetadata > clusterColumns ; CqlRecordWriter ( TaskAttemptContext context ) throws IOException { this ( HadoopCompat . getConfiguration ( context ) ) ; this . context = context ; } CqlRecordWriter ( Configuration conf , Progressable progressable ) { this ( conf ) ; this . progressable = progressable ; } CqlRecordWriter ( Configuration conf ) { this . conf = conf ; this . queueSize = conf . getInt ( CqlOutputFormat . QUEUE_SIZE , <int> * FBUtilities . getAvailableProcessors ( ) ) ; batchThreshold = conf . getLong ( CqlOutputFormat . BATCH_THRESHOLD , <int> ) ; this . clients = new HashMap < > ( ) ; String keyspace = ConfigHelper . getOutputKeyspace ( conf ) ; try ( Cluster cluster = CqlConfigHelper . getOutputCluster ( ConfigHelper . getOutputInitialAddress ( conf ) , conf ) ; Session client = cluster . connect ( keyspace ) ) { ringCache = new NativeRingCache ( conf ) ; if ( client ! = null ) { TableMetadata tableMetadata = client . getCluster ( ) . getMetadata ( ) . getKeyspace ( client . getLoggedKeyspace ( ) ) . getTable ( ConfigHelper . getOutputColumnFamily ( conf ) ) ; clusterColumns = tableMetadata . getClusteringColumns ( ) ; partitionKeyColumns = tableMetadata . getPartitionKey ( ) ; String cqlQuery = CqlConfigHelper . getOutputCql ( conf ) . trim ( ) ; if ( cqlQuery . toLowerCase ( ) . startsWith ( <str> ) ) throw new UnsupportedOperationException ( <str> ) ; cql = appendKeyWhereClauses ( cqlQuery ) ; } else { throw new IllegalArgumentException ( <str> + conf ) ; } } catch ( Exception e ) { throw new RuntimeException ( e ) ; } } public void close ( TaskAttemptContext context ) throws IOException , InterruptedException { close ( ) ; } @Deprecated public void close ( org . apache . hadoop . mapred . Reporter reporter ) throws IOException { close ( ) ; } @Override public void close ( ) throws IOException { IOException clientException = null ; for ( RangeClient client : clients . values ( ) ) { try { client . close ( ) ; } catch ( IOException e ) { clientException = e ; } } if ( clientException ! = null ) throw clientException ; } @Override public void write ( Map < String , ByteBuffer > keyColumns , List < ByteBuffer > values ) throws IOException { TokenRange range = ringCache . getRange ( getPartitionKey ( keyColumns ) ) ; final InetAddress address = ringCache . getEndpoints ( range ) . get ( <int> ) ; RangeClient client = clients . get ( address ) ; if ( client = = null ) { client = new RangeClient ( ringCache . getEndpoints ( range ) ) ; client . start ( ) ; clients . put ( address , client ) ; } List < ByteBuffer > allValues = new ArrayList < ByteBuffer > ( values ) ; for ( ColumnMetadata column : partitionKeyColumns ) allValues . add ( keyColumns . get ( column . getName ( ) ) ) ; for ( ColumnMetadata column : clusterColumns ) allValues . add ( keyColumns . get ( column . getName ( ) ) ) ; client . put ( allValues ) ; if ( progressable ! = null ) progressable . progress ( ) ; if ( context ! = null ) HadoopCompat . progress ( context ) ; } private static void closeSession ( Session session ) { try { if ( session ! = null ) session . close ( ) ; } catch ( Throwable t ) { logger . warn ( <str> , t ) ; } } public class RangeClient extends Thread { protected final List < InetAddress > endpoints ; protected Cluster cluster = null ; protected final BlockingQueue < List < ByteBuffer > > queue = new ArrayBlockingQueue < List < ByteBuffer > > ( queueSize ) ; protected volatile boolean run = true ; protected volatile IOException lastException ; public RangeClient ( List < InetAddress > endpoints ) { super ( <str> + endpoints ) ; this . endpoints = endpoints ; } public void put ( List < ByteBuffer > value ) throws IOException { while ( true ) { if ( lastException ! = null ) throw lastException ; try { if ( queue . offer ( value , <int> , TimeUnit . MILLISECONDS ) ) break ; } catch ( InterruptedException e ) { throw new AssertionError ( e ) ; } } } @SuppressWarnings ( <str> ) public void run ( ) { Session session = null ; try { outer : while ( run | | ! queue . isEmpty ( ) ) { List < ByteBuffer > bindVariables ; try { bindVariables = queue . take ( ) ; } catch ( InterruptedException e ) { continue ; } ListIterator < InetAddress > iter = endpoints . listIterator ( ) ; while ( true ) { if ( session ! = null ) { try { int i = <int> ; PreparedStatement statement = preparedStatement ( session ) ; while ( bindVariables ! = null ) { BoundStatement boundStatement = new BoundStatement ( statement ) ; for ( int columnPosition = <int> ; columnPosition < bindVariables . size ( ) ; columnPosition + + ) { boundStatement . setBytesUnsafe ( columnPosition , bindVariables . get ( columnPosition ) ) ; } session . execute ( boundStatement ) ; i + + ; if ( i > = batchThreshold ) break ; bindVariables = queue . poll ( ) ; } break ; } catch ( Exception e ) { closeInternal ( ) ; if ( ! iter . hasNext ( ) ) { lastException = new IOException ( e ) ; break outer ; } } } try { InetAddress address = iter . next ( ) ; String host = address . getHostName ( ) ; cluster = CqlConfigHelper . getOutputCluster ( host , conf ) ; closeSession ( session ) ; session = cluster . connect ( ) ; } catch ( Exception e ) { if ( canRetryDriverConnection ( e ) ) { iter . previous ( ) ; } closeInternal ( ) ; if ( ( e instanceof AuthenticationException | | e instanceof InvalidQueryException ) | | ! iter . hasNext ( ) ) { lastException = new IOException ( e ) ; break outer ; } } } } } finally { closeSession ( session ) ; } closeInternal ( ) ; } private PreparedStatement preparedStatement ( Session client ) { PreparedStatement statement = preparedStatements . get ( client ) ; if ( statement = = null ) { PreparedStatement result ; try { result = client . prepare ( cql ) ; } catch ( NoHostAvailableException e ) { throw new RuntimeException ( <str> + cql , e ) ; } PreparedStatement previousId = preparedStatements . putIfAbsent ( client , result ) ; statement = previousId = = null ? result : previousId ; } return statement ; } public void close ( ) throws IOException { run = false ; interrupt ( ) ; try { this . join ( ) ; } catch ( InterruptedException e ) { throw new AssertionError ( e ) ; } if ( lastException ! = null ) throw lastException ; } protected void closeInternal ( ) { if ( cluster ! = null ) { cluster . close ( ) ; } } private boolean canRetryDriverConnection ( Exception e ) { if ( e instanceof DriverException & & e . getMessage ( ) . contains ( <str> ) ) return true ; if ( e instanceof NoHostAvailableException ) { if ( ( ( NoHostAvailableException ) e ) . getErrors ( ) . values ( ) . size ( ) = = <int> ) { Throwable cause = ( ( NoHostAvailableException ) e ) . getErrors ( ) . values ( ) . iterator ( ) . next ( ) ; if ( cause ! = null & & cause . getCause ( ) instanceof java . nio . channels . ClosedByInterruptException ) { return true ; } } } return false ; } } private ByteBuffer getPartitionKey ( Map < String , ByteBuffer > keyColumns ) { ByteBuffer partitionKey ; if ( partitionKeyColumns . size ( ) > <int> ) { ByteBuffer [ ] keys = new ByteBuffer [ partitionKeyColumns . size ( ) ] ; for ( int i = <int> ; i < keys . length ; i + + ) keys [ i ] = keyColumns . get ( partitionKeyColumns . get ( i ) . getName ( ) ) ; partitionKey = CompositeType . build ( keys ) ; } else { partitionKey = keyColumns . get ( partitionKeyColumns . get ( <int> ) . getName ( ) ) ; } return partitionKey ; } private String appendKeyWhereClauses ( String cqlQuery ) { String keyWhereClause = <str> ; for ( ColumnMetadata partitionKey : partitionKeyColumns ) keyWhereClause + = String . format ( <str> , keyWhereClause . isEmpty ( ) ? quote ( partitionKey . getName ( ) ) : ( <str> + quote ( partitionKey . getName ( ) ) ) ) ; for ( ColumnMetadata clusterColumn : clusterColumns ) keyWhereClause + = <str> + quote ( clusterColumn . getName ( ) ) + <str> ; return cqlQuery + <str> + keyWhereClause ; } private String quote ( String identifier ) { return <str> + identifier . replaceAll ( <str> , <str> ) + <str> ; } static class NativeRingCache { private Map < TokenRange , Set < Host > > rangeMap ; private Metadata metadata ; private final IPartitioner partitioner ; private final Configuration conf ; public NativeRingCache ( Configuration conf ) { this . conf = conf ; this . partitioner = ConfigHelper . getOutputPartitioner ( conf ) ; refreshEndpointMap ( ) ; } private void refreshEndpointMap ( ) { String keyspace = ConfigHelper . getOutputKeyspace ( conf ) ; try ( Cluster cluster = CqlConfigHelper . getOutputCluster ( ConfigHelper . getOutputInitialAddress ( conf ) , conf ) ; Session session = cluster . connect ( keyspace ) ) { rangeMap = new HashMap < > ( ) ; metadata = session . getCluster ( ) . getMetadata ( ) ; Set < TokenRange > ranges = metadata . getTokenRanges ( ) ; for ( TokenRange range : ranges ) rangeMap . put ( range , metadata . getReplicas ( keyspace , range ) ) ; } } public TokenRange getRange ( ByteBuffer key ) { Token t = partitioner . getToken ( key ) ; com . datastax . driver . core . Token driverToken = metadata . newToken ( partitioner . getTokenFactory ( ) . toString ( t ) ) ; for ( TokenRange range : rangeMap . keySet ( ) ) { if ( range . contains ( driverToken ) ) { return range ; } } throw new RuntimeException ( <str> + rangeMap ) ; } public List < InetAddress > getEndpoints ( TokenRange range ) { Set < Host > hostSet = rangeMap . get ( range ) ; List < InetAddress > addresses = new ArrayList < > ( hostSet . size ( ) ) ; for ( Host host : hostSet ) { addresses . add ( host . getAddress ( ) ) ; } return addresses ; } } } 
