package org . elasticsearch . action . termvectors ; import org . elasticsearch . ElasticsearchParseException ; import org . elasticsearch . action . ActionRequestValidationException ; import org . elasticsearch . action . DocumentRequest ; import org . elasticsearch . action . RealtimeRequest ; import org . elasticsearch . action . ValidateActions ; import org . elasticsearch . action . get . MultiGetRequest ; import org . elasticsearch . action . support . single . shard . SingleShardRequest ; import org . elasticsearch . common . Nullable ; import org . elasticsearch . common . bytes . BytesReference ; import org . elasticsearch . common . io . stream . StreamInput ; import org . elasticsearch . common . io . stream . StreamOutput ; import org . elasticsearch . common . lucene . uid . Versions ; import org . elasticsearch . common . util . set . Sets ; import org . elasticsearch . common . xcontent . XContentBuilder ; import org . elasticsearch . common . xcontent . XContentParser ; import org . elasticsearch . index . VersionType ; import java . io . IOException ; import java . util . ArrayList ; import java . util . EnumSet ; import java . util . HashMap ; import java . util . HashSet ; import java . util . List ; import java . util . Map ; import java . util . Set ; import java . util . concurrent . atomic . AtomicInteger ; import static org . elasticsearch . common . xcontent . XContentFactory . jsonBuilder ; public class TermVectorsRequest extends SingleShardRequest < TermVectorsRequest > implements DocumentRequest < TermVectorsRequest > , RealtimeRequest { private String type ; private String id ; private BytesReference doc ; private String routing ; private VersionType versionType = VersionType . INTERNAL ; private long version = Versions . MATCH_ANY ; protected String preference ; private static final AtomicInteger randomInt = new AtomicInteger ( <int> ) ; private Set < String > selectedFields ; Boolean realtime ; private Map < String , String > perFieldAnalyzer ; private FilterSettings filterSettings ; public static final class FilterSettings { public Integer maxNumTerms ; public Integer minTermFreq ; public Integer maxTermFreq ; public Integer minDocFreq ; public Integer maxDocFreq ; public Integer minWordLength ; public Integer maxWordLength ; public FilterSettings ( ) { } public FilterSettings ( @Nullable Integer maxNumTerms , @Nullable Integer minTermFreq , @Nullable Integer maxTermFreq , @Nullable Integer minDocFreq , @Nullable Integer maxDocFreq , @Nullable Integer minWordLength , @Nullable Integer maxWordLength ) { this . maxNumTerms = maxNumTerms ; this . minTermFreq = minTermFreq ; this . maxTermFreq = maxTermFreq ; this . minDocFreq = minDocFreq ; this . maxDocFreq = maxDocFreq ; this . minWordLength = minWordLength ; this . maxWordLength = maxWordLength ; } public void readFrom ( StreamInput in ) throws IOException { maxNumTerms = in . readOptionalVInt ( ) ; minTermFreq = in . readOptionalVInt ( ) ; maxTermFreq = in . readOptionalVInt ( ) ; minDocFreq = in . readOptionalVInt ( ) ; maxDocFreq = in . readOptionalVInt ( ) ; minWordLength = in . readOptionalVInt ( ) ; maxWordLength = in . readOptionalVInt ( ) ; } public void writeTo ( StreamOutput out ) throws IOException { out . writeOptionalVInt ( maxNumTerms ) ; out . writeOptionalVInt ( minTermFreq ) ; out . writeOptionalVInt ( maxTermFreq ) ; out . writeOptionalVInt ( minDocFreq ) ; out . writeOptionalVInt ( maxDocFreq ) ; out . writeOptionalVInt ( minWordLength ) ; out . writeOptionalVInt ( maxWordLength ) ; } } private EnumSet < Flag > flagsEnum = EnumSet . of ( Flag . Positions , Flag . Offsets , Flag . Payloads , Flag . FieldStatistics ) ; long startTime ; public TermVectorsRequest ( ) { } public TermVectorsRequest ( String index , String type , String id ) { super ( index ) ; this . id = id ; this . type = type ; } public TermVectorsRequest ( TermVectorsRequest other ) { super ( other . index ( ) ) ; this . id = other . id ( ) ; this . type = other . type ( ) ; if ( this . doc ! = null ) { this . doc = other . doc ( ) . copyBytesArray ( ) ; } this . flagsEnum = other . getFlags ( ) . clone ( ) ; this . preference = other . preference ( ) ; this . routing = other . routing ( ) ; if ( other . selectedFields ! = null ) { this . selectedFields = new HashSet < > ( other . selectedFields ) ; } if ( other . perFieldAnalyzer ! = null ) { this . perFieldAnalyzer = new HashMap < > ( other . perFieldAnalyzer ) ; } this . realtime = other . realtime ( ) ; this . version = other . version ( ) ; this . versionType = VersionType . fromValue ( other . versionType ( ) . getValue ( ) ) ; this . startTime = other . startTime ( ) ; this . filterSettings = other . filterSettings ( ) ; } public TermVectorsRequest ( MultiGetRequest . Item item ) { super ( item . index ( ) ) ; this . id = item . id ( ) ; this . type = item . type ( ) ; this . selectedFields ( item . fields ( ) ) ; this . routing ( item . routing ( ) ) ; } public EnumSet < Flag > getFlags ( ) { return flagsEnum ; } public TermVectorsRequest type ( String type ) { this . type = type ; return this ; } @Override public String type ( ) { return type ; } @Override public String id ( ) { return id ; } public TermVectorsRequest id ( String id ) { this . id = id ; return this ; } public BytesReference doc ( ) { return doc ; } public TermVectorsRequest doc ( XContentBuilder documentBuilder ) { return this . doc ( documentBuilder . bytes ( ) , true ) ; } public TermVectorsRequest doc ( BytesReference doc , boolean generateRandomId ) { if ( generateRandomId ) { this . id ( String . valueOf ( randomInt . getAndAdd ( <int> ) ) ) ; } this . doc = doc ; return this ; } @Override public String routing ( ) { return routing ; } @Override public TermVectorsRequest routing ( String routing ) { this . routing = routing ; return this ; } public TermVectorsRequest parent ( String parent ) { if ( routing = = null ) { routing = parent ; } return this ; } public String preference ( ) { return this . preference ; } public TermVectorsRequest preference ( String preference ) { this . preference = preference ; return this ; } public TermVectorsRequest offsets ( boolean offsets ) { setFlag ( Flag . Offsets , offsets ) ; return this ; } public boolean offsets ( ) { return flagsEnum . contains ( Flag . Offsets ) ; } public TermVectorsRequest positions ( boolean positions ) { setFlag ( Flag . Positions , positions ) ; return this ; } public boolean positions ( ) { return flagsEnum . contains ( Flag . Positions ) ; } public boolean payloads ( ) { return flagsEnum . contains ( Flag . Payloads ) ; } public TermVectorsRequest payloads ( boolean payloads ) { setFlag ( Flag . Payloads , payloads ) ; return this ; } public boolean termStatistics ( ) { return flagsEnum . contains ( Flag . TermStatistics ) ; } public TermVectorsRequest termStatistics ( boolean termStatistics ) { setFlag ( Flag . TermStatistics , termStatistics ) ; return this ; } public boolean fieldStatistics ( ) { return flagsEnum . contains ( Flag . FieldStatistics ) ; } public TermVectorsRequest fieldStatistics ( boolean fieldStatistics ) { setFlag ( Flag . FieldStatistics , fieldStatistics ) ; return this ; } public boolean dfs ( ) { return flagsEnum . contains ( Flag . Dfs ) ; } public TermVectorsRequest dfs ( boolean dfs ) { setFlag ( Flag . Dfs , dfs ) ; return this ; } public Set < String > selectedFields ( ) { return selectedFields ; } public TermVectorsRequest selectedFields ( String . . . fields ) { selectedFields = fields ! = null & & fields . length ! = <int> ? Sets . newHashSet ( fields ) : null ; return this ; } public boolean realtime ( ) { return this . realtime = = null ? true : this . realtime ; } @Override public TermVectorsRequest realtime ( Boolean realtime ) { this . realtime = realtime ; return this ; } public Map < String , String > perFieldAnalyzer ( ) { return perFieldAnalyzer ; } public TermVectorsRequest perFieldAnalyzer ( Map < String , String > perFieldAnalyzer ) { this . perFieldAnalyzer = perFieldAnalyzer ! = null & & perFieldAnalyzer . size ( ) ! = <int> ? new HashMap < > ( perFieldAnalyzer ) : null ; return this ; } public FilterSettings filterSettings ( ) { return this . filterSettings ; } public TermVectorsRequest filterSettings ( FilterSettings settings ) { this . filterSettings = settings ! = null ? settings : null ; return this ; } public long version ( ) { return version ; } public TermVectorsRequest version ( long version ) { this . version = version ; return this ; } public VersionType versionType ( ) { return versionType ; } public TermVectorsRequest versionType ( VersionType versionType ) { this . versionType = versionType ; return this ; } private void setFlag ( Flag flag , boolean set ) { if ( set & & ! flagsEnum . contains ( flag ) ) { flagsEnum . add ( flag ) ; } else if ( ! set ) { flagsEnum . remove ( flag ) ; assert ( ! flagsEnum . contains ( flag ) ) ; } } public long startTime ( ) { return this . startTime ; } @Override public ActionRequestValidationException validate ( ) { ActionRequestValidationException validationException = super . validateNonNullIndex ( ) ; if ( type = = null ) { validationException = ValidateActions . addValidationError ( <str> , validationException ) ; } if ( id = = null & & doc = = null ) { validationException = ValidateActions . addValidationError ( <str> , validationException ) ; } return validationException ; } public static TermVectorsRequest readTermVectorsRequest ( StreamInput in ) throws IOException { TermVectorsRequest termVectorsRequest = new TermVectorsRequest ( ) ; termVectorsRequest . readFrom ( in ) ; return termVectorsRequest ; } @Override public void readFrom ( StreamInput in ) throws IOException { super . readFrom ( in ) ; type = in . readString ( ) ; id = in . readString ( ) ; if ( in . readBoolean ( ) ) { doc = in . readBytesReference ( ) ; } routing = in . readOptionalString ( ) ; preference = in . readOptionalString ( ) ; long flags = in . readVLong ( ) ; flagsEnum . clear ( ) ; for ( Flag flag : Flag . values ( ) ) { if ( ( flags & ( <int> < < flag . ordinal ( ) ) ) ! = <int> ) { flagsEnum . add ( flag ) ; } } int numSelectedFields = in . readVInt ( ) ; if ( numSelectedFields > <int> ) { selectedFields = new HashSet < > ( ) ; for ( int i = <int> ; i < numSelectedFields ; i + + ) { selectedFields . add ( in . readString ( ) ) ; } } if ( in . readBoolean ( ) ) { perFieldAnalyzer = readPerFieldAnalyzer ( in . readMap ( ) ) ; } if ( in . readBoolean ( ) ) { filterSettings = new FilterSettings ( ) ; filterSettings . readFrom ( in ) ; } realtime = in . readBoolean ( ) ; versionType = VersionType . fromValue ( in . readByte ( ) ) ; version = in . readLong ( ) ; } @Override public void writeTo ( StreamOutput out ) throws IOException { super . writeTo ( out ) ; out . writeString ( type ) ; out . writeString ( id ) ; out . writeBoolean ( doc ! = null ) ; if ( doc ! = null ) { out . writeBytesReference ( doc ) ; } out . writeOptionalString ( routing ) ; out . writeOptionalString ( preference ) ; long longFlags = <int> ; for ( Flag flag : flagsEnum ) { longFlags | = ( <int> < < flag . ordinal ( ) ) ; } out . writeVLong ( longFlags ) ; if ( selectedFields ! = null ) { out . writeVInt ( selectedFields . size ( ) ) ; for ( String selectedField : selectedFields ) { out . writeString ( selectedField ) ; } } else { out . writeVInt ( <int> ) ; } out . writeBoolean ( perFieldAnalyzer ! = null ) ; if ( perFieldAnalyzer ! = null ) { out . writeGenericValue ( perFieldAnalyzer ) ; } out . writeBoolean ( filterSettings ! = null ) ; if ( filterSettings ! = null ) { filterSettings . writeTo ( out ) ; } out . writeBoolean ( realtime ( ) ) ; out . writeByte ( versionType . getValue ( ) ) ; out . writeLong ( version ) ; } public static enum Flag { Positions , Offsets , Payloads , FieldStatistics , TermStatistics , Dfs } public static void parseRequest ( TermVectorsRequest termVectorsRequest , XContentParser parser ) throws IOException { XContentParser . Token token ; String currentFieldName = null ; List < String > fields = new ArrayList < > ( ) ; while ( ( token = parser . nextToken ( ) ) ! = XContentParser . Token . END_OBJECT ) { if ( token = = XContentParser . Token . FIELD_NAME ) { currentFieldName = parser . currentName ( ) ; } else if ( currentFieldName ! = null ) { if ( currentFieldName . equals ( <str> ) ) { if ( token = = XContentParser . Token . START_ARRAY ) { while ( parser . nextToken ( ) ! = XContentParser . Token . END_ARRAY ) { fields . add ( parser . text ( ) ) ; } } else { throw new ElasticsearchParseException ( <str> ) ; } } else if ( currentFieldName . equals ( <str> ) ) { termVectorsRequest . offsets ( parser . booleanValue ( ) ) ; } else if ( currentFieldName . equals ( <str> ) ) { termVectorsRequest . positions ( parser . booleanValue ( ) ) ; } else if ( currentFieldName . equals ( <str> ) ) { termVectorsRequest . payloads ( parser . booleanValue ( ) ) ; } else if ( currentFieldName . equals ( <str> ) | | currentFieldName . equals ( <str> ) ) { termVectorsRequest . termStatistics ( parser . booleanValue ( ) ) ; } else if ( currentFieldName . equals ( <str> ) | | currentFieldName . equals ( <str> ) ) { termVectorsRequest . fieldStatistics ( parser . booleanValue ( ) ) ; } else if ( currentFieldName . equals ( <str> ) ) { termVectorsRequest . dfs ( parser . booleanValue ( ) ) ; } else if ( currentFieldName . equals ( <str> ) | | currentFieldName . equals ( <str> ) ) { termVectorsRequest . perFieldAnalyzer ( readPerFieldAnalyzer ( parser . map ( ) ) ) ; } else if ( currentFieldName . equals ( <str> ) ) { termVectorsRequest . filterSettings ( readFilterSettings ( parser , termVectorsRequest ) ) ; } else if ( <str> . equals ( currentFieldName ) ) { termVectorsRequest . index = parser . text ( ) ; } else if ( <str> . equals ( currentFieldName ) ) { termVectorsRequest . type = parser . text ( ) ; } else if ( <str> . equals ( currentFieldName ) ) { if ( termVectorsRequest . doc ! = null ) { throw new ElasticsearchParseException ( <str> ) ; } termVectorsRequest . id = parser . text ( ) ; } else if ( <str> . equals ( currentFieldName ) ) { if ( termVectorsRequest . id ! = null ) { throw new ElasticsearchParseException ( <str> ) ; } termVectorsRequest . doc ( jsonBuilder ( ) . copyCurrentStructure ( parser ) ) ; } else if ( <str> . equals ( currentFieldName ) | | <str> . equals ( currentFieldName ) ) { termVectorsRequest . routing = parser . text ( ) ; } else if ( <str> . equals ( currentFieldName ) | | <str> . equals ( currentFieldName ) ) { termVectorsRequest . version = parser . longValue ( ) ; } else if ( <str> . equals ( currentFieldName ) | | <str> . equals ( currentFieldName ) | | <str> . equals ( currentFieldName ) | | <str> . equals ( currentFieldName ) ) { termVectorsRequest . versionType = VersionType . fromString ( parser . text ( ) ) ; } else { throw new ElasticsearchParseException ( <str> , currentFieldName ) ; } } } if ( fields . size ( ) > <int> ) { String [ ] fieldsAsArray = new String [ fields . size ( ) ] ; termVectorsRequest . selectedFields ( fields . toArray ( fieldsAsArray ) ) ; } } public static Map < String , String > readPerFieldAnalyzer ( Map < String , Object > map ) { Map < String , String > mapStrStr = new HashMap < > ( ) ; for ( Map . Entry < String , Object > e : map . entrySet ( ) ) { if ( e . getValue ( ) instanceof String ) { mapStrStr . put ( e . getKey ( ) , ( String ) e . getValue ( ) ) ; } else { throw new ElasticsearchParseException ( <str> , e . getKey ( ) , e . getValue ( ) . getClass ( ) ) ; } } return mapStrStr ; } private static FilterSettings readFilterSettings ( XContentParser parser , TermVectorsRequest termVectorsRequest ) throws IOException { FilterSettings settings = new FilterSettings ( ) ; XContentParser . Token token ; String currentFieldName = null ; while ( ( token = parser . nextToken ( ) ) ! = XContentParser . Token . END_OBJECT ) { if ( token = = XContentParser . Token . FIELD_NAME ) { currentFieldName = parser . currentName ( ) ; } else if ( currentFieldName ! = null ) { if ( currentFieldName . equals ( <str> ) ) { settings . maxNumTerms = parser . intValue ( ) ; } else if ( currentFieldName . equals ( <str> ) ) { settings . minTermFreq = parser . intValue ( ) ; } else if ( currentFieldName . equals ( <str> ) ) { settings . maxTermFreq = parser . intValue ( ) ; } else if ( currentFieldName . equals ( <str> ) ) { settings . minDocFreq = parser . intValue ( ) ; } else if ( currentFieldName . equals ( <str> ) ) { settings . maxDocFreq = parser . intValue ( ) ; } else if ( currentFieldName . equals ( <str> ) ) { settings . minWordLength = parser . intValue ( ) ; } else if ( currentFieldName . equals ( <str> ) ) { settings . maxWordLength = parser . intValue ( ) ; } else { throw new ElasticsearchParseException ( <str> , currentFieldName ) ; } } } return settings ; } } 
