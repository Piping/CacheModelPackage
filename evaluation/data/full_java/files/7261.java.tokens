package org . elasticsearch . search . aggregations . bucket . terms ; import org . apache . lucene . index . DocValues ; import org . apache . lucene . index . LeafReaderContext ; import org . apache . lucene . index . RandomAccessOrds ; import org . apache . lucene . index . SortedDocValues ; import org . apache . lucene . util . ArrayUtil ; import org . apache . lucene . util . BytesRef ; import org . apache . lucene . util . LongBitSet ; import org . apache . lucene . util . RamUsageEstimator ; import org . elasticsearch . common . io . stream . StreamInput ; import org . elasticsearch . common . io . stream . StreamOutput ; import org . elasticsearch . common . lease . Releasables ; import org . elasticsearch . common . util . IntArray ; import org . elasticsearch . common . util . LongHash ; import org . elasticsearch . common . xcontent . XContentBuilder ; import org . elasticsearch . index . fielddata . AbstractRandomAccessOrds ; import org . elasticsearch . index . fielddata . ordinals . GlobalOrdinalMapping ; import org . elasticsearch . search . aggregations . Aggregator ; import org . elasticsearch . search . aggregations . AggregatorFactories ; import org . elasticsearch . search . aggregations . InternalAggregation ; import org . elasticsearch . search . aggregations . InternalAggregations ; import org . elasticsearch . search . aggregations . LeafBucketCollector ; import org . elasticsearch . search . aggregations . LeafBucketCollectorBase ; import org . elasticsearch . search . aggregations . bucket . terms . InternalTerms . Bucket ; import org . elasticsearch . search . aggregations . bucket . terms . support . BucketPriorityQueue ; import org . elasticsearch . search . aggregations . bucket . terms . support . IncludeExclude ; import org . elasticsearch . search . aggregations . pipeline . PipelineAggregator ; import org . elasticsearch . search . aggregations . support . AggregationContext ; import org . elasticsearch . search . aggregations . support . ValuesSource ; import java . io . IOException ; import java . util . Arrays ; import java . util . List ; import java . util . Map ; public class GlobalOrdinalsStringTermsAggregator extends AbstractStringTermsAggregator { protected final ValuesSource . Bytes . WithOrdinals valuesSource ; protected final IncludeExclude . OrdinalsFilter includeExclude ; protected LongBitSet acceptedGlobalOrdinals ; protected RandomAccessOrds globalOrds ; public GlobalOrdinalsStringTermsAggregator ( String name , AggregatorFactories factories , ValuesSource . Bytes . WithOrdinals valuesSource , Terms . Order order , BucketCountThresholds bucketCountThresholds , IncludeExclude . OrdinalsFilter includeExclude , AggregationContext aggregationContext , Aggregator parent , SubAggCollectionMode collectionMode , boolean showTermDocCountError , List < PipelineAggregator > pipelineAggregators , Map < String , Object > metaData ) throws IOException { super ( name , factories , aggregationContext , parent , order , bucketCountThresholds , collectionMode , showTermDocCountError , pipelineAggregators , metaData ) ; this . valuesSource = valuesSource ; this . includeExclude = includeExclude ; } protected long getBucketOrd ( long termOrd ) { return termOrd ; } @Override public LeafBucketCollector getLeafCollector ( LeafReaderContext ctx , final LeafBucketCollector sub ) throws IOException { globalOrds = valuesSource . globalOrdinalsValues ( ctx ) ; if ( acceptedGlobalOrdinals = = null & & includeExclude ! = null ) { acceptedGlobalOrdinals = includeExclude . acceptedGlobalOrdinals ( globalOrds , valuesSource ) ; } if ( acceptedGlobalOrdinals ! = null ) { globalOrds = new FilteredOrdinals ( globalOrds , acceptedGlobalOrdinals ) ; } return newCollector ( globalOrds , sub ) ; } protected LeafBucketCollector newCollector ( final RandomAccessOrds ords , final LeafBucketCollector sub ) { grow ( ords . getValueCount ( ) ) ; final SortedDocValues singleValues = DocValues . unwrapSingleton ( ords ) ; if ( singleValues ! = null ) { return new LeafBucketCollectorBase ( sub , ords ) { @Override public void collect ( int doc , long bucket ) throws IOException { assert bucket = = <int> ; final int ord = singleValues . getOrd ( doc ) ; if ( ord > = <int> ) { collectExistingBucket ( sub , doc , ord ) ; } } } ; } else { return new LeafBucketCollectorBase ( sub , ords ) { @Override public void collect ( int doc , long bucket ) throws IOException { assert bucket = = <int> ; ords . setDocument ( doc ) ; final int numOrds = ords . cardinality ( ) ; for ( int i = <int> ; i < numOrds ; i + + ) { final long globalOrd = ords . ordAt ( i ) ; collectExistingBucket ( sub , doc , globalOrd ) ; } } } ; } } protected static void copy ( BytesRef from , BytesRef to ) { if ( to . bytes . length < from . length ) { to . bytes = new byte [ ArrayUtil . oversize ( from . length , RamUsageEstimator . NUM_BYTES_BYTE ) ] ; } to . offset = <int> ; to . length = from . length ; System . arraycopy ( from . bytes , from . offset , to . bytes , <int> , from . length ) ; } @Override public InternalAggregation buildAggregation ( long owningBucketOrdinal ) throws IOException { if ( globalOrds = = null ) { return buildEmptyAggregation ( ) ; } final int size ; if ( bucketCountThresholds . getMinDocCount ( ) = = <int> ) { size = ( int ) Math . min ( globalOrds . getValueCount ( ) , bucketCountThresholds . getShardSize ( ) ) ; } else { size = ( int ) Math . min ( maxBucketOrd ( ) , bucketCountThresholds . getShardSize ( ) ) ; } long otherDocCount = <int> ; BucketPriorityQueue ordered = new BucketPriorityQueue ( size , order . comparator ( this ) ) ; OrdBucket spare = new OrdBucket ( - <int> , <int> , null , showTermDocCountError , <int> ) ; for ( long globalTermOrd = <int> ; globalTermOrd < globalOrds . getValueCount ( ) ; + + globalTermOrd ) { if ( includeExclude ! = null & & ! acceptedGlobalOrdinals . get ( globalTermOrd ) ) { continue ; } final long bucketOrd = getBucketOrd ( globalTermOrd ) ; final int bucketDocCount = bucketOrd < <int> ? <int> : bucketDocCount ( bucketOrd ) ; if ( bucketCountThresholds . getMinDocCount ( ) > <int> & & bucketDocCount = = <int> ) { continue ; } otherDocCount + = bucketDocCount ; spare . globalOrd = globalTermOrd ; spare . bucketOrd = bucketOrd ; spare . docCount = bucketDocCount ; if ( bucketCountThresholds . getShardMinDocCount ( ) < = spare . docCount ) { spare = ( OrdBucket ) ordered . insertWithOverflow ( spare ) ; if ( spare = = null ) { spare = new OrdBucket ( - <int> , <int> , null , showTermDocCountError , <int> ) ; } } } final InternalTerms . Bucket [ ] list = new InternalTerms . Bucket [ ordered . size ( ) ] ; long survivingBucketOrds [ ] = new long [ ordered . size ( ) ] ; for ( int i = ordered . size ( ) - <int> ; i > = <int> ; - - i ) { final OrdBucket bucket = ( OrdBucket ) ordered . pop ( ) ; survivingBucketOrds [ i ] = bucket . bucketOrd ; BytesRef scratch = new BytesRef ( ) ; copy ( globalOrds . lookupOrd ( bucket . globalOrd ) , scratch ) ; list [ i ] = new StringTerms . Bucket ( scratch , bucket . docCount , null , showTermDocCountError , <int> ) ; list [ i ] . bucketOrd = bucket . bucketOrd ; otherDocCount - = list [ i ] . docCount ; } runDeferredCollections ( survivingBucketOrds ) ; for ( int i = <int> ; i < list . length ; i + + ) { Bucket bucket = list [ i ] ; bucket . aggregations = bucket . docCount = = <int> ? bucketEmptyAggregations ( ) : bucketAggregations ( bucket . bucketOrd ) ; bucket . docCountError = <int> ; } return new StringTerms ( name , order , bucketCountThresholds . getRequiredSize ( ) , bucketCountThresholds . getShardSize ( ) , bucketCountThresholds . getMinDocCount ( ) , Arrays . asList ( list ) , showTermDocCountError , <int> , otherDocCount , pipelineAggregators ( ) , metaData ( ) ) ; } static class OrdBucket extends InternalTerms . Bucket { long globalOrd ; OrdBucket ( long globalOrd , long docCount , InternalAggregations aggregations , boolean showDocCountError , long docCountError ) { super ( docCount , aggregations , showDocCountError , docCountError , null ) ; this . globalOrd = globalOrd ; } @Override int compareTerm ( Terms . Bucket other ) { return Long . compare ( globalOrd , ( ( OrdBucket ) other ) . globalOrd ) ; } @Override public String getKeyAsString ( ) { throw new UnsupportedOperationException ( ) ; } @Override public Object getKey ( ) { throw new UnsupportedOperationException ( ) ; } @Override Bucket newBucket ( long docCount , InternalAggregations aggs , long docCountError ) { throw new UnsupportedOperationException ( ) ; } @Override public Number getKeyAsNumber ( ) { throw new UnsupportedOperationException ( ) ; } @Override public void readFrom ( StreamInput in ) throws IOException { throw new UnsupportedOperationException ( ) ; } @Override public void writeTo ( StreamOutput out ) throws IOException { throw new UnsupportedOperationException ( ) ; } @Override public XContentBuilder toXContent ( XContentBuilder builder , Params params ) throws IOException { throw new UnsupportedOperationException ( ) ; } } public static class WithHash extends GlobalOrdinalsStringTermsAggregator { private final LongHash bucketOrds ; public WithHash ( String name , AggregatorFactories factories , ValuesSource . Bytes . WithOrdinals . FieldData valuesSource , Terms . Order order , BucketCountThresholds bucketCountThresholds , IncludeExclude . OrdinalsFilter includeExclude , AggregationContext aggregationContext , Aggregator parent , SubAggCollectionMode collectionMode , boolean showTermDocCountError , List < PipelineAggregator > pipelineAggregators , Map < String , Object > metaData ) throws IOException { super ( name , factories , valuesSource , order , bucketCountThresholds , includeExclude , aggregationContext , parent , collectionMode , showTermDocCountError , pipelineAggregators , metaData ) ; bucketOrds = new LongHash ( <int> , aggregationContext . bigArrays ( ) ) ; } @Override protected LeafBucketCollector newCollector ( final RandomAccessOrds ords , final LeafBucketCollector sub ) { final SortedDocValues singleValues = DocValues . unwrapSingleton ( ords ) ; if ( singleValues ! = null ) { return new LeafBucketCollectorBase ( sub , ords ) { @Override public void collect ( int doc , long bucket ) throws IOException { final int globalOrd = singleValues . getOrd ( doc ) ; if ( globalOrd > = <int> ) { long bucketOrd = bucketOrds . add ( globalOrd ) ; if ( bucketOrd < <int> ) { bucketOrd = - <int> - bucketOrd ; collectExistingBucket ( sub , doc , bucketOrd ) ; } else { collectBucket ( sub , doc , bucketOrd ) ; } } } } ; } else { return new LeafBucketCollectorBase ( sub , ords ) { @Override public void collect ( int doc , long bucket ) throws IOException { ords . setDocument ( doc ) ; final int numOrds = ords . cardinality ( ) ; for ( int i = <int> ; i < numOrds ; i + + ) { final long globalOrd = ords . ordAt ( i ) ; long bucketOrd = bucketOrds . add ( globalOrd ) ; if ( bucketOrd < <int> ) { bucketOrd = - <int> - bucketOrd ; collectExistingBucket ( sub , doc , bucketOrd ) ; } else { collectBucket ( sub , doc , bucketOrd ) ; } } } } ; } } @Override protected long getBucketOrd ( long termOrd ) { return bucketOrds . find ( termOrd ) ; } @Override protected void doClose ( ) { Releasables . close ( bucketOrds ) ; } } public static class LowCardinality extends GlobalOrdinalsStringTermsAggregator { private IntArray segmentDocCounts ; private RandomAccessOrds segmentOrds ; public LowCardinality ( String name , AggregatorFactories factories , ValuesSource . Bytes . WithOrdinals valuesSource , Terms . Order order , BucketCountThresholds bucketCountThresholds , AggregationContext aggregationContext , Aggregator parent , SubAggCollectionMode collectionMode , boolean showTermDocCountError , List < PipelineAggregator > pipelineAggregators , Map < String , Object > metaData ) throws IOException { super ( name , factories , valuesSource , order , bucketCountThresholds , null , aggregationContext , parent , collectionMode , showTermDocCountError , pipelineAggregators , metaData ) ; assert factories = = null | | factories . count ( ) = = <int> ; this . segmentDocCounts = context . bigArrays ( ) . newIntArray ( <int> , true ) ; } @Override protected LeafBucketCollector newCollector ( final RandomAccessOrds ords , LeafBucketCollector sub ) { segmentDocCounts = context . bigArrays ( ) . grow ( segmentDocCounts , <int> + ords . getValueCount ( ) ) ; assert sub = = LeafBucketCollector . NO_OP_COLLECTOR ; final SortedDocValues singleValues = DocValues . unwrapSingleton ( ords ) ; if ( singleValues ! = null ) { return new LeafBucketCollectorBase ( sub , ords ) { @Override public void collect ( int doc , long bucket ) throws IOException { assert bucket = = <int> ; final int ord = singleValues . getOrd ( doc ) ; segmentDocCounts . increment ( ord + <int> , <int> ) ; } } ; } else { return new LeafBucketCollectorBase ( sub , ords ) { @Override public void collect ( int doc , long bucket ) throws IOException { assert bucket = = <int> ; ords . setDocument ( doc ) ; final int numOrds = ords . cardinality ( ) ; for ( int i = <int> ; i < numOrds ; i + + ) { final long segmentOrd = ords . ordAt ( i ) ; segmentDocCounts . increment ( segmentOrd + <int> , <int> ) ; } } } ; } } @Override public LeafBucketCollector getLeafCollector ( LeafReaderContext ctx , final LeafBucketCollector sub ) throws IOException { if ( segmentOrds ! = null ) { mapSegmentCountsToGlobalCounts ( ) ; } globalOrds = valuesSource . globalOrdinalsValues ( ctx ) ; segmentOrds = valuesSource . ordinalsValues ( ctx ) ; return newCollector ( segmentOrds , sub ) ; } @Override protected void doPostCollection ( ) { if ( segmentOrds ! = null ) { mapSegmentCountsToGlobalCounts ( ) ; } } @Override protected void doClose ( ) { Releasables . close ( segmentDocCounts ) ; } private void mapSegmentCountsToGlobalCounts ( ) { GlobalOrdinalMapping mapping ; if ( globalOrds instanceof GlobalOrdinalMapping ) { mapping = ( GlobalOrdinalMapping ) globalOrds ; } else { assert globalOrds . getValueCount ( ) = = segmentOrds . getValueCount ( ) ; mapping = null ; } for ( long i = <int> ; i < segmentDocCounts . size ( ) ; i + + ) { final int inc = segmentDocCounts . set ( i , <int> ) ; if ( inc = = <int> ) { continue ; } final long ord = i - <int> ; final long globalOrd = mapping = = null ? ord : mapping . getGlobalOrd ( ord ) ; incrementBucketDocCount ( globalOrd , inc ) ; } } } private static final class FilteredOrdinals extends AbstractRandomAccessOrds { private final RandomAccessOrds inner ; private final LongBitSet accepted ; private int cardinality ; private long [ ] ords = new long [ <int> ] ; private FilteredOrdinals ( RandomAccessOrds inner , LongBitSet accepted ) { this . inner = inner ; this . accepted = accepted ; } @Override public long getValueCount ( ) { return inner . getValueCount ( ) ; } @Override public long ordAt ( int index ) { return ords [ index ] ; } @Override public void doSetDocument ( int docId ) { inner . setDocument ( docId ) ; final int innerCardinality = inner . cardinality ( ) ; ords = ArrayUtil . grow ( ords , innerCardinality ) ; cardinality = <int> ; for ( int slot = <int> ; slot < innerCardinality ; slot + + ) { long ord = inner . ordAt ( slot ) ; if ( accepted . get ( ord ) ) { ords [ cardinality + + ] = ord ; } } } @Override public int cardinality ( ) { return cardinality ; } @Override public BytesRef lookupOrd ( long ord ) { return inner . lookupOrd ( ord ) ; } } } 
