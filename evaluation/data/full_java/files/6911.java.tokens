package org . elasticsearch . percolator ; import org . apache . lucene . analysis . Analyzer ; import org . apache . lucene . analysis . TokenStream ; import org . apache . lucene . index . * ; import org . apache . lucene . index . memory . MemoryIndex ; import org . apache . lucene . search . IndexSearcher ; import org . apache . lucene . util . CloseableThreadLocal ; import org . elasticsearch . ElasticsearchException ; import org . elasticsearch . index . engine . Engine ; import org . elasticsearch . index . mapper . ParseContext ; import org . elasticsearch . index . mapper . ParsedDocument ; import org . elasticsearch . index . mapper . internal . UidFieldMapper ; import java . io . IOException ; import java . util . List ; class MultiDocumentPercolatorIndex implements PercolatorIndex { private final CloseableThreadLocal < MemoryIndex > cache ; MultiDocumentPercolatorIndex ( CloseableThreadLocal < MemoryIndex > cache ) { this . cache = cache ; } @Override public void prepare ( PercolateContext context , ParsedDocument parsedDocument ) { IndexReader [ ] memoryIndices = new IndexReader [ parsedDocument . docs ( ) . size ( ) ] ; List < ParseContext . Document > docs = parsedDocument . docs ( ) ; int rootDocIndex = docs . size ( ) - <int> ; assert rootDocIndex > <int> ; MemoryIndex rootDocMemoryIndex = null ; for ( int i = <int> ; i < docs . size ( ) ; i + + ) { ParseContext . Document d = docs . get ( i ) ; MemoryIndex memoryIndex ; if ( rootDocIndex = = i ) { memoryIndex = rootDocMemoryIndex = cache . get ( ) ; } else { memoryIndex = new MemoryIndex ( true ) ; } Analyzer analyzer = context . mapperService ( ) . documentMapper ( parsedDocument . type ( ) ) . mappers ( ) . indexAnalyzer ( ) ; memoryIndices [ i ] = indexDoc ( d , analyzer , memoryIndex ) . createSearcher ( ) . getIndexReader ( ) ; } try { MultiReader mReader = new MultiReader ( memoryIndices , true ) ; LeafReader slowReader = SlowCompositeReaderWrapper . wrap ( mReader ) ; final IndexSearcher slowSearcher = new IndexSearcher ( slowReader ) ; slowSearcher . setQueryCache ( null ) ; DocSearcher docSearcher = new DocSearcher ( slowSearcher , rootDocMemoryIndex ) ; context . initialize ( docSearcher , parsedDocument ) ; } catch ( IOException e ) { throw new ElasticsearchException ( <str> , e ) ; } } MemoryIndex indexDoc ( ParseContext . Document d , Analyzer analyzer , MemoryIndex memoryIndex ) { for ( IndexableField field : d . getFields ( ) ) { if ( field . fieldType ( ) . indexOptions ( ) = = IndexOptions . NONE & & field . name ( ) . equals ( UidFieldMapper . NAME ) ) { continue ; } try { try ( TokenStream tokenStream = field . tokenStream ( analyzer , null ) ) { if ( tokenStream ! = null ) { memoryIndex . addField ( field . name ( ) , tokenStream , field . boost ( ) ) ; } } } catch ( IOException e ) { throw new ElasticsearchException ( <str> , e ) ; } } return memoryIndex ; } private class DocSearcher extends Engine . Searcher { private final MemoryIndex rootDocMemoryIndex ; private DocSearcher ( IndexSearcher searcher , MemoryIndex rootDocMemoryIndex ) { super ( <str> , searcher ) ; this . rootDocMemoryIndex = rootDocMemoryIndex ; } @Override public void close ( ) { try { this . reader ( ) . close ( ) ; rootDocMemoryIndex . reset ( ) ; } catch ( IOException e ) { throw new ElasticsearchException ( <str> , e ) ; } } } } 
