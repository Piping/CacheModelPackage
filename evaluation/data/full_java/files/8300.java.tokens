package org . elasticsearch . index . snapshots . blobstore ; import org . apache . lucene . util . BytesRef ; import org . apache . lucene . util . Version ; import org . elasticsearch . ElasticsearchParseException ; import org . elasticsearch . common . unit . ByteSizeValue ; import org . elasticsearch . common . xcontent . ToXContent ; import org . elasticsearch . common . xcontent . XContentBuilder ; import org . elasticsearch . common . xcontent . XContentFactory ; import org . elasticsearch . common . xcontent . XContentParser ; import org . elasticsearch . common . xcontent . XContentType ; import org . elasticsearch . index . snapshots . blobstore . BlobStoreIndexShardSnapshot . FileInfo . Fields ; import org . elasticsearch . index . store . StoreFileMetaData ; import org . elasticsearch . test . ESTestCase ; import java . io . IOException ; import static org . hamcrest . Matchers . containsString ; import static org . hamcrest . Matchers . equalTo ; import static org . hamcrest . Matchers . is ; public class FileInfoTests extends ESTestCase { public void testToFromXContent ( ) throws IOException { final int iters = scaledRandomIntBetween ( <int> , <int> ) ; for ( int iter = <int> ; iter < iters ; iter + + ) { final BytesRef hash = new BytesRef ( scaledRandomIntBetween ( <int> , <int> * <int> ) ) ; hash . length = hash . bytes . length ; for ( int i = <int> ; i < hash . length ; i + + ) { hash . bytes [ i ] = randomByte ( ) ; } StoreFileMetaData meta = new StoreFileMetaData ( <str> , Math . abs ( randomLong ( ) ) , randomAsciiOfLengthBetween ( <int> , <int> ) , Version . LATEST , hash ) ; ByteSizeValue size = new ByteSizeValue ( Math . abs ( randomLong ( ) ) ) ; BlobStoreIndexShardSnapshot . FileInfo info = new BlobStoreIndexShardSnapshot . FileInfo ( <str> , meta , size ) ; XContentBuilder builder = XContentFactory . contentBuilder ( XContentType . JSON ) . prettyPrint ( ) ; BlobStoreIndexShardSnapshot . FileInfo . toXContent ( info , builder , ToXContent . EMPTY_PARAMS ) ; byte [ ] xcontent = builder . bytes ( ) . toBytes ( ) ; final BlobStoreIndexShardSnapshot . FileInfo parsedInfo ; try ( XContentParser parser = XContentFactory . xContent ( XContentType . JSON ) . createParser ( xcontent ) ) { parser . nextToken ( ) ; parsedInfo = BlobStoreIndexShardSnapshot . FileInfo . fromXContent ( parser ) ; } assertThat ( info . name ( ) , equalTo ( parsedInfo . name ( ) ) ) ; assertThat ( info . physicalName ( ) , equalTo ( parsedInfo . physicalName ( ) ) ) ; assertThat ( info . length ( ) , equalTo ( parsedInfo . length ( ) ) ) ; assertThat ( info . checksum ( ) , equalTo ( parsedInfo . checksum ( ) ) ) ; assertThat ( info . partSize ( ) , equalTo ( parsedInfo . partSize ( ) ) ) ; assertThat ( parsedInfo . metadata ( ) . hash ( ) . length , equalTo ( hash . length ) ) ; assertThat ( parsedInfo . metadata ( ) . hash ( ) , equalTo ( hash ) ) ; assertThat ( parsedInfo . metadata ( ) . writtenBy ( ) , equalTo ( Version . LATEST ) ) ; assertThat ( parsedInfo . isSame ( info . metadata ( ) ) , is ( true ) ) ; } } public void testInvalidFieldsInFromXContent ( ) throws IOException { final int iters = scaledRandomIntBetween ( <int> , <int> ) ; for ( int iter = <int> ; iter < iters ; iter + + ) { final BytesRef hash = new BytesRef ( scaledRandomIntBetween ( <int> , <int> * <int> ) ) ; hash . length = hash . bytes . length ; for ( int i = <int> ; i < hash . length ; i + + ) { hash . bytes [ i ] = randomByte ( ) ; } String name = <str> ; String physicalName = <str> ; String failure = null ; long length = Math . max ( <int> , Math . abs ( randomLong ( ) ) ) ; switch ( randomIntBetween ( <int> , <int> ) ) { case <int> : name = <str> ; failure = <str> ; break ; case <int> : physicalName = <str> ; failure = <str> ; break ; case <int> : length = - Math . abs ( randomLong ( ) ) ; failure = <str> ; break ; case <int> : break ; default : fail ( <str> ) ; } XContentBuilder builder = XContentFactory . contentBuilder ( XContentType . JSON ) ; builder . startObject ( ) ; builder . field ( Fields . NAME , name ) ; builder . field ( Fields . PHYSICAL_NAME , physicalName ) ; builder . field ( Fields . LENGTH , length ) ; builder . endObject ( ) ; byte [ ] xContent = builder . bytes ( ) . toBytes ( ) ; if ( failure = = null ) { final BlobStoreIndexShardSnapshot . FileInfo parsedInfo ; try ( XContentParser parser = XContentFactory . xContent ( XContentType . JSON ) . createParser ( xContent ) ) { parser . nextToken ( ) ; parsedInfo = BlobStoreIndexShardSnapshot . FileInfo . fromXContent ( parser ) ; } assertThat ( name , equalTo ( parsedInfo . name ( ) ) ) ; assertThat ( physicalName , equalTo ( parsedInfo . physicalName ( ) ) ) ; assertThat ( length , equalTo ( parsedInfo . length ( ) ) ) ; assertNull ( parsedInfo . checksum ( ) ) ; assertNull ( parsedInfo . metadata ( ) . checksum ( ) ) ; assertNull ( parsedInfo . metadata ( ) . writtenBy ( ) ) ; } else { try ( XContentParser parser = XContentFactory . xContent ( XContentType . JSON ) . createParser ( xContent ) ) { parser . nextToken ( ) ; BlobStoreIndexShardSnapshot . FileInfo . fromXContent ( parser ) ; fail ( <str> + failure + <str> ) ; } catch ( ElasticsearchParseException ex ) { assertThat ( ex . getMessage ( ) , containsString ( failure ) ) ; } } } } public void testGetPartSize ( ) { BlobStoreIndexShardSnapshot . FileInfo info = new BlobStoreIndexShardSnapshot . FileInfo ( <str> , new StoreFileMetaData ( <str> , <int> ) , new ByteSizeValue ( <int> ) ) ; int numBytes = <int> ; for ( int i = <int> ; i < info . numberOfParts ( ) ; i + + ) { numBytes + = info . partBytes ( i ) ; } assertEquals ( numBytes , <int> ) ; info = new BlobStoreIndexShardSnapshot . FileInfo ( <str> , new StoreFileMetaData ( <str> , <int> ) , new ByteSizeValue ( <int> ) ) ; numBytes = <int> ; for ( int i = <int> ; i < info . numberOfParts ( ) ; i + + ) { numBytes + = info . partBytes ( i ) ; } assertEquals ( numBytes , <int> ) ; final int numIters = randomIntBetween ( <int> , <int> ) ; for ( int j = <int> ; j < numIters ; j + + ) { StoreFileMetaData metaData = new StoreFileMetaData ( <str> , randomIntBetween ( <int> , <int> ) ) ; info = new BlobStoreIndexShardSnapshot . FileInfo ( <str> , metaData , new ByteSizeValue ( randomIntBetween ( <int> , <int> ) ) ) ; numBytes = <int> ; for ( int i = <int> ; i < info . numberOfParts ( ) ; i + + ) { numBytes + = info . partBytes ( i ) ; } assertEquals ( numBytes , metaData . length ( ) ) ; } } } 
