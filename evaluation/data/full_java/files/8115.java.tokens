package org . elasticsearch . index . fielddata ; import com . carrotsearch . randomizedtesting . generators . RandomPicks ; import org . apache . lucene . document . Document ; import org . apache . lucene . document . Field ; import org . apache . lucene . document . Field . Store ; import org . apache . lucene . document . SortedSetDocValuesField ; import org . apache . lucene . document . StringField ; import org . apache . lucene . index . DirectoryReader ; import org . apache . lucene . index . LeafReaderContext ; import org . apache . lucene . index . RandomAccessOrds ; import org . apache . lucene . index . Term ; import org . apache . lucene . index . TermsEnum ; import org . apache . lucene . search . ConstantScoreQuery ; import org . apache . lucene . search . IndexSearcher ; import org . apache . lucene . search . MatchAllDocsQuery ; import org . apache . lucene . search . Query ; import org . apache . lucene . search . Sort ; import org . apache . lucene . search . SortField ; import org . apache . lucene . search . TermQuery ; import org . apache . lucene . search . TopFieldDocs ; import org . apache . lucene . search . join . QueryBitSetProducer ; import org . apache . lucene . search . join . ScoreMode ; import org . apache . lucene . search . join . ToParentBlockJoinQuery ; import org . apache . lucene . util . Accountable ; import org . apache . lucene . util . BytesRef ; import org . apache . lucene . util . FixedBitSet ; import org . apache . lucene . util . TestUtil ; import org . apache . lucene . util . UnicodeUtil ; import org . elasticsearch . common . lucene . search . Queries ; import org . elasticsearch . common . settings . Settings ; import org . elasticsearch . index . fielddata . IndexFieldData . XFieldComparatorSource ; import org . elasticsearch . index . fielddata . IndexFieldData . XFieldComparatorSource . Nested ; import org . elasticsearch . index . fielddata . fieldcomparator . BytesRefFieldComparatorSource ; import org . elasticsearch . index . fielddata . ordinals . GlobalOrdinalsIndexFieldData ; import org . elasticsearch . search . MultiValueMode ; import java . io . IOException ; import java . util . ArrayList ; import java . util . List ; import static org . hamcrest . Matchers . equalTo ; import static org . hamcrest . Matchers . instanceOf ; import static org . hamcrest . Matchers . is ; import static org . hamcrest . Matchers . not ; import static org . hamcrest . Matchers . nullValue ; import static org . hamcrest . Matchers . sameInstance ; public abstract class AbstractStringFieldDataTestCase extends AbstractFieldDataImplTestCase { private void addField ( Document d , String name , String value ) { d . add ( new StringField ( name , value , Field . Store . YES ) ) ; d . add ( new SortedSetDocValuesField ( name , new BytesRef ( value ) ) ) ; } @Override protected void fillSingleValueAllSet ( ) throws Exception { Document d = new Document ( ) ; addField ( d , <str> , <str> ) ; addField ( d , <str> , <str> ) ; writer . addDocument ( d ) ; d = new Document ( ) ; addField ( d , <str> , <str> ) ; addField ( d , <str> , <str> ) ; writer . addDocument ( d ) ; d = new Document ( ) ; addField ( d , <str> , <str> ) ; addField ( d , <str> , <str> ) ; writer . addDocument ( d ) ; } @Override protected void add2SingleValuedDocumentsAndDeleteOneOfThem ( ) throws Exception { Document d = new Document ( ) ; addField ( d , <str> , <str> ) ; addField ( d , <str> , <str> ) ; writer . addDocument ( d ) ; d = new Document ( ) ; addField ( d , <str> , <str> ) ; addField ( d , <str> , <str> ) ; writer . addDocument ( d ) ; writer . commit ( ) ; writer . deleteDocuments ( new Term ( <str> , <str> ) ) ; } @Override protected void fillSingleValueWithMissing ( ) throws Exception { Document d = new Document ( ) ; addField ( d , <str> , <str> ) ; addField ( d , <str> , <str> ) ; writer . addDocument ( d ) ; d = new Document ( ) ; addField ( d , <str> , <str> ) ; writer . addDocument ( d ) ; d = new Document ( ) ; addField ( d , <str> , <str> ) ; addField ( d , <str> , <str> ) ; writer . addDocument ( d ) ; } @Override protected void fillMultiValueAllSet ( ) throws Exception { Document d = new Document ( ) ; addField ( d , <str> , <str> ) ; addField ( d , <str> , <str> ) ; addField ( d , <str> , <str> ) ; writer . addDocument ( d ) ; d = new Document ( ) ; addField ( d , <str> , <str> ) ; addField ( d , <str> , <str> ) ; writer . addDocument ( d ) ; writer . commit ( ) ; d = new Document ( ) ; addField ( d , <str> , <str> ) ; addField ( d , <str> , <str> ) ; writer . addDocument ( d ) ; } @Override protected void fillMultiValueWithMissing ( ) throws Exception { Document d = new Document ( ) ; addField ( d , <str> , <str> ) ; addField ( d , <str> , <str> ) ; addField ( d , <str> , <str> ) ; writer . addDocument ( d ) ; d = new Document ( ) ; addField ( d , <str> , <str> ) ; writer . addDocument ( d ) ; d = new Document ( ) ; addField ( d , <str> , <str> ) ; addField ( d , <str> , <str> ) ; writer . addDocument ( d ) ; } @Override protected void fillAllMissing ( ) throws Exception { Document d = new Document ( ) ; addField ( d , <str> , <str> ) ; writer . addDocument ( d ) ; d = new Document ( ) ; addField ( d , <str> , <str> ) ; writer . addDocument ( d ) ; d = new Document ( ) ; addField ( d , <str> , <str> ) ; writer . addDocument ( d ) ; } @Override protected void fillExtendedMvSet ( ) throws Exception { Document d = new Document ( ) ; addField ( d , <str> , <str> ) ; addField ( d , <str> , <str> ) ; addField ( d , <str> , <str> ) ; writer . addDocument ( d ) ; d = new Document ( ) ; addField ( d , <str> , <str> ) ; writer . addDocument ( d ) ; d = new Document ( ) ; addField ( d , <str> , <str> ) ; addField ( d , <str> , <str> ) ; writer . addDocument ( d ) ; writer . commit ( ) ; d = new Document ( ) ; addField ( d , <str> , <str> ) ; addField ( d , <str> , <str> ) ; addField ( d , <str> , <str> ) ; addField ( d , <str> , <str> ) ; writer . addDocument ( d ) ; d = new Document ( ) ; addField ( d , <str> , <str> ) ; addField ( d , <str> , <str> ) ; addField ( d , <str> , <str> ) ; addField ( d , <str> , <str> ) ; writer . addDocument ( d ) ; d = new Document ( ) ; d . add ( new StringField ( <str> , <str> , Field . Store . NO ) ) ; writer . addDocument ( d ) ; d = new Document ( ) ; addField ( d , <str> , <str> ) ; addField ( d , <str> , <str> ) ; addField ( d , <str> , <str> ) ; addField ( d , <str> , <str> ) ; writer . addDocument ( d ) ; writer . commit ( ) ; d = new Document ( ) ; addField ( d , <str> , <str> ) ; addField ( d , <str> , <str> ) ; addField ( d , <str> , <str> ) ; addField ( d , <str> , <str> ) ; writer . addDocument ( d ) ; } public void testActualMissingValue ( ) throws IOException { testActualMissingValue ( false ) ; } public void testActualMissingValueReverse ( ) throws IOException { testActualMissingValue ( true ) ; } public void testActualMissingValue ( boolean reverse ) throws IOException { final String [ ] values = new String [ randomIntBetween ( <int> , <int> ) ] ; for ( int i = <int> ; i < values . length ; + + i ) { values [ i ] = TestUtil . randomUnicodeString ( getRandom ( ) ) ; } final int numDocs = scaledRandomIntBetween ( <int> , <int> ) ; for ( int i = <int> ; i < numDocs ; + + i ) { final String value = RandomPicks . randomFrom ( getRandom ( ) , values ) ; if ( value = = null ) { writer . addDocument ( new Document ( ) ) ; } else { Document d = new Document ( ) ; addField ( d , <str> , value ) ; writer . addDocument ( d ) ; } if ( randomInt ( <int> ) = = <int> ) { writer . commit ( ) ; } } final IndexFieldData indexFieldData = getForField ( <str> ) ; final String missingValue = values [ <int> ] ; IndexSearcher searcher = new IndexSearcher ( DirectoryReader . open ( writer , true ) ) ; XFieldComparatorSource comparator = indexFieldData . comparatorSource ( missingValue , MultiValueMode . MIN , null ) ; TopFieldDocs topDocs = searcher . search ( new MatchAllDocsQuery ( ) , randomBoolean ( ) ? numDocs : randomIntBetween ( <int> , numDocs ) , new Sort ( new SortField ( <str> , comparator , reverse ) ) ) ; assertEquals ( numDocs , topDocs . totalHits ) ; BytesRef previousValue = reverse ? UnicodeUtil . BIG_TERM : new BytesRef ( ) ; for ( int i = <int> ; i < topDocs . scoreDocs . length ; + + i ) { final String docValue = searcher . doc ( topDocs . scoreDocs [ i ] . doc ) . get ( <str> ) ; final BytesRef value = new BytesRef ( docValue = = null ? missingValue : docValue ) ; if ( reverse ) { assertTrue ( previousValue . compareTo ( value ) > = <int> ) ; } else { assertTrue ( previousValue . compareTo ( value ) < = <int> ) ; } previousValue = value ; } searcher . getIndexReader ( ) . close ( ) ; } public void testSortMissingFirst ( ) throws IOException { testSortMissing ( true , false ) ; } public void testSortMissingFirstReverse ( ) throws IOException { testSortMissing ( true , true ) ; } public void testSortMissingLast ( ) throws IOException { testSortMissing ( false , false ) ; } public void testSortMissingLastReverse ( ) throws IOException { testSortMissing ( false , true ) ; } public void testSortMissing ( boolean first , boolean reverse ) throws IOException { final String [ ] values = new String [ randomIntBetween ( <int> , <int> ) ] ; for ( int i = <int> ; i < values . length ; + + i ) { values [ i ] = TestUtil . randomUnicodeString ( getRandom ( ) ) ; } final int numDocs = scaledRandomIntBetween ( <int> , <int> ) ; for ( int i = <int> ; i < numDocs ; + + i ) { final String value = RandomPicks . randomFrom ( getRandom ( ) , values ) ; if ( value = = null ) { writer . addDocument ( new Document ( ) ) ; } else { Document d = new Document ( ) ; addField ( d , <str> , value ) ; writer . addDocument ( d ) ; } if ( randomInt ( <int> ) = = <int> ) { writer . commit ( ) ; } } final IndexFieldData indexFieldData = getForField ( <str> ) ; IndexSearcher searcher = new IndexSearcher ( DirectoryReader . open ( writer , true ) ) ; XFieldComparatorSource comparator = indexFieldData . comparatorSource ( first ? <str> : <str> , MultiValueMode . MIN , null ) ; TopFieldDocs topDocs = searcher . search ( new MatchAllDocsQuery ( ) , randomBoolean ( ) ? numDocs : randomIntBetween ( <int> , numDocs ) , new Sort ( new SortField ( <str> , comparator , reverse ) ) ) ; assertEquals ( numDocs , topDocs . totalHits ) ; BytesRef previousValue = first ? null : reverse ? UnicodeUtil . BIG_TERM : new BytesRef ( ) ; for ( int i = <int> ; i < topDocs . scoreDocs . length ; + + i ) { final String docValue = searcher . doc ( topDocs . scoreDocs [ i ] . doc ) . get ( <str> ) ; if ( first & & docValue = = null ) { assertNull ( previousValue ) ; } else if ( ! first & & docValue ! = null ) { assertNotNull ( previousValue ) ; } final BytesRef value = docValue = = null ? null : new BytesRef ( docValue ) ; if ( previousValue ! = null & & value ! = null ) { if ( reverse ) { assertTrue ( previousValue . compareTo ( value ) > = <int> ) ; } else { assertTrue ( previousValue . compareTo ( value ) < = <int> ) ; } } previousValue = value ; } searcher . getIndexReader ( ) . close ( ) ; } public void testNestedSortingMin ( ) throws IOException { testNestedSorting ( MultiValueMode . MIN ) ; } public void testNestedSortingMax ( ) throws IOException { testNestedSorting ( MultiValueMode . MAX ) ; } public void testNestedSorting ( MultiValueMode sortMode ) throws IOException { final String [ ] values = new String [ randomIntBetween ( <int> , <int> ) ] ; for ( int i = <int> ; i < values . length ; + + i ) { values [ i ] = TestUtil . randomSimpleString ( getRandom ( ) ) ; } final int numParents = scaledRandomIntBetween ( <int> , <int> ) ; List < Document > docs = new ArrayList < > ( ) ; FixedBitSet parents = new FixedBitSet ( <int> ) ; for ( int i = <int> ; i < numParents ; + + i ) { docs . clear ( ) ; final int numChildren = randomInt ( <int> ) ; for ( int j = <int> ; j < numChildren ; + + j ) { final Document child = new Document ( ) ; final int numValues = randomInt ( <int> ) ; for ( int k = <int> ; k < numValues ; + + k ) { final String value = RandomPicks . randomFrom ( getRandom ( ) , values ) ; addField ( child , <str> , value ) ; } docs . add ( child ) ; } final Document parent = new Document ( ) ; parent . add ( new StringField ( <str> , <str> , Store . YES ) ) ; final String value = RandomPicks . randomFrom ( getRandom ( ) , values ) ; if ( value ! = null ) { addField ( parent , <str> , value ) ; } docs . add ( parent ) ; int bit = parents . prevSetBit ( parents . length ( ) - <int> ) + docs . size ( ) ; parents = FixedBitSet . ensureCapacity ( parents , bit ) ; parents . set ( bit ) ; writer . addDocuments ( docs ) ; if ( randomInt ( <int> ) = = <int> ) { writer . commit ( ) ; } } IndexSearcher searcher = new IndexSearcher ( DirectoryReader . open ( writer , true ) ) ; IndexFieldData < ? > fieldData = getForField ( <str> ) ; final Object missingValue ; switch ( randomInt ( <int> ) ) { case <int> : missingValue = <str> ; break ; case <int> : missingValue = <str> ; break ; case <int> : missingValue = new BytesRef ( RandomPicks . randomFrom ( getRandom ( ) , values ) ) ; break ; default : missingValue = new BytesRef ( TestUtil . randomSimpleString ( getRandom ( ) ) ) ; break ; } Query parentFilter = new TermQuery ( new Term ( <str> , <str> ) ) ; Query childFilter = Queries . not ( parentFilter ) ; Nested nested = createNested ( searcher , parentFilter , childFilter ) ; BytesRefFieldComparatorSource nestedComparatorSource = new BytesRefFieldComparatorSource ( fieldData , missingValue , sortMode , nested ) ; ToParentBlockJoinQuery query = new ToParentBlockJoinQuery ( new ConstantScoreQuery ( childFilter ) , new QueryBitSetProducer ( parentFilter ) , ScoreMode . None ) ; Sort sort = new Sort ( new SortField ( <str> , nestedComparatorSource ) ) ; TopFieldDocs topDocs = searcher . search ( query , randomIntBetween ( <int> , numParents ) , sort ) ; assertTrue ( topDocs . scoreDocs . length > <int> ) ; BytesRef previous = null ; for ( int i = <int> ; i < topDocs . scoreDocs . length ; + + i ) { final int docID = topDocs . scoreDocs [ i ] . doc ; assertTrue ( <str> + docID + <str> , parents . get ( docID ) ) ; BytesRef cmpValue = null ; for ( int child = parents . prevSetBit ( docID - <int> ) + <int> ; child < docID ; + + child ) { String [ ] sVals = searcher . doc ( child ) . getValues ( <str> ) ; final BytesRef [ ] vals ; if ( sVals . length = = <int> ) { vals = new BytesRef [ <int> ] ; } else { vals = new BytesRef [ sVals . length ] ; for ( int j = <int> ; j < vals . length ; + + j ) { vals [ j ] = new BytesRef ( sVals [ j ] ) ; } } for ( BytesRef value : vals ) { if ( cmpValue = = null ) { cmpValue = value ; } else if ( sortMode = = MultiValueMode . MIN & & value . compareTo ( cmpValue ) < <int> ) { cmpValue = value ; } else if ( sortMode = = MultiValueMode . MAX & & value . compareTo ( cmpValue ) > <int> ) { cmpValue = value ; } } } if ( cmpValue = = null ) { if ( <str> . equals ( missingValue ) ) { cmpValue = new BytesRef ( ) ; } else if ( <str> . equals ( missingValue ) = = false ) { cmpValue = ( BytesRef ) missingValue ; } } if ( previous ! = null & & cmpValue ! = null ) { assertTrue ( previous . utf8ToString ( ) + <str> + cmpValue . utf8ToString ( ) , previous . compareTo ( cmpValue ) < = <int> ) ; } previous = cmpValue ; } searcher . getIndexReader ( ) . close ( ) ; } private void assertIteratorConsistentWithRandomAccess ( RandomAccessOrds ords , int maxDoc ) { for ( int doc = <int> ; doc < maxDoc ; + + doc ) { ords . setDocument ( doc ) ; final int cardinality = ords . cardinality ( ) ; for ( int i = <int> ; i < cardinality ; + + i ) { assertEquals ( ords . nextOrd ( ) , ords . ordAt ( i ) ) ; } for ( int i = <int> ; i < <int> ; + + i ) { assertEquals ( ords . nextOrd ( ) , - <int> ) ; } } } public void testGlobalOrdinals ( ) throws Exception { fillExtendedMvSet ( ) ; refreshReader ( ) ; FieldDataType fieldDataType = new FieldDataType ( <str> , Settings . builder ( ) . put ( <str> , <str> ) ) ; IndexOrdinalsFieldData ifd = getForField ( fieldDataType , <str> , hasDocValues ( ) ) ; IndexOrdinalsFieldData globalOrdinals = ifd . loadGlobal ( topLevelReader ) ; assertThat ( topLevelReader . leaves ( ) . size ( ) , equalTo ( <int> ) ) ; assertThat ( globalOrdinals , instanceOf ( GlobalOrdinalsIndexFieldData . class ) ) ; LeafReaderContext leaf = topLevelReader . leaves ( ) . get ( <int> ) ; AtomicOrdinalsFieldData afd = globalOrdinals . load ( leaf ) ; RandomAccessOrds values = afd . getOrdinalsValues ( ) ; assertIteratorConsistentWithRandomAccess ( values , leaf . reader ( ) . maxDoc ( ) ) ; values . setDocument ( <int> ) ; assertThat ( values . cardinality ( ) , equalTo ( <int> ) ) ; long ord = values . nextOrd ( ) ; assertThat ( ord , equalTo ( <int> ) ) ; assertThat ( values . lookupOrd ( ord ) . utf8ToString ( ) , equalTo ( <str> ) ) ; ord = values . nextOrd ( ) ; assertThat ( ord , equalTo ( <int> ) ) ; assertThat ( values . lookupOrd ( ord ) . utf8ToString ( ) , equalTo ( <str> ) ) ; values . setDocument ( <int> ) ; assertThat ( values . cardinality ( ) , equalTo ( <int> ) ) ; values . setDocument ( <int> ) ; assertThat ( values . cardinality ( ) , equalTo ( <int> ) ) ; ord = values . nextOrd ( ) ; assertThat ( ord , equalTo ( <int> ) ) ; assertThat ( values . lookupOrd ( ord ) . utf8ToString ( ) , equalTo ( <str> ) ) ; leaf = topLevelReader . leaves ( ) . get ( <int> ) ; afd = globalOrdinals . load ( leaf ) ; values = afd . getOrdinalsValues ( ) ; assertIteratorConsistentWithRandomAccess ( values , leaf . reader ( ) . maxDoc ( ) ) ; values . setDocument ( <int> ) ; assertThat ( values . cardinality ( ) , equalTo ( <int> ) ) ; ord = values . nextOrd ( ) ; assertThat ( ord , equalTo ( <int> ) ) ; assertThat ( values . lookupOrd ( ord ) . utf8ToString ( ) , equalTo ( <str> ) ) ; ord = values . nextOrd ( ) ; assertThat ( ord , equalTo ( <int> ) ) ; assertThat ( values . lookupOrd ( ord ) . utf8ToString ( ) , equalTo ( <str> ) ) ; ord = values . nextOrd ( ) ; assertThat ( ord , equalTo ( <int> ) ) ; assertThat ( values . lookupOrd ( ord ) . utf8ToString ( ) , equalTo ( <str> ) ) ; values . setDocument ( <int> ) ; assertThat ( values . cardinality ( ) , equalTo ( <int> ) ) ; ord = values . nextOrd ( ) ; assertThat ( ord , equalTo ( <int> ) ) ; assertThat ( values . lookupOrd ( ord ) . utf8ToString ( ) , equalTo ( <str> ) ) ; ord = values . nextOrd ( ) ; assertThat ( ord , equalTo ( <int> ) ) ; assertThat ( values . lookupOrd ( ord ) . utf8ToString ( ) , equalTo ( <str> ) ) ; ord = values . nextOrd ( ) ; assertThat ( ord , equalTo ( <int> ) ) ; assertThat ( values . lookupOrd ( ord ) . utf8ToString ( ) , equalTo ( <str> ) ) ; values . setDocument ( <int> ) ; assertThat ( values . cardinality ( ) , equalTo ( <int> ) ) ; values . setDocument ( <int> ) ; assertThat ( values . cardinality ( ) , equalTo ( <int> ) ) ; ord = values . nextOrd ( ) ; assertThat ( ord , equalTo ( <int> ) ) ; assertThat ( values . lookupOrd ( ord ) . utf8ToString ( ) , equalTo ( <str> ) ) ; ord = values . nextOrd ( ) ; assertThat ( ord , equalTo ( <int> ) ) ; assertThat ( values . lookupOrd ( ord ) . utf8ToString ( ) , equalTo ( <str> ) ) ; ord = values . nextOrd ( ) ; assertThat ( ord , equalTo ( <int> ) ) ; assertThat ( values . lookupOrd ( ord ) . utf8ToString ( ) , equalTo ( <str> ) ) ; leaf = topLevelReader . leaves ( ) . get ( <int> ) ; afd = globalOrdinals . load ( leaf ) ; values = afd . getOrdinalsValues ( ) ; assertIteratorConsistentWithRandomAccess ( values , leaf . reader ( ) . maxDoc ( ) ) ; values . setDocument ( <int> ) ; values . setDocument ( <int> ) ; assertThat ( values . cardinality ( ) , equalTo ( <int> ) ) ; ord = values . nextOrd ( ) ; assertThat ( ord , equalTo ( <int> l ) ) ; assertThat ( values . lookupOrd ( ord ) . utf8ToString ( ) , equalTo ( <str> ) ) ; ord = values . nextOrd ( ) ; assertThat ( ord , equalTo ( <int> ) ) ; assertThat ( values . lookupOrd ( ord ) . utf8ToString ( ) , equalTo ( <str> ) ) ; ord = values . nextOrd ( ) ; assertThat ( ord , equalTo ( <int> ) ) ; assertThat ( values . lookupOrd ( ord ) . utf8ToString ( ) , equalTo ( <str> ) ) ; } public void testTermsEnum ( ) throws Exception { fillExtendedMvSet ( ) ; LeafReaderContext atomicReaderContext = refreshReader ( ) ; IndexOrdinalsFieldData ifd = getForField ( <str> ) ; AtomicOrdinalsFieldData afd = ifd . load ( atomicReaderContext ) ; TermsEnum termsEnum = afd . getOrdinalsValues ( ) . termsEnum ( ) ; int size = <int> ; while ( termsEnum . next ( ) ! = null ) { size + + ; } assertThat ( size , equalTo ( <int> ) ) ; assertThat ( termsEnum . seekExact ( new BytesRef ( <str> ) ) , is ( true ) ) ; assertThat ( termsEnum . term ( ) . utf8ToString ( ) , equalTo ( <str> ) ) ; assertThat ( termsEnum . next ( ) , nullValue ( ) ) ; assertThat ( termsEnum . seekExact ( new BytesRef ( <str> ) ) , is ( true ) ) ; assertThat ( termsEnum . term ( ) . utf8ToString ( ) , equalTo ( <str> ) ) ; size = <int> ; while ( termsEnum . next ( ) ! = null ) { size + + ; } assertThat ( size , equalTo ( <int> ) ) ; termsEnum . seekExact ( <int> ) ; assertThat ( termsEnum . term ( ) . utf8ToString ( ) , equalTo ( <str> ) ) ; size = <int> ; while ( termsEnum . next ( ) ! = null ) { size + + ; } assertThat ( size , equalTo ( <int> ) ) ; } public void testGlobalOrdinalsGetRemovedOnceIndexReaderCloses ( ) throws Exception { fillExtendedMvSet ( ) ; refreshReader ( ) ; FieldDataType fieldDataType = new FieldDataType ( <str> , Settings . builder ( ) . put ( <str> , <str> ) . put ( <str> , <str> ) ) ; IndexOrdinalsFieldData ifd = getForField ( fieldDataType , <str> , hasDocValues ( ) ) ; IndexOrdinalsFieldData globalOrdinals = ifd . loadGlobal ( topLevelReader ) ; assertThat ( ifd . loadGlobal ( topLevelReader ) , sameInstance ( globalOrdinals ) ) ; assertThat ( indicesFieldDataCache . getCache ( ) . weight ( ) , equalTo ( hasDocValues ( ) ? <int> : <int> ) ) ; IndexOrdinalsFieldData cachedInstance = null ; for ( Accountable ramUsage : indicesFieldDataCache . getCache ( ) . values ( ) ) { if ( ramUsage instanceof IndexOrdinalsFieldData ) { cachedInstance = ( IndexOrdinalsFieldData ) ramUsage ; break ; } } assertThat ( cachedInstance , sameInstance ( globalOrdinals ) ) ; topLevelReader . close ( ) ; assertThat ( indicesFieldDataCache . getCache ( ) . weight ( ) , equalTo ( hasDocValues ( ) ? <int> L : <int> ) ) ; refreshReader ( ) ; assertThat ( ifd . loadGlobal ( topLevelReader ) , not ( sameInstance ( globalOrdinals ) ) ) ; ifdService . clear ( ) ; assertThat ( indicesFieldDataCache . getCache ( ) . weight ( ) , equalTo ( <int> l ) ) ; } } 
