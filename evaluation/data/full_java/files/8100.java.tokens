package org . elasticsearch . index . analysis ; import org . apache . lucene . analysis . Tokenizer ; import org . apache . lucene . analysis . core . WhitespaceTokenizer ; import org . elasticsearch . test . ESTokenStreamTestCase ; import java . io . IOException ; import java . io . StringReader ; import static org . elasticsearch . common . settings . Settings . settingsBuilder ; public class WordDelimiterTokenFilterFactoryTests extends ESTokenStreamTestCase { public void testDefault ( ) throws IOException { AnalysisService analysisService = AnalysisTestsHelper . createAnalysisServiceFromSettings ( settingsBuilder ( ) . put ( <str> , createTempDir ( ) . toString ( ) ) . put ( <str> , <str> ) . build ( ) ) ; TokenFilterFactory tokenFilter = analysisService . tokenFilter ( <str> ) ; String source = <str> ; String [ ] expected = new String [ ] { <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> } ; Tokenizer tokenizer = new WhitespaceTokenizer ( ) ; tokenizer . setReader ( new StringReader ( source ) ) ; assertTokenStreamContents ( tokenFilter . create ( tokenizer ) , expected ) ; } public void testCatenateWords ( ) throws IOException { AnalysisService analysisService = AnalysisTestsHelper . createAnalysisServiceFromSettings ( settingsBuilder ( ) . put ( <str> , createTempDir ( ) . toString ( ) ) . put ( <str> , <str> ) . put ( <str> , <str> ) . put ( <str> , <str> ) . build ( ) ) ; TokenFilterFactory tokenFilter = analysisService . tokenFilter ( <str> ) ; String source = <str> ; String [ ] expected = new String [ ] { <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> } ; Tokenizer tokenizer = new WhitespaceTokenizer ( ) ; tokenizer . setReader ( new StringReader ( source ) ) ; assertTokenStreamContents ( tokenFilter . create ( tokenizer ) , expected ) ; } public void testCatenateNumbers ( ) throws IOException { AnalysisService analysisService = AnalysisTestsHelper . createAnalysisServiceFromSettings ( settingsBuilder ( ) . put ( <str> , createTempDir ( ) . toString ( ) ) . put ( <str> , <str> ) . put ( <str> , <str> ) . put ( <str> , <str> ) . build ( ) ) ; TokenFilterFactory tokenFilter = analysisService . tokenFilter ( <str> ) ; String source = <str> ; String [ ] expected = new String [ ] { <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> } ; Tokenizer tokenizer = new WhitespaceTokenizer ( ) ; tokenizer . setReader ( new StringReader ( source ) ) ; assertTokenStreamContents ( tokenFilter . create ( tokenizer ) , expected ) ; } public void testCatenateAll ( ) throws IOException { AnalysisService analysisService = AnalysisTestsHelper . createAnalysisServiceFromSettings ( settingsBuilder ( ) . put ( <str> , createTempDir ( ) . toString ( ) ) . put ( <str> , <str> ) . put ( <str> , <str> ) . put ( <str> , <str> ) . put ( <str> , <str> ) . build ( ) ) ; TokenFilterFactory tokenFilter = analysisService . tokenFilter ( <str> ) ; String source = <str> ; String [ ] expected = new String [ ] { <str> , <str> , <str> , <str> , <str> , <str> } ; Tokenizer tokenizer = new WhitespaceTokenizer ( ) ; tokenizer . setReader ( new StringReader ( source ) ) ; assertTokenStreamContents ( tokenFilter . create ( tokenizer ) , expected ) ; } public void testSplitOnCaseChange ( ) throws IOException { AnalysisService analysisService = AnalysisTestsHelper . createAnalysisServiceFromSettings ( settingsBuilder ( ) . put ( <str> , createTempDir ( ) . toString ( ) ) . put ( <str> , <str> ) . put ( <str> , <str> ) . build ( ) ) ; TokenFilterFactory tokenFilter = analysisService . tokenFilter ( <str> ) ; String source = <str> ; String [ ] expected = new String [ ] { <str> } ; Tokenizer tokenizer = new WhitespaceTokenizer ( ) ; tokenizer . setReader ( new StringReader ( source ) ) ; assertTokenStreamContents ( tokenFilter . create ( tokenizer ) , expected ) ; } public void testPreserveOriginal ( ) throws IOException { AnalysisService analysisService = AnalysisTestsHelper . createAnalysisServiceFromSettings ( settingsBuilder ( ) . put ( <str> , createTempDir ( ) . toString ( ) ) . put ( <str> , <str> ) . put ( <str> , <str> ) . build ( ) ) ; TokenFilterFactory tokenFilter = analysisService . tokenFilter ( <str> ) ; String source = <str> ; String [ ] expected = new String [ ] { <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> } ; Tokenizer tokenizer = new WhitespaceTokenizer ( ) ; tokenizer . setReader ( new StringReader ( source ) ) ; assertTokenStreamContents ( tokenFilter . create ( tokenizer ) , expected ) ; } public void testStemEnglishPossessive ( ) throws IOException { AnalysisService analysisService = AnalysisTestsHelper . createAnalysisServiceFromSettings ( settingsBuilder ( ) . put ( <str> , createTempDir ( ) . toString ( ) ) . put ( <str> , <str> ) . put ( <str> , <str> ) . build ( ) ) ; TokenFilterFactory tokenFilter = analysisService . tokenFilter ( <str> ) ; String source = <str> ; String [ ] expected = new String [ ] { <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> } ; Tokenizer tokenizer = new WhitespaceTokenizer ( ) ; tokenizer . setReader ( new StringReader ( source ) ) ; assertTokenStreamContents ( tokenFilter . create ( tokenizer ) , expected ) ; } public void testPartsAndCatenate ( ) throws IOException { AnalysisService analysisService = AnalysisTestsHelper . createAnalysisServiceFromSettings ( settingsBuilder ( ) . put ( <str> , createTempDir ( ) . toString ( ) ) . put ( <str> , <str> ) . put ( <str> , <str> ) . put ( <str> , <str> ) . build ( ) ) ; TokenFilterFactory tokenFilter = analysisService . tokenFilter ( <str> ) ; String source = <str> ; String [ ] expected = new String [ ] { <str> , <str> , <str> } ; Tokenizer tokenizer = new WhitespaceTokenizer ( ) ; tokenizer . setReader ( new StringReader ( source ) ) ; assertTokenStreamContents ( tokenFilter . create ( tokenizer ) , expected ) ; } public void testDeprecatedPartsAndCatenate ( ) throws IOException { AnalysisService analysisService = AnalysisTestsHelper . createAnalysisServiceFromSettings ( settingsBuilder ( ) . put ( <str> , createTempDir ( ) . toString ( ) ) . put ( <str> , <str> ) . put ( <str> , <str> ) . put ( <str> , <str> ) . put ( <str> , <str> ) . build ( ) ) ; TokenFilterFactory tokenFilter = analysisService . tokenFilter ( <str> ) ; String source = <str> ; String [ ] expected = new String [ ] { <str> , <str> , <str> } ; Tokenizer tokenizer = new WhitespaceTokenizer ( ) ; tokenizer . setReader ( new StringReader ( source ) ) ; assertTokenStreamContents ( tokenFilter . create ( tokenizer ) , expected ) ; } } 
