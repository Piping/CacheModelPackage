package org . apache . cassandra . db ; import java . io . File ; import java . io . IOError ; import java . io . IOException ; import java . net . InetAddress ; import java . nio . ByteBuffer ; import java . util . * ; import java . util . concurrent . TimeUnit ; import java . util . stream . Collectors ; import java . util . stream . StreamSupport ; import javax . management . openmbean . OpenDataException ; import javax . management . openmbean . TabularData ; import com . google . common . collect . HashMultimap ; import com . google . common . collect . ImmutableSet ; import com . google . common . collect . SetMultimap ; import com . google . common . io . ByteStreams ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; import org . apache . cassandra . config . CFMetaData ; import org . apache . cassandra . config . DatabaseDescriptor ; import org . apache . cassandra . cql3 . QueryProcessor ; import org . apache . cassandra . cql3 . UntypedResultSet ; import org . apache . cassandra . cql3 . functions . * ; import org . apache . cassandra . db . commitlog . ReplayPosition ; import org . apache . cassandra . db . compaction . CompactionHistoryTabularData ; import org . apache . cassandra . db . marshal . * ; import org . apache . cassandra . db . partitions . PartitionUpdate ; import org . apache . cassandra . dht . * ; import org . apache . cassandra . exceptions . ConfigurationException ; import org . apache . cassandra . io . sstable . Descriptor ; import org . apache . cassandra . io . util . * ; import org . apache . cassandra . locator . IEndpointSnitch ; import org . apache . cassandra . metrics . RestorableMeter ; import org . apache . cassandra . net . MessagingService ; import org . apache . cassandra . schema . * ; import org . apache . cassandra . service . StorageService ; import org . apache . cassandra . service . paxos . Commit ; import org . apache . cassandra . service . paxos . PaxosState ; import org . apache . cassandra . thrift . cassandraConstants ; import org . apache . cassandra . transport . Server ; import org . apache . cassandra . utils . * ; import static java . util . Collections . emptyMap ; import static java . util . Collections . singletonMap ; import static org . apache . cassandra . cql3 . QueryProcessor . executeInternal ; import static org . apache . cassandra . cql3 . QueryProcessor . executeOnceInternal ; public final class SystemKeyspace { private SystemKeyspace ( ) { } private static final Logger logger = LoggerFactory . getLogger ( SystemKeyspace . class ) ; public static final CassandraVersion UNREADABLE_VERSION = new CassandraVersion ( <str> ) ; public static final CassandraVersion NULL_VERSION = new CassandraVersion ( <str> ) ; public static final String NAME = <str> ; public static final String BATCHES = <str> ; public static final String PAXOS = <str> ; public static final String BUILT_INDEXES = <str> ; public static final String LOCAL = <str> ; public static final String PEERS = <str> ; public static final String PEER_EVENTS = <str> ; public static final String RANGE_XFERS = <str> ; public static final String COMPACTION_HISTORY = <str> ; public static final String SSTABLE_ACTIVITY = <str> ; public static final String SIZE_ESTIMATES = <str> ; public static final String AVAILABLE_RANGES = <str> ; public static final String VIEWS_BUILDS_IN_PROGRESS = <str> ; public static final String BUILT_VIEWS = <str> ; @Deprecated public static final String LEGACY_HINTS = <str> ; @Deprecated public static final String LEGACY_BATCHLOG = <str> ; @Deprecated public static final String LEGACY_KEYSPACES = <str> ; @Deprecated public static final String LEGACY_COLUMNFAMILIES = <str> ; @Deprecated public static final String LEGACY_COLUMNS = <str> ; @Deprecated public static final String LEGACY_TRIGGERS = <str> ; @Deprecated public static final String LEGACY_USERTYPES = <str> ; @Deprecated public static final String LEGACY_FUNCTIONS = <str> ; @Deprecated public static final String LEGACY_AGGREGATES = <str> ; public static final CFMetaData Batches = compile ( BATCHES , <str> , <str> + <str> + <str> + <str> + <str> ) . copy ( new LocalPartitioner ( TimeUUIDType . instance ) ) . compaction ( CompactionParams . scts ( singletonMap ( <str> , <str> ) ) ) . gcGraceSeconds ( <int> ) ; private static final CFMetaData Paxos = compile ( PAXOS , <str> , <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> ) . compaction ( CompactionParams . lcs ( emptyMap ( ) ) ) ; private static final CFMetaData BuiltIndexes = compile ( BUILT_INDEXES , <str> , <str> + <str> + <str> + <str> + <str> ) ; private static final CFMetaData Local = compile ( LOCAL , <str> , <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> ) ; private static final CFMetaData Peers = compile ( PEERS , <str> , <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> ) ; private static final CFMetaData PeerEvents = compile ( PEER_EVENTS , <str> , <str> + <str> + <str> + <str> ) ; private static final CFMetaData RangeXfers = compile ( RANGE_XFERS , <str> , <str> + <str> + <str> + <str> ) ; private static final CFMetaData CompactionHistory = compile ( COMPACTION_HISTORY , <str> , <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> ) . defaultTimeToLive ( ( int ) TimeUnit . DAYS . toSeconds ( <int> ) ) ; private static final CFMetaData SSTableActivity = compile ( SSTABLE_ACTIVITY , <str> , <str> + <str> + <str> + <str> + <str> + <str> + <str> ) ; private static final CFMetaData SizeEstimates = compile ( SIZE_ESTIMATES , <str> , <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> ) . gcGraceSeconds ( <int> ) ; private static final CFMetaData AvailableRanges = compile ( AVAILABLE_RANGES , <str> , <str> + <str> + <str> + <str> ) ; private static final CFMetaData ViewsBuildsInProgress = compile ( VIEWS_BUILDS_IN_PROGRESS , <str> , <str> + <str> + <str> + <str> + <str> + <str> ) ; private static final CFMetaData BuiltViews = compile ( BUILT_VIEWS , <str> , <str> + <str> + <str> + <str> ) ; @Deprecated public static final CFMetaData LegacyHints = compile ( LEGACY_HINTS , <str> , <str> + <str> + <str> + <str> + <str> + <str> + <str> ) . compaction ( CompactionParams . scts ( singletonMap ( <str> , <str> ) ) ) . gcGraceSeconds ( <int> ) ; @Deprecated public static final CFMetaData LegacyBatchlog = compile ( LEGACY_BATCHLOG , <str> , <str> + <str> + <str> + <str> + <str> + <str> ) . compaction ( CompactionParams . scts ( singletonMap ( <str> , <str> ) ) ) . gcGraceSeconds ( <int> ) ; @Deprecated public static final CFMetaData LegacyKeyspaces = compile ( LEGACY_KEYSPACES , <str> , <str> + <str> + <str> + <str> + <str> + <str> + <str> ) ; @Deprecated public static final CFMetaData LegacyColumnfamilies = compile ( LEGACY_COLUMNFAMILIES , <str> , <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> ) ; @Deprecated public static final CFMetaData LegacyColumns = compile ( LEGACY_COLUMNS , <str> , <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> ) ; @Deprecated public static final CFMetaData LegacyTriggers = compile ( LEGACY_TRIGGERS , <str> , <str> + <str> + <str> + <str> + <str> + <str> ) ; @Deprecated public static final CFMetaData LegacyUsertypes = compile ( LEGACY_USERTYPES , <str> , <str> + <str> + <str> + <str> + <str> + <str> ) ; @Deprecated public static final CFMetaData LegacyFunctions = compile ( LEGACY_FUNCTIONS , <str> , <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> ) ; @Deprecated public static final CFMetaData LegacyAggregates = compile ( LEGACY_AGGREGATES , <str> , <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> ) ; private static CFMetaData compile ( String name , String description , String schema ) { return CFMetaData . compile ( String . format ( schema , name ) , NAME ) . comment ( description ) ; } public static KeyspaceMetadata metadata ( ) { return KeyspaceMetadata . create ( NAME , KeyspaceParams . local ( ) , tables ( ) , Views . none ( ) , Types . none ( ) , functions ( ) ) ; } private static Tables tables ( ) { return Tables . of ( BuiltIndexes , Batches , Paxos , Local , Peers , PeerEvents , RangeXfers , CompactionHistory , SSTableActivity , SizeEstimates , AvailableRanges , ViewsBuildsInProgress , BuiltViews , LegacyHints , LegacyBatchlog , LegacyKeyspaces , LegacyColumnfamilies , LegacyColumns , LegacyTriggers , LegacyUsertypes , LegacyFunctions , LegacyAggregates ) ; } private static Functions functions ( ) { return Functions . builder ( ) . add ( UuidFcts . all ( ) ) . add ( TimeFcts . all ( ) ) . add ( BytesConversionFcts . all ( ) ) . add ( AggregateFcts . all ( ) ) . add ( CastFcts . all ( ) ) . build ( ) ; } private static volatile Map < UUID , Pair < ReplayPosition , Long > > truncationRecords ; public enum BootstrapState { NEEDS_BOOTSTRAP , COMPLETED , IN_PROGRESS , DECOMMISSIONED } public static void finishStartup ( ) { persistLocalMetadata ( ) ; SchemaKeyspace . saveSystemKeyspacesSchema ( ) ; } private static void persistLocalMetadata ( ) { String req = <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> + <str> ; IEndpointSnitch snitch = DatabaseDescriptor . getEndpointSnitch ( ) ; executeOnceInternal ( String . format ( req , LOCAL ) , LOCAL , DatabaseDescriptor . getClusterName ( ) , FBUtilities . getReleaseVersionString ( ) , QueryProcessor . CQL_VERSION . toString ( ) , cassandraConstants . VERSION , String . valueOf ( Server . CURRENT_VERSION ) , snitch . getDatacenter ( FBUtilities . getBroadcastAddress ( ) ) , snitch . getRack ( FBUtilities . getBroadcastAddress ( ) ) , DatabaseDescriptor . getPartitioner ( ) . getClass ( ) . getName ( ) , DatabaseDescriptor . getRpcAddress ( ) , FBUtilities . getBroadcastAddress ( ) , FBUtilities . getLocalAddress ( ) ) ; } public static void updateCompactionHistory ( String ksname , String cfname , long compactedAt , long bytesIn , long bytesOut , Map < Integer , Long > rowsMerged ) { if ( ksname . equals ( <str> ) & & cfname . equals ( COMPACTION_HISTORY ) ) return ; String req = <str> ; executeInternal ( String . format ( req , COMPACTION_HISTORY ) , UUIDGen . getTimeUUID ( ) , ksname , cfname , ByteBufferUtil . bytes ( compactedAt ) , bytesIn , bytesOut , rowsMerged ) ; } public static TabularData getCompactionHistory ( ) throws OpenDataException { UntypedResultSet queryResultSet = executeInternal ( String . format ( <str> , COMPACTION_HISTORY ) ) ; return CompactionHistoryTabularData . from ( queryResultSet ) ; } public static boolean isViewBuilt ( String keyspaceName , String viewName ) { String req = <str> ; UntypedResultSet result = executeInternal ( String . format ( req , NAME , BUILT_VIEWS ) , keyspaceName , viewName ) ; return ! result . isEmpty ( ) ; } public static void setViewBuilt ( String keyspaceName , String viewName ) { String req = <str> ; executeInternal ( String . format ( req , NAME , BUILT_VIEWS ) , keyspaceName , viewName ) ; forceBlockingFlush ( BUILT_VIEWS ) ; } public static void setViewRemoved ( String keyspaceName , String viewName ) { String buildReq = <str> ; executeInternal ( String . format ( buildReq , NAME , VIEWS_BUILDS_IN_PROGRESS ) , keyspaceName , viewName ) ; forceBlockingFlush ( VIEWS_BUILDS_IN_PROGRESS ) ; String builtReq = <str> ; executeInternal ( String . format ( builtReq , NAME , BUILT_VIEWS ) , keyspaceName , viewName ) ; forceBlockingFlush ( BUILT_VIEWS ) ; } public static void beginViewBuild ( String ksname , String viewName , int generationNumber ) { executeInternal ( String . format ( <str> , VIEWS_BUILDS_IN_PROGRESS ) , ksname , viewName , generationNumber ) ; } public static void finishViewBuildStatus ( String ksname , String viewName ) { setViewBuilt ( ksname , viewName ) ; forceBlockingFlush ( BUILT_VIEWS ) ; executeInternal ( String . format ( <str> , VIEWS_BUILDS_IN_PROGRESS ) , ksname , viewName ) ; forceBlockingFlush ( VIEWS_BUILDS_IN_PROGRESS ) ; } public static void updateViewBuildStatus ( String ksname , String viewName , Token token ) { String req = <str> ; Token . TokenFactory factory = ViewsBuildsInProgress . partitioner . getTokenFactory ( ) ; executeInternal ( String . format ( req , VIEWS_BUILDS_IN_PROGRESS ) , ksname , viewName , factory . toString ( token ) ) ; } public static Pair < Integer , Token > getViewBuildStatus ( String ksname , String viewName ) { String req = <str> ; UntypedResultSet queryResultSet = executeInternal ( String . format ( req , VIEWS_BUILDS_IN_PROGRESS ) , ksname , viewName ) ; if ( queryResultSet = = null | | queryResultSet . isEmpty ( ) ) return null ; UntypedResultSet . Row row = queryResultSet . one ( ) ; Integer generation = null ; Token lastKey = null ; if ( row . has ( <str> ) ) generation = row . getInt ( <str> ) ; if ( row . has ( <str> ) ) { Token . TokenFactory factory = ViewsBuildsInProgress . partitioner . getTokenFactory ( ) ; lastKey = factory . fromString ( row . getString ( <str> ) ) ; } return Pair . create ( generation , lastKey ) ; } public static synchronized void saveTruncationRecord ( ColumnFamilyStore cfs , long truncatedAt , ReplayPosition position ) { String req = <str> ; executeInternal ( String . format ( req , LOCAL , LOCAL ) , truncationAsMapEntry ( cfs , truncatedAt , position ) ) ; truncationRecords = null ; forceBlockingFlush ( LOCAL ) ; } public static synchronized void removeTruncationRecord ( UUID cfId ) { String req = <str> ; executeInternal ( String . format ( req , LOCAL , LOCAL ) , cfId ) ; truncationRecords = null ; forceBlockingFlush ( LOCAL ) ; } private static Map < UUID , ByteBuffer > truncationAsMapEntry ( ColumnFamilyStore cfs , long truncatedAt , ReplayPosition position ) { try ( DataOutputBuffer out = new DataOutputBuffer ( ) ) { ReplayPosition . serializer . serialize ( position , out ) ; out . writeLong ( truncatedAt ) ; return singletonMap ( cfs . metadata . cfId , ByteBuffer . wrap ( out . getData ( ) , <int> , out . getLength ( ) ) ) ; } catch ( IOException e ) { throw new RuntimeException ( e ) ; } } public static ReplayPosition getTruncatedPosition ( UUID cfId ) { Pair < ReplayPosition , Long > record = getTruncationRecord ( cfId ) ; return record = = null ? null : record . left ; } public static long getTruncatedAt ( UUID cfId ) { Pair < ReplayPosition , Long > record = getTruncationRecord ( cfId ) ; return record = = null ? Long . MIN_VALUE : record . right ; } private static synchronized Pair < ReplayPosition , Long > getTruncationRecord ( UUID cfId ) { if ( truncationRecords = = null ) truncationRecords = readTruncationRecords ( ) ; return truncationRecords . get ( cfId ) ; } private static Map < UUID , Pair < ReplayPosition , Long > > readTruncationRecords ( ) { UntypedResultSet rows = executeInternal ( String . format ( <str> , LOCAL , LOCAL ) ) ; Map < UUID , Pair < ReplayPosition , Long > > records = new HashMap < > ( ) ; if ( ! rows . isEmpty ( ) & & rows . one ( ) . has ( <str> ) ) { Map < UUID , ByteBuffer > map = rows . one ( ) . getMap ( <str> , UUIDType . instance , BytesType . instance ) ; for ( Map . Entry < UUID , ByteBuffer > entry : map . entrySet ( ) ) records . put ( entry . getKey ( ) , truncationRecordFromBlob ( entry . getValue ( ) ) ) ; } return records ; } private static Pair < ReplayPosition , Long > truncationRecordFromBlob ( ByteBuffer bytes ) { try ( RebufferingInputStream in = new DataInputBuffer ( bytes , true ) ) { return Pair . create ( ReplayPosition . serializer . deserialize ( in ) , in . available ( ) > <int> ? in . readLong ( ) : Long . MIN_VALUE ) ; } catch ( IOException e ) { throw new RuntimeException ( e ) ; } } public static synchronized void updateTokens ( InetAddress ep , Collection < Token > tokens ) { if ( ep . equals ( FBUtilities . getBroadcastAddress ( ) ) ) return ; String req = <str> ; executeInternal ( String . format ( req , PEERS ) , ep , tokensAsSet ( tokens ) ) ; } public static synchronized void updatePreferredIP ( InetAddress ep , InetAddress preferred_ip ) { String req = <str> ; executeInternal ( String . format ( req , PEERS ) , ep , preferred_ip ) ; forceBlockingFlush ( PEERS ) ; } public static synchronized void updatePeerInfo ( InetAddress ep , String columnName , Object value ) { if ( ep . equals ( FBUtilities . getBroadcastAddress ( ) ) ) return ; String req = <str> ; executeInternal ( String . format ( req , PEERS , columnName ) , ep , value ) ; } public static synchronized void updateHintsDropped ( InetAddress ep , UUID timePeriod , int value ) { String req = <str> ; executeInternal ( String . format ( req , PEER_EVENTS ) , timePeriod , value , ep ) ; } public static synchronized void updateSchemaVersion ( UUID version ) { String req = <str> ; executeInternal ( String . format ( req , LOCAL , LOCAL ) , version ) ; } private static Set < String > tokensAsSet ( Collection < Token > tokens ) { if ( tokens . isEmpty ( ) ) return Collections . emptySet ( ) ; Token . TokenFactory factory = StorageService . instance . getTokenFactory ( ) ; Set < String > s = new HashSet < > ( tokens . size ( ) ) ; for ( Token tk : tokens ) s . add ( factory . toString ( tk ) ) ; return s ; } private static Collection < Token > deserializeTokens ( Collection < String > tokensStrings ) { Token . TokenFactory factory = StorageService . instance . getTokenFactory ( ) ; List < Token > tokens = new ArrayList < > ( tokensStrings . size ( ) ) ; for ( String tk : tokensStrings ) tokens . add ( factory . fromString ( tk ) ) ; return tokens ; } public static synchronized void removeEndpoint ( InetAddress ep ) { String req = <str> ; executeInternal ( String . format ( req , PEERS ) , ep ) ; forceBlockingFlush ( PEERS ) ; } public static synchronized void updateTokens ( Collection < Token > tokens ) { assert ! tokens . isEmpty ( ) : <str> ; String req = <str> ; executeInternal ( String . format ( req , LOCAL , LOCAL ) , tokensAsSet ( tokens ) ) ; forceBlockingFlush ( LOCAL ) ; } public static void forceBlockingFlush ( String cfname ) { if ( ! Boolean . getBoolean ( <str> ) ) FBUtilities . waitOnFuture ( Keyspace . open ( NAME ) . getColumnFamilyStore ( cfname ) . forceFlush ( ) ) ; } public static SetMultimap < InetAddress , Token > loadTokens ( ) { SetMultimap < InetAddress , Token > tokenMap = HashMultimap . create ( ) ; for ( UntypedResultSet . Row row : executeInternal ( <str> + PEERS ) ) { InetAddress peer = row . getInetAddress ( <str> ) ; if ( row . has ( <str> ) ) tokenMap . putAll ( peer , deserializeTokens ( row . getSet ( <str> , UTF8Type . instance ) ) ) ; } return tokenMap ; } public static Map < InetAddress , UUID > loadHostIds ( ) { Map < InetAddress , UUID > hostIdMap = new HashMap < > ( ) ; for ( UntypedResultSet . Row row : executeInternal ( <str> + PEERS ) ) { InetAddress peer = row . getInetAddress ( <str> ) ; if ( row . has ( <str> ) ) { hostIdMap . put ( peer , row . getUUID ( <str> ) ) ; } } return hostIdMap ; } public static InetAddress getPreferredIP ( InetAddress ep ) { String req = <str> ; UntypedResultSet result = executeInternal ( String . format ( req , PEERS ) , ep ) ; if ( ! result . isEmpty ( ) & & result . one ( ) . has ( <str> ) ) return result . one ( ) . getInetAddress ( <str> ) ; return ep ; } public static Map < InetAddress , Map < String , String > > loadDcRackInfo ( ) { Map < InetAddress , Map < String , String > > result = new HashMap < > ( ) ; for ( UntypedResultSet . Row row : executeInternal ( <str> + PEERS ) ) { InetAddress peer = row . getInetAddress ( <str> ) ; if ( row . has ( <str> ) & & row . has ( <str> ) ) { Map < String , String > dcRack = new HashMap < > ( ) ; dcRack . put ( <str> , row . getString ( <str> ) ) ; dcRack . put ( <str> , row . getString ( <str> ) ) ; result . put ( peer , dcRack ) ; } } return result ; } public static CassandraVersion getReleaseVersion ( InetAddress ep ) { try { if ( FBUtilities . getBroadcastAddress ( ) . equals ( ep ) ) { return new CassandraVersion ( FBUtilities . getReleaseVersionString ( ) ) ; } String req = <str> ; UntypedResultSet result = executeInternal ( String . format ( req , PEERS ) , ep ) ; if ( result ! = null & & result . one ( ) . has ( <str> ) ) { return new CassandraVersion ( result . one ( ) . getString ( <str> ) ) ; } return null ; } catch ( IllegalArgumentException e ) { return null ; } } public static void checkHealth ( ) throws ConfigurationException { Keyspace keyspace ; try { keyspace = Keyspace . open ( NAME ) ; } catch ( AssertionError err ) { ConfigurationException ex = new ConfigurationException ( <str> ) ; ex . initCause ( err ) ; throw ex ; } ColumnFamilyStore cfs = keyspace . getColumnFamilyStore ( LOCAL ) ; String req = <str> ; UntypedResultSet result = executeInternal ( String . format ( req , LOCAL , LOCAL ) ) ; if ( result . isEmpty ( ) | | ! result . one ( ) . has ( <str> ) ) { if ( ! cfs . getLiveSSTables ( ) . isEmpty ( ) ) throw new ConfigurationException ( <str> ) ; return ; } String savedClusterName = result . one ( ) . getString ( <str> ) ; if ( ! DatabaseDescriptor . getClusterName ( ) . equals ( savedClusterName ) ) throw new ConfigurationException ( <str> + savedClusterName + <str> + DatabaseDescriptor . getClusterName ( ) ) ; } public static Collection < Token > getSavedTokens ( ) { String req = <str> ; UntypedResultSet result = executeInternal ( String . format ( req , LOCAL , LOCAL ) ) ; return result . isEmpty ( ) | | ! result . one ( ) . has ( <str> ) ? Collections . < Token > emptyList ( ) : deserializeTokens ( result . one ( ) . getSet ( <str> , UTF8Type . instance ) ) ; } public static int incrementAndGetGeneration ( ) { String req = <str> ; UntypedResultSet result = executeInternal ( String . format ( req , LOCAL , LOCAL ) ) ; int generation ; if ( result . isEmpty ( ) | | ! result . one ( ) . has ( <str> ) ) { generation = ( int ) ( System . currentTimeMillis ( ) / <int> ) ; } else { final int storedGeneration = result . one ( ) . getInt ( <str> ) + <int> ; final int now = ( int ) ( System . currentTimeMillis ( ) / <int> ) ; if ( storedGeneration > = now ) { logger . warn ( <str> , storedGeneration , now ) ; generation = storedGeneration ; } else { generation = now ; } } req = <str> ; executeInternal ( String . format ( req , LOCAL , LOCAL ) , generation ) ; forceBlockingFlush ( LOCAL ) ; return generation ; } public static BootstrapState getBootstrapState ( ) { String req = <str> ; UntypedResultSet result = executeInternal ( String . format ( req , LOCAL , LOCAL ) ) ; if ( result . isEmpty ( ) | | ! result . one ( ) . has ( <str> ) ) return BootstrapState . NEEDS_BOOTSTRAP ; return BootstrapState . valueOf ( result . one ( ) . getString ( <str> ) ) ; } public static boolean bootstrapComplete ( ) { return getBootstrapState ( ) = = BootstrapState . COMPLETED ; } public static boolean bootstrapInProgress ( ) { return getBootstrapState ( ) = = BootstrapState . IN_PROGRESS ; } public static boolean wasDecommissioned ( ) { return getBootstrapState ( ) = = BootstrapState . DECOMMISSIONED ; } public static void setBootstrapState ( BootstrapState state ) { String req = <str> ; executeInternal ( String . format ( req , LOCAL , LOCAL ) , state . name ( ) ) ; forceBlockingFlush ( LOCAL ) ; } public static boolean isIndexBuilt ( String keyspaceName , String indexName ) { String req = <str> ; UntypedResultSet result = executeInternal ( String . format ( req , NAME , BUILT_INDEXES ) , keyspaceName , indexName ) ; return ! result . isEmpty ( ) ; } public static void setIndexBuilt ( String keyspaceName , String indexName ) { String req = <str> ; executeInternal ( String . format ( req , NAME , BUILT_INDEXES ) , keyspaceName , indexName ) ; forceBlockingFlush ( BUILT_INDEXES ) ; } public static void setIndexRemoved ( String keyspaceName , String indexName ) { String req = <str> ; executeInternal ( String . format ( req , NAME , BUILT_INDEXES ) , keyspaceName , indexName ) ; forceBlockingFlush ( BUILT_INDEXES ) ; } public static List < String > getBuiltIndexes ( String keyspaceName , Set < String > indexNames ) { List < String > names = new ArrayList < > ( indexNames ) ; String req = <str> ; UntypedResultSet results = executeInternal ( String . format ( req , NAME , BUILT_INDEXES ) , keyspaceName , names ) ; return StreamSupport . stream ( results . spliterator ( ) , false ) . map ( r - > r . getString ( <str> ) ) . collect ( Collectors . toList ( ) ) ; } public static UUID getLocalHostId ( ) { String req = <str> ; UntypedResultSet result = executeInternal ( String . format ( req , LOCAL , LOCAL ) ) ; if ( ! result . isEmpty ( ) & & result . one ( ) . has ( <str> ) ) return result . one ( ) . getUUID ( <str> ) ; UUID hostId = UUID . randomUUID ( ) ; logger . warn ( <str> , hostId ) ; return setLocalHostId ( hostId ) ; } public static UUID setLocalHostId ( UUID hostId ) { String req = <str> ; executeInternal ( String . format ( req , LOCAL , LOCAL ) , hostId ) ; return hostId ; } public static String getRack ( ) { String req = <str> ; UntypedResultSet result = executeInternal ( String . format ( req , LOCAL , LOCAL ) ) ; if ( ! result . isEmpty ( ) & & result . one ( ) . has ( <str> ) ) return result . one ( ) . getString ( <str> ) ; return null ; } public static String getDatacenter ( ) { String req = <str> ; UntypedResultSet result = executeInternal ( String . format ( req , LOCAL , LOCAL ) ) ; if ( ! result . isEmpty ( ) & & result . one ( ) . has ( <str> ) ) return result . one ( ) . getString ( <str> ) ; return null ; } public static PaxosState loadPaxosState ( DecoratedKey key , CFMetaData metadata ) { String req = <str> ; UntypedResultSet results = executeInternal ( String . format ( req , PAXOS ) , key . getKey ( ) , metadata . cfId ) ; if ( results . isEmpty ( ) ) return new PaxosState ( key , metadata ) ; UntypedResultSet . Row row = results . one ( ) ; Commit promised = row . has ( <str> ) ? new Commit ( row . getUUID ( <str> ) , new PartitionUpdate ( metadata , key , metadata . partitionColumns ( ) , <int> ) ) : Commit . emptyCommit ( key , metadata ) ; int proposalVersion = row . has ( <str> ) ? row . getInt ( <str> ) : MessagingService . VERSION_21 ; Commit accepted = row . has ( <str> ) ? new Commit ( row . getUUID ( <str> ) , PartitionUpdate . fromBytes ( row . getBytes ( <str> ) , proposalVersion , key ) ) : Commit . emptyCommit ( key , metadata ) ; int mostRecentVersion = row . has ( <str> ) ? row . getInt ( <str> ) : MessagingService . VERSION_21 ; Commit mostRecent = row . has ( <str> ) ? new Commit ( row . getUUID ( <str> ) , PartitionUpdate . fromBytes ( row . getBytes ( <str> ) , mostRecentVersion , key ) ) : Commit . emptyCommit ( key , metadata ) ; return new PaxosState ( promised , accepted , mostRecent ) ; } public static void savePaxosPromise ( Commit promise ) { String req = <str> ; executeInternal ( String . format ( req , PAXOS ) , UUIDGen . microsTimestamp ( promise . ballot ) , paxosTtl ( promise . update . metadata ( ) ) , promise . ballot , promise . update . partitionKey ( ) . getKey ( ) , promise . update . metadata ( ) . cfId ) ; } public static void savePaxosProposal ( Commit proposal ) { executeInternal ( String . format ( <str> , PAXOS ) , UUIDGen . microsTimestamp ( proposal . ballot ) , paxosTtl ( proposal . update . metadata ( ) ) , proposal . ballot , PartitionUpdate . toBytes ( proposal . update , MessagingService . current_version ) , MessagingService . current_version , proposal . update . partitionKey ( ) . getKey ( ) , proposal . update . metadata ( ) . cfId ) ; } private static int paxosTtl ( CFMetaData metadata ) { return Math . max ( <int> * <int> , metadata . params . gcGraceSeconds ) ; } public static void savePaxosCommit ( Commit commit ) { String cql = <str> ; executeInternal ( String . format ( cql , PAXOS ) , UUIDGen . microsTimestamp ( commit . ballot ) , paxosTtl ( commit . update . metadata ( ) ) , commit . ballot , PartitionUpdate . toBytes ( commit . update , MessagingService . current_version ) , MessagingService . current_version , commit . update . partitionKey ( ) . getKey ( ) , commit . update . metadata ( ) . cfId ) ; } public static RestorableMeter getSSTableReadMeter ( String keyspace , String table , int generation ) { String cql = <str> ; UntypedResultSet results = executeInternal ( String . format ( cql , SSTABLE_ACTIVITY ) , keyspace , table , generation ) ; if ( results . isEmpty ( ) ) return new RestorableMeter ( ) ; UntypedResultSet . Row row = results . one ( ) ; double m15rate = row . getDouble ( <str> ) ; double m120rate = row . getDouble ( <str> ) ; return new RestorableMeter ( m15rate , m120rate ) ; } public static void persistSSTableReadMeter ( String keyspace , String table , int generation , RestorableMeter meter ) { String cql = <str> ; executeInternal ( String . format ( cql , SSTABLE_ACTIVITY ) , keyspace , table , generation , meter . fifteenMinuteRate ( ) , meter . twoHourRate ( ) ) ; } public static void clearSSTableReadMeter ( String keyspace , String table , int generation ) { String cql = <str> ; executeInternal ( String . format ( cql , SSTABLE_ACTIVITY ) , keyspace , table , generation ) ; } public static void updateSizeEstimates ( String keyspace , String table , Map < Range < Token > , Pair < Long , Long > > estimates ) { long timestamp = FBUtilities . timestampMicros ( ) ; PartitionUpdate update = new PartitionUpdate ( SizeEstimates , UTF8Type . instance . decompose ( keyspace ) , SizeEstimates . partitionColumns ( ) , estimates . size ( ) ) ; Mutation mutation = new Mutation ( update ) ; int nowInSec = FBUtilities . nowInSeconds ( ) ; update . add ( new RangeTombstone ( Slice . make ( SizeEstimates . comparator , table ) , new DeletionTime ( timestamp - <int> , nowInSec ) ) ) ; for ( Map . Entry < Range < Token > , Pair < Long , Long > > entry : estimates . entrySet ( ) ) { Range < Token > range = entry . getKey ( ) ; Pair < Long , Long > values = entry . getValue ( ) ; new RowUpdateBuilder ( SizeEstimates , timestamp , mutation ) . clustering ( table , range . left . toString ( ) , range . right . toString ( ) ) . add ( <str> , values . left ) . add ( <str> , values . right ) . build ( ) ; } mutation . apply ( ) ; } public static void clearSizeEstimates ( String keyspace , String table ) { String cql = String . format ( <str> , NAME , SIZE_ESTIMATES ) ; executeInternal ( cql , keyspace , table ) ; } public static synchronized void updateAvailableRanges ( String keyspace , Collection < Range < Token > > completedRanges ) { String cql = <str> ; Set < ByteBuffer > rangesToUpdate = new HashSet < > ( completedRanges . size ( ) ) ; for ( Range < Token > range : completedRanges ) { rangesToUpdate . add ( rangeToBytes ( range ) ) ; } executeInternal ( String . format ( cql , AVAILABLE_RANGES ) , rangesToUpdate , keyspace ) ; } public static synchronized Set < Range < Token > > getAvailableRanges ( String keyspace , IPartitioner partitioner ) { Set < Range < Token > > result = new HashSet < > ( ) ; String query = <str> ; UntypedResultSet rs = executeInternal ( String . format ( query , AVAILABLE_RANGES ) , keyspace ) ; for ( UntypedResultSet . Row row : rs ) { Set < ByteBuffer > rawRanges = row . getSet ( <str> , BytesType . instance ) ; for ( ByteBuffer rawRange : rawRanges ) { result . add ( byteBufferToRange ( rawRange , partitioner ) ) ; } } return ImmutableSet . copyOf ( result ) ; } public static void resetAvailableRanges ( ) { ColumnFamilyStore availableRanges = Keyspace . open ( NAME ) . getColumnFamilyStore ( AVAILABLE_RANGES ) ; availableRanges . truncateBlocking ( ) ; } public static boolean snapshotOnVersionChange ( ) throws IOException { String previous = getPreviousVersionString ( ) ; String next = FBUtilities . getReleaseVersionString ( ) ; if ( ! previous . equals ( NULL_VERSION . toString ( ) ) & & ! previous . equals ( next ) ) { logger . info ( <str> , previous , next ) ; String snapshotName = Keyspace . getTimestampedSnapshotName ( String . format ( <str> , previous , next ) ) ; Keyspace systemKs = Keyspace . open ( SystemKeyspace . NAME ) ; systemKs . snapshot ( snapshotName , null ) ; return true ; } return false ; } private static String getPreviousVersionString ( ) { String req = <str> ; UntypedResultSet result = executeInternal ( String . format ( req , SystemKeyspace . LOCAL , SystemKeyspace . LOCAL ) ) ; if ( result . isEmpty ( ) | | ! result . one ( ) . has ( <str> ) ) { for ( File dataDirectory : Directories . getKSChildDirectories ( SystemKeyspace . NAME ) ) { if ( dataDirectory . getName ( ) . equals ( <str> ) & & dataDirectory . listFiles ( ) . length > <int> ) { logger . trace ( <str> ) ; return UNREADABLE_VERSION . toString ( ) ; } } return NULL_VERSION . toString ( ) ; } return result . one ( ) . getString ( <str> ) ; } public static void migrateDataDirs ( ) { Iterable < String > dirs = Arrays . asList ( DatabaseDescriptor . getAllDataFileLocations ( ) ) ; for ( String dataDir : dirs ) { logger . trace ( <str> , dataDir ) ; File dir = new File ( dataDir ) ; assert dir . exists ( ) : dir + <str> ; for ( File ksdir : dir . listFiles ( ( d , n ) - > new File ( d , n ) . isDirectory ( ) ) ) { logger . trace ( <str> , ksdir ) ; for ( File cfdir : ksdir . listFiles ( ( d , n ) - > new File ( d , n ) . isDirectory ( ) ) ) { logger . trace ( <str> , cfdir ) ; if ( Descriptor . isLegacyFile ( cfdir ) ) { FileUtils . deleteRecursive ( cfdir ) ; } else { FileUtils . delete ( cfdir . listFiles ( ( d , n ) - > Descriptor . isLegacyFile ( new File ( d , n ) ) ) ) ; } } } } } private static ByteBuffer rangeToBytes ( Range < Token > range ) { try ( DataOutputBuffer out = new DataOutputBuffer ( ) ) { Range . tokenSerializer . serialize ( range , out , MessagingService . VERSION_22 ) ; return out . buffer ( ) ; } catch ( IOException e ) { throw new IOError ( e ) ; } } @SuppressWarnings ( <str> ) private static Range < Token > byteBufferToRange ( ByteBuffer rawRange , IPartitioner partitioner ) { try { return ( Range < Token > ) Range . tokenSerializer . deserialize ( ByteStreams . newDataInput ( ByteBufferUtil . getArray ( rawRange ) ) , partitioner , MessagingService . VERSION_22 ) ; } catch ( IOException e ) { throw new IOError ( e ) ; } } } 
