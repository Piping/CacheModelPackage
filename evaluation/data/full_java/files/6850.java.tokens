package org . elasticsearch . indices . cache . query ; import org . apache . lucene . index . LeafReaderContext ; import org . apache . lucene . index . Term ; import org . apache . lucene . search . BulkScorer ; import org . apache . lucene . search . Explanation ; import org . apache . lucene . search . LRUQueryCache ; import org . apache . lucene . search . Query ; import org . apache . lucene . search . QueryCache ; import org . apache . lucene . search . QueryCachingPolicy ; import org . apache . lucene . search . Scorer ; import org . apache . lucene . search . Weight ; import org . elasticsearch . common . component . AbstractComponent ; import org . elasticsearch . common . inject . Inject ; import org . elasticsearch . common . lucene . ShardCoreKeyMap ; import org . elasticsearch . common . settings . Settings ; import org . elasticsearch . common . unit . ByteSizeValue ; import org . elasticsearch . common . unit . MemorySizeValue ; import org . elasticsearch . index . cache . query . QueryCacheStats ; import org . elasticsearch . index . shard . ShardId ; import java . io . Closeable ; import java . io . IOException ; import java . util . HashMap ; import java . util . IdentityHashMap ; import java . util . Map ; import java . util . Set ; import java . util . concurrent . ConcurrentHashMap ; public class IndicesQueryCache extends AbstractComponent implements QueryCache , Closeable { public static final String INDICES_CACHE_QUERY_SIZE = <str> ; @Deprecated public static final String DEPRECATED_INDICES_CACHE_QUERY_SIZE = <str> ; public static final String INDICES_CACHE_QUERY_COUNT = <str> ; private final LRUQueryCache cache ; private final ShardCoreKeyMap shardKeyMap = new ShardCoreKeyMap ( ) ; private final Map < ShardId , Stats > shardStats = new ConcurrentHashMap < > ( ) ; private volatile long sharedRamBytesUsed ; private final Map < Object , StatsAndCount > stats2 = new IdentityHashMap < > ( ) ; @Inject public IndicesQueryCache ( Settings settings ) { super ( settings ) ; String sizeString = settings . get ( INDICES_CACHE_QUERY_SIZE ) ; if ( sizeString = = null ) { sizeString = settings . get ( DEPRECATED_INDICES_CACHE_QUERY_SIZE ) ; if ( sizeString ! = null ) { deprecationLogger . deprecated ( <str> + DEPRECATED_INDICES_CACHE_QUERY_SIZE + <str> + INDICES_CACHE_QUERY_SIZE + <str> ) ; } } if ( sizeString = = null ) { sizeString = <str> ; } final ByteSizeValue size = MemorySizeValue . parseBytesSizeValueOrHeapRatio ( sizeString , INDICES_CACHE_QUERY_SIZE ) ; final int count = settings . getAsInt ( INDICES_CACHE_QUERY_COUNT , <int> ) ; logger . debug ( <str> , sizeString , size , count ) ; cache = new LRUQueryCache ( count , size . bytes ( ) ) { private Stats getStats ( Object coreKey ) { final ShardId shardId = shardKeyMap . getShardId ( coreKey ) ; if ( shardId = = null ) { return null ; } return shardStats . get ( shardId ) ; } private Stats getOrCreateStats ( Object coreKey ) { final ShardId shardId = shardKeyMap . getShardId ( coreKey ) ; Stats stats = shardStats . get ( shardId ) ; if ( stats = = null ) { stats = new Stats ( ) ; shardStats . put ( shardId , stats ) ; } return stats ; } @Override protected void onClear ( ) { assert Thread . holdsLock ( this ) ; super . onClear ( ) ; for ( Stats stats : shardStats . values ( ) ) { stats . cacheSize = <int> ; stats . ramBytesUsed = <int> ; } sharedRamBytesUsed = <int> ; } @Override protected void onQueryCache ( Query filter , long ramBytesUsed ) { assert Thread . holdsLock ( this ) ; super . onQueryCache ( filter , ramBytesUsed ) ; sharedRamBytesUsed + = ramBytesUsed ; } @Override protected void onQueryEviction ( Query filter , long ramBytesUsed ) { assert Thread . holdsLock ( this ) ; super . onQueryEviction ( filter , ramBytesUsed ) ; sharedRamBytesUsed - = ramBytesUsed ; } @Override protected void onDocIdSetCache ( Object readerCoreKey , long ramBytesUsed ) { assert Thread . holdsLock ( this ) ; super . onDocIdSetCache ( readerCoreKey , ramBytesUsed ) ; final Stats shardStats = getOrCreateStats ( readerCoreKey ) ; shardStats . cacheSize + = <int> ; shardStats . cacheCount + = <int> ; shardStats . ramBytesUsed + = ramBytesUsed ; StatsAndCount statsAndCount = stats2 . get ( readerCoreKey ) ; if ( statsAndCount = = null ) { statsAndCount = new StatsAndCount ( shardStats ) ; stats2 . put ( readerCoreKey , statsAndCount ) ; } statsAndCount . count + = <int> ; } @Override protected void onDocIdSetEviction ( Object readerCoreKey , int numEntries , long sumRamBytesUsed ) { assert Thread . holdsLock ( this ) ; super . onDocIdSetEviction ( readerCoreKey , numEntries , sumRamBytesUsed ) ; if ( numEntries > <int> ) { final StatsAndCount statsAndCount = stats2 . get ( readerCoreKey ) ; final Stats shardStats = statsAndCount . stats ; shardStats . cacheSize - = numEntries ; shardStats . ramBytesUsed - = sumRamBytesUsed ; statsAndCount . count - = numEntries ; if ( statsAndCount . count = = <int> ) { stats2 . remove ( readerCoreKey ) ; } } } @Override protected void onHit ( Object readerCoreKey , Query filter ) { assert Thread . holdsLock ( this ) ; super . onHit ( readerCoreKey , filter ) ; final Stats shardStats = getStats ( readerCoreKey ) ; shardStats . hitCount + = <int> ; } @Override protected void onMiss ( Object readerCoreKey , Query filter ) { assert Thread . holdsLock ( this ) ; super . onMiss ( readerCoreKey , filter ) ; final Stats shardStats = getOrCreateStats ( readerCoreKey ) ; shardStats . missCount + = <int> ; } } ; sharedRamBytesUsed = <int> ; } public QueryCacheStats getStats ( ShardId shard ) { final Map < ShardId , QueryCacheStats > stats = new HashMap < > ( ) ; for ( Map . Entry < ShardId , Stats > entry : shardStats . entrySet ( ) ) { stats . put ( entry . getKey ( ) , entry . getValue ( ) . toQueryCacheStats ( ) ) ; } QueryCacheStats shardStats = new QueryCacheStats ( ) ; QueryCacheStats info = stats . get ( shard ) ; if ( info = = null ) { info = new QueryCacheStats ( ) ; } shardStats . add ( info ) ; long totalSize = <int> ; for ( QueryCacheStats s : stats . values ( ) ) { totalSize + = s . getCacheSize ( ) ; } final double weight = totalSize = = <int> ? <float> / stats . size ( ) : shardStats . getCacheSize ( ) / totalSize ; final long additionalRamBytesUsed = Math . round ( weight * sharedRamBytesUsed ) ; shardStats . add ( new QueryCacheStats ( additionalRamBytesUsed , <int> , <int> , <int> , <int> ) ) ; return shardStats ; } @Override public Weight doCache ( Weight weight , QueryCachingPolicy policy ) { while ( weight instanceof CachingWeightWrapper ) { weight = ( ( CachingWeightWrapper ) weight ) . in ; } final Weight in = cache . doCache ( weight , policy ) ; return new CachingWeightWrapper ( in ) ; } private class CachingWeightWrapper extends Weight { private final Weight in ; protected CachingWeightWrapper ( Weight in ) { super ( in . getQuery ( ) ) ; this . in = in ; } @Override public void extractTerms ( Set < Term > terms ) { in . extractTerms ( terms ) ; } @Override public Explanation explain ( LeafReaderContext context , int doc ) throws IOException { shardKeyMap . add ( context . reader ( ) ) ; return in . explain ( context , doc ) ; } @Override public float getValueForNormalization ( ) throws IOException { return in . getValueForNormalization ( ) ; } @Override public void normalize ( float norm , float topLevelBoost ) { in . normalize ( norm , topLevelBoost ) ; } @Override public Scorer scorer ( LeafReaderContext context ) throws IOException { shardKeyMap . add ( context . reader ( ) ) ; return in . scorer ( context ) ; } @Override public BulkScorer bulkScorer ( LeafReaderContext context ) throws IOException { shardKeyMap . add ( context . reader ( ) ) ; return in . bulkScorer ( context ) ; } } public void clearIndex ( String index ) { final Set < Object > coreCacheKeys = shardKeyMap . getCoreKeysForIndex ( index ) ; for ( Object coreKey : coreCacheKeys ) { cache . clearCoreCacheKey ( coreKey ) ; } if ( cache . getCacheSize ( ) = = <int> ) { cache . clear ( ) ; } } @Override public void close ( ) { assert shardKeyMap . size ( ) = = <int> : shardKeyMap . size ( ) ; assert shardStats . isEmpty ( ) : shardStats . keySet ( ) ; assert stats2 . isEmpty ( ) : stats2 ; cache . clear ( ) ; } private static class Stats implements Cloneable { volatile long ramBytesUsed ; volatile long hitCount ; volatile long missCount ; volatile long cacheCount ; volatile long cacheSize ; QueryCacheStats toQueryCacheStats ( ) { return new QueryCacheStats ( ramBytesUsed , hitCount , missCount , cacheCount , cacheSize ) ; } } private static class StatsAndCount { int count ; final Stats stats ; StatsAndCount ( Stats stats ) { this . stats = stats ; this . count = <int> ; } } private boolean empty ( Stats stats ) { if ( stats = = null ) { return true ; } return stats . cacheSize = = <int> & & stats . ramBytesUsed = = <int> ; } public void onClose ( ShardId shardId ) { assert empty ( shardStats . get ( shardId ) ) ; shardStats . remove ( shardId ) ; } } 
