package org . elasticsearch . index . analysis ; import com . carrotsearch . randomizedtesting . annotations . ThreadLeakScope ; import com . carrotsearch . randomizedtesting . annotations . ThreadLeakScope . Scope ; import org . apache . lucene . analysis . TokenStream ; import org . apache . lucene . analysis . Tokenizer ; import org . apache . lucene . analysis . core . StopFilter ; import org . apache . lucene . analysis . core . WhitespaceTokenizer ; import org . elasticsearch . test . ESTokenStreamTestCase ; import java . io . IOException ; import java . io . StringReader ; import static org . hamcrest . Matchers . instanceOf ; @ThreadLeakScope ( Scope . NONE ) public class ShingleTokenFilterFactoryTests extends ESTokenStreamTestCase { private static final String RESOURCE = <str> ; public void testDefault ( ) throws IOException { AnalysisService analysisService = AnalysisTestsHelper . createAnalysisServiceFromClassPath ( createTempDir ( ) , RESOURCE ) ; TokenFilterFactory tokenFilter = analysisService . tokenFilter ( <str> ) ; String source = <str> ; String [ ] expected = new String [ ] { <str> , <str> , <str> , <str> , <str> , <str> , <str> } ; Tokenizer tokenizer = new WhitespaceTokenizer ( ) ; tokenizer . setReader ( new StringReader ( source ) ) ; assertTokenStreamContents ( tokenFilter . create ( tokenizer ) , expected ) ; } public void testInverseMapping ( ) throws IOException { AnalysisService analysisService = AnalysisTestsHelper . createAnalysisServiceFromClassPath ( createTempDir ( ) , RESOURCE ) ; TokenFilterFactory tokenFilter = analysisService . tokenFilter ( <str> ) ; assertThat ( tokenFilter , instanceOf ( ShingleTokenFilterFactory . class ) ) ; String source = <str> ; String [ ] expected = new String [ ] { <str> , <str> } ; Tokenizer tokenizer = new WhitespaceTokenizer ( ) ; tokenizer . setReader ( new StringReader ( source ) ) ; assertTokenStreamContents ( tokenFilter . create ( tokenizer ) , expected ) ; } public void testInverseMappingNoShingles ( ) throws IOException { AnalysisService analysisService = AnalysisTestsHelper . createAnalysisServiceFromClassPath ( createTempDir ( ) , RESOURCE ) ; TokenFilterFactory tokenFilter = analysisService . tokenFilter ( <str> ) ; assertThat ( tokenFilter , instanceOf ( ShingleTokenFilterFactory . class ) ) ; String source = <str> ; String [ ] expected = new String [ ] { <str> , <str> } ; Tokenizer tokenizer = new WhitespaceTokenizer ( ) ; tokenizer . setReader ( new StringReader ( source ) ) ; assertTokenStreamContents ( tokenFilter . create ( tokenizer ) , expected ) ; } public void testFillerToken ( ) throws IOException { AnalysisService analysisService = AnalysisTestsHelper . createAnalysisServiceFromClassPath ( createTempDir ( ) , RESOURCE ) ; TokenFilterFactory tokenFilter = analysisService . tokenFilter ( <str> ) ; String source = <str> ; String [ ] expected = new String [ ] { <str> , <str> , <str> } ; Tokenizer tokenizer = new WhitespaceTokenizer ( ) ; tokenizer . setReader ( new StringReader ( source ) ) ; TokenStream stream = new StopFilter ( tokenizer , StopFilter . makeStopSet ( <str> ) ) ; assertTokenStreamContents ( tokenFilter . create ( stream ) , expected ) ; } } 
