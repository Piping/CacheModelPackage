package org . elasticsearch . index . mapper . size ; import org . apache . lucene . util . LuceneTestCase ; import org . apache . lucene . util . TestUtil ; import org . elasticsearch . action . search . SearchResponse ; import org . elasticsearch . common . settings . Settings ; import org . elasticsearch . env . NodeEnvironment ; import org . elasticsearch . plugin . mapper . MapperSizePlugin ; import org . elasticsearch . plugins . Plugin ; import org . elasticsearch . search . SearchHit ; import org . elasticsearch . search . SearchHitField ; import org . elasticsearch . test . ESIntegTestCase ; import org . elasticsearch . test . InternalTestCluster ; import org . elasticsearch . test . hamcrest . ElasticsearchAssertions ; import java . io . IOException ; import java . io . InputStream ; import java . nio . file . Files ; import java . nio . file . Path ; import java . util . Collection ; import java . util . Collections ; import java . util . Map ; import java . util . concurrent . ExecutionException ; @ESIntegTestCase.ClusterScope ( scope = ESIntegTestCase . Scope . TEST , numDataNodes = <int> ) @LuceneTestCase.SuppressFileSystems ( <str> ) public class SizeFieldMapperUpgradeTests extends ESIntegTestCase { @Override protected Collection < Class < ? extends Plugin > > nodePlugins ( ) { return Collections . singleton ( MapperSizePlugin . class ) ; } public void testUpgradeOldMapping ( ) throws IOException , ExecutionException , InterruptedException { final String indexName = <str> ; InternalTestCluster . Async < String > master = internalCluster ( ) . startNodeAsync ( ) ; Path unzipDir = createTempDir ( ) ; Path unzipDataDir = unzipDir . resolve ( <str> ) ; Path backwardsIndex = getBwcIndicesPath ( ) . resolve ( indexName + <str> ) ; try ( InputStream stream = Files . newInputStream ( backwardsIndex ) ) { TestUtil . unzip ( stream , unzipDir ) ; } assertTrue ( Files . exists ( unzipDataDir ) ) ; Path dataPath = createTempDir ( ) ; Settings settings = Settings . builder ( ) . put ( <str> , dataPath ) . build ( ) ; final String node = internalCluster ( ) . startDataOnlyNode ( settings ) ; Path [ ] nodePaths = internalCluster ( ) . getInstance ( NodeEnvironment . class , node ) . nodeDataPaths ( ) ; assertEquals ( <int> , nodePaths . length ) ; dataPath = nodePaths [ <int> ] . resolve ( NodeEnvironment . INDICES_FOLDER ) ; assertFalse ( Files . exists ( dataPath ) ) ; Path src = unzipDataDir . resolve ( indexName + <str> ) ; Files . move ( src , dataPath ) ; master . get ( ) ; client ( ) . admin ( ) . cluster ( ) . prepareReroute ( ) . get ( ) ; ensureGreen ( indexName ) ; final SearchResponse countResponse = client ( ) . prepareSearch ( indexName ) . setSize ( <int> ) . get ( ) ; ElasticsearchAssertions . assertHitCount ( countResponse , <int> ) ; final SearchResponse sizeResponse = client ( ) . prepareSearch ( indexName ) . addField ( <str> ) . addField ( <str> ) . get ( ) ; ElasticsearchAssertions . assertHitCount ( sizeResponse , <int> ) ; for ( SearchHit hit : sizeResponse . getHits ( ) . getHits ( ) ) { String source = hit . getSourceAsString ( ) ; assertNotNull ( source ) ; Map < String , SearchHitField > fields = hit . getFields ( ) ; assertTrue ( fields . containsKey ( <str> ) ) ; Number size = fields . get ( <str> ) . getValue ( ) ; assertNotNull ( size ) ; assertEquals ( source . length ( ) , size . longValue ( ) ) ; } } } 
