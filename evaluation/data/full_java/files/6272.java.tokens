package org . elasticsearch . index . analysis ; import org . apache . lucene . analysis . Tokenizer ; import org . apache . lucene . analysis . standard . ClassicTokenizer ; import org . apache . lucene . analysis . standard . StandardAnalyzer ; import org . elasticsearch . common . settings . Settings ; import org . elasticsearch . env . Environment ; import org . elasticsearch . index . IndexSettings ; public class ClassicTokenizerFactory extends AbstractTokenizerFactory { private final int maxTokenLength ; public ClassicTokenizerFactory ( IndexSettings indexSettings , Environment environment , String name , Settings settings ) { super ( indexSettings , name , settings ) ; maxTokenLength = settings . getAsInt ( <str> , StandardAnalyzer . DEFAULT_MAX_TOKEN_LENGTH ) ; } @Override public Tokenizer create ( ) { ClassicTokenizer tokenizer = new ClassicTokenizer ( ) ; tokenizer . setMaxTokenLength ( maxTokenLength ) ; return tokenizer ; } } 
