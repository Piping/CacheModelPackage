package org . elasticsearch . index . engine ; import org . apache . lucene . index . * ; import org . apache . lucene . search . IndexSearcher ; import org . apache . lucene . search . Query ; import org . apache . lucene . search . SearcherManager ; import org . apache . lucene . search . join . BitSetProducer ; import org . apache . lucene . util . Accountable ; import org . apache . lucene . util . Accountables ; import org . elasticsearch . ExceptionsHelper ; import org . elasticsearch . common . Base64 ; import org . elasticsearch . common . Nullable ; import org . elasticsearch . common . bytes . BytesReference ; import org . elasticsearch . common . io . stream . StreamInput ; import org . elasticsearch . common . io . stream . StreamOutput ; import org . elasticsearch . common . io . stream . Writeable ; import org . elasticsearch . common . lease . Releasable ; import org . elasticsearch . common . lease . Releasables ; import org . elasticsearch . common . logging . ESLogger ; import org . elasticsearch . common . logging . Loggers ; import org . elasticsearch . common . lucene . Lucene ; import org . elasticsearch . common . lucene . uid . Versions ; import org . elasticsearch . common . util . concurrent . ReleasableLock ; import org . elasticsearch . index . VersionType ; import org . elasticsearch . index . mapper . ParseContext . Document ; import org . elasticsearch . index . mapper . ParsedDocument ; import org . elasticsearch . index . mapper . Uid ; import org . elasticsearch . index . merge . MergeStats ; import org . elasticsearch . index . shard . ShardId ; import org . elasticsearch . index . store . Store ; import org . elasticsearch . index . translog . Translog ; import java . io . Closeable ; import java . io . IOException ; import java . util . * ; import java . util . concurrent . TimeUnit ; import java . util . concurrent . atomic . AtomicBoolean ; import java . util . concurrent . locks . Condition ; import java . util . concurrent . locks . Lock ; import java . util . concurrent . locks . ReentrantLock ; import java . util . concurrent . locks . ReentrantReadWriteLock ; import java . util . function . Function ; public abstract class Engine implements Closeable { public static final String SYNC_COMMIT_ID = <str> ; protected final ShardId shardId ; protected final ESLogger logger ; protected final EngineConfig engineConfig ; protected final Store store ; protected final AtomicBoolean isClosed = new AtomicBoolean ( false ) ; protected final EventListener eventListener ; protected final SnapshotDeletionPolicy deletionPolicy ; protected final ReentrantLock failEngineLock = new ReentrantLock ( ) ; protected final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock ( ) ; protected final ReleasableLock readLock = new ReleasableLock ( rwl . readLock ( ) ) ; protected final ReleasableLock writeLock = new ReleasableLock ( rwl . writeLock ( ) ) ; protected volatile Throwable failedEngine = null ; protected volatile long lastWriteNanos = System . nanoTime ( ) ; protected Engine ( EngineConfig engineConfig ) { Objects . requireNonNull ( engineConfig . getStore ( ) , <str> ) ; Objects . requireNonNull ( engineConfig . getDeletionPolicy ( ) , <str> ) ; this . engineConfig = engineConfig ; this . shardId = engineConfig . getShardId ( ) ; this . store = engineConfig . getStore ( ) ; this . logger = Loggers . getLogger ( Engine . class , engineConfig . getIndexSettings ( ) . getSettings ( ) , engineConfig . getShardId ( ) ) ; this . eventListener = engineConfig . getEventListener ( ) ; this . deletionPolicy = engineConfig . getDeletionPolicy ( ) ; } protected static long guardedRamBytesUsed ( Accountable a ) { if ( a = = null ) { return <int> ; } return a . ramBytesUsed ( ) ; } protected static SegmentReader segmentReader ( LeafReader reader ) { if ( reader instanceof SegmentReader ) { return ( SegmentReader ) reader ; } else if ( reader instanceof FilterLeafReader ) { final FilterLeafReader fReader = ( FilterLeafReader ) reader ; return segmentReader ( FilterLeafReader . unwrap ( fReader ) ) ; } throw new IllegalStateException ( <str> + reader + <str> ) ; } protected static boolean isMergedSegment ( LeafReader reader ) { final Map < String , String > diagnostics = segmentReader ( reader ) . getSegmentInfo ( ) . info . getDiagnostics ( ) ; final String source = diagnostics . get ( IndexWriter . SOURCE ) ; assert Arrays . asList ( IndexWriter . SOURCE_ADDINDEXES_READERS , IndexWriter . SOURCE_FLUSH , IndexWriter . SOURCE_MERGE ) . contains ( source ) : <str> + source ; return IndexWriter . SOURCE_MERGE . equals ( source ) ; } protected Searcher newSearcher ( String source , IndexSearcher searcher , SearcherManager manager ) { return new EngineSearcher ( source , searcher , manager , store , logger ) ; } public final EngineConfig config ( ) { return engineConfig ; } protected abstract SegmentInfos getLastCommittedSegmentInfos ( ) ; public MergeStats getMergeStats ( ) { return new MergeStats ( ) ; } protected static final class IndexThrottle { private static final ReleasableLock NOOP_LOCK = new ReleasableLock ( new NoOpLock ( ) ) ; private final ReleasableLock lockReference = new ReleasableLock ( new ReentrantLock ( ) ) ; private volatile ReleasableLock lock = NOOP_LOCK ; public Releasable acquireThrottle ( ) { return lock . acquire ( ) ; } public void activate ( ) { assert lock = = NOOP_LOCK : <str> ; lock = lockReference ; } public void deactivate ( ) { assert lock ! = NOOP_LOCK : <str> ; lock = NOOP_LOCK ; } } protected static final class NoOpLock implements Lock { @Override public void lock ( ) { } @Override public void lockInterruptibly ( ) throws InterruptedException { } @Override public boolean tryLock ( ) { return true ; } @Override public boolean tryLock ( long time , TimeUnit unit ) throws InterruptedException { return true ; } @Override public void unlock ( ) { } @Override public Condition newCondition ( ) { throw new UnsupportedOperationException ( <str> ) ; } } public abstract boolean index ( Index operation ) throws EngineException ; public abstract void delete ( Delete delete ) throws EngineException ; public abstract SyncedFlushResult syncFlush ( String syncId , CommitId expectedCommitId ) throws EngineException ; public enum SyncedFlushResult { SUCCESS , COMMIT_MISMATCH , PENDING_OPERATIONS } final protected GetResult getFromSearcher ( Get get , Function < String , Searcher > searcherFactory ) throws EngineException { final Searcher searcher = searcherFactory . apply ( <str> ) ; final Versions . DocIdAndVersion docIdAndVersion ; try { docIdAndVersion = Versions . loadDocIdAndVersion ( searcher . reader ( ) , get . uid ( ) ) ; } catch ( Throwable e ) { Releasables . closeWhileHandlingException ( searcher ) ; throw new EngineException ( shardId , <str> , e ) ; } if ( docIdAndVersion ! = null ) { if ( get . versionType ( ) . isVersionConflictForReads ( docIdAndVersion . version , get . version ( ) ) ) { Releasables . close ( searcher ) ; Uid uid = Uid . createUid ( get . uid ( ) . text ( ) ) ; throw new VersionConflictEngineException ( shardId , uid . type ( ) , uid . id ( ) , get . versionType ( ) . explainConflictForReads ( docIdAndVersion . version , get . version ( ) ) ) ; } } if ( docIdAndVersion ! = null ) { return new GetResult ( searcher , docIdAndVersion ) ; } else { Releasables . close ( searcher ) ; return GetResult . NOT_EXISTS ; } } public final GetResult get ( Get get ) throws EngineException { return get ( get , this : : acquireSearcher ) ; } public abstract GetResult get ( Get get , Function < String , Searcher > searcherFactory ) throws EngineException ; public final Searcher acquireSearcher ( String source ) throws EngineException { boolean success = false ; store . incRef ( ) ; try { final SearcherManager manager = getSearcherManager ( ) ; final IndexSearcher searcher = manager . acquire ( ) ; try { final Searcher retVal = newSearcher ( source , searcher , manager ) ; success = true ; return retVal ; } finally { if ( ! success ) { manager . release ( searcher ) ; } } } catch ( EngineClosedException ex ) { throw ex ; } catch ( Throwable ex ) { ensureOpen ( ) ; logger . error ( <str> , ex , source ) ; throw new EngineException ( shardId , <str> + source , ex ) ; } finally { if ( ! success ) { store . decRef ( ) ; } } } public abstract Translog getTranslog ( ) ; protected void ensureOpen ( ) { if ( isClosed . get ( ) ) { throw new EngineClosedException ( shardId , failedEngine ) ; } } public CommitStats commitStats ( ) { return new CommitStats ( getLastCommittedSegmentInfos ( ) ) ; } protected static SegmentInfos readLastCommittedSegmentInfos ( final SearcherManager sm , final Store store ) throws IOException { IndexSearcher searcher = sm . acquire ( ) ; try { IndexCommit latestCommit = ( ( DirectoryReader ) searcher . getIndexReader ( ) ) . getIndexCommit ( ) ; return Lucene . readSegmentInfos ( latestCommit ) ; } catch ( IOException e ) { try { return store . readLastCommittedSegmentsInfo ( ) ; } catch ( IOException e2 ) { e2 . addSuppressed ( e ) ; throw e2 ; } } finally { sm . release ( searcher ) ; } } public final SegmentsStats segmentsStats ( ) { ensureOpen ( ) ; try ( final Searcher searcher = acquireSearcher ( <str> ) ) { SegmentsStats stats = new SegmentsStats ( ) ; for ( LeafReaderContext reader : searcher . reader ( ) . leaves ( ) ) { final SegmentReader segmentReader = segmentReader ( reader . reader ( ) ) ; stats . add ( <int> , segmentReader . ramBytesUsed ( ) ) ; stats . addTermsMemoryInBytes ( guardedRamBytesUsed ( segmentReader . getPostingsReader ( ) ) ) ; stats . addStoredFieldsMemoryInBytes ( guardedRamBytesUsed ( segmentReader . getFieldsReader ( ) ) ) ; stats . addTermVectorsMemoryInBytes ( guardedRamBytesUsed ( segmentReader . getTermVectorsReader ( ) ) ) ; stats . addNormsMemoryInBytes ( guardedRamBytesUsed ( segmentReader . getNormsReader ( ) ) ) ; stats . addDocValuesMemoryInBytes ( guardedRamBytesUsed ( segmentReader . getDocValuesReader ( ) ) ) ; } writerSegmentStats ( stats ) ; return stats ; } } protected void writerSegmentStats ( SegmentsStats stats ) { stats . addVersionMapMemoryInBytes ( <int> ) ; stats . addIndexWriterMemoryInBytes ( <int> ) ; stats . addIndexWriterMaxMemoryInBytes ( <int> ) ; } abstract public long indexWriterRAMBytesUsed ( ) ; protected Segment [ ] getSegmentInfo ( SegmentInfos lastCommittedSegmentInfos , boolean verbose ) { ensureOpen ( ) ; Map < String , Segment > segments = new HashMap < > ( ) ; Searcher searcher = acquireSearcher ( <str> ) ; try { for ( LeafReaderContext reader : searcher . reader ( ) . leaves ( ) ) { SegmentCommitInfo info = segmentReader ( reader . reader ( ) ) . getSegmentInfo ( ) ; assert ! segments . containsKey ( info . info . name ) ; Segment segment = new Segment ( info . info . name ) ; segment . search = true ; segment . docCount = reader . reader ( ) . numDocs ( ) ; segment . delDocCount = reader . reader ( ) . numDeletedDocs ( ) ; segment . version = info . info . getVersion ( ) ; segment . compound = info . info . getUseCompoundFile ( ) ; try { segment . sizeInBytes = info . sizeInBytes ( ) ; } catch ( IOException e ) { logger . trace ( <str> , e , info . info . name ) ; } final SegmentReader segmentReader = segmentReader ( reader . reader ( ) ) ; segment . memoryInBytes = segmentReader . ramBytesUsed ( ) ; if ( verbose ) { segment . ramTree = Accountables . namedAccountable ( <str> , segmentReader ) ; } segments . put ( info . info . name , segment ) ; } } finally { searcher . close ( ) ; } if ( lastCommittedSegmentInfos ! = null ) { SegmentInfos infos = lastCommittedSegmentInfos ; for ( SegmentCommitInfo info : infos ) { Segment segment = segments . get ( info . info . name ) ; if ( segment = = null ) { segment = new Segment ( info . info . name ) ; segment . search = false ; segment . committed = true ; segment . docCount = info . info . maxDoc ( ) ; segment . delDocCount = info . getDelCount ( ) ; segment . version = info . info . getVersion ( ) ; segment . compound = info . info . getUseCompoundFile ( ) ; try { segment . sizeInBytes = info . sizeInBytes ( ) ; } catch ( IOException e ) { logger . trace ( <str> , e , info . info . name ) ; } segments . put ( info . info . name , segment ) ; } else { segment . committed = true ; } } } Segment [ ] segmentsArr = segments . values ( ) . toArray ( new Segment [ segments . values ( ) . size ( ) ] ) ; Arrays . sort ( segmentsArr , new Comparator < Segment > ( ) { @Override public int compare ( Segment o1 , Segment o2 ) { return ( int ) ( o1 . getGeneration ( ) - o2 . getGeneration ( ) ) ; } } ) ; return segmentsArr ; } public abstract List < Segment > segments ( boolean verbose ) ; public final boolean refreshNeeded ( ) { if ( store . tryIncRef ( ) ) { try { return ! getSearcherManager ( ) . isSearcherCurrent ( ) ; } catch ( IOException e ) { logger . error ( <str> , e ) ; failEngine ( <str> , e ) ; throw new EngineException ( shardId , <str> , e ) ; } finally { store . decRef ( ) ; } } return false ; } public abstract void refresh ( String source ) throws EngineException ; public abstract CommitId flush ( boolean force , boolean waitIfOngoing ) throws EngineException ; public abstract CommitId flush ( ) throws EngineException ; public void forceMerge ( boolean flush ) throws IOException { forceMerge ( flush , <int> , false , false , false ) ; } public abstract void forceMerge ( boolean flush , int maxNumSegments , boolean onlyExpungeDeletes , boolean upgrade , boolean upgradeOnlyAncientSegments ) throws EngineException , IOException ; public abstract IndexCommit snapshotIndex ( boolean flushFirst ) throws EngineException ; public void failEngine ( String reason , @Nullable Throwable failure ) { if ( failEngineLock . tryLock ( ) ) { store . incRef ( ) ; try { try { closeNoLock ( <str> + reason + <str> ) ; } finally { if ( failedEngine ! = null ) { logger . debug ( <str> , reason , failure ) ; return ; } logger . warn ( <str> , failure , reason ) ; failedEngine = ( failure ! = null ) ? failure : new IllegalStateException ( reason ) ; if ( Lucene . isCorruptionException ( failure ) ) { try { store . markStoreCorrupted ( new IOException ( <str> + reason + <str> , ExceptionsHelper . unwrapCorruption ( failure ) ) ) ; } catch ( IOException e ) { logger . warn ( <str> , e ) ; } } eventListener . onFailedEngine ( reason , failure ) ; } } catch ( Throwable t ) { logger . warn ( <str> , t ) ; } finally { store . decRef ( ) ; } } else { logger . debug ( <str> , reason , failure ) ; } } protected boolean maybeFailEngine ( String source , Throwable t ) { if ( Lucene . isCorruptionException ( t ) ) { failEngine ( <str> + source + <str> , t ) ; return true ; } else if ( ExceptionsHelper . isOOM ( t ) ) { failEngine ( <str> + source + <str> , t ) ; return true ; } return false ; } public interface EventListener { default void onFailedEngine ( String reason , @Nullable Throwable t ) { } } public static class Searcher implements Releasable { private final String source ; private final IndexSearcher searcher ; public Searcher ( String source , IndexSearcher searcher ) { this . source = source ; this . searcher = searcher ; } public String source ( ) { return source ; } public IndexReader reader ( ) { return searcher . getIndexReader ( ) ; } public DirectoryReader getDirectoryReader ( ) { if ( reader ( ) instanceof DirectoryReader ) { return ( DirectoryReader ) reader ( ) ; } throw new IllegalStateException ( <str> + reader ( ) . getClass ( ) + <str> ) ; } public IndexSearcher searcher ( ) { return searcher ; } @Override public void close ( ) { } } public static abstract class Operation { private final Term uid ; private long version ; private final VersionType versionType ; private final Origin origin ; private Translog . Location location ; private final long startTime ; private long endTime ; public Operation ( Term uid , long version , VersionType versionType , Origin origin , long startTime ) { this . uid = uid ; this . version = version ; this . versionType = versionType ; this . origin = origin ; this . startTime = startTime ; } public static enum Origin { PRIMARY , REPLICA , RECOVERY } public Origin origin ( ) { return this . origin ; } public Term uid ( ) { return this . uid ; } public long version ( ) { return this . version ; } public void updateVersion ( long version ) { this . version = version ; } public void setTranslogLocation ( Translog . Location location ) { this . location = location ; } public Translog . Location getTranslogLocation ( ) { return this . location ; } public VersionType versionType ( ) { return this . versionType ; } public long startTime ( ) { return this . startTime ; } public void endTime ( long endTime ) { this . endTime = endTime ; } public long endTime ( ) { return this . endTime ; } } public static class Index extends Operation { private final ParsedDocument doc ; public Index ( Term uid , ParsedDocument doc , long version , VersionType versionType , Origin origin , long startTime ) { super ( uid , version , versionType , origin , startTime ) ; this . doc = doc ; } public Index ( Term uid , ParsedDocument doc ) { this ( uid , doc , Versions . MATCH_ANY ) ; } public Index ( Term uid , ParsedDocument doc , long version ) { this ( uid , doc , version , VersionType . INTERNAL , Origin . PRIMARY , System . nanoTime ( ) ) ; } public ParsedDocument parsedDoc ( ) { return this . doc ; } public String type ( ) { return this . doc . type ( ) ; } public String id ( ) { return this . doc . id ( ) ; } public String routing ( ) { return this . doc . routing ( ) ; } public long timestamp ( ) { return this . doc . timestamp ( ) ; } public long ttl ( ) { return this . doc . ttl ( ) ; } @Override public void updateVersion ( long version ) { super . updateVersion ( version ) ; this . doc . version ( ) . setLongValue ( version ) ; } public String parent ( ) { return this . doc . parent ( ) ; } public List < Document > docs ( ) { return this . doc . docs ( ) ; } public BytesReference source ( ) { return this . doc . source ( ) ; } } public static class Delete extends Operation { private final String type ; private final String id ; private boolean found ; public Delete ( String type , String id , Term uid , long version , VersionType versionType , Origin origin , long startTime , boolean found ) { super ( uid , version , versionType , origin , startTime ) ; this . type = type ; this . id = id ; this . found = found ; } public Delete ( String type , String id , Term uid ) { this ( type , id , uid , Versions . MATCH_ANY , VersionType . INTERNAL , Origin . PRIMARY , System . nanoTime ( ) , false ) ; } public Delete ( Delete template , VersionType versionType ) { this ( template . type ( ) , template . id ( ) , template . uid ( ) , template . version ( ) , versionType , template . origin ( ) , template . startTime ( ) , template . found ( ) ) ; } public String type ( ) { return this . type ; } public String id ( ) { return this . id ; } public void updateVersion ( long version , boolean found ) { updateVersion ( version ) ; this . found = found ; } public boolean found ( ) { return this . found ; } } public static class DeleteByQuery { private final Query query ; private final BytesReference source ; private final String [ ] filteringAliases ; private final Query aliasFilter ; private final String [ ] types ; private final BitSetProducer parentFilter ; private final Operation . Origin origin ; private final long startTime ; private long endTime ; public DeleteByQuery ( Query query , BytesReference source , @Nullable String [ ] filteringAliases , @Nullable Query aliasFilter , BitSetProducer parentFilter , Operation . Origin origin , long startTime , String . . . types ) { this . query = query ; this . source = source ; this . types = types ; this . filteringAliases = filteringAliases ; this . aliasFilter = aliasFilter ; this . parentFilter = parentFilter ; this . startTime = startTime ; this . origin = origin ; } public Query query ( ) { return this . query ; } public BytesReference source ( ) { return this . source ; } public String [ ] types ( ) { return this . types ; } public String [ ] filteringAliases ( ) { return filteringAliases ; } public Query aliasFilter ( ) { return aliasFilter ; } public boolean nested ( ) { return parentFilter ! = null ; } public BitSetProducer parentFilter ( ) { return parentFilter ; } public Operation . Origin origin ( ) { return this . origin ; } public long startTime ( ) { return this . startTime ; } public DeleteByQuery endTime ( long endTime ) { this . endTime = endTime ; return this ; } public long endTime ( ) { return this . endTime ; } } public static class Get { private final boolean realtime ; private final Term uid ; private long version = Versions . MATCH_ANY ; private VersionType versionType = VersionType . INTERNAL ; public Get ( boolean realtime , Term uid ) { this . realtime = realtime ; this . uid = uid ; } public boolean realtime ( ) { return this . realtime ; } public Term uid ( ) { return uid ; } public long version ( ) { return version ; } public Get version ( long version ) { this . version = version ; return this ; } public VersionType versionType ( ) { return versionType ; } public Get versionType ( VersionType versionType ) { this . versionType = versionType ; return this ; } } public static class GetResult { private final boolean exists ; private final long version ; private final Translog . Source source ; private final Versions . DocIdAndVersion docIdAndVersion ; private final Searcher searcher ; public static final GetResult NOT_EXISTS = new GetResult ( false , Versions . NOT_FOUND , null ) ; public GetResult ( boolean exists , long version , @Nullable Translog . Source source ) { this . source = source ; this . exists = exists ; this . version = version ; this . docIdAndVersion = null ; this . searcher = null ; } public GetResult ( Searcher searcher , Versions . DocIdAndVersion docIdAndVersion ) { this . exists = true ; this . source = null ; this . version = docIdAndVersion . version ; this . docIdAndVersion = docIdAndVersion ; this . searcher = searcher ; } public boolean exists ( ) { return exists ; } public long version ( ) { return this . version ; } @Nullable public Translog . Source source ( ) { return source ; } public Searcher searcher ( ) { return this . searcher ; } public Versions . DocIdAndVersion docIdAndVersion ( ) { return docIdAndVersion ; } public void release ( ) { if ( searcher ! = null ) { searcher . close ( ) ; } } } protected abstract SearcherManager getSearcherManager ( ) ; protected abstract void closeNoLock ( String reason ) ; public void flushAndClose ( ) throws IOException { if ( isClosed . get ( ) = = false ) { logger . trace ( <str> ) ; try ( ReleasableLock lock = writeLock . acquire ( ) ) { logger . trace ( <str> ) ; try { logger . debug ( <str> ) ; try { flush ( ) ; } catch ( FlushNotAllowedEngineException ex ) { logger . debug ( <str> ) ; } catch ( EngineClosedException ex ) { logger . debug ( <str> ) ; } } finally { close ( ) ; } } } } @Override public void close ( ) throws IOException { if ( isClosed . get ( ) = = false ) { logger . debug ( <str> ) ; try ( ReleasableLock lock = writeLock . acquire ( ) ) { logger . debug ( <str> ) ; closeNoLock ( <str> ) ; } } } public static class CommitId implements Writeable { private final byte [ ] id ; public CommitId ( byte [ ] id ) { assert id ! = null ; this . id = Arrays . copyOf ( id , id . length ) ; } public CommitId ( StreamInput in ) throws IOException { assert in ! = null ; this . id = in . readByteArray ( ) ; } @Override public String toString ( ) { return Base64 . encodeBytes ( id ) ; } @Override public CommitId readFrom ( StreamInput in ) throws IOException { return new CommitId ( in ) ; } @Override public void writeTo ( StreamOutput out ) throws IOException { out . writeByteArray ( id ) ; } public boolean idsEqual ( byte [ ] id ) { return Arrays . equals ( id , this . id ) ; } @Override public boolean equals ( Object o ) { if ( this = = o ) { return true ; } if ( o = = null | | getClass ( ) ! = o . getClass ( ) ) { return false ; } CommitId commitId = ( CommitId ) o ; if ( ! Arrays . equals ( id , commitId . id ) ) { return false ; } return true ; } @Override public int hashCode ( ) { return Arrays . hashCode ( id ) ; } } public void onSettingsChanged ( ) { } public long getLastWriteNanos ( ) { return this . lastWriteNanos ; } public interface Warmer { void warm ( Engine . Searcher searcher , boolean isTopLevelReader ) ; } } 
