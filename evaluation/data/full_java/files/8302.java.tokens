package org . elasticsearch . index . store ; import com . carrotsearch . randomizedtesting . generators . RandomPicks ; import org . apache . lucene . index . CheckIndex ; import org . apache . lucene . index . IndexFileNames ; import org . elasticsearch . action . admin . cluster . health . ClusterHealthResponse ; import org . elasticsearch . action . admin . cluster . node . stats . NodeStats ; import org . elasticsearch . action . admin . cluster . node . stats . NodesStatsResponse ; import org . elasticsearch . action . admin . cluster . snapshots . create . CreateSnapshotResponse ; import org . elasticsearch . action . admin . cluster . state . ClusterStateResponse ; import org . elasticsearch . action . index . IndexRequestBuilder ; import org . elasticsearch . action . search . SearchResponse ; import org . elasticsearch . client . Requests ; import org . elasticsearch . cluster . ClusterState ; import org . elasticsearch . cluster . health . ClusterHealthStatus ; import org . elasticsearch . cluster . metadata . IndexMetaData ; import org . elasticsearch . cluster . node . DiscoveryNode ; import org . elasticsearch . cluster . routing . * ; import org . elasticsearch . cluster . routing . allocation . decider . EnableAllocationDecider ; import org . elasticsearch . cluster . routing . allocation . decider . ThrottlingAllocationDecider ; import org . elasticsearch . common . Nullable ; import org . elasticsearch . common . bytes . BytesArray ; import org . elasticsearch . common . io . PathUtils ; import org . elasticsearch . common . io . stream . BytesStreamOutput ; import org . elasticsearch . common . lucene . Lucene ; import org . elasticsearch . common . settings . Settings ; import org . elasticsearch . common . unit . ByteSizeUnit ; import org . elasticsearch . gateway . PrimaryShardAllocator ; import org . elasticsearch . index . shard . * ; import org . elasticsearch . indices . recovery . RecoveryFileChunkRequest ; import org . elasticsearch . indices . recovery . RecoverySettings ; import org . elasticsearch . indices . recovery . RecoveryTarget ; import org . elasticsearch . monitor . fs . FsInfo ; import org . elasticsearch . plugins . Plugin ; import org . elasticsearch . snapshots . SnapshotState ; import org . elasticsearch . test . CorruptionUtils ; import org . elasticsearch . test . ESIntegTestCase ; import org . elasticsearch . test . InternalTestCluster ; import org . elasticsearch . test . MockIndexEventListener ; import org . elasticsearch . test . store . MockFSIndexStore ; import org . elasticsearch . test . transport . MockTransportService ; import org . elasticsearch . transport . TransportException ; import org . elasticsearch . transport . TransportRequest ; import org . elasticsearch . transport . TransportRequestOptions ; import org . elasticsearch . transport . TransportService ; import java . io . IOException ; import java . io . OutputStream ; import java . io . PrintStream ; import java . nio . charset . StandardCharsets ; import java . nio . file . DirectoryStream ; import java . nio . file . Files ; import java . nio . file . Path ; import java . util . * ; import java . util . concurrent . CopyOnWriteArrayList ; import java . util . concurrent . CountDownLatch ; import java . util . concurrent . ExecutionException ; import java . util . concurrent . TimeUnit ; import java . util . concurrent . atomic . AtomicBoolean ; import static org . elasticsearch . common . settings . Settings . settingsBuilder ; import static org . elasticsearch . common . util . CollectionUtils . iterableAsArrayList ; import static org . elasticsearch . test . hamcrest . ElasticsearchAssertions . * ; import static org . hamcrest . Matchers . * ; @ESIntegTestCase.ClusterScope ( scope = ESIntegTestCase . Scope . SUITE ) public class CorruptedFileIT extends ESIntegTestCase { @Override protected Settings nodeSettings ( int nodeOrdinal ) { return Settings . builder ( ) . put ( super . nodeSettings ( nodeOrdinal ) ) . put ( RecoverySettings . INDICES_RECOVERY_CONCURRENT_STREAMS , <int> ) . put ( RecoverySettings . INDICES_RECOVERY_CONCURRENT_SMALL_FILE_STREAMS , <int> ) . put ( ThrottlingAllocationDecider . CLUSTER_ROUTING_ALLOCATION_NODE_CONCURRENT_RECOVERIES , <int> ) . build ( ) ; } @Override protected Collection < Class < ? extends Plugin > > nodePlugins ( ) { return pluginList ( MockTransportService . TestPlugin . class , MockIndexEventListener . TestPlugin . class ) ; } public void testCorruptFileAndRecover ( ) throws ExecutionException , InterruptedException , IOException { int numDocs = scaledRandomIntBetween ( <int> , <int> ) ; internalCluster ( ) . ensureAtLeastNumDataNodes ( <int> ) ; if ( cluster ( ) . numDataNodes ( ) = = <int> ) { logger . info ( <str> ) ; } assertThat ( cluster ( ) . numDataNodes ( ) , greaterThanOrEqualTo ( <int> ) ) ; assertAcked ( prepareCreate ( <str> ) . setSettings ( Settings . builder ( ) . put ( IndexMetaData . SETTING_NUMBER_OF_SHARDS , <str> ) . put ( IndexMetaData . SETTING_NUMBER_OF_REPLICAS , <str> ) . put ( MergePolicyConfig . INDEX_MERGE_ENABLED , false ) . put ( MockFSIndexStore . CHECK_INDEX_ON_CLOSE , false ) . put ( IndexShard . INDEX_TRANSLOG_DISABLE_FLUSH , true ) . put ( <str> , <int> ) ) ) ; ensureGreen ( ) ; disableAllocation ( <str> ) ; IndexRequestBuilder [ ] builders = new IndexRequestBuilder [ numDocs ] ; for ( int i = <int> ; i < builders . length ; i + + ) { builders [ i ] = client ( ) . prepareIndex ( <str> , <str> ) . setSource ( <str> , <str> ) ; } indexRandom ( true , builders ) ; ensureGreen ( ) ; assertAllSuccessful ( client ( ) . admin ( ) . indices ( ) . prepareFlush ( ) . setForce ( true ) . setWaitIfOngoing ( true ) . execute ( ) . actionGet ( ) ) ; SearchResponse countResponse = client ( ) . prepareSearch ( ) . setSize ( <int> ) . get ( ) ; assertHitCount ( countResponse , numDocs ) ; final int numShards = numShards ( <str> ) ; ShardRouting corruptedShardRouting = corruptRandomPrimaryFile ( ) ; logger . info ( <str> , corruptedShardRouting ) ; enableAllocation ( <str> ) ; Settings build = Settings . builder ( ) . put ( IndexMetaData . SETTING_NUMBER_OF_REPLICAS , <str> ) . build ( ) ; client ( ) . admin ( ) . indices ( ) . prepareUpdateSettings ( <str> ) . setSettings ( build ) . get ( ) ; ClusterHealthResponse health = client ( ) . admin ( ) . cluster ( ) . health ( Requests . clusterHealthRequest ( <str> ) . waitForGreenStatus ( ) . timeout ( <str> ) . waitForRelocatingShards ( <int> ) ) . actionGet ( ) ; if ( health . isTimedOut ( ) ) { logger . info ( <str> , client ( ) . admin ( ) . cluster ( ) . prepareState ( ) . get ( ) . getState ( ) . prettyPrint ( ) , client ( ) . admin ( ) . cluster ( ) . preparePendingClusterTasks ( ) . get ( ) . prettyPrint ( ) ) ; assertThat ( <str> , health . isTimedOut ( ) , equalTo ( false ) ) ; } assertThat ( health . getStatus ( ) , equalTo ( ClusterHealthStatus . GREEN ) ) ; final int numIterations = scaledRandomIntBetween ( <int> , <int> ) ; for ( int i = <int> ; i < numIterations ; i + + ) { SearchResponse response = client ( ) . prepareSearch ( ) . setSize ( numDocs ) . get ( ) ; assertHitCount ( response , numDocs ) ; } final CountDownLatch latch = new CountDownLatch ( numShards * <int> ) ; final CopyOnWriteArrayList < Throwable > exception = new CopyOnWriteArrayList < > ( ) ; final IndexEventListener listener = new IndexEventListener ( ) { @Override public void afterIndexShardClosed ( ShardId sid , @Nullable IndexShard indexShard , Settings indexSettings ) { if ( indexShard ! = null ) { Store store = indexShard . store ( ) ; store . incRef ( ) ; try { if ( ! Lucene . indexExists ( store . directory ( ) ) & & indexShard . state ( ) = = IndexShardState . STARTED ) { return ; } try ( CheckIndex checkIndex = new CheckIndex ( store . directory ( ) ) ) { BytesStreamOutput os = new BytesStreamOutput ( ) ; PrintStream out = new PrintStream ( os , false , StandardCharsets . UTF_8 . name ( ) ) ; checkIndex . setInfoStream ( out ) ; out . flush ( ) ; CheckIndex . Status status = checkIndex . checkIndex ( ) ; if ( ! status . clean ) { logger . warn ( <str> , new String ( os . bytes ( ) . toBytes ( ) , StandardCharsets . UTF_8 ) ) ; throw new IOException ( <str> ) ; } } } catch ( Throwable t ) { exception . add ( t ) ; } finally { store . decRef ( ) ; latch . countDown ( ) ; } } } } ; for ( MockIndexEventListener . TestEventListener eventListener : internalCluster ( ) . getDataNodeInstances ( MockIndexEventListener . TestEventListener . class ) ) { eventListener . setNewDelegate ( listener ) ; } try { client ( ) . admin ( ) . indices ( ) . prepareDelete ( <str> ) . get ( ) ; latch . await ( ) ; assertThat ( exception , empty ( ) ) ; } finally { for ( MockIndexEventListener . TestEventListener eventListener : internalCluster ( ) . getDataNodeInstances ( MockIndexEventListener . TestEventListener . class ) ) { eventListener . setNewDelegate ( null ) ; } } } public void testCorruptPrimaryNoReplica ( ) throws ExecutionException , InterruptedException , IOException { int numDocs = scaledRandomIntBetween ( <int> , <int> ) ; internalCluster ( ) . ensureAtLeastNumDataNodes ( <int> ) ; assertAcked ( prepareCreate ( <str> ) . setSettings ( Settings . builder ( ) . put ( IndexMetaData . SETTING_NUMBER_OF_REPLICAS , <str> ) . put ( MergePolicyConfig . INDEX_MERGE_ENABLED , false ) . put ( MockFSIndexStore . CHECK_INDEX_ON_CLOSE , false ) . put ( IndexShard . INDEX_TRANSLOG_DISABLE_FLUSH , true ) . put ( <str> , <int> ) ) ) ; ensureGreen ( ) ; IndexRequestBuilder [ ] builders = new IndexRequestBuilder [ numDocs ] ; for ( int i = <int> ; i < builders . length ; i + + ) { builders [ i ] = client ( ) . prepareIndex ( <str> , <str> ) . setSource ( <str> , <str> ) ; } indexRandom ( true , builders ) ; ensureGreen ( ) ; assertAllSuccessful ( client ( ) . admin ( ) . indices ( ) . prepareFlush ( ) . setForce ( true ) . setWaitIfOngoing ( true ) . execute ( ) . actionGet ( ) ) ; SearchResponse countResponse = client ( ) . prepareSearch ( ) . setSize ( <int> ) . get ( ) ; assertHitCount ( countResponse , numDocs ) ; ShardRouting shardRouting = corruptRandomPrimaryFile ( ) ; Settings build = Settings . builder ( ) . put ( IndexMetaData . SETTING_NUMBER_OF_REPLICAS , <str> ) . build ( ) ; client ( ) . admin ( ) . indices ( ) . prepareUpdateSettings ( <str> ) . setSettings ( build ) . get ( ) ; client ( ) . admin ( ) . cluster ( ) . prepareReroute ( ) . get ( ) ; boolean didClusterTurnRed = awaitBusy ( ( ) - > { ClusterHealthStatus test = client ( ) . admin ( ) . cluster ( ) . health ( Requests . clusterHealthRequest ( <str> ) ) . actionGet ( ) . getStatus ( ) ; return test = = ClusterHealthStatus . RED ; } , <int> , TimeUnit . MINUTES ) ; final ClusterHealthResponse response = client ( ) . admin ( ) . cluster ( ) . health ( Requests . clusterHealthRequest ( <str> ) ) . get ( ) ; if ( response . getStatus ( ) ! = ClusterHealthStatus . RED ) { logger . info ( <str> , didClusterTurnRed ) ; logger . info ( <str> , client ( ) . admin ( ) . cluster ( ) . prepareState ( ) . get ( ) . getState ( ) . prettyPrint ( ) , client ( ) . admin ( ) . cluster ( ) . preparePendingClusterTasks ( ) . get ( ) . prettyPrint ( ) ) ; } assertThat ( response . getStatus ( ) , is ( ClusterHealthStatus . RED ) ) ; ClusterState state = client ( ) . admin ( ) . cluster ( ) . prepareState ( ) . get ( ) . getState ( ) ; GroupShardsIterator shardIterators = state . getRoutingNodes ( ) . getRoutingTable ( ) . activePrimaryShardsGrouped ( new String [ ] { <str> } , false ) ; for ( ShardIterator iterator : shardIterators ) { ShardRouting routing ; while ( ( routing = iterator . nextOrNull ( ) ) ! = null ) { if ( routing . getId ( ) = = shardRouting . getId ( ) ) { assertThat ( routing . state ( ) , equalTo ( ShardRoutingState . UNASSIGNED ) ) ; } else { assertThat ( routing . state ( ) , anyOf ( equalTo ( ShardRoutingState . RELOCATING ) , equalTo ( ShardRoutingState . STARTED ) ) ) ; } } } final List < Path > files = listShardFiles ( shardRouting ) ; Path corruptedFile = null ; for ( Path file : files ) { if ( file . getFileName ( ) . toString ( ) . startsWith ( <str> ) ) { corruptedFile = file ; break ; } } assertThat ( corruptedFile , notNullValue ( ) ) ; } public void testCorruptionOnNetworkLayerFinalizingRecovery ( ) throws ExecutionException , InterruptedException , IOException { internalCluster ( ) . ensureAtLeastNumDataNodes ( <int> ) ; NodesStatsResponse nodeStats = client ( ) . admin ( ) . cluster ( ) . prepareNodesStats ( ) . get ( ) ; List < NodeStats > dataNodeStats = new ArrayList < > ( ) ; for ( NodeStats stat : nodeStats . getNodes ( ) ) { if ( stat . getNode ( ) . isDataNode ( ) ) { dataNodeStats . add ( stat ) ; } } assertThat ( dataNodeStats . size ( ) , greaterThanOrEqualTo ( <int> ) ) ; Collections . shuffle ( dataNodeStats , random ( ) ) ; NodeStats primariesNode = dataNodeStats . get ( <int> ) ; NodeStats unluckyNode = dataNodeStats . get ( <int> ) ; assertAcked ( prepareCreate ( <str> ) . setSettings ( Settings . builder ( ) . put ( IndexMetaData . SETTING_NUMBER_OF_REPLICAS , <str> ) . put ( IndexMetaData . SETTING_NUMBER_OF_SHARDS , <int> ) . put ( <str> , primariesNode . getNode ( ) . name ( ) ) . put ( EnableAllocationDecider . INDEX_ROUTING_REBALANCE_ENABLE , EnableAllocationDecider . Rebalance . NONE ) ) ) ; ensureGreen ( ) ; final AtomicBoolean corrupt = new AtomicBoolean ( true ) ; final CountDownLatch hasCorrupted = new CountDownLatch ( <int> ) ; for ( NodeStats dataNode : dataNodeStats ) { MockTransportService mockTransportService = ( ( MockTransportService ) internalCluster ( ) . getInstance ( TransportService . class , dataNode . getNode ( ) . name ( ) ) ) ; mockTransportService . addDelegate ( internalCluster ( ) . getInstance ( TransportService . class , unluckyNode . getNode ( ) . name ( ) ) , new MockTransportService . DelegateTransport ( mockTransportService . original ( ) ) { @Override public void sendRequest ( DiscoveryNode node , long requestId , String action , TransportRequest request , TransportRequestOptions options ) throws IOException , TransportException { if ( corrupt . get ( ) & & action . equals ( RecoveryTarget . Actions . FILE_CHUNK ) ) { RecoveryFileChunkRequest req = ( RecoveryFileChunkRequest ) request ; byte [ ] array = req . content ( ) . array ( ) ; int i = randomIntBetween ( <int> , req . content ( ) . length ( ) - <int> ) ; array [ i ] = ( byte ) ~ array [ i ] ; hasCorrupted . countDown ( ) ; } super . sendRequest ( node , requestId , action , request , options ) ; } } ) ; } Settings build = Settings . builder ( ) . put ( IndexMetaData . SETTING_NUMBER_OF_REPLICAS , <str> ) . put ( <str> , primariesNode . getNode ( ) . name ( ) + <str> + unluckyNode . getNode ( ) . name ( ) ) . build ( ) ; client ( ) . admin ( ) . indices ( ) . prepareUpdateSettings ( <str> ) . setSettings ( build ) . get ( ) ; client ( ) . admin ( ) . cluster ( ) . prepareReroute ( ) . get ( ) ; hasCorrupted . await ( ) ; corrupt . set ( false ) ; ensureGreen ( ) ; } public void testCorruptionOnNetworkLayer ( ) throws ExecutionException , InterruptedException { int numDocs = scaledRandomIntBetween ( <int> , <int> ) ; internalCluster ( ) . ensureAtLeastNumDataNodes ( <int> ) ; if ( cluster ( ) . numDataNodes ( ) < <int> ) { internalCluster ( ) . startNode ( Settings . builder ( ) . put ( <str> , true ) . put ( <str> , false ) . put ( <str> , false ) ) ; } NodesStatsResponse nodeStats = client ( ) . admin ( ) . cluster ( ) . prepareNodesStats ( ) . get ( ) ; List < NodeStats > dataNodeStats = new ArrayList < > ( ) ; for ( NodeStats stat : nodeStats . getNodes ( ) ) { if ( stat . getNode ( ) . isDataNode ( ) ) { dataNodeStats . add ( stat ) ; } } assertThat ( dataNodeStats . size ( ) , greaterThanOrEqualTo ( <int> ) ) ; Collections . shuffle ( dataNodeStats , random ( ) ) ; NodeStats primariesNode = dataNodeStats . get ( <int> ) ; NodeStats unluckyNode = dataNodeStats . get ( <int> ) ; assertAcked ( prepareCreate ( <str> ) . setSettings ( Settings . builder ( ) . put ( IndexMetaData . SETTING_NUMBER_OF_REPLICAS , <str> ) . put ( IndexMetaData . SETTING_NUMBER_OF_SHARDS , between ( <int> , <int> ) ) . put ( MockFSIndexStore . CHECK_INDEX_ON_CLOSE , false ) . put ( <str> , primariesNode . getNode ( ) . name ( ) ) . put ( EnableAllocationDecider . INDEX_ROUTING_REBALANCE_ENABLE , EnableAllocationDecider . Rebalance . NONE ) ) ) ; ensureGreen ( ) ; IndexRequestBuilder [ ] builders = new IndexRequestBuilder [ numDocs ] ; for ( int i = <int> ; i < builders . length ; i + + ) { builders [ i ] = client ( ) . prepareIndex ( <str> , <str> ) . setSource ( <str> , <str> ) ; } indexRandom ( true , builders ) ; ensureGreen ( ) ; assertAllSuccessful ( client ( ) . admin ( ) . indices ( ) . prepareFlush ( ) . setForce ( true ) . setWaitIfOngoing ( true ) . execute ( ) . actionGet ( ) ) ; SearchResponse countResponse = client ( ) . prepareSearch ( ) . setSize ( <int> ) . get ( ) ; assertHitCount ( countResponse , numDocs ) ; final boolean truncate = randomBoolean ( ) ; for ( NodeStats dataNode : dataNodeStats ) { MockTransportService mockTransportService = ( ( MockTransportService ) internalCluster ( ) . getInstance ( TransportService . class , dataNode . getNode ( ) . name ( ) ) ) ; mockTransportService . addDelegate ( internalCluster ( ) . getInstance ( TransportService . class , unluckyNode . getNode ( ) . name ( ) ) , new MockTransportService . DelegateTransport ( mockTransportService . original ( ) ) { @Override public void sendRequest ( DiscoveryNode node , long requestId , String action , TransportRequest request , TransportRequestOptions options ) throws IOException , TransportException { if ( action . equals ( RecoveryTarget . Actions . FILE_CHUNK ) ) { RecoveryFileChunkRequest req = ( RecoveryFileChunkRequest ) request ; if ( truncate & & req . length ( ) > <int> ) { BytesArray array = new BytesArray ( req . content ( ) . array ( ) , req . content ( ) . arrayOffset ( ) , ( int ) req . length ( ) - <int> ) ; request = new RecoveryFileChunkRequest ( req . recoveryId ( ) , req . shardId ( ) , req . metadata ( ) , req . position ( ) , array , req . lastChunk ( ) , req . totalTranslogOps ( ) , req . sourceThrottleTimeInNanos ( ) ) ; } else { byte [ ] array = req . content ( ) . array ( ) ; int i = randomIntBetween ( <int> , req . content ( ) . length ( ) - <int> ) ; array [ i ] = ( byte ) ~ array [ i ] ; } } super . sendRequest ( node , requestId , action , request , options ) ; } } ) ; } Settings build = Settings . builder ( ) . put ( IndexMetaData . SETTING_NUMBER_OF_REPLICAS , <str> ) . put ( <str> , <str> ) . build ( ) ; client ( ) . admin ( ) . indices ( ) . prepareUpdateSettings ( <str> ) . setSettings ( build ) . get ( ) ; client ( ) . admin ( ) . cluster ( ) . prepareReroute ( ) . get ( ) ; ClusterHealthResponse actionGet = client ( ) . admin ( ) . cluster ( ) . health ( Requests . clusterHealthRequest ( <str> ) . waitForGreenStatus ( ) ) . actionGet ( ) ; if ( actionGet . isTimedOut ( ) ) { logger . info ( <str> , client ( ) . admin ( ) . cluster ( ) . prepareState ( ) . get ( ) . getState ( ) . prettyPrint ( ) , client ( ) . admin ( ) . cluster ( ) . preparePendingClusterTasks ( ) . get ( ) . prettyPrint ( ) ) ; assertThat ( <str> , actionGet . isTimedOut ( ) , equalTo ( false ) ) ; } ClusterStateResponse clusterStateResponse = client ( ) . admin ( ) . cluster ( ) . prepareState ( ) . get ( ) ; for ( IndexShardRoutingTable table : clusterStateResponse . getState ( ) . getRoutingNodes ( ) . getRoutingTable ( ) . index ( <str> ) ) { for ( ShardRouting routing : table ) { if ( unluckyNode . getNode ( ) . getId ( ) . equals ( routing . currentNodeId ( ) ) ) { assertThat ( routing . state ( ) , not ( equalTo ( ShardRoutingState . STARTED ) ) ) ; assertThat ( routing . state ( ) , not ( equalTo ( ShardRoutingState . RELOCATING ) ) ) ; } } } final int numIterations = scaledRandomIntBetween ( <int> , <int> ) ; for ( int i = <int> ; i < numIterations ; i + + ) { SearchResponse response = client ( ) . prepareSearch ( ) . setSize ( numDocs ) . get ( ) ; assertHitCount ( response , numDocs ) ; } } public void testCorruptFileThenSnapshotAndRestore ( ) throws ExecutionException , InterruptedException , IOException { int numDocs = scaledRandomIntBetween ( <int> , <int> ) ; internalCluster ( ) . ensureAtLeastNumDataNodes ( <int> ) ; assertAcked ( prepareCreate ( <str> ) . setSettings ( Settings . builder ( ) . put ( IndexMetaData . SETTING_NUMBER_OF_REPLICAS , <str> ) . put ( MergePolicyConfig . INDEX_MERGE_ENABLED , false ) . put ( MockFSIndexStore . CHECK_INDEX_ON_CLOSE , false ) . put ( IndexShard . INDEX_TRANSLOG_DISABLE_FLUSH , true ) . put ( <str> , <int> ) ) ) ; ensureGreen ( ) ; IndexRequestBuilder [ ] builders = new IndexRequestBuilder [ numDocs ] ; for ( int i = <int> ; i < builders . length ; i + + ) { builders [ i ] = client ( ) . prepareIndex ( <str> , <str> ) . setSource ( <str> , <str> ) ; } indexRandom ( true , builders ) ; ensureGreen ( ) ; assertAllSuccessful ( client ( ) . admin ( ) . indices ( ) . prepareFlush ( ) . setForce ( true ) . setWaitIfOngoing ( true ) . execute ( ) . actionGet ( ) ) ; SearchResponse countResponse = client ( ) . prepareSearch ( ) . setSize ( <int> ) . get ( ) ; assertHitCount ( countResponse , numDocs ) ; ShardRouting shardRouting = corruptRandomPrimaryFile ( false ) ; logger . info ( <str> ) ; assertAcked ( client ( ) . admin ( ) . cluster ( ) . preparePutRepository ( <str> ) . setType ( <str> ) . setSettings ( settingsBuilder ( ) . put ( <str> , randomRepoPath ( ) . toAbsolutePath ( ) ) . put ( <str> , randomBoolean ( ) ) . put ( <str> , randomIntBetween ( <int> , <int> ) , ByteSizeUnit . BYTES ) ) ) ; logger . info ( <str> ) ; CreateSnapshotResponse createSnapshotResponse = client ( ) . admin ( ) . cluster ( ) . prepareCreateSnapshot ( <str> , <str> ) . setWaitForCompletion ( true ) . setIndices ( <str> ) . get ( ) ; assertThat ( createSnapshotResponse . getSnapshotInfo ( ) . state ( ) , equalTo ( SnapshotState . PARTIAL ) ) ; logger . info ( <str> ) ; final List < Path > files = listShardFiles ( shardRouting ) ; Path corruptedFile = null ; for ( Path file : files ) { if ( file . getFileName ( ) . toString ( ) . startsWith ( <str> ) ) { corruptedFile = file ; break ; } } assertThat ( corruptedFile , notNullValue ( ) ) ; } public void testReplicaCorruption ( ) throws Exception { int numDocs = scaledRandomIntBetween ( <int> , <int> ) ; internalCluster ( ) . ensureAtLeastNumDataNodes ( <int> ) ; assertAcked ( prepareCreate ( <str> ) . setSettings ( Settings . builder ( ) . put ( PrimaryShardAllocator . INDEX_RECOVERY_INITIAL_SHARDS , <str> ) . put ( IndexMetaData . SETTING_NUMBER_OF_REPLICAS , cluster ( ) . numDataNodes ( ) - <int> ) . put ( MergePolicyConfig . INDEX_MERGE_ENABLED , false ) . put ( MockFSIndexStore . CHECK_INDEX_ON_CLOSE , false ) . put ( IndexShard . INDEX_TRANSLOG_DISABLE_FLUSH , true ) . put ( <str> , <int> ) ) ) ; ensureGreen ( ) ; IndexRequestBuilder [ ] builders = new IndexRequestBuilder [ numDocs ] ; for ( int i = <int> ; i < builders . length ; i + + ) { builders [ i ] = client ( ) . prepareIndex ( <str> , <str> ) . setSource ( <str> , <str> ) ; } indexRandom ( true , builders ) ; ensureGreen ( ) ; assertAllSuccessful ( client ( ) . admin ( ) . indices ( ) . prepareFlush ( ) . setForce ( true ) . setWaitIfOngoing ( true ) . execute ( ) . actionGet ( ) ) ; SearchResponse countResponse = client ( ) . prepareSearch ( ) . setSize ( <int> ) . get ( ) ; assertHitCount ( countResponse , numDocs ) ; final Map < String , List < Path > > filesToCorrupt = findFilesToCorruptForReplica ( ) ; internalCluster ( ) . fullRestart ( new InternalTestCluster . RestartCallback ( ) { @Override public Settings onNodeStopped ( String nodeName ) throws Exception { List < Path > paths = filesToCorrupt . get ( nodeName ) ; if ( paths ! = null ) { for ( Path path : paths ) { try ( OutputStream os = Files . newOutputStream ( path ) ) { os . write ( <int> ) ; } logger . info ( <str> , path , nodeName ) ; } } return null ; } } ) ; ensureGreen ( ) ; } private int numShards ( String . . . index ) { ClusterState state = client ( ) . admin ( ) . cluster ( ) . prepareState ( ) . get ( ) . getState ( ) ; GroupShardsIterator shardIterators = state . getRoutingNodes ( ) . getRoutingTable ( ) . activePrimaryShardsGrouped ( index , false ) ; return shardIterators . size ( ) ; } private Map < String , List < Path > > findFilesToCorruptForReplica ( ) throws IOException { Map < String , List < Path > > filesToNodes = new HashMap < > ( ) ; ClusterState state = client ( ) . admin ( ) . cluster ( ) . prepareState ( ) . get ( ) . getState ( ) ; for ( ShardRouting shardRouting : state . getRoutingTable ( ) . allShards ( <str> ) ) { if ( shardRouting . primary ( ) = = true ) { continue ; } assertTrue ( shardRouting . assignedToNode ( ) ) ; NodesStatsResponse nodeStatses = client ( ) . admin ( ) . cluster ( ) . prepareNodesStats ( shardRouting . currentNodeId ( ) ) . setFs ( true ) . get ( ) ; NodeStats nodeStats = nodeStatses . getNodes ( ) [ <int> ] ; List < Path > files = new ArrayList < > ( ) ; filesToNodes . put ( nodeStats . getNode ( ) . getName ( ) , files ) ; for ( FsInfo . Path info : nodeStats . getFs ( ) ) { String path = info . getPath ( ) ; final String relativeDataLocationPath = <str> + Integer . toString ( shardRouting . getId ( ) ) + <str> ; Path file = PathUtils . get ( path ) . resolve ( relativeDataLocationPath ) ; if ( Files . exists ( file ) ) { try ( DirectoryStream < Path > stream = Files . newDirectoryStream ( file ) ) { for ( Path item : stream ) { if ( item . getFileName ( ) . toString ( ) . startsWith ( <str> ) ) { files . add ( item ) ; } } } } } } return filesToNodes ; } private ShardRouting corruptRandomPrimaryFile ( ) throws IOException { return corruptRandomPrimaryFile ( true ) ; } private ShardRouting corruptRandomPrimaryFile ( final boolean includePerCommitFiles ) throws IOException { ClusterState state = client ( ) . admin ( ) . cluster ( ) . prepareState ( ) . get ( ) . getState ( ) ; GroupShardsIterator shardIterators = state . getRoutingNodes ( ) . getRoutingTable ( ) . activePrimaryShardsGrouped ( new String [ ] { <str> } , false ) ; List < ShardIterator > iterators = iterableAsArrayList ( shardIterators ) ; ShardIterator shardIterator = RandomPicks . randomFrom ( getRandom ( ) , iterators ) ; ShardRouting shardRouting = shardIterator . nextOrNull ( ) ; assertNotNull ( shardRouting ) ; assertTrue ( shardRouting . primary ( ) ) ; assertTrue ( shardRouting . assignedToNode ( ) ) ; String nodeId = shardRouting . currentNodeId ( ) ; NodesStatsResponse nodeStatses = client ( ) . admin ( ) . cluster ( ) . prepareNodesStats ( nodeId ) . setFs ( true ) . get ( ) ; Set < Path > files = new TreeSet < > ( ) ; for ( FsInfo . Path info : nodeStatses . getNodes ( ) [ <int> ] . getFs ( ) ) { String path = info . getPath ( ) ; final String relativeDataLocationPath = <str> + Integer . toString ( shardRouting . getId ( ) ) + <str> ; Path file = PathUtils . get ( path ) . resolve ( relativeDataLocationPath ) ; if ( Files . exists ( file ) ) { try ( DirectoryStream < Path > stream = Files . newDirectoryStream ( file ) ) { for ( Path item : stream ) { if ( Files . isRegularFile ( item ) & & <str> . equals ( item . getFileName ( ) . toString ( ) ) = = false ) { if ( includePerCommitFiles | | isPerSegmentFile ( item . getFileName ( ) . toString ( ) ) ) { files . add ( item ) ; } } } } } } pruneOldDeleteGenerations ( files ) ; CorruptionUtils . corruptFile ( getRandom ( ) , files . toArray ( new Path [ <int> ] ) ) ; return shardRouting ; } private static final boolean isPerCommitFile ( String fileName ) { return fileName . startsWith ( <str> ) | | fileName . endsWith ( <str> ) ; } private static final boolean isPerSegmentFile ( String fileName ) { return isPerCommitFile ( fileName ) = = false ; } private void pruneOldDeleteGenerations ( Set < Path > files ) { final TreeSet < Path > delFiles = new TreeSet < > ( ) ; for ( Path file : files ) { if ( file . getFileName ( ) . toString ( ) . endsWith ( <str> ) ) { delFiles . add ( file ) ; } } Path last = null ; for ( Path current : delFiles ) { if ( last ! = null ) { final String newSegmentName = IndexFileNames . parseSegmentName ( current . getFileName ( ) . toString ( ) ) ; final String oldSegmentName = IndexFileNames . parseSegmentName ( last . getFileName ( ) . toString ( ) ) ; if ( newSegmentName . equals ( oldSegmentName ) ) { int oldGen = Integer . parseInt ( IndexFileNames . stripExtension ( IndexFileNames . stripSegmentName ( last . getFileName ( ) . toString ( ) ) ) . replace ( <str> , <str> ) , Character . MAX_RADIX ) ; int newGen = Integer . parseInt ( IndexFileNames . stripExtension ( IndexFileNames . stripSegmentName ( current . getFileName ( ) . toString ( ) ) ) . replace ( <str> , <str> ) , Character . MAX_RADIX ) ; if ( newGen > oldGen ) { files . remove ( last ) ; } else { files . remove ( current ) ; continue ; } } } last = current ; } } public List < Path > listShardFiles ( ShardRouting routing ) throws IOException { NodesStatsResponse nodeStatses = client ( ) . admin ( ) . cluster ( ) . prepareNodesStats ( routing . currentNodeId ( ) ) . setFs ( true ) . get ( ) ; assertThat ( routing . toString ( ) , nodeStatses . getNodes ( ) . length , equalTo ( <int> ) ) ; List < Path > files = new ArrayList < > ( ) ; for ( FsInfo . Path info : nodeStatses . getNodes ( ) [ <int> ] . getFs ( ) ) { String path = info . getPath ( ) ; Path file = PathUtils . get ( path ) . resolve ( <str> + Integer . toString ( routing . getId ( ) ) + <str> ) ; if ( Files . exists ( file ) ) { try ( DirectoryStream < Path > stream = Files . newDirectoryStream ( file ) ) { for ( Path item : stream ) { files . add ( item ) ; } } } } return files ; } } 
