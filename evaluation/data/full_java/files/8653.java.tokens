package org . elasticsearch . index . analysis ; import com . ibm . icu . text . Collator ; import com . ibm . icu . text . RawCollationKey ; import org . apache . lucene . analysis . TokenFilter ; import org . apache . lucene . analysis . TokenStream ; import org . apache . lucene . analysis . tokenattributes . CharTermAttribute ; import org . apache . lucene . collation . ICUCollationDocValuesField ; import java . io . IOException ; @Deprecated public final class ICUCollationKeyFilter extends TokenFilter { private Collator collator = null ; private RawCollationKey reusableKey = new RawCollationKey ( ) ; private final CharTermAttribute termAtt = addAttribute ( CharTermAttribute . class ) ; public ICUCollationKeyFilter ( TokenStream input , Collator collator ) { super ( input ) ; try { this . collator = ( Collator ) collator . clone ( ) ; } catch ( CloneNotSupportedException e ) { throw new RuntimeException ( e ) ; } } @Override public boolean incrementToken ( ) throws IOException { if ( input . incrementToken ( ) ) { char [ ] termBuffer = termAtt . buffer ( ) ; String termText = new String ( termBuffer , <int> , termAtt . length ( ) ) ; collator . getRawCollationKey ( termText , reusableKey ) ; int encodedLength = IndexableBinaryStringTools . getEncodedLength ( reusableKey . bytes , <int> , reusableKey . size ) ; if ( encodedLength > termBuffer . length ) { termAtt . resizeBuffer ( encodedLength ) ; } termAtt . setLength ( encodedLength ) ; IndexableBinaryStringTools . encode ( reusableKey . bytes , <int> , reusableKey . size , termAtt . buffer ( ) , <int> , encodedLength ) ; return true ; } else { return false ; } } } 
