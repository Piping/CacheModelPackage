package org . elasticsearch . search . dfs ; import com . carrotsearch . hppc . ObjectObjectHashMap ; import com . carrotsearch . hppc . cursors . ObjectObjectCursor ; import org . apache . lucene . index . Term ; import org . apache . lucene . search . CollectionStatistics ; import org . apache . lucene . search . TermStatistics ; import org . elasticsearch . common . collect . HppcMaps ; import org . elasticsearch . common . io . stream . StreamInput ; import org . elasticsearch . common . io . stream . StreamOutput ; import org . elasticsearch . common . io . stream . Streamable ; import java . io . IOException ; public class AggregatedDfs implements Streamable { private ObjectObjectHashMap < Term , TermStatistics > termStatistics ; private ObjectObjectHashMap < String , CollectionStatistics > fieldStatistics ; private long maxDoc ; private AggregatedDfs ( ) { } public AggregatedDfs ( ObjectObjectHashMap < Term , TermStatistics > termStatistics , ObjectObjectHashMap < String , CollectionStatistics > fieldStatistics , long maxDoc ) { this . termStatistics = termStatistics ; this . fieldStatistics = fieldStatistics ; this . maxDoc = maxDoc ; } public ObjectObjectHashMap < Term , TermStatistics > termStatistics ( ) { return termStatistics ; } public ObjectObjectHashMap < String , CollectionStatistics > fieldStatistics ( ) { return fieldStatistics ; } public long maxDoc ( ) { return maxDoc ; } public static AggregatedDfs readAggregatedDfs ( StreamInput in ) throws IOException { AggregatedDfs result = new AggregatedDfs ( ) ; result . readFrom ( in ) ; return result ; } @Override public void readFrom ( StreamInput in ) throws IOException { int size = in . readVInt ( ) ; termStatistics = HppcMaps . newMap ( size ) ; for ( int i = <int> ; i < size ; i + + ) { Term term = new Term ( in . readString ( ) , in . readBytesRef ( ) ) ; TermStatistics stats = new TermStatistics ( in . readBytesRef ( ) , in . readVLong ( ) , DfsSearchResult . subOne ( in . readVLong ( ) ) ) ; termStatistics . put ( term , stats ) ; } fieldStatistics = DfsSearchResult . readFieldStats ( in ) ; maxDoc = in . readVLong ( ) ; } @Override public void writeTo ( final StreamOutput out ) throws IOException { out . writeVInt ( termStatistics . size ( ) ) ; for ( ObjectObjectCursor < Term , TermStatistics > c : termStatistics ( ) ) { Term term = ( Term ) c . key ; out . writeString ( term . field ( ) ) ; out . writeBytesRef ( term . bytes ( ) ) ; TermStatistics stats = ( TermStatistics ) c . value ; out . writeBytesRef ( stats . term ( ) ) ; out . writeVLong ( stats . docFreq ( ) ) ; out . writeVLong ( DfsSearchResult . addOne ( stats . totalTermFreq ( ) ) ) ; } DfsSearchResult . writeFieldStats ( out , fieldStatistics ) ; out . writeVLong ( maxDoc ) ; } } 
