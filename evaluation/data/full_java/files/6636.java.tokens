package org . elasticsearch . index . query ; import org . elasticsearch . common . ParseField ; import org . elasticsearch . common . ParsingException ; import org . elasticsearch . common . xcontent . XContentParser ; import org . elasticsearch . index . query . MoreLikeThisQueryBuilder . Item ; import java . io . IOException ; import java . util . ArrayList ; import java . util . List ; public class MoreLikeThisQueryParser implements QueryParser < MoreLikeThisQueryBuilder > { public interface Field { ParseField FIELDS = new ParseField ( <str> ) ; ParseField LIKE = new ParseField ( <str> ) ; ParseField UNLIKE = new ParseField ( <str> ) ; ParseField LIKE_TEXT = new ParseField ( <str> ) . withAllDeprecated ( <str> ) ; ParseField IDS = new ParseField ( <str> ) . withAllDeprecated ( <str> ) ; ParseField DOCS = new ParseField ( <str> ) . withAllDeprecated ( <str> ) ; ParseField MAX_QUERY_TERMS = new ParseField ( <str> ) ; ParseField MIN_TERM_FREQ = new ParseField ( <str> ) ; ParseField MIN_DOC_FREQ = new ParseField ( <str> ) ; ParseField MAX_DOC_FREQ = new ParseField ( <str> ) ; ParseField MIN_WORD_LENGTH = new ParseField ( <str> , <str> ) ; ParseField MAX_WORD_LENGTH = new ParseField ( <str> , <str> ) ; ParseField STOP_WORDS = new ParseField ( <str> ) ; ParseField ANALYZER = new ParseField ( <str> ) ; ParseField MINIMUM_SHOULD_MATCH = new ParseField ( <str> ) ; ParseField BOOST_TERMS = new ParseField ( <str> ) ; ParseField INCLUDE = new ParseField ( <str> ) ; ParseField FAIL_ON_UNSUPPORTED_FIELD = new ParseField ( <str> ) ; } @Override public String [ ] names ( ) { return new String [ ] { MoreLikeThisQueryBuilder . NAME , <str> , <str> } ; } @Override public MoreLikeThisQueryBuilder fromXContent ( QueryParseContext parseContext ) throws IOException { XContentParser parser = parseContext . parser ( ) ; List < String > fields = null ; List < String > likeTexts = new ArrayList < > ( ) ; List < String > unlikeTexts = new ArrayList < > ( ) ; List < Item > likeItems = new ArrayList < > ( ) ; List < Item > unlikeItems = new ArrayList < > ( ) ; int maxQueryTerms = MoreLikeThisQueryBuilder . DEFAULT_MAX_QUERY_TERMS ; int minTermFreq = MoreLikeThisQueryBuilder . DEFAULT_MIN_TERM_FREQ ; int minDocFreq = MoreLikeThisQueryBuilder . DEFAULT_MIN_DOC_FREQ ; int maxDocFreq = MoreLikeThisQueryBuilder . DEFAULT_MAX_DOC_FREQ ; int minWordLength = MoreLikeThisQueryBuilder . DEFAULT_MIN_WORD_LENGTH ; int maxWordLength = MoreLikeThisQueryBuilder . DEFAULT_MAX_WORD_LENGTH ; List < String > stopWords = null ; String analyzer = null ; String minimumShouldMatch = MoreLikeThisQueryBuilder . DEFAULT_MINIMUM_SHOULD_MATCH ; float boostTerms = MoreLikeThisQueryBuilder . DEFAULT_BOOST_TERMS ; boolean include = MoreLikeThisQueryBuilder . DEFAULT_INCLUDE ; boolean failOnUnsupportedField = MoreLikeThisQueryBuilder . DEFAULT_FAIL_ON_UNSUPPORTED_FIELDS ; float boost = AbstractQueryBuilder . DEFAULT_BOOST ; String queryName = null ; XContentParser . Token token ; String currentFieldName = null ; while ( ( token = parser . nextToken ( ) ) ! = XContentParser . Token . END_OBJECT ) { if ( token = = XContentParser . Token . FIELD_NAME ) { currentFieldName = parser . currentName ( ) ; } else if ( token . isValue ( ) ) { if ( parseContext . parseFieldMatcher ( ) . match ( currentFieldName , Field . LIKE ) ) { parseLikeField ( parseContext , likeTexts , likeItems ) ; } else if ( parseContext . parseFieldMatcher ( ) . match ( currentFieldName , Field . UNLIKE ) ) { parseLikeField ( parseContext , unlikeTexts , unlikeItems ) ; } else if ( parseContext . parseFieldMatcher ( ) . match ( currentFieldName , Field . LIKE_TEXT ) ) { likeTexts . add ( parser . text ( ) ) ; } else if ( parseContext . parseFieldMatcher ( ) . match ( currentFieldName , Field . MAX_QUERY_TERMS ) ) { maxQueryTerms = parser . intValue ( ) ; } else if ( parseContext . parseFieldMatcher ( ) . match ( currentFieldName , Field . MIN_TERM_FREQ ) ) { minTermFreq = parser . intValue ( ) ; } else if ( parseContext . parseFieldMatcher ( ) . match ( currentFieldName , Field . MIN_DOC_FREQ ) ) { minDocFreq = parser . intValue ( ) ; } else if ( parseContext . parseFieldMatcher ( ) . match ( currentFieldName , Field . MAX_DOC_FREQ ) ) { maxDocFreq = parser . intValue ( ) ; } else if ( parseContext . parseFieldMatcher ( ) . match ( currentFieldName , Field . MIN_WORD_LENGTH ) ) { minWordLength = parser . intValue ( ) ; } else if ( parseContext . parseFieldMatcher ( ) . match ( currentFieldName , Field . MAX_WORD_LENGTH ) ) { maxWordLength = parser . intValue ( ) ; } else if ( parseContext . parseFieldMatcher ( ) . match ( currentFieldName , Field . ANALYZER ) ) { analyzer = parser . text ( ) ; } else if ( parseContext . parseFieldMatcher ( ) . match ( currentFieldName , Field . MINIMUM_SHOULD_MATCH ) ) { minimumShouldMatch = parser . text ( ) ; } else if ( parseContext . parseFieldMatcher ( ) . match ( currentFieldName , Field . BOOST_TERMS ) ) { boostTerms = parser . floatValue ( ) ; } else if ( parseContext . parseFieldMatcher ( ) . match ( currentFieldName , Field . INCLUDE ) ) { include = parser . booleanValue ( ) ; } else if ( parseContext . parseFieldMatcher ( ) . match ( currentFieldName , Field . FAIL_ON_UNSUPPORTED_FIELD ) ) { failOnUnsupportedField = parser . booleanValue ( ) ; } else if ( <str> . equals ( currentFieldName ) ) { boost = parser . floatValue ( ) ; } else if ( <str> . equals ( currentFieldName ) ) { queryName = parser . text ( ) ; } else { throw new ParsingException ( parser . getTokenLocation ( ) , <str> + currentFieldName + <str> ) ; } } else if ( token = = XContentParser . Token . START_ARRAY ) { if ( parseContext . parseFieldMatcher ( ) . match ( currentFieldName , Field . FIELDS ) ) { fields = new ArrayList < > ( ) ; while ( ( token = parser . nextToken ( ) ) ! = XContentParser . Token . END_ARRAY ) { fields . add ( parser . text ( ) ) ; } } else if ( parseContext . parseFieldMatcher ( ) . match ( currentFieldName , Field . LIKE ) ) { while ( ( token = parser . nextToken ( ) ) ! = XContentParser . Token . END_ARRAY ) { parseLikeField ( parseContext , likeTexts , likeItems ) ; } } else if ( parseContext . parseFieldMatcher ( ) . match ( currentFieldName , Field . UNLIKE ) ) { while ( ( token = parser . nextToken ( ) ) ! = XContentParser . Token . END_ARRAY ) { parseLikeField ( parseContext , unlikeTexts , unlikeItems ) ; } } else if ( parseContext . parseFieldMatcher ( ) . match ( currentFieldName , Field . IDS ) ) { while ( ( token = parser . nextToken ( ) ) ! = XContentParser . Token . END_ARRAY ) { if ( ! token . isValue ( ) ) { throw new IllegalArgumentException ( <str> ) ; } likeItems . add ( new Item ( null , null , parser . text ( ) ) ) ; } } else if ( parseContext . parseFieldMatcher ( ) . match ( currentFieldName , Field . DOCS ) ) { while ( ( token = parser . nextToken ( ) ) ! = XContentParser . Token . END_ARRAY ) { if ( token ! = XContentParser . Token . START_OBJECT ) { throw new IllegalArgumentException ( <str> ) ; } likeItems . add ( Item . parse ( parser , parseContext . parseFieldMatcher ( ) , new Item ( ) ) ) ; } } else if ( parseContext . parseFieldMatcher ( ) . match ( currentFieldName , Field . STOP_WORDS ) ) { stopWords = new ArrayList < > ( ) ; while ( ( token = parser . nextToken ( ) ) ! = XContentParser . Token . END_ARRAY ) { stopWords . add ( parser . text ( ) ) ; } } else { throw new ParsingException ( parser . getTokenLocation ( ) , <str> + currentFieldName + <str> ) ; } } else if ( token = = XContentParser . Token . START_OBJECT ) { if ( parseContext . parseFieldMatcher ( ) . match ( currentFieldName , Field . LIKE ) ) { parseLikeField ( parseContext , likeTexts , likeItems ) ; } else if ( parseContext . parseFieldMatcher ( ) . match ( currentFieldName , Field . UNLIKE ) ) { parseLikeField ( parseContext , unlikeTexts , unlikeItems ) ; } else { throw new ParsingException ( parser . getTokenLocation ( ) , <str> + currentFieldName + <str> ) ; } } } if ( likeTexts . isEmpty ( ) & & likeItems . isEmpty ( ) ) { throw new ParsingException ( parser . getTokenLocation ( ) , <str> ) ; } if ( fields ! = null & & fields . isEmpty ( ) ) { throw new ParsingException ( parser . getTokenLocation ( ) , <str> ) ; } String [ ] fieldsArray = fields = = null ? null : fields . toArray ( new String [ fields . size ( ) ] ) ; String [ ] likeTextsArray = likeTexts . isEmpty ( ) ? null : likeTexts . toArray ( new String [ likeTexts . size ( ) ] ) ; String [ ] unlikeTextsArray = unlikeTexts . isEmpty ( ) ? null : unlikeTexts . toArray ( new String [ unlikeTexts . size ( ) ] ) ; Item [ ] likeItemsArray = likeItems . isEmpty ( ) ? null : likeItems . toArray ( new Item [ likeItems . size ( ) ] ) ; Item [ ] unlikeItemsArray = unlikeItems . isEmpty ( ) ? null : unlikeItems . toArray ( new Item [ unlikeItems . size ( ) ] ) ; MoreLikeThisQueryBuilder moreLikeThisQueryBuilder = new MoreLikeThisQueryBuilder ( fieldsArray , likeTextsArray , likeItemsArray ) . unlike ( unlikeTextsArray ) . unlike ( unlikeItemsArray ) . maxQueryTerms ( maxQueryTerms ) . minTermFreq ( minTermFreq ) . minDocFreq ( minDocFreq ) . maxDocFreq ( maxDocFreq ) . minWordLength ( minWordLength ) . maxWordLength ( maxWordLength ) . analyzer ( analyzer ) . minimumShouldMatch ( minimumShouldMatch ) . boostTerms ( boostTerms ) . include ( include ) . failOnUnsupportedField ( failOnUnsupportedField ) . boost ( boost ) . queryName ( queryName ) ; if ( stopWords ! = null ) { moreLikeThisQueryBuilder . stopWords ( stopWords ) ; } return moreLikeThisQueryBuilder ; } private static void parseLikeField ( QueryParseContext parseContext , List < String > texts , List < Item > items ) throws IOException { XContentParser parser = parseContext . parser ( ) ; if ( parser . currentToken ( ) . isValue ( ) ) { texts . add ( parser . text ( ) ) ; } else if ( parser . currentToken ( ) = = XContentParser . Token . START_OBJECT ) { items . add ( Item . parse ( parser , parseContext . parseFieldMatcher ( ) , new Item ( ) ) ) ; } else { throw new IllegalArgumentException ( <str> ) ; } } @Override public MoreLikeThisQueryBuilder getBuilderPrototype ( ) { return MoreLikeThisQueryBuilder . PROTOTYPE ; } } 
