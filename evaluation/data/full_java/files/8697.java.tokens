package org . elasticsearch . index . analysis ; import org . apache . lucene . analysis . Analyzer ; import org . apache . lucene . analysis . TokenStream ; import org . apache . lucene . analysis . Tokenizer ; import org . apache . lucene . analysis . core . KeywordTokenizer ; import org . apache . lucene . analysis . tokenattributes . CharTermAttribute ; import org . elasticsearch . Version ; import org . elasticsearch . cluster . metadata . IndexMetaData ; import org . elasticsearch . common . inject . Injector ; import org . elasticsearch . common . inject . ModulesBuilder ; import org . elasticsearch . common . settings . Settings ; import org . elasticsearch . common . settings . SettingsFilter ; import org . elasticsearch . common . settings . SettingsModule ; import org . elasticsearch . env . Environment ; import org . elasticsearch . env . EnvironmentModule ; import org . elasticsearch . index . Index ; import org . elasticsearch . indices . analysis . AnalysisModule ; import org . elasticsearch . plugin . analysis . stempel . AnalysisStempelPlugin ; import org . elasticsearch . test . ESTestCase ; import org . elasticsearch . test . IndexSettingsModule ; import java . io . IOException ; import java . io . StringReader ; import static org . hamcrest . Matchers . equalTo ; public class SimplePolishTokenFilterTests extends ESTestCase { public void testBasicUsage ( ) throws Exception { testToken ( <str> , <str> ) ; testToken ( <str> , <str> ) ; testToken ( <str> , <str> ) ; testToken ( <str> , <str> ) ; testAnalyzer ( <str> , <str> , <str> ) ; } private void testToken ( String source , String expected ) throws IOException { Index index = new Index ( <str> ) ; Settings settings = Settings . settingsBuilder ( ) . put ( IndexMetaData . SETTING_VERSION_CREATED , Version . CURRENT ) . put ( <str> , createTempDir ( ) ) . put ( <str> , <str> ) . build ( ) ; AnalysisService analysisService = createAnalysisService ( index , settings ) ; TokenFilterFactory filterFactory = analysisService . tokenFilter ( <str> ) ; Tokenizer tokenizer = new KeywordTokenizer ( ) ; tokenizer . setReader ( new StringReader ( source ) ) ; TokenStream ts = filterFactory . create ( tokenizer ) ; CharTermAttribute term1 = ts . addAttribute ( CharTermAttribute . class ) ; ts . reset ( ) ; assertThat ( ts . incrementToken ( ) , equalTo ( true ) ) ; assertThat ( term1 . toString ( ) , equalTo ( expected ) ) ; } private void testAnalyzer ( String source , String . . . expected_terms ) throws IOException { Index index = new Index ( <str> ) ; Settings settings = Settings . settingsBuilder ( ) . put ( IndexMetaData . SETTING_VERSION_CREATED , Version . CURRENT ) . put ( <str> , createTempDir ( ) ) . build ( ) ; AnalysisService analysisService = createAnalysisService ( index , settings ) ; Analyzer analyzer = analysisService . analyzer ( <str> ) . analyzer ( ) ; TokenStream ts = analyzer . tokenStream ( <str> , source ) ; CharTermAttribute term1 = ts . addAttribute ( CharTermAttribute . class ) ; ts . reset ( ) ; for ( String expected : expected_terms ) { assertThat ( ts . incrementToken ( ) , equalTo ( true ) ) ; assertThat ( term1 . toString ( ) , equalTo ( expected ) ) ; } } private AnalysisService createAnalysisService ( Index index , Settings settings ) throws IOException { AnalysisModule analysisModule = new AnalysisModule ( new Environment ( settings ) ) ; new AnalysisStempelPlugin ( ) . onModule ( analysisModule ) ; Injector parentInjector = new ModulesBuilder ( ) . add ( new SettingsModule ( settings , new SettingsFilter ( settings ) ) , new EnvironmentModule ( new Environment ( settings ) ) , analysisModule ) . createInjector ( ) ; return parentInjector . getInstance ( AnalysisRegistry . class ) . build ( IndexSettingsModule . newIndexSettings ( index , settings ) ) ; } } 
