package org . elasticsearch . action . termvectors ; import org . apache . lucene . analysis . Analyzer ; import org . apache . lucene . analysis . TokenFilter ; import org . apache . lucene . analysis . Tokenizer ; import org . apache . lucene . analysis . core . LowerCaseFilter ; import org . apache . lucene . analysis . miscellaneous . PerFieldAnalyzerWrapper ; import org . apache . lucene . analysis . payloads . TypeAsPayloadTokenFilter ; import org . apache . lucene . analysis . standard . StandardAnalyzer ; import org . apache . lucene . analysis . standard . StandardTokenizer ; import org . apache . lucene . analysis . util . CharArraySet ; import org . apache . lucene . document . * ; import org . apache . lucene . index . * ; import org . apache . lucene . search . IndexSearcher ; import org . apache . lucene . search . ScoreDoc ; import org . apache . lucene . search . TermQuery ; import org . apache . lucene . search . TopDocs ; import org . apache . lucene . store . Directory ; import org . apache . lucene . store . RAMDirectory ; import org . elasticsearch . action . admin . indices . alias . Alias ; import org . elasticsearch . common . inject . internal . Join ; import org . elasticsearch . common . settings . Settings ; import org . elasticsearch . common . xcontent . XContentBuilder ; import org . elasticsearch . test . ESIntegTestCase ; import java . io . IOException ; import java . util . * ; import static org . elasticsearch . common . xcontent . XContentFactory . jsonBuilder ; import static org . elasticsearch . test . hamcrest . ElasticsearchAssertions . assertAcked ; import static org . hamcrest . Matchers . equalTo ; public abstract class AbstractTermVectorsTestCase extends ESIntegTestCase { protected static class TestFieldSetting { final public String name ; final public boolean storedOffset ; final public boolean storedPayloads ; final public boolean storedPositions ; public TestFieldSetting ( String name , boolean storedOffset , boolean storedPayloads , boolean storedPositions ) { this . name = name ; this . storedOffset = storedOffset ; this . storedPayloads = storedPayloads ; this . storedPositions = storedPositions ; } public void addToMappings ( XContentBuilder mappingsBuilder ) throws IOException { mappingsBuilder . startObject ( name ) ; mappingsBuilder . field ( <str> , <str> ) ; String tv_settings ; if ( storedPositions & & storedOffset & & storedPayloads ) { tv_settings = <str> ; } else if ( storedPositions & & storedOffset ) { tv_settings = <str> ; } else if ( storedPayloads ) { tv_settings = <str> ; } else if ( storedPositions ) { tv_settings = <str> ; } else if ( storedOffset ) { tv_settings = <str> ; } else { tv_settings = <str> ; } mappingsBuilder . field ( <str> , tv_settings ) ; if ( storedPayloads ) { mappingsBuilder . field ( <str> , <str> ) ; } mappingsBuilder . endObject ( ) ; } @Override public String toString ( ) { StringBuilder sb = new StringBuilder ( <str> ) . append ( name ) . append ( <str> ) ; if ( storedPayloads ) { sb . append ( <str> ) ; } if ( storedOffset ) { sb . append ( <str> ) ; } if ( storedPositions ) { sb . append ( <str> ) ; } return sb . toString ( ) ; } } protected static class TestDoc { final public String id ; final public TestFieldSetting [ ] fieldSettings ; final public String [ ] fieldContent ; public String index = <str> ; public String alias = <str> ; public String type = <str> ; public TestDoc ( String id , TestFieldSetting [ ] fieldSettings , String [ ] fieldContent ) { this . id = id ; assertEquals ( fieldSettings . length , fieldContent . length ) ; this . fieldSettings = fieldSettings ; this . fieldContent = fieldContent ; } public TestDoc index ( String index ) { this . index = index ; return this ; } public TestDoc alias ( String alias ) { this . alias = alias ; return this ; } @Override public String toString ( ) { StringBuilder sb = new StringBuilder ( <str> ) . append ( index ) . append ( <str> ) . append ( type ) . append ( <str> ) . append ( id ) ; for ( int i = <int> ; i < fieldSettings . length ; i + + ) { TestFieldSetting f = fieldSettings [ i ] ; sb . append ( <str> ) . append ( <str> ) . append ( f ) . append ( <str> ) . append ( fieldContent [ i ] ) ; } sb . append ( <str> ) ; return sb . toString ( ) ; } } protected static class TestConfig { final public TestDoc doc ; final public String [ ] selectedFields ; final public boolean requestPositions ; final public boolean requestOffsets ; final public boolean requestPayloads ; public Class expectedException = null ; public TestConfig ( TestDoc doc , String [ ] selectedFields , boolean requestPositions , boolean requestOffsets , boolean requestPayloads ) { this . doc = doc ; this . selectedFields = selectedFields ; this . requestPositions = requestPositions ; this . requestOffsets = requestOffsets ; this . requestPayloads = requestPayloads ; } public TestConfig expectedException ( Class exceptionClass ) { this . expectedException = exceptionClass ; return this ; } @Override public String toString ( ) { String requested = <str> ; if ( requestOffsets ) { requested + = <str> ; } if ( requestPositions ) { requested + = <str> ; } if ( requestPayloads ) { requested + = <str> ; } Locale aLocale = new Locale ( <str> , <str> ) ; return String . format ( aLocale , <str> , doc , requested , selectedFields = = null ? <str> : Join . join ( <str> , selectedFields ) ) ; } } protected void createIndexBasedOnFieldSettings ( String index , String alias , TestFieldSetting [ ] fieldSettings ) throws IOException { XContentBuilder mappingBuilder = jsonBuilder ( ) ; mappingBuilder . startObject ( ) . startObject ( <str> ) . startObject ( <str> ) ; for ( TestFieldSetting field : fieldSettings ) { field . addToMappings ( mappingBuilder ) ; } mappingBuilder . endObject ( ) . endObject ( ) . endObject ( ) ; Settings . Builder settings = Settings . settingsBuilder ( ) . put ( indexSettings ( ) ) . put ( <str> , <str> ) . putArray ( <str> , <str> , <str> ) ; assertAcked ( prepareCreate ( index ) . addMapping ( <str> , mappingBuilder ) . setSettings ( settings ) . addAlias ( new Alias ( alias ) ) ) ; ensureYellow ( ) ; } protected TestDoc [ ] generateTestDocs ( String index , TestFieldSetting [ ] fieldSettings ) { String [ ] fieldContentOptions = new String [ ] { <str> , <str> , <str> , <str> , <str> } ; String [ ] contentArray = new String [ fieldSettings . length ] ; Map < String , Object > docSource = new HashMap < > ( ) ; int totalShards = getNumShards ( index ) . numPrimaries ; TestDoc [ ] testDocs = new TestDoc [ totalShards ] ; for ( int i = <int> ; i < totalShards ; i + + ) { docSource . clear ( ) ; for ( int j = <int> ; j < contentArray . length ; j + + ) { contentArray [ j ] = fieldContentOptions [ randomInt ( fieldContentOptions . length - <int> ) ] ; docSource . put ( fieldSettings [ j ] . name , contentArray [ j ] ) ; } final String id = routingKeyForShard ( index , <str> , i ) ; TestDoc doc = new TestDoc ( id , fieldSettings , contentArray . clone ( ) ) ; index ( doc . index , doc . type , doc . id , docSource ) ; testDocs [ i ] = doc ; } refresh ( ) ; return testDocs ; } protected TestConfig [ ] generateTestConfigs ( int numberOfTests , TestDoc [ ] testDocs , TestFieldSetting [ ] fieldSettings ) { ArrayList < TestConfig > configs = new ArrayList < > ( ) ; for ( int i = <int> ; i < numberOfTests ; i + + ) { ArrayList < String > selectedFields = null ; if ( randomBoolean ( ) ) { selectedFields = new ArrayList < > ( ) ; if ( randomBoolean ( ) ) { selectedFields . add ( <str> ) ; } for ( TestFieldSetting field : fieldSettings ) if ( randomBoolean ( ) ) { selectedFields . add ( field . name ) ; } if ( selectedFields . size ( ) = = <int> ) { selectedFields = null ; } } TestConfig config = new TestConfig ( testDocs [ randomInt ( testDocs . length - <int> ) ] , selectedFields = = null ? null : selectedFields . toArray ( new String [ ] { } ) , randomBoolean ( ) , randomBoolean ( ) , randomBoolean ( ) ) ; configs . add ( config ) ; } configs . add ( new TestConfig ( new TestDoc ( <str> , new TestFieldSetting [ ] { } , new String [ ] { } ) . index ( <str> ) . alias ( <str> ) , new String [ ] { <str> } , true , true , true ) . expectedException ( org . elasticsearch . index . IndexNotFoundException . class ) ) ; refresh ( ) ; return configs . toArray ( new TestConfig [ configs . size ( ) ] ) ; } protected TestFieldSetting [ ] getFieldSettings ( ) { return new TestFieldSetting [ ] { new TestFieldSetting ( <str> , false , false , true ) , new TestFieldSetting ( <str> , true , false , false ) , new TestFieldSetting ( <str> , false , false , false ) , new TestFieldSetting ( <str> , false , false , true ) , new TestFieldSetting ( <str> , false , true , true ) } ; } protected DirectoryReader indexDocsWithLucene ( TestDoc [ ] testDocs ) throws IOException { Map < String , Analyzer > mapping = new HashMap < > ( ) ; for ( TestFieldSetting field : testDocs [ <int> ] . fieldSettings ) { if ( field . storedPayloads ) { mapping . put ( field . name , new Analyzer ( ) { @Override protected TokenStreamComponents createComponents ( String fieldName ) { Tokenizer tokenizer = new StandardTokenizer ( ) ; TokenFilter filter = new LowerCaseFilter ( tokenizer ) ; filter = new TypeAsPayloadTokenFilter ( filter ) ; return new TokenStreamComponents ( tokenizer , filter ) ; } } ) ; } } PerFieldAnalyzerWrapper wrapper = new PerFieldAnalyzerWrapper ( new StandardAnalyzer ( CharArraySet . EMPTY_SET ) , mapping ) ; Directory dir = new RAMDirectory ( ) ; IndexWriterConfig conf = new IndexWriterConfig ( wrapper ) ; conf . setOpenMode ( IndexWriterConfig . OpenMode . CREATE ) ; IndexWriter writer = new IndexWriter ( dir , conf ) ; for ( TestDoc doc : testDocs ) { Document d = new Document ( ) ; d . add ( new Field ( <str> , doc . id , StringField . TYPE_STORED ) ) ; for ( int i = <int> ; i < doc . fieldContent . length ; i + + ) { FieldType type = new FieldType ( TextField . TYPE_STORED ) ; TestFieldSetting fieldSetting = doc . fieldSettings [ i ] ; type . setStoreTermVectorOffsets ( fieldSetting . storedOffset ) ; type . setStoreTermVectorPayloads ( fieldSetting . storedPayloads ) ; type . setStoreTermVectorPositions ( fieldSetting . storedPositions | | fieldSetting . storedPayloads | | fieldSetting . storedOffset ) ; type . setStoreTermVectors ( true ) ; type . freeze ( ) ; d . add ( new Field ( fieldSetting . name , doc . fieldContent [ i ] , type ) ) ; } writer . updateDocument ( new Term ( <str> , doc . id ) , d ) ; writer . commit ( ) ; } writer . close ( ) ; return DirectoryReader . open ( dir ) ; } protected void validateResponse ( TermVectorsResponse esResponse , Fields luceneFields , TestConfig testConfig ) throws IOException { assertThat ( esResponse . getIndex ( ) , equalTo ( testConfig . doc . index ) ) ; TestDoc testDoc = testConfig . doc ; HashSet < String > selectedFields = testConfig . selectedFields = = null ? null : new HashSet < > ( Arrays . asList ( testConfig . selectedFields ) ) ; Fields esTermVectorFields = esResponse . getFields ( ) ; for ( TestFieldSetting field : testDoc . fieldSettings ) { Terms esTerms = esTermVectorFields . terms ( field . name ) ; if ( selectedFields ! = null & & ! selectedFields . contains ( field . name ) ) { assertNull ( esTerms ) ; continue ; } assertNotNull ( esTerms ) ; Terms luceneTerms = luceneFields . terms ( field . name ) ; TermsEnum esTermEnum = esTerms . iterator ( ) ; TermsEnum luceneTermEnum = luceneTerms . iterator ( ) ; while ( esTermEnum . next ( ) ! = null ) { assertNotNull ( luceneTermEnum . next ( ) ) ; assertThat ( esTermEnum . totalTermFreq ( ) , equalTo ( luceneTermEnum . totalTermFreq ( ) ) ) ; PostingsEnum esDocsPosEnum = esTermEnum . postings ( null , PostingsEnum . POSITIONS ) ; PostingsEnum luceneDocsPosEnum = luceneTermEnum . postings ( null , PostingsEnum . POSITIONS ) ; if ( luceneDocsPosEnum = = null ) { assertFalse ( field . storedOffset ) ; assertFalse ( field . storedPayloads ) ; assertFalse ( field . storedPositions ) ; continue ; } String currentTerm = esTermEnum . term ( ) . utf8ToString ( ) ; assertThat ( <str> + field . name , currentTerm , equalTo ( luceneTermEnum . term ( ) . utf8ToString ( ) ) ) ; esDocsPosEnum . nextDoc ( ) ; luceneDocsPosEnum . nextDoc ( ) ; int freq = esDocsPosEnum . freq ( ) ; assertThat ( freq , equalTo ( luceneDocsPosEnum . freq ( ) ) ) ; for ( int i = <int> ; i < freq ; i + + ) { String failDesc = <str> + field . name + <str> + currentTerm + <str> ; int lucenePos = luceneDocsPosEnum . nextPosition ( ) ; int esPos = esDocsPosEnum . nextPosition ( ) ; if ( field . storedPositions & & testConfig . requestPositions ) { assertThat ( <str> + failDesc , lucenePos , equalTo ( esPos ) ) ; } else { assertThat ( <str> + failDesc , esPos , equalTo ( - <int> ) ) ; } if ( field . storedOffset & & testConfig . requestOffsets ) { assertThat ( <str> + failDesc , luceneDocsPosEnum . startOffset ( ) , equalTo ( esDocsPosEnum . startOffset ( ) ) ) ; assertThat ( <str> + failDesc , luceneDocsPosEnum . endOffset ( ) , equalTo ( esDocsPosEnum . endOffset ( ) ) ) ; } else { assertThat ( <str> + failDesc , esDocsPosEnum . startOffset ( ) , equalTo ( - <int> ) ) ; assertThat ( <str> + failDesc , esDocsPosEnum . endOffset ( ) , equalTo ( - <int> ) ) ; } if ( field . storedPayloads & & testConfig . requestPayloads ) { assertThat ( <str> + failDesc , luceneDocsPosEnum . getPayload ( ) , equalTo ( esDocsPosEnum . getPayload ( ) ) ) ; } else { assertThat ( <str> + failDesc , esDocsPosEnum . getPayload ( ) , equalTo ( null ) ) ; } } } assertNull ( <str> , luceneTermEnum . next ( ) ) ; } } protected TermVectorsRequestBuilder getRequestForConfig ( TestConfig config ) { return client ( ) . prepareTermVectors ( randomBoolean ( ) ? config . doc . index : config . doc . alias , config . doc . type , config . doc . id ) . setPayloads ( config . requestPayloads ) . setOffsets ( config . requestOffsets ) . setPositions ( config . requestPositions ) . setFieldStatistics ( true ) . setTermStatistics ( true ) . setSelectedFields ( config . selectedFields ) ; } protected Fields getTermVectorsFromLucene ( DirectoryReader directoryReader , TestDoc doc ) throws IOException { IndexSearcher searcher = new IndexSearcher ( directoryReader ) ; TopDocs search = searcher . search ( new TermQuery ( new Term ( <str> , doc . id ) ) , <int> ) ; ScoreDoc [ ] scoreDocs = search . scoreDocs ; assertEquals ( <int> , scoreDocs . length ) ; return directoryReader . getTermVectors ( scoreDocs [ <int> ] . doc ) ; } } 
