package org . elasticsearch . indices . recovery ; import org . apache . lucene . index . CorruptIndexException ; import org . apache . lucene . index . IndexCommit ; import org . apache . lucene . index . IndexFormatTooNewException ; import org . apache . lucene . index . IndexFormatTooOldException ; import org . apache . lucene . store . IOContext ; import org . apache . lucene . store . IndexInput ; import org . apache . lucene . store . RateLimiter ; import org . apache . lucene . util . ArrayUtil ; import org . apache . lucene . util . IOUtils ; import org . elasticsearch . ElasticsearchException ; import org . elasticsearch . ExceptionsHelper ; import org . elasticsearch . common . Nullable ; import org . elasticsearch . common . StopWatch ; import org . elasticsearch . common . bytes . BytesArray ; import org . elasticsearch . common . io . Streams ; import org . elasticsearch . common . logging . ESLogger ; import org . elasticsearch . common . lucene . store . InputStreamIndexInput ; import org . elasticsearch . common . unit . ByteSizeUnit ; import org . elasticsearch . common . unit . ByteSizeValue ; import org . elasticsearch . common . unit . TimeValue ; import org . elasticsearch . common . util . CancellableThreads ; import org . elasticsearch . common . util . CancellableThreads . Interruptable ; import org . elasticsearch . index . engine . RecoveryEngineException ; import org . elasticsearch . index . shard . * ; import org . elasticsearch . index . store . Store ; import org . elasticsearch . index . store . StoreFileMetaData ; import org . elasticsearch . index . translog . Translog ; import org . elasticsearch . transport . EmptyTransportResponseHandler ; import org . elasticsearch . transport . RemoteTransportException ; import org . elasticsearch . transport . TransportRequestOptions ; import org . elasticsearch . transport . TransportService ; import java . io . BufferedOutputStream ; import java . io . IOException ; import java . io . OutputStream ; import java . util . ArrayList ; import java . util . Comparator ; import java . util . List ; import java . util . concurrent . ExecutionException ; import java . util . concurrent . Future ; import java . util . concurrent . ThreadPoolExecutor ; import java . util . concurrent . atomic . AtomicBoolean ; import java . util . concurrent . atomic . AtomicLong ; import java . util . function . Function ; import java . util . stream . StreamSupport ; public class RecoverySourceHandler { protected final ESLogger logger ; private final IndexShard shard ; private final String indexName ; private final int shardId ; private final StartRecoveryRequest request ; private final RecoverySettings recoverySettings ; private final TransportService transportService ; private final int chunkSizeInBytes ; protected final RecoveryResponse response ; private final CancellableThreads cancellableThreads = new CancellableThreads ( ) { @Override protected void onCancel ( String reason , @Nullable Throwable suppressedException ) { RuntimeException e ; if ( shard . state ( ) = = IndexShardState . CLOSED ) { e = new IndexShardClosedException ( shard . shardId ( ) , <str> + reason + <str> ) ; } else { e = new ExecutionCancelledException ( <str> + reason + <str> ) ; } if ( suppressedException ! = null ) { e . addSuppressed ( suppressedException ) ; } throw e ; } } ; public RecoverySourceHandler ( final IndexShard shard , final StartRecoveryRequest request , final RecoverySettings recoverySettings , final TransportService transportService , final ESLogger logger ) { this . shard = shard ; this . request = request ; this . recoverySettings = recoverySettings ; this . logger = logger ; this . transportService = transportService ; this . indexName = this . request . shardId ( ) . index ( ) . name ( ) ; this . shardId = this . request . shardId ( ) . id ( ) ; this . chunkSizeInBytes = recoverySettings . getChunkSize ( ) . bytesAsInt ( ) ; this . response = new RecoveryResponse ( ) ; } public RecoveryResponse recoverToTarget ( ) { try ( Translog . View translogView = shard . acquireTranslogView ( ) ) { logger . trace ( <str> , translogView . minTranslogGeneration ( ) ) ; final IndexCommit phase1Snapshot ; try { phase1Snapshot = shard . snapshotIndex ( false ) ; } catch ( Throwable e ) { IOUtils . closeWhileHandlingException ( translogView ) ; throw new RecoveryEngineException ( shard . shardId ( ) , <int> , <str> , e ) ; } try { phase1 ( phase1Snapshot , translogView ) ; } catch ( Throwable e ) { throw new RecoveryEngineException ( shard . shardId ( ) , <int> , <str> , e ) ; } finally { try { shard . releaseSnapshot ( phase1Snapshot ) ; } catch ( IOException ex ) { logger . warn ( <str> , ex ) ; } } logger . trace ( <str> , translogView . totalOperations ( ) ) ; try ( Translog . Snapshot phase2Snapshot = translogView . snapshot ( ) ) { phase2 ( phase2Snapshot ) ; } catch ( Throwable e ) { throw new RecoveryEngineException ( shard . shardId ( ) , <int> , <str> , e ) ; } finalizeRecovery ( ) ; } return response ; } public void phase1 ( final IndexCommit snapshot , final Translog . View translogView ) { cancellableThreads . checkForCancel ( ) ; long totalSize = <int> ; long existingTotalSize = <int> ; final Store store = shard . store ( ) ; store . incRef ( ) ; try { StopWatch stopWatch = new StopWatch ( ) . start ( ) ; final Store . MetadataSnapshot recoverySourceMetadata ; try { recoverySourceMetadata = store . getMetadata ( snapshot ) ; } catch ( CorruptIndexException | IndexFormatTooOldException | IndexFormatTooNewException ex ) { shard . failShard ( <str> , ex ) ; throw ex ; } for ( String name : snapshot . getFileNames ( ) ) { final StoreFileMetaData md = recoverySourceMetadata . get ( name ) ; if ( md = = null ) { logger . info ( <str> , name , recoverySourceMetadata . asMap ( ) ) ; throw new CorruptIndexException ( <str> + recoverySourceMetadata . asMap ( ) . size ( ) + <str> , name ) ; } } String recoverySourceSyncId = recoverySourceMetadata . getSyncId ( ) ; String recoveryTargetSyncId = request . metadataSnapshot ( ) . getSyncId ( ) ; final boolean recoverWithSyncId = recoverySourceSyncId ! = null & & recoverySourceSyncId . equals ( recoveryTargetSyncId ) ; if ( recoverWithSyncId ) { final long numDocsTarget = request . metadataSnapshot ( ) . getNumDocs ( ) ; final long numDocsSource = recoverySourceMetadata . getNumDocs ( ) ; if ( numDocsTarget ! = numDocsSource ) { throw new IllegalStateException ( <str> + request . shardId ( ) + <str> + numDocsTarget + <str> + request . sourceNode ( ) . getName ( ) + <str> + numDocsSource + <str> + request . targetNode ( ) . getName ( ) + <str> ) ; } logger . trace ( <str> , indexName , shardId , request . targetNode ( ) , recoverySourceSyncId ) ; } else { final Store . RecoveryDiff diff = recoverySourceMetadata . recoveryDiff ( request . metadataSnapshot ( ) ) ; for ( StoreFileMetaData md : diff . identical ) { response . phase1ExistingFileNames . add ( md . name ( ) ) ; response . phase1ExistingFileSizes . add ( md . length ( ) ) ; existingTotalSize + = md . length ( ) ; if ( logger . isTraceEnabled ( ) ) { logger . trace ( <str> , indexName , shardId , request . targetNode ( ) , md . name ( ) , md . checksum ( ) , md . length ( ) ) ; } totalSize + = md . length ( ) ; } List < StoreFileMetaData > phase1Files = new ArrayList < > ( diff . different . size ( ) + diff . missing . size ( ) ) ; phase1Files . addAll ( diff . different ) ; phase1Files . addAll ( diff . missing ) ; for ( StoreFileMetaData md : phase1Files ) { if ( request . metadataSnapshot ( ) . asMap ( ) . containsKey ( md . name ( ) ) ) { logger . trace ( <str> , indexName , shardId , request . targetNode ( ) , md . name ( ) , request . metadataSnapshot ( ) . asMap ( ) . get ( md . name ( ) ) , md ) ; } else { logger . trace ( <str> , indexName , shardId , request . targetNode ( ) , md . name ( ) ) ; } response . phase1FileNames . add ( md . name ( ) ) ; response . phase1FileSizes . add ( md . length ( ) ) ; totalSize + = md . length ( ) ; } response . phase1TotalSize = totalSize ; response . phase1ExistingTotalSize = existingTotalSize ; logger . trace ( <str> , indexName , shardId , request . targetNode ( ) , response . phase1FileNames . size ( ) , new ByteSizeValue ( totalSize ) , response . phase1ExistingFileNames . size ( ) , new ByteSizeValue ( existingTotalSize ) ) ; cancellableThreads . execute ( ( ) - > { RecoveryFilesInfoRequest recoveryInfoFilesRequest = new RecoveryFilesInfoRequest ( request . recoveryId ( ) , request . shardId ( ) , response . phase1FileNames , response . phase1FileSizes , response . phase1ExistingFileNames , response . phase1ExistingFileSizes , translogView . totalOperations ( ) ) ; transportService . submitRequest ( request . targetNode ( ) , RecoveryTarget . Actions . FILES_INFO , recoveryInfoFilesRequest , TransportRequestOptions . builder ( ) . withTimeout ( recoverySettings . internalActionTimeout ( ) ) . build ( ) , EmptyTransportResponseHandler . INSTANCE_SAME ) . txGet ( ) ; } ) ; final AtomicLong bytesSinceLastPause = new AtomicLong ( ) ; final Function < StoreFileMetaData , OutputStream > outputStreamFactories = ( md ) - > new BufferedOutputStream ( new RecoveryOutputStream ( md , bytesSinceLastPause , translogView ) , chunkSizeInBytes ) ; sendFiles ( store , phase1Files . toArray ( new StoreFileMetaData [ phase1Files . size ( ) ] ) , outputStreamFactories ) ; cancellableThreads . execute ( ( ) - > { try { transportService . submitRequest ( request . targetNode ( ) , RecoveryTarget . Actions . CLEAN_FILES , new RecoveryCleanFilesRequest ( request . recoveryId ( ) , shard . shardId ( ) , recoverySourceMetadata , translogView . totalOperations ( ) ) , TransportRequestOptions . builder ( ) . withTimeout ( recoverySettings . internalActionTimeout ( ) ) . build ( ) , EmptyTransportResponseHandler . INSTANCE_SAME ) . txGet ( ) ; } catch ( RemoteTransportException remoteException ) { final IOException corruptIndexException ; if ( ( corruptIndexException = ExceptionsHelper . unwrapCorruption ( remoteException ) ) ! = null ) { try { final Store . MetadataSnapshot recoverySourceMetadata1 = store . getMetadata ( snapshot ) ; StoreFileMetaData [ ] metadata = StreamSupport . stream ( recoverySourceMetadata1 . spliterator ( ) , false ) . toArray ( size - > new StoreFileMetaData [ size ] ) ; ArrayUtil . timSort ( metadata , new Comparator < StoreFileMetaData > ( ) { @Override public int compare ( StoreFileMetaData o1 , StoreFileMetaData o2 ) { return Long . compare ( o1 . length ( ) , o2 . length ( ) ) ; } } ) ; for ( StoreFileMetaData md : metadata ) { logger . debug ( <str> , shard . shardId ( ) , md ) ; if ( store . checkIntegrityNoException ( md ) = = false ) { shard . failShard ( <str> , corruptIndexException ) ; logger . warn ( <str> , shard . shardId ( ) , md ) ; throw corruptIndexException ; } } } catch ( IOException ex ) { remoteException . addSuppressed ( ex ) ; throw remoteException ; } RemoteTransportException exception = new RemoteTransportException ( <str> , null ) ; exception . addSuppressed ( remoteException ) ; logger . warn ( <str> , corruptIndexException , shard . shardId ( ) , request . targetNode ( ) ) ; throw exception ; } else { throw remoteException ; } } } ) ; } prepareTargetForTranslog ( translogView ) ; logger . trace ( <str> , indexName , shardId , request . targetNode ( ) , stopWatch . totalTime ( ) ) ; response . phase1Time = stopWatch . totalTime ( ) . millis ( ) ; } catch ( Throwable e ) { throw new RecoverFilesRecoveryException ( request . shardId ( ) , response . phase1FileNames . size ( ) , new ByteSizeValue ( totalSize ) , e ) ; } finally { store . decRef ( ) ; } } protected void prepareTargetForTranslog ( final Translog . View translogView ) { StopWatch stopWatch = new StopWatch ( ) . start ( ) ; logger . trace ( <str> , request . shardId ( ) , request . targetNode ( ) ) ; final long startEngineStart = stopWatch . totalTime ( ) . millis ( ) ; cancellableThreads . execute ( new Interruptable ( ) { @Override public void run ( ) throws InterruptedException { transportService . submitRequest ( request . targetNode ( ) , RecoveryTarget . Actions . PREPARE_TRANSLOG , new RecoveryPrepareForTranslogOperationsRequest ( request . recoveryId ( ) , request . shardId ( ) , translogView . totalOperations ( ) ) , TransportRequestOptions . builder ( ) . withTimeout ( recoverySettings . internalActionTimeout ( ) ) . build ( ) , EmptyTransportResponseHandler . INSTANCE_SAME ) . txGet ( ) ; } } ) ; stopWatch . stop ( ) ; response . startTime = stopWatch . totalTime ( ) . millis ( ) - startEngineStart ; logger . trace ( <str> , request . shardId ( ) , request . targetNode ( ) , stopWatch . totalTime ( ) ) ; } public void phase2 ( Translog . Snapshot snapshot ) { if ( shard . state ( ) = = IndexShardState . CLOSED ) { throw new IndexShardClosedException ( request . shardId ( ) ) ; } cancellableThreads . checkForCancel ( ) ; StopWatch stopWatch = new StopWatch ( ) . start ( ) ; logger . trace ( <str> , request . shardId ( ) , request . targetNode ( ) ) ; int totalOperations = sendSnapshot ( snapshot ) ; stopWatch . stop ( ) ; logger . trace ( <str> , request . shardId ( ) , request . targetNode ( ) , stopWatch . totalTime ( ) ) ; response . phase2Time = stopWatch . totalTime ( ) . millis ( ) ; response . phase2Operations = totalOperations ; } public void finalizeRecovery ( ) { if ( shard . state ( ) = = IndexShardState . CLOSED ) { throw new IndexShardClosedException ( request . shardId ( ) ) ; } cancellableThreads . checkForCancel ( ) ; StopWatch stopWatch = new StopWatch ( ) . start ( ) ; logger . trace ( <str> , indexName , shardId , request . targetNode ( ) ) ; cancellableThreads . execute ( new Interruptable ( ) { @Override public void run ( ) throws InterruptedException { transportService . submitRequest ( request . targetNode ( ) , RecoveryTarget . Actions . FINALIZE , new RecoveryFinalizeRecoveryRequest ( request . recoveryId ( ) , request . shardId ( ) ) , TransportRequestOptions . builder ( ) . withTimeout ( recoverySettings . internalActionLongTimeout ( ) ) . build ( ) , EmptyTransportResponseHandler . INSTANCE_SAME ) . txGet ( ) ; } } ) ; if ( request . markAsRelocated ( ) ) { try { shard . relocated ( <str> + request . targetNode ( ) ) ; } catch ( IllegalIndexShardStateException e ) { } } stopWatch . stop ( ) ; logger . trace ( <str> , indexName , shardId , request . targetNode ( ) , stopWatch . totalTime ( ) ) ; } protected int sendSnapshot ( final Translog . Snapshot snapshot ) { int ops = <int> ; long size = <int> ; int totalOperations = <int> ; final List < Translog . Operation > operations = new ArrayList < > ( ) ; Translog . Operation operation ; try { operation = snapshot . next ( ) ; } catch ( IOException ex ) { throw new ElasticsearchException ( <str> , ex ) ; } final TransportRequestOptions recoveryOptions = TransportRequestOptions . builder ( ) . withCompress ( true ) . withType ( TransportRequestOptions . Type . RECOVERY ) . withTimeout ( recoverySettings . internalActionLongTimeout ( ) ) . build ( ) ; if ( operation = = null ) { logger . trace ( <str> , indexName , shardId , request . targetNode ( ) ) ; } while ( operation ! = null ) { if ( shard . state ( ) = = IndexShardState . CLOSED ) { throw new IndexShardClosedException ( request . shardId ( ) ) ; } cancellableThreads . checkForCancel ( ) ; operations . add ( operation ) ; ops + = <int> ; size + = operation . estimateSize ( ) ; totalOperations + + ; if ( size > = chunkSizeInBytes ) { cancellableThreads . execute ( ( ) - > { final RecoveryTranslogOperationsRequest translogOperationsRequest = new RecoveryTranslogOperationsRequest ( request . recoveryId ( ) , request . shardId ( ) , operations , snapshot . estimatedTotalOperations ( ) ) ; transportService . submitRequest ( request . targetNode ( ) , RecoveryTarget . Actions . TRANSLOG_OPS , translogOperationsRequest , recoveryOptions , EmptyTransportResponseHandler . INSTANCE_SAME ) . txGet ( ) ; } ) ; if ( logger . isTraceEnabled ( ) ) { logger . trace ( <str> , indexName , shardId , ops , new ByteSizeValue ( size ) , snapshot . estimatedTotalOperations ( ) , request . targetNode ( ) ) ; } ops = <int> ; size = <int> ; operations . clear ( ) ; } try { operation = snapshot . next ( ) ; } catch ( IOException ex ) { throw new ElasticsearchException ( <str> , ex ) ; } } if ( ! operations . isEmpty ( ) ) { cancellableThreads . execute ( ( ) - > { RecoveryTranslogOperationsRequest translogOperationsRequest = new RecoveryTranslogOperationsRequest ( request . recoveryId ( ) , request . shardId ( ) , operations , snapshot . estimatedTotalOperations ( ) ) ; transportService . submitRequest ( request . targetNode ( ) , RecoveryTarget . Actions . TRANSLOG_OPS , translogOperationsRequest , recoveryOptions , EmptyTransportResponseHandler . INSTANCE_SAME ) . txGet ( ) ; } ) ; } if ( logger . isTraceEnabled ( ) ) { logger . trace ( <str> , indexName , shardId , ops , new ByteSizeValue ( size ) , snapshot . estimatedTotalOperations ( ) , request . targetNode ( ) ) ; } return totalOperations ; } public void cancel ( String reason ) { cancellableThreads . cancel ( reason ) ; } @Override public String toString ( ) { return <str> + <str> + request . shardId ( ) + <str> + request . sourceNode ( ) + <str> + request . targetNode ( ) + <str> ; } final class RecoveryOutputStream extends OutputStream { private final StoreFileMetaData md ; private final AtomicLong bytesSinceLastPause ; private final Translog . View translogView ; private long position = <int> ; RecoveryOutputStream ( StoreFileMetaData md , AtomicLong bytesSinceLastPause , Translog . View translogView ) { this . md = md ; this . bytesSinceLastPause = bytesSinceLastPause ; this . translogView = translogView ; } @Override public final void write ( int b ) throws IOException { throw new UnsupportedOperationException ( <str> ) ; } @Override public final void write ( byte [ ] b , int offset , int length ) throws IOException { sendNextChunk ( position , new BytesArray ( b , offset , length ) , md . length ( ) = = position + length ) ; position + = length ; assert md . length ( ) > = position : <str> + md . length ( ) + <str> + position ; } private void sendNextChunk ( long position , BytesArray content , boolean lastChunk ) throws IOException { final TransportRequestOptions chunkSendOptions = TransportRequestOptions . builder ( ) . withCompress ( false ) . withType ( TransportRequestOptions . Type . RECOVERY ) . withTimeout ( recoverySettings . internalActionTimeout ( ) ) . build ( ) ; cancellableThreads . execute ( ( ) - > { final long throttleTimeInNanos ; final RateLimiter rl = recoverySettings . rateLimiter ( ) ; if ( rl ! = null ) { long bytes = bytesSinceLastPause . addAndGet ( content . length ( ) ) ; if ( bytes > rl . getMinPauseCheckBytes ( ) ) { bytesSinceLastPause . addAndGet ( - bytes ) ; try { throttleTimeInNanos = rl . pause ( bytes ) ; shard . recoveryStats ( ) . addThrottleTime ( throttleTimeInNanos ) ; } catch ( IOException e ) { throw new ElasticsearchException ( <str> , e ) ; } } else { throttleTimeInNanos = <int> ; } } else { throttleTimeInNanos = <int> ; } transportService . submitRequest ( request . targetNode ( ) , RecoveryTarget . Actions . FILE_CHUNK , new RecoveryFileChunkRequest ( request . recoveryId ( ) , request . shardId ( ) , md , position , content , lastChunk , translogView . totalOperations ( ) , throttleTimeInNanos ) , chunkSendOptions , EmptyTransportResponseHandler . INSTANCE_SAME ) . txGet ( ) ; } ) ; if ( shard . state ( ) = = IndexShardState . CLOSED ) { throw new IndexShardClosedException ( request . shardId ( ) ) ; } } } void sendFiles ( Store store , StoreFileMetaData [ ] files , Function < StoreFileMetaData , OutputStream > outputStreamFactory ) throws Throwable { store . incRef ( ) ; try { Future [ ] runners = asyncSendFiles ( store , files , outputStreamFactory ) ; IOException corruptedEngine = null ; final List < Throwable > exceptions = new ArrayList < > ( ) ; for ( int i = <int> ; i < runners . length ; i + + ) { StoreFileMetaData md = files [ i ] ; try { runners [ i ] . get ( ) ; } catch ( ExecutionException t ) { corruptedEngine = handleExecutionException ( store , corruptedEngine , exceptions , md , t . getCause ( ) ) ; } catch ( InterruptedException t ) { corruptedEngine = handleExecutionException ( store , corruptedEngine , exceptions , md , t ) ; } } if ( corruptedEngine ! = null ) { failEngine ( corruptedEngine ) ; throw corruptedEngine ; } else { ExceptionsHelper . rethrowAndSuppress ( exceptions ) ; } } finally { store . decRef ( ) ; } } private IOException handleExecutionException ( Store store , IOException corruptedEngine , List < Throwable > exceptions , StoreFileMetaData md , Throwable t ) { logger . debug ( <str> + md + <str> ) ; final IOException corruptIndexException ; final boolean checkIntegrity = corruptedEngine = = null ; if ( ( corruptIndexException = ExceptionsHelper . unwrapCorruption ( t ) ) ! = null ) { if ( checkIntegrity & & store . checkIntegrityNoException ( md ) = = false ) { logger . warn ( <str> , shardId , md ) ; corruptedEngine = corruptIndexException ; } else { RemoteTransportException exception = new RemoteTransportException ( <str> , null ) ; exception . addSuppressed ( t ) ; if ( checkIntegrity ) { logger . warn ( <str> , corruptIndexException , shardId , request . targetNode ( ) , md ) ; } else { logger . warn ( <str> , corruptIndexException , shardId , request . targetNode ( ) , md ) ; } exceptions . add ( exception ) ; } } else { exceptions . add ( t ) ; } return corruptedEngine ; } protected void failEngine ( IOException cause ) { shard . failShard ( <str> , cause ) ; } Future < Void > [ ] asyncSendFiles ( Store store , StoreFileMetaData [ ] files , Function < StoreFileMetaData , OutputStream > outputStreamFactory ) { store . incRef ( ) ; try { final Future < Void > [ ] futures = new Future [ files . length ] ; for ( int i = <int> ; i < files . length ; i + + ) { final StoreFileMetaData md = files [ i ] ; long fileSize = md . length ( ) ; ThreadPoolExecutor pool ; if ( fileSize > RecoverySettings . SMALL_FILE_CUTOFF_BYTES ) { pool = recoverySettings . concurrentStreamPool ( ) ; } else { pool = recoverySettings . concurrentSmallFileStreamPool ( ) ; } Future < Void > future = pool . submit ( ( ) - > { try ( final IndexInput indexInput = store . directory ( ) . openInput ( md . name ( ) , IOContext . READONCE ) ) { Streams . copy ( new InputStreamIndexInput ( indexInput , md . length ( ) ) , outputStreamFactory . apply ( md ) ) ; } return null ; } ) ; futures [ i ] = future ; } return futures ; } finally { store . decRef ( ) ; } } } 
