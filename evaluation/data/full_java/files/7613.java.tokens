package org . elasticsearch . search . suggest . phrase ; import org . apache . lucene . index . IndexReader ; import org . apache . lucene . index . MultiFields ; import org . apache . lucene . index . Terms ; import org . apache . lucene . index . TermsEnum ; import org . apache . lucene . util . BytesRef ; import org . apache . lucene . util . BytesRefBuilder ; import org . elasticsearch . common . lucene . index . FreqTermsEnum ; import org . elasticsearch . common . util . BigArrays ; import org . elasticsearch . search . suggest . phrase . DirectCandidateGenerator . Candidate ; import org . elasticsearch . search . suggest . phrase . DirectCandidateGenerator . CandidateSet ; import java . io . IOException ; public abstract class WordScorer { protected final IndexReader reader ; protected final String field ; protected final Terms terms ; protected final long vocabluarySize ; protected final double realWordLikelyhood ; protected final BytesRefBuilder spare = new BytesRefBuilder ( ) ; protected final BytesRef separator ; private final TermsEnum termsEnum ; private final long numTerms ; private final boolean useTotalTermFreq ; public WordScorer ( IndexReader reader , String field , double realWordLikelyHood , BytesRef separator ) throws IOException { this ( reader , MultiFields . getTerms ( reader , field ) , field , realWordLikelyHood , separator ) ; } public WordScorer ( IndexReader reader , Terms terms , String field , double realWordLikelyHood , BytesRef separator ) throws IOException { this . field = field ; if ( terms = = null ) { throw new IllegalArgumentException ( <str> + field + <str> ) ; } this . terms = terms ; final long vocSize = terms . getSumTotalTermFreq ( ) ; this . vocabluarySize = vocSize = = - <int> ? reader . maxDoc ( ) : vocSize ; this . useTotalTermFreq = vocSize ! = - <int> ; this . numTerms = terms . size ( ) ; this . termsEnum = new FreqTermsEnum ( reader , field , ! useTotalTermFreq , useTotalTermFreq , null , BigArrays . NON_RECYCLING_INSTANCE ) ; this . reader = reader ; this . realWordLikelyhood = realWordLikelyHood ; this . separator = separator ; } public long frequency ( BytesRef term ) throws IOException { if ( termsEnum . seekExact ( term ) ) { return useTotalTermFreq ? termsEnum . totalTermFreq ( ) : termsEnum . docFreq ( ) ; } return <int> ; } protected double channelScore ( Candidate candidate , Candidate original ) throws IOException { if ( candidate . stringDistance = = <float> ) { return realWordLikelyhood ; } return candidate . stringDistance ; } public double score ( Candidate [ ] path , CandidateSet [ ] candidateSet , int at , int gramSize ) throws IOException { if ( at = = <int> | | gramSize = = <int> ) { return Math . log10 ( channelScore ( path [ at ] , candidateSet [ at ] . originalTerm ) * scoreUnigram ( path [ at ] ) ) ; } else if ( at = = <int> | | gramSize = = <int> ) { return Math . log10 ( channelScore ( path [ at ] , candidateSet [ at ] . originalTerm ) * scoreBigram ( path [ at ] , path [ at - <int> ] ) ) ; } else { return Math . log10 ( channelScore ( path [ at ] , candidateSet [ at ] . originalTerm ) * scoreTrigram ( path [ at ] , path [ at - <int> ] , path [ at - <int> ] ) ) ; } } protected double scoreUnigram ( Candidate word ) throws IOException { return ( <float> + frequency ( word . term ) ) / ( vocabluarySize + numTerms ) ; } protected double scoreBigram ( Candidate word , Candidate w_1 ) throws IOException { return scoreUnigram ( word ) ; } protected double scoreTrigram ( Candidate word , Candidate w_1 , Candidate w_2 ) throws IOException { return scoreBigram ( word , w_1 ) ; } public static interface WordScorerFactory { public WordScorer newScorer ( IndexReader reader , Terms terms , String field , double realWordLikelyhood , BytesRef separator ) throws IOException ; } } 
