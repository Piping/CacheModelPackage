package org . apache . lucene . search . postingshighlight ; import org . apache . lucene . analysis . MockAnalyzer ; import org . apache . lucene . document . Document ; import org . apache . lucene . document . Field ; import org . apache . lucene . document . FieldType ; import org . apache . lucene . document . TextField ; import org . apache . lucene . index . IndexOptions ; import org . apache . lucene . index . IndexReader ; import org . apache . lucene . index . IndexWriterConfig ; import org . apache . lucene . index . RandomIndexWriter ; import org . apache . lucene . index . Term ; import org . apache . lucene . search . IndexSearcher ; import org . apache . lucene . search . Query ; import org . apache . lucene . search . Sort ; import org . apache . lucene . search . TermQuery ; import org . apache . lucene . search . TopDocs ; import org . apache . lucene . search . highlight . DefaultEncoder ; import org . apache . lucene . store . Directory ; import org . elasticsearch . search . highlight . HighlightUtils ; import org . elasticsearch . test . ESTestCase ; import static org . hamcrest . CoreMatchers . equalTo ; public class CustomPostingsHighlighterTests extends ESTestCase { public void testCustomPostingsHighlighter ( ) throws Exception { Directory dir = newDirectory ( ) ; IndexWriterConfig iwc = newIndexWriterConfig ( new MockAnalyzer ( random ( ) ) ) ; iwc . setMergePolicy ( newLogMergePolicy ( ) ) ; RandomIndexWriter iw = new RandomIndexWriter ( random ( ) , dir , iwc ) ; FieldType offsetsType = new FieldType ( TextField . TYPE_STORED ) ; offsetsType . setIndexOptions ( IndexOptions . DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS ) ; final String firstValue = <str> ; Field body = new Field ( <str> , <str> , offsetsType ) ; Document doc = new Document ( ) ; doc . add ( body ) ; body . setStringValue ( firstValue ) ; final String secondValue = <str> ; Field body2 = new Field ( <str> , <str> , offsetsType ) ; doc . add ( body2 ) ; body2 . setStringValue ( secondValue ) ; final String thirdValue = <str> ; Field body3 = new Field ( <str> , <str> , offsetsType ) ; doc . add ( body3 ) ; body3 . setStringValue ( thirdValue ) ; final String fourthValue = <str> ; Field body4 = new Field ( <str> , <str> , offsetsType ) ; doc . add ( body4 ) ; body4 . setStringValue ( fourthValue ) ; iw . addDocument ( doc ) ; IndexReader ir = iw . getReader ( ) ; iw . close ( ) ; String firstHlValue = <str> ; String secondHlValue = <str> ; String thirdHlValue = <str> ; String fourthHlValue = <str> ; IndexSearcher searcher = newSearcher ( ir ) ; Query query = new TermQuery ( new Term ( <str> , <str> ) ) ; TopDocs topDocs = searcher . search ( query , <int> , Sort . INDEXORDER ) ; assertThat ( topDocs . totalHits , equalTo ( <int> ) ) ; int docId = topDocs . scoreDocs [ <int> ] . doc ; String fieldValue = firstValue + HighlightUtils . PARAGRAPH_SEPARATOR + secondValue + HighlightUtils . PARAGRAPH_SEPARATOR + thirdValue + HighlightUtils . PARAGRAPH_SEPARATOR + fourthValue ; CustomPostingsHighlighter highlighter = new CustomPostingsHighlighter ( null , new CustomPassageFormatter ( <str> , <str> , new DefaultEncoder ( ) ) , fieldValue , false ) ; Snippet [ ] snippets = highlighter . highlightField ( <str> , query , searcher , docId , <int> ) ; assertThat ( snippets . length , equalTo ( <int> ) ) ; assertThat ( snippets [ <int> ] . getText ( ) , equalTo ( firstHlValue ) ) ; assertThat ( snippets [ <int> ] . getText ( ) , equalTo ( secondHlValue ) ) ; assertThat ( snippets [ <int> ] . getText ( ) , equalTo ( thirdHlValue ) ) ; assertThat ( snippets [ <int> ] . getText ( ) , equalTo ( fourthHlValue ) ) ; ir . close ( ) ; dir . close ( ) ; } public void testNoMatchSize ( ) throws Exception { Directory dir = newDirectory ( ) ; IndexWriterConfig iwc = newIndexWriterConfig ( new MockAnalyzer ( random ( ) ) ) ; iwc . setMergePolicy ( newLogMergePolicy ( ) ) ; RandomIndexWriter iw = new RandomIndexWriter ( random ( ) , dir , iwc ) ; FieldType offsetsType = new FieldType ( TextField . TYPE_STORED ) ; offsetsType . setIndexOptions ( IndexOptions . DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS ) ; Field body = new Field ( <str> , <str> , offsetsType ) ; Field none = new Field ( <str> , <str> , offsetsType ) ; Document doc = new Document ( ) ; doc . add ( body ) ; doc . add ( none ) ; String firstValue = <str> ; body . setStringValue ( firstValue ) ; none . setStringValue ( firstValue ) ; iw . addDocument ( doc ) ; IndexReader ir = iw . getReader ( ) ; iw . close ( ) ; Query query = new TermQuery ( new Term ( <str> , <str> ) ) ; IndexSearcher searcher = newSearcher ( ir ) ; TopDocs topDocs = searcher . search ( query , <int> , Sort . INDEXORDER ) ; assertThat ( topDocs . totalHits , equalTo ( <int> ) ) ; int docId = topDocs . scoreDocs [ <int> ] . doc ; CustomPassageFormatter passageFormatter = new CustomPassageFormatter ( <str> , <str> , new DefaultEncoder ( ) ) ; CustomPostingsHighlighter highlighter = new CustomPostingsHighlighter ( null , passageFormatter , firstValue , false ) ; Snippet [ ] snippets = highlighter . highlightField ( <str> , query , searcher , docId , <int> ) ; assertThat ( snippets . length , equalTo ( <int> ) ) ; highlighter = new CustomPostingsHighlighter ( null , passageFormatter , firstValue , true ) ; snippets = highlighter . highlightField ( <str> , query , searcher , docId , <int> ) ; assertThat ( snippets . length , equalTo ( <int> ) ) ; assertThat ( snippets [ <int> ] . getText ( ) , equalTo ( <str> ) ) ; ir . close ( ) ; dir . close ( ) ; } } 
