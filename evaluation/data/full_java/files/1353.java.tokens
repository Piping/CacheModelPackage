package org . apache . cassandra . cql3 ; import java . io . File ; import java . io . IOException ; import java . math . BigDecimal ; import java . math . BigInteger ; import java . net . InetAddress ; import java . net . ServerSocket ; import java . nio . ByteBuffer ; import java . util . * ; import java . util . concurrent . CountDownLatch ; import java . util . concurrent . ExecutionException ; import java . util . concurrent . TimeUnit ; import java . util . concurrent . atomic . AtomicInteger ; import java . util . stream . Collectors ; import com . datastax . driver . core . * ; import com . datastax . driver . core . ResultSet ; import com . google . common . base . Objects ; import com . google . common . collect . ImmutableList ; import com . google . common . collect . ImmutableSet ; import org . junit . * ; import com . datastax . driver . core . Cluster ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; import org . apache . cassandra . SchemaLoader ; import org . apache . cassandra . concurrent . ScheduledExecutors ; import org . apache . cassandra . config . CFMetaData ; import org . apache . cassandra . config . DatabaseDescriptor ; import org . apache . cassandra . config . Schema ; import org . apache . cassandra . cql3 . functions . FunctionName ; import org . apache . cassandra . cql3 . functions . ThreadAwareSecurityManager ; import org . apache . cassandra . cql3 . statements . ParsedStatement ; import org . apache . cassandra . db . * ; import org . apache . cassandra . db . commitlog . CommitLog ; import org . apache . cassandra . db . marshal . * ; import org . apache . cassandra . db . marshal . TupleType ; import org . apache . cassandra . dht . Murmur3Partitioner ; import org . apache . cassandra . exceptions . * ; import org . apache . cassandra . io . util . FileUtils ; import org . apache . cassandra . serializers . TypeSerializer ; import org . apache . cassandra . service . ClientState ; import org . apache . cassandra . service . QueryState ; import org . apache . cassandra . service . StorageService ; import org . apache . cassandra . transport . Event ; import org . apache . cassandra . transport . Server ; import org . apache . cassandra . transport . messages . ResultMessage ; import org . apache . cassandra . utils . ByteBufferUtil ; import static junit . framework . Assert . assertNotNull ; public abstract class CQLTester { protected static final Logger logger = LoggerFactory . getLogger ( CQLTester . class ) ; public static final String KEYSPACE = <str> ; public static final String KEYSPACE_PER_TEST = <str> ; protected static final boolean USE_PREPARED_VALUES = Boolean . valueOf ( System . getProperty ( <str> , <str> ) ) ; protected static final boolean REUSE_PREPARED = Boolean . valueOf ( System . getProperty ( <str> , <str> ) ) ; protected static final long ROW_CACHE_SIZE_IN_MB = Integer . valueOf ( System . getProperty ( <str> , <str> ) ) ; private static final AtomicInteger seqNumber = new AtomicInteger ( ) ; private static org . apache . cassandra . transport . Server server ; protected static final int nativePort ; protected static final InetAddress nativeAddr ; private static final Map < Integer , Cluster > clusters = new HashMap < > ( ) ; private static final Map < Integer , Session > sessions = new HashMap < > ( ) ; private static boolean isServerPrepared = false ; public static final List < Integer > PROTOCOL_VERSIONS ; static { ImmutableList . Builder < Integer > builder = ImmutableList . builder ( ) ; for ( int version = Server . MIN_SUPPORTED_VERSION ; version < = Server . CURRENT_VERSION ; version + + ) { try { ProtocolVersion . fromInt ( version ) ; builder . add ( version ) ; } catch ( IllegalArgumentException e ) { break ; } } PROTOCOL_VERSIONS = builder . build ( ) ; prepareServer ( ) ; nativeAddr = InetAddress . getLoopbackAddress ( ) ; try { try ( ServerSocket serverSocket = new ServerSocket ( <int> ) ) { nativePort = serverSocket . getLocalPort ( ) ; } Thread . sleep ( <int> ) ; } catch ( Exception e ) { throw new RuntimeException ( e ) ; } } public static ResultMessage lastSchemaChangeResult ; private List < String > tables = new ArrayList < > ( ) ; private List < String > types = new ArrayList < > ( ) ; private List < String > functions = new ArrayList < > ( ) ; private List < String > aggregates = new ArrayList < > ( ) ; private boolean usePrepared = USE_PREPARED_VALUES ; private static boolean reusePrepared = REUSE_PREPARED ; public static void prepareServer ( ) { if ( isServerPrepared ) return ; try { cleanupAndLeaveDirs ( ) ; } catch ( IOException e ) { logger . error ( <str> ) ; throw new RuntimeException ( e ) ; } Thread . setDefaultUncaughtExceptionHandler ( new Thread . UncaughtExceptionHandler ( ) { public void uncaughtException ( Thread t , Throwable e ) { logger . error ( <str> + t , e ) ; } } ) ; ThreadAwareSecurityManager . install ( ) ; Keyspace . setInitialized ( ) ; isServerPrepared = true ; } public static void cleanupAndLeaveDirs ( ) throws IOException { CommitLog . instance . stopUnsafe ( true ) ; mkdirs ( ) ; cleanup ( ) ; mkdirs ( ) ; CommitLog . instance . restartUnsafe ( ) ; } public static void cleanup ( ) { String [ ] directoryNames = { DatabaseDescriptor . getCommitLogLocation ( ) , } ; for ( String dirName : directoryNames ) { File dir = new File ( dirName ) ; if ( ! dir . exists ( ) ) throw new RuntimeException ( <str> + dir . getAbsolutePath ( ) ) ; FileUtils . deleteRecursive ( dir ) ; } cleanupSavedCaches ( ) ; for ( String dirName : DatabaseDescriptor . getAllDataFileLocations ( ) ) { File dir = new File ( dirName ) ; if ( ! dir . exists ( ) ) throw new RuntimeException ( <str> + dir . getAbsolutePath ( ) ) ; FileUtils . deleteRecursive ( dir ) ; } } public static void mkdirs ( ) { DatabaseDescriptor . createAllDirectories ( ) ; } public static void cleanupSavedCaches ( ) { File cachesDir = new File ( DatabaseDescriptor . getSavedCachesLocation ( ) ) ; if ( ! cachesDir . exists ( ) | | ! cachesDir . isDirectory ( ) ) return ; FileUtils . delete ( cachesDir . listFiles ( ) ) ; } @BeforeClass public static void setUpClass ( ) { if ( ROW_CACHE_SIZE_IN_MB > <int> ) DatabaseDescriptor . setRowCacheSizeInMB ( ROW_CACHE_SIZE_IN_MB ) ; StorageService . instance . setPartitionerUnsafe ( Murmur3Partitioner . instance ) ; } @AfterClass public static void tearDownClass ( ) { for ( Session sess : sessions . values ( ) ) sess . close ( ) ; for ( Cluster cl : clusters . values ( ) ) cl . close ( ) ; if ( server ! = null ) server . stop ( ) ; if ( reusePrepared ) QueryProcessor . clearInternalStatementsCache ( ) ; } @Before public void beforeTest ( ) throws Throwable { schemaChange ( String . format ( <str> , KEYSPACE ) ) ; schemaChange ( String . format ( <str> , KEYSPACE_PER_TEST ) ) ; } @After public void afterTest ( ) throws Throwable { dropPerTestKeyspace ( ) ; usePrepared = USE_PREPARED_VALUES ; reusePrepared = REUSE_PREPARED ; final List < String > tablesToDrop = copy ( tables ) ; final List < String > typesToDrop = copy ( types ) ; final List < String > functionsToDrop = copy ( functions ) ; final List < String > aggregatesToDrop = copy ( aggregates ) ; tables = null ; types = null ; functions = null ; aggregates = null ; ScheduledExecutors . optionalTasks . execute ( new Runnable ( ) { public void run ( ) { try { for ( int i = tablesToDrop . size ( ) - <int> ; i > = <int> ; i - - ) schemaChange ( String . format ( <str> , KEYSPACE , tablesToDrop . get ( i ) ) ) ; for ( int i = aggregatesToDrop . size ( ) - <int> ; i > = <int> ; i - - ) schemaChange ( String . format ( <str> , aggregatesToDrop . get ( i ) ) ) ; for ( int i = functionsToDrop . size ( ) - <int> ; i > = <int> ; i - - ) schemaChange ( String . format ( <str> , functionsToDrop . get ( i ) ) ) ; for ( int i = typesToDrop . size ( ) - <int> ; i > = <int> ; i - - ) schemaChange ( String . format ( <str> , KEYSPACE , typesToDrop . get ( i ) ) ) ; final CountDownLatch latch = new CountDownLatch ( <int> ) ; ScheduledExecutors . nonPeriodicTasks . execute ( new Runnable ( ) { public void run ( ) { latch . countDown ( ) ; } } ) ; latch . await ( <int> , TimeUnit . SECONDS ) ; removeAllSSTables ( KEYSPACE , tablesToDrop ) ; } catch ( Exception e ) { throw new RuntimeException ( e ) ; } } } ) ; } protected static void requireNetwork ( ) throws ConfigurationException { if ( server ! = null ) return ; SystemKeyspace . finishStartup ( ) ; StorageService . instance . initServer ( ) ; SchemaLoader . startGossiper ( ) ; server = new Server . Builder ( ) . withHost ( nativeAddr ) . withPort ( nativePort ) . build ( ) ; server . start ( ) ; for ( int version : PROTOCOL_VERSIONS ) { if ( clusters . containsKey ( version ) ) continue ; Cluster cluster = Cluster . builder ( ) . addContactPoints ( nativeAddr ) . withClusterName ( <str> ) . withPort ( nativePort ) . withProtocolVersion ( ProtocolVersion . fromInt ( version ) ) . build ( ) ; clusters . put ( version , cluster ) ; sessions . put ( version , cluster . connect ( ) ) ; logger . info ( <str> , version ) ; } } protected void dropPerTestKeyspace ( ) throws Throwable { execute ( String . format ( <str> , KEYSPACE_PER_TEST ) ) ; } private static List < String > copy ( List < String > list ) { return list . isEmpty ( ) ? Collections . < String > emptyList ( ) : new ArrayList < > ( list ) ; } public ColumnFamilyStore getCurrentColumnFamilyStore ( ) { String currentTable = currentTable ( ) ; return currentTable = = null ? null : Keyspace . open ( KEYSPACE ) . getColumnFamilyStore ( currentTable ) ; } public void flush ( ) { ColumnFamilyStore store = getCurrentColumnFamilyStore ( ) ; if ( store ! = null ) store . forceBlockingFlush ( ) ; } public void compact ( ) { try { String currentTable = currentTable ( ) ; if ( currentTable ! = null ) Keyspace . open ( KEYSPACE ) . getColumnFamilyStore ( currentTable ) . forceMajorCompaction ( ) ; } catch ( InterruptedException | ExecutionException e ) { throw new RuntimeException ( e ) ; } } public void cleanupCache ( ) { String currentTable = currentTable ( ) ; if ( currentTable ! = null ) Keyspace . open ( KEYSPACE ) . getColumnFamilyStore ( currentTable ) . cleanupCache ( ) ; } public static FunctionName parseFunctionName ( String qualifiedName ) { int i = qualifiedName . indexOf ( <str> ) ; return i = = - <int> ? FunctionName . nativeFunction ( qualifiedName ) : new FunctionName ( qualifiedName . substring ( <int> , i ) . trim ( ) , qualifiedName . substring ( i + <int> ) . trim ( ) ) ; } public static String shortFunctionName ( String f ) { return parseFunctionName ( f ) . name ; } private static void removeAllSSTables ( String ks , List < String > tables ) { for ( File d : Directories . getKSChildDirectories ( ks ) ) { if ( d . exists ( ) & & containsAny ( d . getName ( ) , tables ) ) FileUtils . deleteRecursive ( d ) ; } } private static boolean containsAny ( String filename , List < String > tables ) { for ( int i = <int> , m = tables . size ( ) ; i < m ; i + + ) if ( filename . contains ( tables . get ( i ) + <str> ) ) return true ; return false ; } protected String keyspace ( ) { return KEYSPACE ; } protected String currentTable ( ) { if ( tables . isEmpty ( ) ) return null ; return tables . get ( tables . size ( ) - <int> ) ; } protected ByteBuffer unset ( ) { return ByteBufferUtil . UNSET_BYTE_BUFFER ; } protected void forcePreparedValues ( ) { this . usePrepared = true ; } protected void stopForcingPreparedValues ( ) { this . usePrepared = USE_PREPARED_VALUES ; } protected void disablePreparedReuseForTest ( ) { this . reusePrepared = false ; } protected String createType ( String query ) { String typeName = <str> + seqNumber . getAndIncrement ( ) ; String fullQuery = String . format ( query , KEYSPACE + <str> + typeName ) ; types . add ( typeName ) ; logger . info ( fullQuery ) ; schemaChange ( fullQuery ) ; return typeName ; } protected String createFunction ( String keyspace , String argTypes , String query ) throws Throwable { String functionName = keyspace + <str> + seqNumber . getAndIncrement ( ) ; createFunctionOverload ( functionName , argTypes , query ) ; return functionName ; } protected void createFunctionOverload ( String functionName , String argTypes , String query ) throws Throwable { String fullQuery = String . format ( query , functionName ) ; functions . add ( functionName + <str> + argTypes + <str> ) ; logger . info ( fullQuery ) ; schemaChange ( fullQuery ) ; } protected String createAggregate ( String keyspace , String argTypes , String query ) throws Throwable { String aggregateName = keyspace + <str> + <str> + seqNumber . getAndIncrement ( ) ; createAggregateOverload ( aggregateName , argTypes , query ) ; return aggregateName ; } protected void createAggregateOverload ( String aggregateName , String argTypes , String query ) throws Throwable { String fullQuery = String . format ( query , aggregateName ) ; aggregates . add ( aggregateName + <str> + argTypes + <str> ) ; logger . info ( fullQuery ) ; schemaChange ( fullQuery ) ; } protected String createTable ( String query ) { String currentTable = createTableName ( ) ; String fullQuery = formatQuery ( query ) ; logger . info ( fullQuery ) ; schemaChange ( fullQuery ) ; return currentTable ; } protected String createTableName ( ) { String currentTable = <str> + seqNumber . getAndIncrement ( ) ; tables . add ( currentTable ) ; return currentTable ; } protected void createTableMayThrow ( String query ) throws Throwable { String currentTable = <str> + seqNumber . getAndIncrement ( ) ; tables . add ( currentTable ) ; String fullQuery = formatQuery ( query ) ; logger . info ( fullQuery ) ; QueryProcessor . executeOnceInternal ( fullQuery ) ; } protected void alterTable ( String query ) { String fullQuery = formatQuery ( query ) ; logger . info ( fullQuery ) ; schemaChange ( fullQuery ) ; } protected void alterTableMayThrow ( String query ) throws Throwable { String fullQuery = formatQuery ( query ) ; logger . info ( fullQuery ) ; QueryProcessor . executeOnceInternal ( fullQuery ) ; } protected void dropTable ( String query ) { String fullQuery = String . format ( query , KEYSPACE + <str> + currentTable ( ) ) ; logger . info ( fullQuery ) ; schemaChange ( fullQuery ) ; } protected void createIndex ( String query ) { String fullQuery = formatQuery ( query ) ; logger . info ( fullQuery ) ; schemaChange ( fullQuery ) ; } protected boolean waitForIndex ( String keyspace , String table , String index ) throws Throwable { long start = System . currentTimeMillis ( ) ; boolean indexCreated = false ; while ( ! indexCreated ) { Object [ ] [ ] results = getRows ( execute ( <str> , keyspace ) ) ; for ( int i = <int> ; i < results . length ; i + + ) { if ( index . equals ( results [ i ] [ <int> ] ) ) { indexCreated = true ; break ; } } if ( System . currentTimeMillis ( ) - start > <int> ) break ; Thread . sleep ( <int> ) ; } return indexCreated ; } protected void createIndexMayThrow ( String query ) throws Throwable { String fullQuery = formatQuery ( query ) ; logger . info ( fullQuery ) ; QueryProcessor . executeOnceInternal ( fullQuery ) ; } protected void dropIndex ( String query ) throws Throwable { String fullQuery = String . format ( query , KEYSPACE ) ; logger . info ( fullQuery ) ; schemaChange ( fullQuery ) ; } protected void assertLastSchemaChange ( Event . SchemaChange . Change change , Event . SchemaChange . Target target , String keyspace , String name , String . . . argTypes ) { Assert . assertTrue ( lastSchemaChangeResult instanceof ResultMessage . SchemaChange ) ; ResultMessage . SchemaChange schemaChange = ( ResultMessage . SchemaChange ) lastSchemaChangeResult ; Assert . assertSame ( change , schemaChange . change . change ) ; Assert . assertSame ( target , schemaChange . change . target ) ; Assert . assertEquals ( keyspace , schemaChange . change . keyspace ) ; Assert . assertEquals ( name , schemaChange . change . name ) ; Assert . assertEquals ( argTypes ! = null ? Arrays . asList ( argTypes ) : null , schemaChange . change . argTypes ) ; } protected static void schemaChange ( String query ) { try { ClientState state = ClientState . forInternalCalls ( ) ; state . setKeyspace ( SystemKeyspace . NAME ) ; QueryState queryState = new QueryState ( state ) ; ParsedStatement . Prepared prepared = QueryProcessor . parseStatement ( query , queryState ) ; prepared . statement . validate ( state ) ; QueryOptions options = QueryOptions . forInternalCalls ( Collections . < ByteBuffer > emptyList ( ) ) ; lastSchemaChangeResult = prepared . statement . executeInternal ( queryState , options ) ; } catch ( Exception e ) { throw new RuntimeException ( <str> + query + <str> , e ) ; } } protected CFMetaData currentTableMetadata ( ) { return Schema . instance . getCFMetaData ( KEYSPACE , currentTable ( ) ) ; } protected com . datastax . driver . core . ResultSet executeNet ( int protocolVersion , String query , Object . . . values ) throws Throwable { return sessionNet ( protocolVersion ) . execute ( formatQuery ( query ) , values ) ; } protected Session sessionNet ( ) { return sessionNet ( PROTOCOL_VERSIONS . get ( PROTOCOL_VERSIONS . size ( ) - <int> ) ) ; } protected Session sessionNet ( int protocolVersion ) { requireNetwork ( ) ; return sessions . get ( protocolVersion ) ; } private String formatQuery ( String query ) { String currentTable = currentTable ( ) ; return currentTable = = null ? query : String . format ( query , KEYSPACE + <str> + currentTable ) ; } protected UntypedResultSet execute ( String query , Object . . . values ) throws Throwable { query = formatQuery ( query ) ; UntypedResultSet rs ; if ( usePrepared ) { if ( logger . isDebugEnabled ( ) ) logger . debug ( <str> , query , formatAllValues ( values ) ) ; if ( reusePrepared ) { rs = QueryProcessor . executeInternal ( query , transformValues ( values ) ) ; if ( query . startsWith ( <str> ) ) QueryProcessor . clearInternalStatementsCache ( ) ; } else { rs = QueryProcessor . executeOnceInternal ( query , transformValues ( values ) ) ; } } else { query = replaceValues ( query , values ) ; if ( logger . isDebugEnabled ( ) ) logger . debug ( <str> , query ) ; rs = QueryProcessor . executeOnceInternal ( query ) ; } if ( rs ! = null ) { if ( logger . isDebugEnabled ( ) ) logger . debug ( <str> , rs . size ( ) ) ; } return rs ; } protected void assertRowsNet ( int protocolVersion , ResultSet result , Object [ ] . . . rows ) { requireNetwork ( ) ; if ( result = = null ) { if ( rows . length > <int> ) Assert . fail ( String . format ( <str> , rows . length ) ) ; return ; } ColumnDefinitions meta = result . getColumnDefinitions ( ) ; Iterator < Row > iter = result . iterator ( ) ; int i = <int> ; while ( iter . hasNext ( ) & & i < rows . length ) { Object [ ] expected = rows [ i ] ; Row actual = iter . next ( ) ; Assert . assertEquals ( String . format ( <str> , i , protocolVersion ) , meta . size ( ) , expected . length ) ; for ( int j = <int> ; j < meta . size ( ) ; j + + ) { DataType type = meta . getType ( j ) ; com . datastax . driver . core . TypeCodec < Object > codec = clusters . get ( protocolVersion ) . getConfiguration ( ) . getCodecRegistry ( ) . codecFor ( type ) ; ByteBuffer expectedByteValue = codec . serialize ( expected [ j ] , ProtocolVersion . fromInt ( protocolVersion ) ) ; int expectedBytes = expectedByteValue = = null ? - <int> : expectedByteValue . remaining ( ) ; ByteBuffer actualValue = actual . getBytesUnsafe ( meta . getName ( j ) ) ; int actualBytes = actualValue = = null ? - <int> : actualValue . remaining ( ) ; if ( ! Objects . equal ( expectedByteValue , actualValue ) ) Assert . fail ( String . format ( <str> + <str> + <str> , i , j , meta . getName ( j ) , type , codec . format ( expected [ j ] ) , expectedBytes , codec . format ( codec . deserialize ( actualValue , ProtocolVersion . fromInt ( protocolVersion ) ) ) , actualBytes , protocolVersion ) ) ; } i + + ; } if ( iter . hasNext ( ) ) { while ( iter . hasNext ( ) ) { iter . next ( ) ; i + + ; } Assert . fail ( String . format ( <str> , rows . length , i , protocolVersion ) ) ; } Assert . assertTrue ( String . format ( <str> , rows . length > i ? <str> : <str> , rows . length , i , protocolVersion ) , i = = rows . length ) ; } public static void assertRows ( UntypedResultSet result , Object [ ] . . . rows ) { if ( result = = null ) { if ( rows . length > <int> ) Assert . fail ( String . format ( <str> , rows . length ) ) ; return ; } List < ColumnSpecification > meta = result . metadata ( ) ; Iterator < UntypedResultSet . Row > iter = result . iterator ( ) ; int i = <int> ; while ( iter . hasNext ( ) & & i < rows . length ) { Object [ ] expected = rows [ i ] ; UntypedResultSet . Row actual = iter . next ( ) ; Assert . assertEquals ( String . format ( <str> , i ) , expected = = null ? <int> : expected . length , meta . size ( ) ) ; for ( int j = <int> ; j < meta . size ( ) ; j + + ) { ColumnSpecification column = meta . get ( j ) ; ByteBuffer expectedByteValue = makeByteBuffer ( expected = = null ? null : expected [ j ] , column . type ) ; ByteBuffer actualValue = actual . getBytes ( column . name . toString ( ) ) ; if ( ! Objects . equal ( expectedByteValue , actualValue ) ) { Object actualValueDecoded = actualValue = = null ? null : column . type . getSerializer ( ) . deserialize ( actualValue ) ; if ( ! Objects . equal ( expected [ j ] , actualValueDecoded ) ) Assert . fail ( String . format ( <str> , i , j , column . name , column . type . asCQL3Type ( ) , formatValue ( expectedByteValue , column . type ) , formatValue ( actualValue , column . type ) ) ) ; } } i + + ; } if ( iter . hasNext ( ) ) { while ( iter . hasNext ( ) ) { iter . next ( ) ; i + + ; } Assert . fail ( String . format ( <str> , rows . length , i ) ) ; } Assert . assertTrue ( String . format ( <str> , rows . length > i ? <str> : <str> , rows . length , i ) , i = = rows . length ) ; } public static void assertRowsIgnoringOrder ( UntypedResultSet result , Object [ ] . . . rows ) { if ( result = = null ) { if ( rows . length > <int> ) Assert . fail ( String . format ( <str> , rows . length ) ) ; return ; } List < ColumnSpecification > meta = result . metadata ( ) ; Set < List < ByteBuffer > > expectedRows = new HashSet < > ( rows . length ) ; for ( Object [ ] expected : rows ) { Assert . assertEquals ( <str> , expected . length , meta . size ( ) ) ; List < ByteBuffer > expectedRow = new ArrayList < > ( meta . size ( ) ) ; for ( int j = <int> ; j < meta . size ( ) ; j + + ) expectedRow . add ( makeByteBuffer ( expected [ j ] , meta . get ( j ) . type ) ) ; expectedRows . add ( expectedRow ) ; } Set < List < ByteBuffer > > actualRows = new HashSet < > ( result . size ( ) ) ; for ( UntypedResultSet . Row actual : result ) { List < ByteBuffer > actualRow = new ArrayList < > ( meta . size ( ) ) ; for ( int j = <int> ; j < meta . size ( ) ; j + + ) actualRow . add ( actual . getBytes ( meta . get ( j ) . name . toString ( ) ) ) ; actualRows . add ( actualRow ) ; } com . google . common . collect . Sets . SetView < List < ByteBuffer > > extra = com . google . common . collect . Sets . difference ( actualRows , expectedRows ) ; com . google . common . collect . Sets . SetView < List < ByteBuffer > > missing = com . google . common . collect . Sets . difference ( expectedRows , actualRows ) ; if ( ! extra . isEmpty ( ) | | ! missing . isEmpty ( ) ) { List < String > extraRows = makeRowStrings ( extra , meta ) ; List < String > missingRows = makeRowStrings ( missing , meta ) ; StringBuilder sb = new StringBuilder ( ) ; if ( ! extra . isEmpty ( ) ) { sb . append ( <str> ) . append ( extra . size ( ) ) . append ( <str> ) ; if ( ! missing . isEmpty ( ) ) sb . append ( <str> ) . append ( missing . size ( ) ) . append ( <str> ) ; sb . append ( <str> ) ; sb . append ( extraRows . stream ( ) . collect ( Collectors . joining ( <str> ) ) ) ; if ( ! missing . isEmpty ( ) ) sb . append ( <str> ) . append ( missingRows . stream ( ) . collect ( Collectors . joining ( <str> ) ) ) ; Assert . fail ( sb . toString ( ) ) ; } if ( ! missing . isEmpty ( ) ) Assert . fail ( <str> + missing . size ( ) + <str> + missingRows . stream ( ) . collect ( Collectors . joining ( <str> ) ) ) ; } assert expectedRows . size ( ) = = actualRows . size ( ) ; } private static List < String > makeRowStrings ( Iterable < List < ByteBuffer > > rows , List < ColumnSpecification > meta ) { List < String > strings = new ArrayList < > ( ) ; for ( List < ByteBuffer > row : rows ) { StringBuilder sb = new StringBuilder ( <str> ) ; for ( int j = <int> ; j < row . size ( ) ; j + + ) { ColumnSpecification column = meta . get ( j ) ; sb . append ( column . name . toString ( ) ) . append ( <str> ) . append ( formatValue ( row . get ( j ) , column . type ) ) ; if ( j < ( row . size ( ) - <int> ) ) sb . append ( <str> ) ; } strings . add ( sb . append ( <str> ) . toString ( ) ) ; } return strings ; } protected void assertRowCount ( UntypedResultSet result , int numExpectedRows ) { if ( result = = null ) { if ( numExpectedRows > <int> ) Assert . fail ( String . format ( <str> , numExpectedRows ) ) ; return ; } List < ColumnSpecification > meta = result . metadata ( ) ; Iterator < UntypedResultSet . Row > iter = result . iterator ( ) ; int i = <int> ; while ( iter . hasNext ( ) & & i < numExpectedRows ) { UntypedResultSet . Row actual = iter . next ( ) ; assertNotNull ( actual ) ; i + + ; } if ( iter . hasNext ( ) ) { while ( iter . hasNext ( ) ) { iter . next ( ) ; i + + ; } Assert . fail ( String . format ( <str> , numExpectedRows , i ) ) ; } Assert . assertTrue ( String . format ( <str> , numExpectedRows > i ? <str> : <str> , numExpectedRows , i ) , i = = numExpectedRows ) ; } protected Object [ ] [ ] getRows ( UntypedResultSet result ) { if ( result = = null ) return new Object [ <int> ] [ ] ; List < Object [ ] > ret = new ArrayList < > ( ) ; List < ColumnSpecification > meta = result . metadata ( ) ; Iterator < UntypedResultSet . Row > iter = result . iterator ( ) ; while ( iter . hasNext ( ) ) { UntypedResultSet . Row rowVal = iter . next ( ) ; Object [ ] row = new Object [ meta . size ( ) ] ; for ( int j = <int> ; j < meta . size ( ) ; j + + ) { ColumnSpecification column = meta . get ( j ) ; ByteBuffer val = rowVal . getBytes ( column . name . toString ( ) ) ; row [ j ] = val = = null ? null : column . type . getSerializer ( ) . deserialize ( val ) ; } ret . add ( row ) ; } Object [ ] [ ] a = new Object [ ret . size ( ) ] [ ] ; return ret . toArray ( a ) ; } protected void assertColumnNames ( UntypedResultSet result , String . . . expectedColumnNames ) { if ( result = = null ) { Assert . fail ( <str> ) ; return ; } List < ColumnSpecification > metadata = result . metadata ( ) ; Assert . assertEquals ( <str> , expectedColumnNames . length , metadata . size ( ) ) ; for ( int i = <int> , m = metadata . size ( ) ; i < m ; i + + ) { ColumnSpecification columnSpec = metadata . get ( i ) ; Assert . assertEquals ( expectedColumnNames [ i ] , columnSpec . name . toString ( ) ) ; } } protected void assertAllRows ( Object [ ] . . . rows ) throws Throwable { assertRows ( execute ( <str> ) , rows ) ; } public static Object [ ] row ( Object . . . expected ) { return expected ; } protected void assertEmpty ( UntypedResultSet result ) throws Throwable { if ( result ! = null & & ! result . isEmpty ( ) ) throw new AssertionError ( String . format ( <str> , result . size ( ) ) ) ; } protected void assertInvalid ( String query , Object . . . values ) throws Throwable { assertInvalidMessage ( null , query , values ) ; } protected void assertInvalidMessage ( String errorMessage , String query , Object . . . values ) throws Throwable { assertInvalidThrowMessage ( errorMessage , null , query , values ) ; } protected void assertInvalidThrow ( Class < ? extends Throwable > exception , String query , Object . . . values ) throws Throwable { assertInvalidThrowMessage ( null , exception , query , values ) ; } protected void assertInvalidThrowMessage ( String errorMessage , Class < ? extends Throwable > exception , String query , Object . . . values ) throws Throwable { try { execute ( query , values ) ; String q = USE_PREPARED_VALUES ? query + <str> + formatAllValues ( values ) + <str> : replaceValues ( query , values ) ; Assert . fail ( <str> + q ) ; } catch ( CassandraException e ) { if ( exception ! = null & & ! exception . isAssignableFrom ( e . getClass ( ) ) ) { Assert . fail ( <str> + <str> + exception . getName ( ) + <str> + e . getClass ( ) . getName ( ) + <str> + <str> + queryInfo ( query , values ) ) ; } if ( errorMessage ! = null ) { assertMessageContains ( errorMessage , e ) ; } } } private static String queryInfo ( String query , Object [ ] values ) { return USE_PREPARED_VALUES ? query + <str> + formatAllValues ( values ) + <str> : replaceValues ( query , values ) ; } protected void assertValidSyntax ( String query ) throws Throwable { try { QueryProcessor . parseStatement ( query ) ; } catch ( SyntaxException e ) { Assert . fail ( String . format ( <str> , query , e . getMessage ( ) ) ) ; } } protected void assertInvalidSyntax ( String query , Object . . . values ) throws Throwable { assertInvalidSyntaxMessage ( null , query , values ) ; } protected void assertInvalidSyntaxMessage ( String errorMessage , String query , Object . . . values ) throws Throwable { try { execute ( query , values ) ; Assert . fail ( <str> + queryInfo ( query , values ) ) ; } catch ( SyntaxException e ) { if ( errorMessage ! = null ) { assertMessageContains ( errorMessage , e ) ; } } } private static void assertMessageContains ( String text , Exception e ) { Assert . assertTrue ( <str> + text + <str> + e . getMessage ( ) + <str> , e . getMessage ( ) . contains ( text ) ) ; } private static String replaceValues ( String query , Object [ ] values ) { StringBuilder sb = new StringBuilder ( ) ; int last = <int> ; int i = <int> ; int idx ; while ( ( idx = query . indexOf ( <str> , last ) ) > <int> ) { if ( i > = values . length ) throw new IllegalArgumentException ( String . format ( <str> , i , values . length ) ) ; sb . append ( query . substring ( last , idx ) ) ; Object value = values [ i + + ] ; if ( idx > = <int> & & value instanceof List & & query . substring ( idx - <int> , idx ) . equalsIgnoreCase ( <str> ) ) { List l = ( List ) value ; sb . append ( <str> ) ; for ( int j = <int> ; j < l . size ( ) ; j + + ) { if ( j > <int> ) sb . append ( <str> ) ; sb . append ( formatForCQL ( l . get ( j ) ) ) ; } sb . append ( <str> ) ; } else { sb . append ( formatForCQL ( value ) ) ; } last = idx + <int> ; } sb . append ( query . substring ( last ) ) ; return sb . toString ( ) ; } private static Object [ ] transformValues ( Object [ ] values ) { Object [ ] buffers = new ByteBuffer [ values . length ] ; for ( int i = <int> ; i < values . length ; i + + ) { Object value = values [ i ] ; if ( value = = null ) { buffers [ i ] = null ; continue ; } else if ( value = = ByteBufferUtil . UNSET_BYTE_BUFFER ) { buffers [ i ] = ByteBufferUtil . UNSET_BYTE_BUFFER ; continue ; } try { buffers [ i ] = typeFor ( value ) . decompose ( serializeTuples ( value ) ) ; } catch ( Exception ex ) { logger . info ( <str> , value , ex ) ; throw ex ; } } return buffers ; } private static Object serializeTuples ( Object value ) { if ( value instanceof TupleValue ) { return ( ( TupleValue ) value ) . toByteBuffer ( ) ; } if ( value instanceof List ) { List l = ( List ) value ; List n = new ArrayList ( l . size ( ) ) ; for ( Object o : l ) n . add ( serializeTuples ( o ) ) ; return n ; } if ( value instanceof Set ) { Set s = ( Set ) value ; Set n = new LinkedHashSet ( s . size ( ) ) ; for ( Object o : s ) n . add ( serializeTuples ( o ) ) ; return n ; } if ( value instanceof Map ) { Map m = ( Map ) value ; Map n = new LinkedHashMap ( m . size ( ) ) ; for ( Object entry : m . entrySet ( ) ) n . put ( serializeTuples ( ( ( Map . Entry ) entry ) . getKey ( ) ) , serializeTuples ( ( ( Map . Entry ) entry ) . getValue ( ) ) ) ; return n ; } return value ; } private static String formatAllValues ( Object [ ] values ) { StringBuilder sb = new StringBuilder ( ) ; sb . append ( <str> ) ; for ( int i = <int> ; i < values . length ; i + + ) { if ( i > <int> ) sb . append ( <str> ) ; sb . append ( formatForCQL ( values [ i ] ) ) ; } sb . append ( <str> ) ; return sb . toString ( ) ; } private static String formatForCQL ( Object value ) { if ( value = = null ) return <str> ; if ( value instanceof TupleValue ) return ( ( TupleValue ) value ) . toCQLString ( ) ; if ( value instanceof Collection | | value instanceof Map ) { StringBuilder sb = new StringBuilder ( ) ; if ( value instanceof List ) { List l = ( List ) value ; sb . append ( <str> ) ; for ( int i = <int> ; i < l . size ( ) ; i + + ) { if ( i > <int> ) sb . append ( <str> ) ; sb . append ( formatForCQL ( l . get ( i ) ) ) ; } sb . append ( <str> ) ; } else if ( value instanceof Set ) { Set s = ( Set ) value ; sb . append ( <str> ) ; Iterator iter = s . iterator ( ) ; while ( iter . hasNext ( ) ) { sb . append ( formatForCQL ( iter . next ( ) ) ) ; if ( iter . hasNext ( ) ) sb . append ( <str> ) ; } sb . append ( <str> ) ; } else { Map m = ( Map ) value ; sb . append ( <str> ) ; Iterator iter = m . entrySet ( ) . iterator ( ) ; while ( iter . hasNext ( ) ) { Map . Entry entry = ( Map . Entry ) iter . next ( ) ; sb . append ( formatForCQL ( entry . getKey ( ) ) ) . append ( <str> ) . append ( formatForCQL ( entry . getValue ( ) ) ) ; if ( iter . hasNext ( ) ) sb . append ( <str> ) ; } sb . append ( <str> ) ; } return sb . toString ( ) ; } AbstractType type = typeFor ( value ) ; String s = type . getString ( type . decompose ( value ) ) ; if ( type instanceof InetAddressType | | type instanceof TimestampType ) return String . format ( <str> , s ) ; else if ( type instanceof UTF8Type ) return String . format ( <str> , s . replaceAll ( <str> , <str> ) ) ; else if ( type instanceof BytesType ) return <str> + s ; return s ; } private static ByteBuffer makeByteBuffer ( Object value , AbstractType type ) { if ( value = = null ) return null ; if ( value instanceof TupleValue ) return ( ( TupleValue ) value ) . toByteBuffer ( ) ; if ( value instanceof ByteBuffer ) return ( ByteBuffer ) value ; return type . decompose ( value ) ; } private static String formatValue ( ByteBuffer bb , AbstractType < ? > type ) { if ( bb = = null ) return <str> ; if ( type instanceof CollectionType ) { TypeSerializer ser = type . getSerializer ( ) ; return ser . toString ( ser . deserialize ( bb ) ) ; } return type . getString ( bb ) ; } protected Object tuple ( Object . . . values ) { return new TupleValue ( values ) ; } protected Object userType ( Object . . . values ) { return new TupleValue ( values ) . toByteBuffer ( ) ; } protected Object list ( Object . . . values ) { return Arrays . asList ( values ) ; } protected Object set ( Object . . . values ) { return ImmutableSet . copyOf ( values ) ; } protected Object map ( Object . . . values ) { if ( values . length % <int> ! = <int> ) throw new IllegalArgumentException ( ) ; int size = values . length / <int> ; Map m = new LinkedHashMap ( size ) ; for ( int i = <int> ; i < size ; i + + ) m . put ( values [ <int> * i ] , values [ ( <int> * i ) + <int> ] ) ; return m ; } protected com . datastax . driver . core . TupleType tupleTypeOf ( int protocolVersion , DataType . . . types ) { requireNetwork ( ) ; return clusters . get ( protocolVersion ) . getMetadata ( ) . newTupleType ( types ) ; } private static AbstractType typeFor ( Object value ) { if ( value instanceof ByteBuffer | | value instanceof TupleValue | | value = = null ) return BytesType . instance ; if ( value instanceof Byte ) return ByteType . instance ; if ( value instanceof Short ) return ShortType . instance ; if ( value instanceof Integer ) return Int32Type . instance ; if ( value instanceof Long ) return LongType . instance ; if ( value instanceof Float ) return FloatType . instance ; if ( value instanceof Double ) return DoubleType . instance ; if ( value instanceof BigInteger ) return IntegerType . instance ; if ( value instanceof BigDecimal ) return DecimalType . instance ; if ( value instanceof String ) return UTF8Type . instance ; if ( value instanceof Boolean ) return BooleanType . instance ; if ( value instanceof InetAddress ) return InetAddressType . instance ; if ( value instanceof Date ) return TimestampType . instance ; if ( value instanceof UUID ) return UUIDType . instance ; if ( value instanceof List ) { List l = ( List ) value ; AbstractType elt = l . isEmpty ( ) ? BytesType . instance : typeFor ( l . get ( <int> ) ) ; return ListType . getInstance ( elt , true ) ; } if ( value instanceof Set ) { Set s = ( Set ) value ; AbstractType elt = s . isEmpty ( ) ? BytesType . instance : typeFor ( s . iterator ( ) . next ( ) ) ; return SetType . getInstance ( elt , true ) ; } if ( value instanceof Map ) { Map m = ( Map ) value ; AbstractType keys , values ; if ( m . isEmpty ( ) ) { keys = BytesType . instance ; values = BytesType . instance ; } else { Map . Entry entry = ( Map . Entry ) m . entrySet ( ) . iterator ( ) . next ( ) ; keys = typeFor ( entry . getKey ( ) ) ; values = typeFor ( entry . getValue ( ) ) ; } return MapType . getInstance ( keys , values , true ) ; } throw new IllegalArgumentException ( <str> + value + <str> ) ; } private static class TupleValue { private final Object [ ] values ; TupleValue ( Object [ ] values ) { this . values = values ; } public ByteBuffer toByteBuffer ( ) { ByteBuffer [ ] bbs = new ByteBuffer [ values . length ] ; for ( int i = <int> ; i < values . length ; i + + ) bbs [ i ] = makeByteBuffer ( values [ i ] , typeFor ( values [ i ] ) ) ; return TupleType . buildValue ( bbs ) ; } public String toCQLString ( ) { StringBuilder sb = new StringBuilder ( ) ; sb . append ( <str> ) ; for ( int i = <int> ; i < values . length ; i + + ) { if ( i > <int> ) sb . append ( <str> ) ; sb . append ( formatForCQL ( values [ i ] ) ) ; } sb . append ( <str> ) ; return sb . toString ( ) ; } public String toString ( ) { return <str> + toCQLString ( ) ; } } } 
