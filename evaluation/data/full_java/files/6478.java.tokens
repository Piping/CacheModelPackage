package org . elasticsearch . index . fielddata . ordinals ; import org . apache . lucene . index . FilteredTermsEnum ; import org . apache . lucene . index . PostingsEnum ; import org . apache . lucene . index . TermsEnum ; import org . apache . lucene . search . DocIdSetIterator ; import org . apache . lucene . util . * ; import org . apache . lucene . util . packed . GrowableWriter ; import org . apache . lucene . util . packed . PackedInts ; import org . apache . lucene . util . packed . PagedGrowableWriter ; import org . elasticsearch . common . settings . Settings ; import java . io . Closeable ; import java . io . IOException ; import java . util . Arrays ; public final class OrdinalsBuilder implements Closeable { public static final String FORCE_MULTI_ORDINALS = <str> ; public static final float DEFAULT_ACCEPTABLE_OVERHEAD_RATIO = PackedInts . FAST ; private static class OrdinalsStore { private static final int PAGE_SIZE = <int> < < <int> ; private static int numSlots ( int level ) { return <int> < < level ; } private static int slotsMask ( int level ) { return numSlots ( level ) - <int> ; } private static long position ( int level , long offset ) { assert level > = <int> ; return ( <int> < < ( level - <int> ) ) | ( offset < < level ) ; } private static int level ( long position ) { return <int> + Long . numberOfTrailingZeros ( position ) ; } private static long offset ( long position , int level ) { return position > > > level ; } private static long sliceID ( int level , long offset ) { return offset > > > level ; } private static long startOffset ( int level , long slice ) { return slice < < level ; } private static int numOrdinals ( int level , long offset ) { return ( <int> < < level ) + ( int ) ( offset & slotsMask ( level ) ) ; } private PagedGrowableWriter positions ; private final GrowableWriter firstOrdinals ; private PagedGrowableWriter firstNextLevelSlices ; private final PagedGrowableWriter [ ] ordinals ; private final PagedGrowableWriter [ ] nextLevelSlices ; private final int [ ] sizes ; private final int startBitsPerValue ; private final float acceptableOverheadRatio ; OrdinalsStore ( int maxDoc , int startBitsPerValue , float acceptableOverheadRatio ) { this . startBitsPerValue = startBitsPerValue ; this . acceptableOverheadRatio = acceptableOverheadRatio ; positions = new PagedGrowableWriter ( maxDoc , PAGE_SIZE , startBitsPerValue , acceptableOverheadRatio ) ; firstOrdinals = new GrowableWriter ( startBitsPerValue , maxDoc , acceptableOverheadRatio ) ; ordinals = new PagedGrowableWriter [ <int> ] ; nextLevelSlices = new PagedGrowableWriter [ <int> ] ; sizes = new int [ <int> ] ; Arrays . fill ( sizes , <int> ) ; } private long newSlice ( int level ) { final long newSlice = sizes [ level ] + + ; if ( ordinals [ level ] = = null ) { ordinals [ level ] = new PagedGrowableWriter ( <int> * numSlots ( level ) , PAGE_SIZE , startBitsPerValue , acceptableOverheadRatio ) ; } else { ordinals [ level ] = ordinals [ level ] . grow ( sizes [ level ] * numSlots ( level ) ) ; if ( nextLevelSlices [ level ] ! = null ) { nextLevelSlices [ level ] = nextLevelSlices [ level ] . grow ( sizes [ level ] ) ; } } return newSlice ; } public int addOrdinal ( int docID , long ordinal ) { final long position = positions . get ( docID ) ; if ( position = = <int> L ) { if ( firstOrdinals . get ( docID ) = = <int> L ) { firstOrdinals . set ( docID , ordinal + <int> ) ; return <int> ; } else { final long newSlice = newSlice ( <int> ) ; if ( firstNextLevelSlices = = null ) { firstNextLevelSlices = new PagedGrowableWriter ( firstOrdinals . size ( ) , PAGE_SIZE , <int> , acceptableOverheadRatio ) ; } firstNextLevelSlices . set ( docID , newSlice ) ; final long offset = startOffset ( <int> , newSlice ) ; ordinals [ <int> ] . set ( offset , ordinal + <int> ) ; positions . set ( docID , position ( <int> , offset ) ) ; return <int> ; } } else { int level = level ( position ) ; long offset = offset ( position , level ) ; assert offset ! = <int> L ; if ( ( ( offset + <int> ) & slotsMask ( level ) ) = = <int> L ) { final long newSlice = newSlice ( level + <int> ) ; if ( nextLevelSlices [ level ] = = null ) { nextLevelSlices [ level ] = new PagedGrowableWriter ( sizes [ level ] , PAGE_SIZE , <int> , acceptableOverheadRatio ) ; } nextLevelSlices [ level ] . set ( sliceID ( level , offset ) , newSlice ) ; + + level ; offset = startOffset ( level , newSlice ) ; assert ( offset & slotsMask ( level ) ) = = <int> L ; } else { + + offset ; } ordinals [ level ] . set ( offset , ordinal + <int> ) ; final long newPosition = position ( level , offset ) ; positions . set ( docID , newPosition ) ; return numOrdinals ( level , offset ) ; } } public void appendOrdinals ( int docID , LongsRef ords ) { final long firstOrd = firstOrdinals . get ( docID ) ; if ( firstOrd = = <int> L ) { return ; } ords . longs = ArrayUtil . grow ( ords . longs , ords . offset + ords . length + <int> ) ; ords . longs [ ords . offset + ords . length + + ] = firstOrd - <int> ; if ( firstNextLevelSlices = = null ) { return ; } long sliceID = firstNextLevelSlices . get ( docID ) ; if ( sliceID = = <int> L ) { return ; } for ( int level = <int> ; ; + + level ) { final int numSlots = numSlots ( level ) ; ords . longs = ArrayUtil . grow ( ords . longs , ords . offset + ords . length + numSlots ) ; final long offset = startOffset ( level , sliceID ) ; for ( int j = <int> ; j < numSlots ; + + j ) { final long ord = ordinals [ level ] . get ( offset + j ) ; if ( ord = = <int> L ) { return ; } ords . longs [ ords . offset + ords . length + + ] = ord - <int> ; } if ( nextLevelSlices [ level ] = = null ) { return ; } sliceID = nextLevelSlices [ level ] . get ( sliceID ) ; if ( sliceID = = <int> L ) { return ; } } } } private final int maxDoc ; private long currentOrd = - <int> ; private int numDocsWithValue = <int> ; private int numMultiValuedDocs = <int> ; private int totalNumOrds = <int> ; private OrdinalsStore ordinals ; private final LongsRef spare ; public OrdinalsBuilder ( long numTerms , int maxDoc , float acceptableOverheadRatio ) throws IOException { this . maxDoc = maxDoc ; int startBitsPerValue = <int> ; if ( numTerms > = <int> ) { startBitsPerValue = PackedInts . bitsRequired ( numTerms ) ; } ordinals = new OrdinalsStore ( maxDoc , startBitsPerValue , acceptableOverheadRatio ) ; spare = new LongsRef ( ) ; } public OrdinalsBuilder ( int maxDoc , float acceptableOverheadRatio ) throws IOException { this ( - <int> , maxDoc , acceptableOverheadRatio ) ; } public OrdinalsBuilder ( int maxDoc ) throws IOException { this ( maxDoc , DEFAULT_ACCEPTABLE_OVERHEAD_RATIO ) ; } public LongsRef docOrds ( int docID ) { spare . offset = spare . length = <int> ; ordinals . appendOrdinals ( docID , spare ) ; return spare ; } public PackedInts . Reader getFirstOrdinals ( ) { return ordinals . firstOrdinals ; } public long nextOrdinal ( ) { return + + currentOrd ; } public long currentOrdinal ( ) { return currentOrd ; } public OrdinalsBuilder addDoc ( int doc ) { totalNumOrds + + ; final int numValues = ordinals . addOrdinal ( doc , currentOrd ) ; if ( numValues = = <int> ) { + + numDocsWithValue ; } else if ( numValues = = <int> ) { + + numMultiValuedDocs ; } return this ; } public boolean isMultiValued ( ) { return numMultiValuedDocs > <int> ; } public int getNumDocsWithValue ( ) { return numDocsWithValue ; } public int getNumSingleValuedDocs ( ) { return numDocsWithValue - numMultiValuedDocs ; } public int getNumMultiValuesDocs ( ) { return numMultiValuedDocs ; } public int getTotalNumOrds ( ) { return totalNumOrds ; } public long getValueCount ( ) { return currentOrd + <int> ; } public BitSet buildDocsWithValuesSet ( ) { if ( numDocsWithValue = = maxDoc ) { return null ; } final FixedBitSet bitSet = new FixedBitSet ( maxDoc ) ; for ( int docID = <int> ; docID < maxDoc ; + + docID ) { if ( ordinals . firstOrdinals . get ( docID ) ! = <int> ) { bitSet . set ( docID ) ; } } return bitSet ; } public Ordinals build ( Settings settings ) { final float acceptableOverheadRatio = settings . getAsFloat ( <str> , PackedInts . FASTEST ) ; final boolean forceMultiOrdinals = settings . getAsBoolean ( FORCE_MULTI_ORDINALS , false ) ; if ( forceMultiOrdinals | | numMultiValuedDocs > <int> | | MultiOrdinals . significantlySmallerThanSinglePackedOrdinals ( maxDoc , numDocsWithValue , getValueCount ( ) , acceptableOverheadRatio ) ) { return new MultiOrdinals ( this , acceptableOverheadRatio ) ; } else { return new SinglePackedOrdinals ( this , acceptableOverheadRatio ) ; } } public int maxDoc ( ) { return maxDoc ; } public static TermsEnum wrapNumeric64Bit ( TermsEnum termsEnum ) { return new FilteredTermsEnum ( termsEnum , false ) { @Override protected AcceptStatus accept ( BytesRef term ) throws IOException { return NumericUtils . getPrefixCodedLongShift ( term ) = = <int> ? AcceptStatus . YES : AcceptStatus . END ; } } ; } public static TermsEnum wrapNumeric32Bit ( TermsEnum termsEnum ) { return new FilteredTermsEnum ( termsEnum , false ) { @Override protected AcceptStatus accept ( BytesRef term ) throws IOException { return NumericUtils . getPrefixCodedIntShift ( term ) = = <int> ? AcceptStatus . YES : AcceptStatus . END ; } } ; } public BytesRefIterator buildFromTerms ( final TermsEnum termsEnum ) throws IOException { return new BytesRefIterator ( ) { private PostingsEnum docsEnum = null ; @Override public BytesRef next ( ) throws IOException { BytesRef ref ; if ( ( ref = termsEnum . next ( ) ) ! = null ) { docsEnum = termsEnum . postings ( docsEnum , PostingsEnum . NONE ) ; nextOrdinal ( ) ; int docId ; while ( ( docId = docsEnum . nextDoc ( ) ) ! = DocIdSetIterator . NO_MORE_DOCS ) { addDoc ( docId ) ; } } return ref ; } } ; } @Override public void close ( ) throws IOException { ordinals = null ; } } 
