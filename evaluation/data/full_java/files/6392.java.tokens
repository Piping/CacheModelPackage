package org . elasticsearch . index . analysis . compound ; import org . apache . lucene . analysis . TokenStream ; import org . apache . lucene . analysis . compound . HyphenationCompoundWordTokenFilter ; import org . apache . lucene . analysis . compound . Lucene43HyphenationCompoundWordTokenFilter ; import org . apache . lucene . analysis . compound . hyphenation . HyphenationTree ; import org . apache . lucene . util . Version ; import org . elasticsearch . env . Environment ; import org . elasticsearch . common . settings . Settings ; import org . elasticsearch . index . IndexSettings ; import org . xml . sax . InputSource ; import java . nio . file . Files ; import java . nio . file . Path ; public class HyphenationCompoundWordTokenFilterFactory extends AbstractCompoundWordTokenFilterFactory { private final HyphenationTree hyphenationTree ; public HyphenationCompoundWordTokenFilterFactory ( IndexSettings indexSettings , Environment env , String name , Settings settings ) { super ( indexSettings , env , name , settings ) ; String hyphenationPatternsPath = settings . get ( <str> , null ) ; if ( hyphenationPatternsPath = = null ) { throw new IllegalArgumentException ( <str> ) ; } Path hyphenationPatternsFile = env . configFile ( ) . resolve ( hyphenationPatternsPath ) ; try { hyphenationTree = HyphenationCompoundWordTokenFilter . getHyphenationTree ( new InputSource ( Files . newInputStream ( hyphenationPatternsFile ) ) ) ; } catch ( Exception e ) { throw new IllegalArgumentException ( <str> , e ) ; } } @Override public TokenStream create ( TokenStream tokenStream ) { if ( version . onOrAfter ( Version . LUCENE_4_4_0 ) ) { return new HyphenationCompoundWordTokenFilter ( tokenStream , hyphenationTree , wordList , minWordSize , minSubwordSize , maxSubwordSize , onlyLongestMatch ) ; } else { return new Lucene43HyphenationCompoundWordTokenFilter ( tokenStream , hyphenationTree , wordList , minWordSize , minSubwordSize , maxSubwordSize , onlyLongestMatch ) ; } } } 
