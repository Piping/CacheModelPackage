package org . elasticsearch . index . engine ; import org . apache . lucene . index . DirectoryReader ; import org . apache . lucene . index . IndexCommit ; import org . apache . lucene . index . SegmentInfos ; import org . apache . lucene . search . SearcherFactory ; import org . apache . lucene . search . SearcherManager ; import org . apache . lucene . store . AlreadyClosedException ; import org . apache . lucene . util . IOUtils ; import org . elasticsearch . common . lucene . Lucene ; import org . elasticsearch . common . lucene . index . ElasticsearchDirectoryReader ; import org . elasticsearch . common . unit . TimeValue ; import org . elasticsearch . common . util . concurrent . ReleasableLock ; import org . elasticsearch . index . translog . Translog ; import java . io . IOException ; import java . util . Arrays ; import java . util . List ; import java . util . function . Function ; public class ShadowEngine extends Engine { public final static String NONEXISTENT_INDEX_RETRY_WAIT = <str> ; public final static TimeValue DEFAULT_NONEXISTENT_INDEX_RETRY_WAIT = TimeValue . timeValueSeconds ( <int> ) ; private volatile SearcherManager searcherManager ; private volatile SegmentInfos lastCommittedSegmentInfos ; public ShadowEngine ( EngineConfig engineConfig ) { super ( engineConfig ) ; SearcherFactory searcherFactory = new EngineSearcherFactory ( engineConfig ) ; final long nonexistentRetryTime = engineConfig . getIndexSettings ( ) . getSettings ( ) . getAsTime ( NONEXISTENT_INDEX_RETRY_WAIT , DEFAULT_NONEXISTENT_INDEX_RETRY_WAIT ) . getMillis ( ) ; try { DirectoryReader reader = null ; store . incRef ( ) ; boolean success = false ; try { if ( Lucene . waitForIndex ( store . directory ( ) , nonexistentRetryTime ) ) { reader = ElasticsearchDirectoryReader . wrap ( DirectoryReader . open ( store . directory ( ) ) , shardId ) ; this . searcherManager = new SearcherManager ( reader , searcherFactory ) ; this . lastCommittedSegmentInfos = readLastCommittedSegmentInfos ( searcherManager , store ) ; success = true ; } else { throw new IllegalStateException ( <str> + nonexistentRetryTime + <str> + <str> ) ; } } catch ( Throwable e ) { logger . warn ( <str> , e ) ; throw e ; } finally { if ( success = = false ) { IOUtils . closeWhileHandlingException ( reader ) ; store . decRef ( ) ; } } } catch ( IOException ex ) { throw new EngineCreationFailureException ( shardId , <str> , ex ) ; } logger . trace ( <str> ) ; } @Override public boolean index ( Index index ) throws EngineException { throw new UnsupportedOperationException ( shardId + <str> ) ; } @Override public void delete ( Delete delete ) throws EngineException { throw new UnsupportedOperationException ( shardId + <str> ) ; } @Override public SyncedFlushResult syncFlush ( String syncId , CommitId expectedCommitId ) { throw new UnsupportedOperationException ( shardId + <str> ) ; } @Override public CommitId flush ( ) throws EngineException { return flush ( false , false ) ; } @Override public CommitId flush ( boolean force , boolean waitIfOngoing ) throws EngineException { logger . trace ( <str> ) ; refresh ( <str> ) ; store . incRef ( ) ; try ( ReleasableLock lock = readLock . acquire ( ) ) { lastCommittedSegmentInfos = readLastCommittedSegmentInfos ( searcherManager , store ) ; } catch ( Throwable e ) { if ( isClosed . get ( ) = = false ) { logger . warn ( <str> , e ) ; if ( Lucene . isCorruptionException ( e ) ) { throw new FlushFailedEngineException ( shardId , e ) ; } } } finally { store . decRef ( ) ; } return new CommitId ( lastCommittedSegmentInfos . getId ( ) ) ; } @Override public void forceMerge ( boolean flush , int maxNumSegments , boolean onlyExpungeDeletes , boolean upgrade , boolean upgradeOnlyAncientSegments ) throws EngineException { logger . trace ( <str> ) ; } @Override public GetResult get ( Get get , Function < String , Searcher > searcherFacotry ) throws EngineException { return getFromSearcher ( get , searcherFacotry ) ; } @Override public Translog getTranslog ( ) { throw new UnsupportedOperationException ( <str> ) ; } @Override public List < Segment > segments ( boolean verbose ) { try ( ReleasableLock lock = readLock . acquire ( ) ) { Segment [ ] segmentsArr = getSegmentInfo ( lastCommittedSegmentInfos , verbose ) ; for ( int i = <int> ; i < segmentsArr . length ; i + + ) { segmentsArr [ i ] . committed = true ; } return Arrays . asList ( segmentsArr ) ; } } @Override public void refresh ( String source ) throws EngineException { try ( ReleasableLock lock = readLock . acquire ( ) ) { ensureOpen ( ) ; searcherManager . maybeRefreshBlocking ( ) ; } catch ( AlreadyClosedException e ) { ensureOpen ( ) ; } catch ( EngineClosedException e ) { throw e ; } catch ( Throwable t ) { failEngine ( <str> , t ) ; throw new RefreshFailedEngineException ( shardId , t ) ; } } @Override public IndexCommit snapshotIndex ( boolean flushFirst ) throws EngineException { throw new UnsupportedOperationException ( <str> ) ; } @Override protected SearcherManager getSearcherManager ( ) { return searcherManager ; } @Override protected void closeNoLock ( String reason ) { if ( isClosed . compareAndSet ( false , true ) ) { try { logger . debug ( <str> , store . refCount ( ) ) ; IOUtils . close ( searcherManager ) ; } catch ( Throwable t ) { logger . warn ( <str> , t ) ; } finally { store . decRef ( ) ; } } } @Override protected SegmentInfos getLastCommittedSegmentInfos ( ) { return lastCommittedSegmentInfos ; } @Override public long indexWriterRAMBytesUsed ( ) { throw new UnsupportedOperationException ( <str> ) ; } } 
