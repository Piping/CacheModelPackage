package org . apache . cassandra . db ; import java . io . IOException ; import java . util . * ; import java . util . concurrent . ThreadLocalRandom ; import java . util . function . Predicate ; import com . google . common . collect . Iterators ; import com . google . common . collect . Lists ; import org . junit . AfterClass ; import org . junit . Test ; import junit . framework . Assert ; import org . apache . cassandra . MockSchema ; import org . apache . cassandra . config . CFMetaData ; import org . apache . cassandra . config . ColumnDefinition ; import org . apache . cassandra . db . marshal . SetType ; import org . apache . cassandra . db . marshal . UTF8Type ; import org . apache . cassandra . io . util . DataInputBuffer ; import org . apache . cassandra . io . util . DataOutputBuffer ; import org . apache . cassandra . utils . btree . BTreeSet ; import static org . apache . cassandra . utils . ByteBufferUtil . bytes ; public class ColumnsTest { private static final CFMetaData cfMetaData = MockSchema . newCFS ( ) . metadata ; @Test public void testContainsWithoutAndMergeTo ( ) { for ( ColumnsCheck randomColumns : randomSmall ( true ) ) testContainsWithoutAndMergeTo ( randomColumns ) ; } private void testContainsWithoutAndMergeTo ( ColumnsCheck input ) { List < List < ColumnDefinition > > removeGroups = shuffleAndGroup ( Lists . newArrayList ( input . definitions ) ) ; for ( List < ColumnDefinition > defs : removeGroups ) { ColumnsCheck subset = input . remove ( defs ) ; subset . assertContents ( ) ; assertSubset ( input . columns , subset . columns ) ; Columns otherSubset = input . columns ; for ( ColumnDefinition def : subset . definitions ) { otherSubset = otherSubset . without ( def ) ; assertContents ( otherSubset . mergeTo ( subset . columns ) , input . definitions ) ; } testContainsWithoutAndMergeTo ( subset ) ; } } private void assertSubset ( Columns superset , Columns subset ) { Assert . assertTrue ( superset . containsAll ( superset ) ) ; Assert . assertTrue ( superset . containsAll ( subset ) ) ; Assert . assertFalse ( subset . containsAll ( superset ) ) ; } @Test public void testSerialize ( ) throws IOException { testSerialize ( Columns . NONE , Collections . emptyList ( ) ) ; for ( ColumnsCheck randomColumns : randomSmall ( false ) ) testSerialize ( randomColumns . columns , randomColumns . definitions ) ; } private void testSerialize ( Columns columns , List < ColumnDefinition > definitions ) throws IOException { try ( DataOutputBuffer out = new DataOutputBuffer ( ) ) { Columns . serializer . serialize ( columns , out ) ; Assert . assertEquals ( Columns . serializer . serializedSize ( columns ) , out . buffer ( ) . remaining ( ) ) ; Columns deserialized = Columns . serializer . deserialize ( new DataInputBuffer ( out . buffer ( ) , false ) , mock ( columns ) ) ; Assert . assertEquals ( columns , deserialized ) ; Assert . assertEquals ( columns . hashCode ( ) , deserialized . hashCode ( ) ) ; assertContents ( deserialized , definitions ) ; } } @Test public void testSerializeSmallSubset ( ) throws IOException { for ( ColumnsCheck randomColumns : randomSmall ( true ) ) testSerializeSubset ( randomColumns ) ; } @Test public void testSerializeHugeSubset ( ) throws IOException { for ( ColumnsCheck randomColumns : randomHuge ( ) ) testSerializeSubset ( randomColumns ) ; } @Test public void testContainsAllWithLargeNumberOfColumns ( ) { List < String > names = new ArrayList < > ( ) ; for ( int i = <int> ; i < <int> ; i + + ) names . add ( <str> + i ) ; List < ColumnDefinition > defs = new ArrayList < > ( ) ; addClustering ( names , defs ) ; Columns columns = Columns . from ( new HashSet < > ( defs ) ) ; defs = new ArrayList < > ( ) ; addClustering ( names . subList ( <int> , <int> ) , defs ) ; Columns subset = Columns . from ( new HashSet < > ( defs ) ) ; Assert . assertTrue ( columns . containsAll ( subset ) ) ; } private void testSerializeSubset ( ColumnsCheck input ) throws IOException { testSerializeSubset ( input . columns , input . columns , input . definitions ) ; testSerializeSubset ( input . columns , Columns . NONE , Collections . emptyList ( ) ) ; List < List < ColumnDefinition > > removeGroups = shuffleAndGroup ( Lists . newArrayList ( input . definitions ) ) ; for ( List < ColumnDefinition > defs : removeGroups ) { Collections . sort ( defs ) ; ColumnsCheck subset = input . remove ( defs ) ; testSerializeSubset ( input . columns , subset . columns , subset . definitions ) ; } } private void testSerializeSubset ( Columns superset , Columns subset , List < ColumnDefinition > subsetDefinitions ) throws IOException { try ( DataOutputBuffer out = new DataOutputBuffer ( ) ) { Columns . serializer . serializeSubset ( subset , superset , out ) ; Assert . assertEquals ( Columns . serializer . serializedSubsetSize ( subset , superset ) , out . buffer ( ) . remaining ( ) ) ; Columns deserialized = Columns . serializer . deserializeSubset ( superset , new DataInputBuffer ( out . buffer ( ) , false ) ) ; Assert . assertEquals ( subset , deserialized ) ; Assert . assertEquals ( subset . hashCode ( ) , deserialized . hashCode ( ) ) ; assertContents ( deserialized , subsetDefinitions ) ; } } private static void assertContents ( Columns columns , List < ColumnDefinition > defs ) { Assert . assertEquals ( defs , Lists . newArrayList ( columns ) ) ; boolean hasSimple = false , hasComplex = false ; int firstComplexIdx = <int> ; int i = <int> ; Iterator < ColumnDefinition > simple = columns . simpleColumns ( ) ; Iterator < ColumnDefinition > complex = columns . complexColumns ( ) ; Iterator < ColumnDefinition > all = columns . iterator ( ) ; Predicate < ColumnDefinition > predicate = columns . inOrderInclusionTester ( ) ; for ( ColumnDefinition def : defs ) { Assert . assertEquals ( def , all . next ( ) ) ; Assert . assertTrue ( columns . contains ( def ) ) ; Assert . assertTrue ( predicate . test ( def ) ) ; if ( def . isSimple ( ) ) { hasSimple = true ; Assert . assertEquals ( i , columns . simpleIdx ( def ) ) ; Assert . assertEquals ( def , columns . getSimple ( i ) ) ; Assert . assertEquals ( def , simple . next ( ) ) ; + + firstComplexIdx ; } else { Assert . assertFalse ( simple . hasNext ( ) ) ; hasComplex = true ; Assert . assertEquals ( i - firstComplexIdx , columns . complexIdx ( def ) ) ; Assert . assertEquals ( def , columns . getComplex ( i - firstComplexIdx ) ) ; Assert . assertEquals ( def , complex . next ( ) ) ; } i + + ; } Assert . assertEquals ( defs . isEmpty ( ) , columns . isEmpty ( ) ) ; Assert . assertFalse ( simple . hasNext ( ) ) ; Assert . assertFalse ( complex . hasNext ( ) ) ; Assert . assertFalse ( all . hasNext ( ) ) ; Assert . assertEquals ( hasSimple , columns . hasSimple ( ) ) ; Assert . assertEquals ( hasComplex , columns . hasComplex ( ) ) ; if ( ! columns . hasSimple ( ) | | ! columns . getSimple ( <int> ) . kind . isPrimaryKeyKind ( ) ) { List < ColumnDefinition > selectOrderDefs = new ArrayList < > ( defs ) ; Collections . sort ( selectOrderDefs , ( a , b ) - > a . name . bytes . compareTo ( b . name . bytes ) ) ; List < ColumnDefinition > selectOrderColumns = new ArrayList < > ( ) ; Iterators . addAll ( selectOrderColumns , columns . selectOrderIterator ( ) ) ; Assert . assertEquals ( selectOrderDefs , selectOrderColumns ) ; } } private static < V > List < List < V > > shuffleAndGroup ( List < V > list ) { ThreadLocalRandom random = ThreadLocalRandom . current ( ) ; for ( int i = <int> ; i < list . size ( ) - <int> ; i + + ) { int j = random . nextInt ( i , list . size ( ) ) ; V v = list . get ( i ) ; list . set ( i , list . get ( j ) ) ; list . set ( j , v ) ; } List < List < V > > result = new ArrayList < > ( ) ; for ( int i = <int> ; i < list . size ( ) ; ) { List < V > group = new ArrayList < > ( ) ; int maxCount = list . size ( ) - i ; int count = maxCount < = <int> ? maxCount : random . nextInt ( <int> , maxCount ) ; for ( int j = <int> ; j < count ; j + + ) group . add ( list . get ( i + j ) ) ; i + = count ; result . add ( group ) ; } return result ; } @AfterClass public static void cleanup ( ) { MockSchema . cleanup ( ) ; } private static class ColumnsCheck { final Columns columns ; final List < ColumnDefinition > definitions ; private ColumnsCheck ( Columns columns , List < ColumnDefinition > definitions ) { this . columns = columns ; this . definitions = definitions ; } private ColumnsCheck ( List < ColumnDefinition > definitions ) { this . columns = Columns . from ( BTreeSet . of ( definitions ) ) ; this . definitions = definitions ; } ColumnsCheck remove ( List < ColumnDefinition > remove ) { Columns subset = columns ; for ( ColumnDefinition def : remove ) subset = subset . without ( def ) ; Assert . assertEquals ( columns . size ( ) - remove . size ( ) , subset . size ( ) ) ; List < ColumnDefinition > remainingDefs = Lists . newArrayList ( columns ) ; remainingDefs . removeAll ( remove ) ; return new ColumnsCheck ( subset , remainingDefs ) ; } void assertContents ( ) { ColumnsTest . assertContents ( columns , definitions ) ; } } private static List < ColumnsCheck > randomHuge ( ) { List < ColumnsCheck > result = new ArrayList < > ( ) ; ThreadLocalRandom random = ThreadLocalRandom . current ( ) ; result . add ( randomHuge ( random . nextInt ( <int> , <int> ) , <int> , <int> , <int> ) ) ; result . add ( randomHuge ( <int> , random . nextInt ( <int> , <int> ) , <int> , <int> ) ) ; result . add ( randomHuge ( <int> , <int> , random . nextInt ( <int> , <int> ) , <int> ) ) ; result . add ( randomHuge ( <int> , <int> , <int> , random . nextInt ( <int> , <int> ) ) ) ; result . add ( randomHuge ( random . nextInt ( <int> , <int> ) , random . nextInt ( <int> , <int> ) , <int> , <int> ) ) ; result . add ( randomHuge ( <int> , random . nextInt ( <int> , <int> ) , random . nextInt ( <int> , <int> ) , <int> ) ) ; result . add ( randomHuge ( <int> , <int> , random . nextInt ( <int> , <int> ) , random . nextInt ( <int> , <int> ) ) ) ; result . add ( randomHuge ( random . nextInt ( <int> , <int> ) , random . nextInt ( <int> , <int> ) , random . nextInt ( <int> , <int> ) , <int> ) ) ; result . add ( randomHuge ( <int> , random . nextInt ( <int> , <int> ) , random . nextInt ( <int> , <int> ) , random . nextInt ( <int> , <int> ) ) ) ; result . add ( randomHuge ( random . nextInt ( <int> , <int> ) , random . nextInt ( <int> , <int> ) , random . nextInt ( <int> , <int> ) , random . nextInt ( <int> , <int> ) ) ) ; return result ; } private static List < ColumnsCheck > randomSmall ( boolean permitMultiplePartitionKeys ) { List < ColumnsCheck > random = new ArrayList < > ( ) ; for ( int i = <int> ; i < = <int> ; i + + ) { int pkCount = permitMultiplePartitionKeys ? i - <int> : <int> ; if ( permitMultiplePartitionKeys ) random . add ( randomSmall ( i , i - <int> , i - <int> , i - <int> ) ) ; random . add ( randomSmall ( <int> , <int> , i , i ) ) ; random . add ( randomSmall ( pkCount , i , i - <int> , i - <int> ) ) ; random . add ( randomSmall ( pkCount , i - <int> , i , i - <int> ) ) ; random . add ( randomSmall ( pkCount , i - <int> , i - <int> , i ) ) ; } return random ; } private static ColumnsCheck randomSmall ( int pkCount , int clCount , int regularCount , int complexCount ) { List < String > names = new ArrayList < > ( ) ; for ( char c = <str> ; c < = <str> ; c + + ) names . add ( Character . toString ( c ) ) ; List < ColumnDefinition > result = new ArrayList < > ( ) ; addPartition ( select ( names , pkCount ) , result ) ; addClustering ( select ( names , clCount ) , result ) ; addRegular ( select ( names , regularCount ) , result ) ; addComplex ( select ( names , complexCount ) , result ) ; Collections . sort ( result ) ; return new ColumnsCheck ( result ) ; } private static List < String > select ( List < String > names , int count ) { List < String > result = new ArrayList < > ( ) ; ThreadLocalRandom random = ThreadLocalRandom . current ( ) ; for ( int i = <int> ; i < count ; i + + ) { int v = random . nextInt ( names . size ( ) ) ; result . add ( names . get ( v ) ) ; names . remove ( v ) ; } return result ; } private static ColumnsCheck randomHuge ( int pkCount , int clCount , int regularCount , int complexCount ) { List < ColumnDefinition > result = new ArrayList < > ( ) ; Set < String > usedNames = new HashSet < > ( ) ; addPartition ( names ( pkCount , usedNames ) , result ) ; addClustering ( names ( clCount , usedNames ) , result ) ; addRegular ( names ( regularCount , usedNames ) , result ) ; addComplex ( names ( complexCount , usedNames ) , result ) ; Collections . sort ( result ) ; return new ColumnsCheck ( result ) ; } private static List < String > names ( int count , Set < String > usedNames ) { List < String > names = new ArrayList < > ( ) ; StringBuilder builder = new StringBuilder ( ) ; ThreadLocalRandom random = ThreadLocalRandom . current ( ) ; for ( int i = <int> ; i < count ; i + + ) { builder . setLength ( <int> ) ; for ( int j = <int> ; j < <int> | | usedNames . contains ( builder . toString ( ) ) ; j + + ) builder . append ( ( char ) random . nextInt ( <str> , <str> + <int> ) ) ; String name = builder . toString ( ) ; names . add ( name ) ; usedNames . add ( name ) ; } return names ; } private static void addPartition ( List < String > names , List < ColumnDefinition > results ) { for ( String name : names ) results . add ( ColumnDefinition . partitionKeyDef ( cfMetaData , bytes ( name ) , UTF8Type . instance , <int> ) ) ; } private static void addClustering ( List < String > names , List < ColumnDefinition > results ) { int i = <int> ; for ( String name : names ) results . add ( ColumnDefinition . clusteringDef ( cfMetaData , bytes ( name ) , UTF8Type . instance , i + + ) ) ; } private static void addRegular ( List < String > names , List < ColumnDefinition > results ) { for ( String name : names ) results . add ( ColumnDefinition . regularDef ( cfMetaData , bytes ( name ) , UTF8Type . instance ) ) ; } private static < V > void addComplex ( List < String > names , List < ColumnDefinition > results ) { for ( String name : names ) results . add ( ColumnDefinition . regularDef ( cfMetaData , bytes ( name ) , SetType . getInstance ( UTF8Type . instance , true ) ) ) ; } private static CFMetaData mock ( Columns columns ) { if ( columns . isEmpty ( ) ) return cfMetaData ; CFMetaData . Builder builder = CFMetaData . Builder . create ( cfMetaData . ksName , cfMetaData . cfName ) ; boolean hasPartitionKey = false ; for ( ColumnDefinition def : columns ) { switch ( def . kind ) { case PARTITION_KEY : builder . addPartitionKey ( def . name , def . type ) ; hasPartitionKey = true ; break ; case CLUSTERING : builder . addClusteringColumn ( def . name , def . type ) ; break ; case REGULAR : builder . addRegularColumn ( def . name , def . type ) ; break ; } } if ( ! hasPartitionKey ) builder . addPartitionKey ( <str> , UTF8Type . instance ) ; return builder . build ( ) ; } } 
