package org . apache . cassandra . io . sstable ; import java . io . IOException ; import java . nio . ByteOrder ; import java . util . Map ; import java . util . TreeMap ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; import org . apache . cassandra . db . DecoratedKey ; import org . apache . cassandra . dht . IPartitioner ; import org . apache . cassandra . io . util . Memory ; import org . apache . cassandra . io . util . SafeMemoryWriter ; import static org . apache . cassandra . io . sstable . Downsampling . BASE_SAMPLING_LEVEL ; public class IndexSummaryBuilder implements AutoCloseable { private static final Logger logger = LoggerFactory . getLogger ( IndexSummaryBuilder . class ) ; private final SafeMemoryWriter offsets ; private final SafeMemoryWriter entries ; private final int minIndexInterval ; private final int samplingLevel ; private final int [ ] startPoints ; private long keysWritten = <int> ; private long indexIntervalMatches = <int> ; private long nextSamplePosition ; private TreeMap < Long , ReadableBoundary > lastReadableByData = new TreeMap < > ( ) ; private TreeMap < Long , ReadableBoundary > lastReadableByIndex = new TreeMap < > ( ) ; private long dataSyncPosition ; private long indexSyncPosition ; private ReadableBoundary lastReadableBoundary ; public static class ReadableBoundary { public final DecoratedKey lastKey ; public final long indexLength ; public final long dataLength ; public final int summaryCount ; public final long entriesLength ; public ReadableBoundary ( DecoratedKey lastKey , long indexLength , long dataLength , int summaryCount , long entriesLength ) { this . lastKey = lastKey ; this . indexLength = indexLength ; this . dataLength = dataLength ; this . summaryCount = summaryCount ; this . entriesLength = entriesLength ; } } public IndexSummaryBuilder ( long expectedKeys , int minIndexInterval , int samplingLevel ) { this . samplingLevel = samplingLevel ; this . startPoints = Downsampling . getStartPoints ( BASE_SAMPLING_LEVEL , samplingLevel ) ; long maxExpectedEntries = expectedKeys / minIndexInterval ; if ( maxExpectedEntries > Integer . MAX_VALUE ) { int effectiveMinInterval = ( int ) Math . ceil ( ( double ) Integer . MAX_VALUE / expectedKeys ) ; maxExpectedEntries = expectedKeys / effectiveMinInterval ; assert maxExpectedEntries < = Integer . MAX_VALUE : maxExpectedEntries ; logger . warn ( <str> , minIndexInterval , expectedKeys , effectiveMinInterval ) ; this . minIndexInterval = effectiveMinInterval ; } else { this . minIndexInterval = minIndexInterval ; } maxExpectedEntries = Math . max ( <int> , ( maxExpectedEntries * samplingLevel ) / BASE_SAMPLING_LEVEL ) ; offsets = new SafeMemoryWriter ( <int> * maxExpectedEntries ) . order ( ByteOrder . nativeOrder ( ) ) ; entries = new SafeMemoryWriter ( <int> * maxExpectedEntries ) . order ( ByteOrder . nativeOrder ( ) ) ; nextSamplePosition = <int> ; indexIntervalMatches + + ; } public void markIndexSynced ( long upToPosition ) { indexSyncPosition = upToPosition ; refreshReadableBoundary ( ) ; } public void markDataSynced ( long upToPosition ) { dataSyncPosition = upToPosition ; refreshReadableBoundary ( ) ; } private void refreshReadableBoundary ( ) { Map . Entry < ? , ReadableBoundary > byData = lastReadableByData . floorEntry ( dataSyncPosition ) ; Map . Entry < ? , ReadableBoundary > byIndex = lastReadableByIndex . floorEntry ( indexSyncPosition ) ; if ( byData = = null | | byIndex = = null ) return ; lastReadableBoundary = byIndex . getValue ( ) . indexLength < byData . getValue ( ) . indexLength ? byIndex . getValue ( ) : byData . getValue ( ) ; lastReadableByData . headMap ( lastReadableBoundary . dataLength , false ) . clear ( ) ; lastReadableByIndex . headMap ( lastReadableBoundary . indexLength , false ) . clear ( ) ; } public ReadableBoundary getLastReadableBoundary ( ) { return lastReadableBoundary ; } public IndexSummaryBuilder maybeAddEntry ( DecoratedKey decoratedKey , long indexStart ) throws IOException { return maybeAddEntry ( decoratedKey , indexStart , <int> , <int> ) ; } public IndexSummaryBuilder maybeAddEntry ( DecoratedKey decoratedKey , long indexStart , long indexEnd , long dataEnd ) throws IOException { if ( keysWritten = = nextSamplePosition ) { assert entries . length ( ) < = Integer . MAX_VALUE ; offsets . writeInt ( ( int ) entries . length ( ) ) ; entries . write ( decoratedKey . getKey ( ) ) ; entries . writeLong ( indexStart ) ; setNextSamplePosition ( keysWritten ) ; } else if ( dataEnd ! = <int> & & keysWritten + <int> = = nextSamplePosition ) { ReadableBoundary boundary = new ReadableBoundary ( decoratedKey , indexEnd , dataEnd , ( int ) ( offsets . length ( ) / <int> ) , entries . length ( ) ) ; lastReadableByData . put ( dataEnd , boundary ) ; lastReadableByIndex . put ( indexEnd , boundary ) ; } keysWritten + + ; return this ; } private void setNextSamplePosition ( long position ) { tryAgain : while ( true ) { position + = minIndexInterval ; long test = indexIntervalMatches + + ; for ( int start : startPoints ) if ( ( test - start ) % BASE_SAMPLING_LEVEL = = <int> ) continue tryAgain ; nextSamplePosition = position ; return ; } } public void prepareToCommit ( ) { entries . setCapacity ( entries . length ( ) ) ; offsets . setCapacity ( offsets . length ( ) ) ; } public IndexSummary build ( IPartitioner partitioner ) { return build ( partitioner , null ) ; } public IndexSummary build ( IPartitioner partitioner , ReadableBoundary boundary ) { assert entries . length ( ) > <int> ; int count = ( int ) ( offsets . length ( ) / <int> ) ; long entriesLength = entries . length ( ) ; if ( boundary ! = null ) { count = boundary . summaryCount ; entriesLength = boundary . entriesLength ; } int sizeAtFullSampling = ( int ) Math . ceil ( keysWritten / ( double ) minIndexInterval ) ; assert count > <int> ; return new IndexSummary ( partitioner , offsets . currentBuffer ( ) . sharedCopy ( ) , count , entries . currentBuffer ( ) . sharedCopy ( ) , entriesLength , sizeAtFullSampling , minIndexInterval , samplingLevel ) ; } public void close ( ) { entries . close ( ) ; offsets . close ( ) ; } public Throwable close ( Throwable accumulate ) { accumulate = entries . close ( accumulate ) ; accumulate = offsets . close ( accumulate ) ; return accumulate ; } public static int entriesAtSamplingLevel ( int samplingLevel , int maxSummarySize ) { return ( int ) Math . ceil ( ( samplingLevel * maxSummarySize ) / ( double ) BASE_SAMPLING_LEVEL ) ; } public static int calculateSamplingLevel ( int currentSamplingLevel , int currentNumEntries , long targetNumEntries , int minIndexInterval , int maxIndexInterval ) { int effectiveMinSamplingLevel = Math . max ( <int> , ( int ) Math . ceil ( ( BASE_SAMPLING_LEVEL * minIndexInterval ) / ( double ) maxIndexInterval ) ) ; int newSamplingLevel = ( int ) ( targetNumEntries * currentSamplingLevel ) / currentNumEntries ; return Math . min ( BASE_SAMPLING_LEVEL , Math . max ( effectiveMinSamplingLevel , newSamplingLevel ) ) ; } @SuppressWarnings ( <str> ) public static IndexSummary downsample ( IndexSummary existing , int newSamplingLevel , int minIndexInterval , IPartitioner partitioner ) { int currentSamplingLevel = existing . getSamplingLevel ( ) ; assert currentSamplingLevel > newSamplingLevel ; assert minIndexInterval = = existing . getMinIndexInterval ( ) ; int [ ] startPoints = Downsampling . getStartPoints ( currentSamplingLevel , newSamplingLevel ) ; int newKeyCount = existing . size ( ) ; long newEntriesLength = existing . getEntriesLength ( ) ; for ( int start : startPoints ) { for ( int j = start ; j < existing . size ( ) ; j + = currentSamplingLevel ) { newKeyCount - - ; long length = existing . getEndInSummary ( j ) - existing . getPositionInSummary ( j ) ; newEntriesLength - = length ; } } Memory oldEntries = existing . getEntries ( ) ; Memory newOffsets = Memory . allocate ( newKeyCount * <int> ) ; Memory newEntries = Memory . allocate ( newEntriesLength ) ; int i = <int> ; int newEntriesOffset = <int> ; outer : for ( int oldSummaryIndex = <int> ; oldSummaryIndex < existing . size ( ) ; oldSummaryIndex + + ) { for ( int start : startPoints ) { if ( ( oldSummaryIndex - start ) % currentSamplingLevel = = <int> ) continue outer ; } newOffsets . setInt ( i * <int> , newEntriesOffset ) ; i + + ; long start = existing . getPositionInSummary ( oldSummaryIndex ) ; long length = existing . getEndInSummary ( oldSummaryIndex ) - start ; newEntries . put ( newEntriesOffset , oldEntries , start , length ) ; newEntriesOffset + = length ; } assert newEntriesOffset = = newEntriesLength ; return new IndexSummary ( partitioner , newOffsets , newKeyCount , newEntries , newEntriesLength , existing . getMaxNumberOfEntries ( ) , minIndexInterval , newSamplingLevel ) ; } } 
