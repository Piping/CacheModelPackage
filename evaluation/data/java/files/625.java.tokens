package org . apache . cassandra . batchlog ; import java . io . IOException ; import java . net . InetAddress ; import java . nio . ByteBuffer ; import java . util . * ; import java . util . concurrent . TimeUnit ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; import org . apache . cassandra . cql3 . QueryProcessor ; import org . apache . cassandra . cql3 . UntypedResultSet ; import org . apache . cassandra . db . * ; import org . apache . cassandra . db . marshal . UUIDType ; import org . apache . cassandra . db . partitions . PartitionUpdate ; import org . apache . cassandra . exceptions . WriteFailureException ; import org . apache . cassandra . exceptions . WriteTimeoutException ; import org . apache . cassandra . io . util . DataInputBuffer ; import org . apache . cassandra . io . util . DataOutputBuffer ; import org . apache . cassandra . net . MessagingService ; import org . apache . cassandra . service . AbstractWriteResponseHandler ; import org . apache . cassandra . service . WriteResponseHandler ; import org . apache . cassandra . utils . FBUtilities ; import org . apache . cassandra . utils . UUIDGen ; public final class LegacyBatchlogMigrator { private static final Logger logger = LoggerFactory . getLogger ( LegacyBatchlogMigrator . class ) ; private LegacyBatchlogMigrator ( ) { } @SuppressWarnings ( <str> ) public static void migrate ( ) { ColumnFamilyStore store = Keyspace . open ( SystemKeyspace . NAME ) . getColumnFamilyStore ( SystemKeyspace . LEGACY_BATCHLOG ) ; if ( store . isEmpty ( ) ) return ; logger . info ( <str> ) ; int convertedBatches = <int> ; String query = String . format ( <str> , SystemKeyspace . NAME , SystemKeyspace . LEGACY_BATCHLOG ) ; int pageSize = BatchlogManager . calculatePageSize ( store ) ; UntypedResultSet rows = QueryProcessor . executeInternalWithPaging ( query , pageSize ) ; for ( UntypedResultSet . Row row : rows ) { if ( apply ( row , convertedBatches ) ) convertedBatches + + ; } if ( convertedBatches > <int> ) Keyspace . openAndGetStore ( SystemKeyspace . LegacyBatchlog ) . truncateBlocking ( ) ; } @SuppressWarnings ( <str> ) public static boolean isLegacyBatchlogMutation ( Mutation mutation ) { return mutation . getKeyspaceName ( ) . equals ( SystemKeyspace . NAME ) & & mutation . getPartitionUpdate ( SystemKeyspace . LegacyBatchlog . cfId ) ! = null ; } @SuppressWarnings ( <str> ) public static void handleLegacyMutation ( Mutation mutation ) { PartitionUpdate update = mutation . getPartitionUpdate ( SystemKeyspace . LegacyBatchlog . cfId ) ; logger . trace ( <str> , update ) ; update . forEach ( row - > apply ( UntypedResultSet . Row . fromInternalRow ( update . metadata ( ) , update . partitionKey ( ) , row ) , - <int> ) ) ; } private static boolean apply ( UntypedResultSet . Row row , long counter ) { UUID id = row . getUUID ( <str> ) ; long timestamp = id . version ( ) = = <int> ? UUIDGen . unixTimestamp ( id ) : row . getLong ( <str> ) ; int version = row . has ( <str> ) ? row . getInt ( <str> ) : MessagingService . VERSION_12 ; if ( id . version ( ) ! = <int> ) id = UUIDGen . getTimeUUID ( timestamp , counter ) ; logger . trace ( <str> , timestamp ) ; try ( DataInputBuffer in = new DataInputBuffer ( row . getBytes ( <str> ) , false ) ) { int numMutations = in . readInt ( ) ; List < Mutation > mutations = new ArrayList < > ( numMutations ) ; for ( int i = <int> ; i < numMutations ; i + + ) mutations . add ( Mutation . serializer . deserialize ( in , version ) ) ; BatchlogManager . store ( Batch . createLocal ( id , TimeUnit . MILLISECONDS . toMicros ( timestamp ) , mutations ) ) ; return true ; } catch ( Throwable t ) { logger . error ( <str> , id , timestamp , t ) ; return false ; } } public static void syncWriteToBatchlog ( WriteResponseHandler < ? > handler , Batch batch , Collection < InetAddress > endpoints ) throws WriteTimeoutException , WriteFailureException { for ( InetAddress target : endpoints ) { logger . trace ( <str> , batch . id , target , batch . size ( ) ) ; int targetVersion = MessagingService . instance ( ) . getVersion ( target ) ; MessagingService . instance ( ) . sendRR ( getStoreMutation ( batch , targetVersion ) . createMessage ( MessagingService . Verb . MUTATION ) , target , handler , false ) ; } } public static void asyncRemoveFromBatchlog ( Collection < InetAddress > endpoints , UUID uuid ) { AbstractWriteResponseHandler < IMutation > handler = new WriteResponseHandler < > ( endpoints , Collections . < InetAddress > emptyList ( ) , ConsistencyLevel . ANY , Keyspace . open ( SystemKeyspace . NAME ) , null , WriteType . SIMPLE ) ; Mutation mutation = getRemoveMutation ( uuid ) ; for ( InetAddress target : endpoints ) { logger . trace ( <str> , uuid , target ) ; MessagingService . instance ( ) . sendRR ( mutation . createMessage ( MessagingService . Verb . MUTATION ) , target , handler , false ) ; } } static void store ( Batch batch , int version ) { getStoreMutation ( batch , version ) . apply ( ) ; } @SuppressWarnings ( <str> ) static Mutation getStoreMutation ( Batch batch , int version ) { return new RowUpdateBuilder ( SystemKeyspace . LegacyBatchlog , batch . creationTime , batch . id ) . clustering ( ) . add ( <str> , new Date ( batch . creationTime / <int> ) ) . add ( <str> , getSerializedMutations ( version , batch . decodedMutations ) ) . add ( <str> , version ) . build ( ) ; } @SuppressWarnings ( <str> ) private static Mutation getRemoveMutation ( UUID uuid ) { return new Mutation ( PartitionUpdate . fullPartitionDelete ( SystemKeyspace . LegacyBatchlog , UUIDType . instance . decompose ( uuid ) , FBUtilities . timestampMicros ( ) , FBUtilities . nowInSeconds ( ) ) ) ; } private static ByteBuffer getSerializedMutations ( int version , Collection < Mutation > mutations ) { try ( DataOutputBuffer buf = new DataOutputBuffer ( ) ) { buf . writeInt ( mutations . size ( ) ) ; for ( Mutation mutation : mutations ) Mutation . serializer . serialize ( mutation , buf , version ) ; return buf . buffer ( ) ; } catch ( IOException e ) { throw new RuntimeException ( e ) ; } } } 
