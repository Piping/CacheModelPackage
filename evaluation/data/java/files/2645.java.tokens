package org . nd4j . linalg . jcublas . ops . executioner ; import org . nd4j . linalg . api . blas . BlasBufferUtil ; import org . nd4j . linalg . api . buffer . DataBuffer ; import org . nd4j . linalg . api . complex . IComplexNDArray ; import org . nd4j . linalg . api . complex . IComplexNumber ; import org . nd4j . linalg . api . ndarray . INDArray ; import org . nd4j . linalg . api . ops . * ; import org . nd4j . linalg . api . ops . executioner . DefaultOpExecutioner ; import org . nd4j . linalg . api . ops . impl . broadcast . BroadcastDimensions ; import org . nd4j . linalg . api . ops . impl . transforms . arithmetic . CopyOp ; import org . nd4j . linalg . factory . Nd4j ; import org . nd4j . linalg . jcublas . SimpleJCublas ; import org . nd4j . linalg . jcublas . buffer . JCudaBuffer ; import org . nd4j . linalg . jcublas . context . ContextHolder ; import org . nd4j . linalg . jcublas . context . CudaContext ; import org . nd4j . linalg . jcublas . gpumetrics . GpuMetrics ; import org . nd4j . linalg . jcublas . kernel . KernelFunctionLoader ; import org . nd4j . linalg . jcublas . kernel . KernelFunctions ; import org . nd4j . linalg . jcublas . util . KernelParamsWrapper ; import org . nd4j . linalg . jcublas . util . PointerUtil ; import org . nd4j . linalg . util . ArrayUtil ; public class JCudaExecutioner extends DefaultOpExecutioner { private JCudaBuffer dummyFloatPointer , dummyDoublePointer ; public JCudaExecutioner ( ) { try { SimpleJCublas . init ( ) ; } catch ( Exception e ) { throw new RuntimeException ( e ) ; } dummyFloatPointer = KernelFunctions . alloc ( new float [ ] { <int> } ) ; dummyDoublePointer = KernelFunctions . alloc ( new double [ ] { <int> } ) ; } @Override public INDArray exec ( Accumulation op , int . . . dimension ) { ContextHolder . getInstance ( ) . setContext ( ) ; for ( int i = <int> ; i < dimension . length ; i + + ) { if ( dimension [ i ] < <int> ) dimension [ i ] + = op . x ( ) . rank ( ) ; } if ( dimension . length = = op . x ( ) . rank ( ) ) dimension = new int [ ] { Integer . MAX_VALUE } ; if ( op . isPassThrough ( ) ) { op . exec ( dimension ) ; return op . z ( ) ; } if ( dimension [ <int> ] = = Integer . MAX_VALUE ) { if ( op . x ( ) instanceof IComplexNDArray ) return Nd4j . scalar ( execAndReturn ( op ) . getFinalResultComplex ( ) ) ; return Nd4j . scalar ( execAndReturn ( op ) . getFinalResult ( ) . doubleValue ( ) ) ; } if ( op instanceof IComplexNDArray ) { int [ ] retShape = ArrayUtil . removeIndex ( op . x ( ) . shape ( ) , dimension ) ; if ( retShape . length = = <int> ) { if ( dimension [ <int> ] = = <int> ) retShape = new int [ ] { <int> , retShape [ <int> ] } ; else retShape = new int [ ] { retShape [ <int> ] , <int> } ; } else if ( retShape . length = = <int> ) { retShape = new int [ ] { <int> , <int> } ; } IComplexNDArray ret = Nd4j . createComplex ( retShape ) ; IComplexNDArray linear = ret ; for ( int i = <int> ; i < op . x ( ) . tensorssAlongDimension ( dimension ) ; i + + ) { Op op2 = op . opForDimension ( i , dimension ) ; IComplexNumber result = execAndReturn ( ( Accumulation ) op2 ) . getFinalResultComplex ( ) ; linear . putScalar ( i , result ) ; } if ( ret . ordering ( ) = = <str> ) ret . setStride ( ArrayUtil . reverseCopy ( ret . stride ( ) ) ) ; return ret ; } else { int [ ] retShape = ArrayUtil . removeIndex ( op . x ( ) . shape ( ) , dimension ) ; if ( retShape . length = = <int> ) { if ( dimension [ <int> ] = = <int> ) retShape = new int [ ] { <int> , retShape [ <int> ] } ; else retShape = new int [ ] { retShape [ <int> ] , <int> } ; } else if ( retShape . length = = <int> ) { retShape = new int [ ] { <int> , <int> } ; } if ( ArrayUtil . prod ( retShape ) = = op . x ( ) . length ( ) ) return op . x ( ) ; INDArray retArray = Nd4j . create ( retShape ) ; invoke ( op , dimension , retArray , true ) ; return retArray ; } } @Override public INDArray execAndReturn ( TransformOp op , int . . . dimension ) { ContextHolder . getInstance ( ) . setContext ( ) ; return super . execAndReturn ( op , dimension ) ; } @Override public INDArray execAndReturn ( ScalarOp op , int . . . dimension ) { ContextHolder . getInstance ( ) . setContext ( ) ; return super . execAndReturn ( op , dimension ) ; } @Override public Op exec ( Op op , int . . . dimension ) { ContextHolder . getInstance ( ) . setContext ( ) ; return super . exec ( op , dimension ) ; } @Override public Op exec ( Op op ) { if ( op . x ( ) instanceof IComplexNDArray | | executionMode ( ) = = ExecutionMode . JAVA | | op . isPassThrough ( ) | | op instanceof CopyOp ) return super . exec ( op ) ; if ( op instanceof TransformOp ) { TransformOp t = ( TransformOp ) op ; invoke ( t , true ) ; } else if ( op instanceof Accumulation ) { Accumulation acc = ( Accumulation ) op ; invoke ( acc , null , Nd4j . scalar ( <int> ) , true ) ; } else if ( op instanceof ScalarOp ) { ScalarOp sc = ( ScalarOp ) op ; invoke ( sc , true ) ; } else if ( op instanceof BroadcastOp ) { BroadcastOp broadcastOp = ( BroadcastOp ) op ; invoke ( broadcastOp , true ) ; } return op ; } private JCudaBuffer dummyDouble ( ) { return dummyDoublePointer ; } private JCudaBuffer dummyFloat ( ) { return dummyFloatPointer ; } @Override public INDArray execAndReturn ( TransformOp op ) { invoke ( op , true ) ; return op . z ( ) ; } private JCudaBuffer toArgs ( Object [ ] extraArgs , String dataType ) { if ( dataType . equals ( <str> ) ) { if ( extraArgs = = null | | extraArgs . length < <int> ) return dummyDouble ( ) ; return KernelFunctions . alloc ( PointerUtil . toDoubles ( extraArgs ) ) ; } else if ( dataType . equals ( <str> ) ) { if ( extraArgs = = null | | extraArgs . length < <int> ) return dummyFloat ( ) ; return KernelFunctions . alloc ( PointerUtil . toFloats ( extraArgs ) ) ; } throw new IllegalArgumentException ( <str> ) ; } public void calculateBlockResult ( Accumulation op , INDArray resultAcrossBlocks ) { int oldN = op . n ( ) ; op . setX ( resultAcrossBlocks ) ; op . setApplyFinalTransform ( false ) ; if ( op . y ( ) ! = null ) { op . setY ( Nd4j . valueArrayOf ( op . x ( ) . shape ( ) , op . zeroDouble ( ) ) ) ; } doAccumulationOp ( op ) ; op . setApplyFinalTransform ( true ) ; op . setN ( oldN ) ; op . getAndSetFinalResult ( op . getFinalResult ( ) . doubleValue ( ) ) ; } private CudaContext invoke ( BroadcastOp op , boolean sync ) { CudaContext ctx ; ContextHolder . getInstance ( ) . setContext ( ) ; if ( ! KernelFunctionLoader . getInstance ( ) . exists ( op . name ( ) ) | | executionMode ( ) = = ExecutionMode . JAVA | | op . isPassThrough ( ) | | op instanceof CopyOp ) super . exec ( op ) ; int [ ] dimensions = op . getDimension ( ) = = null ? BroadcastDimensions . getDimensions ( op . y ( ) . shape ( ) ) : op . getDimension ( ) ; GpuMetrics metrics = GpuMetrics . blockAndThreads ( getType ( op ) , op . n ( ) ) ; metrics . setGridSizeNotOverMax ( <int> ) ; int blocksPerGrid = ( op . n ( ) + metrics . getGridSize ( ) - <int> ) / metrics . getGridSize ( ) ; metrics . setBlockSizeNotOverMax ( blocksPerGrid ) ; metrics . setSharedMemoryNotOverMax ( <int> ) ; if ( op . y ( ) = = null ) throw new IllegalArgumentException ( <str> ) ; Object [ ] kernelParams = new Object [ ] { op . x ( ) , KernelFunctions . alloc ( PointerUtil . toShapeInfoBuffer ( op . x ( ) , dimensions ) ) , op . y ( ) , KernelFunctions . alloc ( PointerUtil . toShapeInfoBuffer ( op . y ( ) ) ) , op . z ( ) , KernelFunctions . alloc ( PointerUtil . toShapeInfoBuffer ( op . z ( ) , dimensions ) ) , KernelFunctions . alloc ( dimensions ) , dimensions . length , KernelFunctions . alloc ( metrics . getGpuDefinitionInfo ( ) ) , } ; try ( KernelParamsWrapper kParams = new KernelParamsWrapper ( op , sync , kernelParams ) . setResultArray ( op . z ( ) ) ) { invokeFunction ( op , sync , metrics , kParams . getContext ( ) , kParams . getKernelParameters ( ) ) ; ctx = kParams . getContext ( ) ; if ( sync ) kParams . sync ( ) ; } catch ( Exception e ) { throw new RuntimeException ( <str> + metrics , e ) ; } return ctx ; } private int toInt ( boolean val ) { return val ? <int> : <int> ; } private CudaContext invoke ( Accumulation op , int [ ] dimension , INDArray result , boolean sync ) { CudaContext ctx ; ContextHolder . getInstance ( ) . setContext ( ) ; if ( ! KernelFunctionLoader . getInstance ( ) . exists ( op . name ( ) ) | | executionMode ( ) = = ExecutionMode . JAVA | | op . isPassThrough ( ) ) super . exec ( op ) ; GpuMetrics metrics = GpuMetrics . blockAndThreads ( getType ( op ) , op . n ( ) ) ; if ( dimension ! = null & & dimension . length > = <int> & & dimension [ <int> ] ! = Integer . MAX_VALUE ) { int length = op . x ( ) . tensorssAlongDimension ( dimension ) ; if ( length > <int> ) length = <int> ; metrics . setGridSizeNotOverMax ( length ) ; metrics . setBlockSizeNotOverMax ( op . x ( ) . tensorAlongDimension ( <int> , dimension ) . length ( ) ) ; int sharedMemBasedOnBlockSize = op . x ( ) . tensorAlongDimension ( <int> , dimension ) . length ( ) * <int> * op . x ( ) . data ( ) . getElementSize ( ) ; if ( sharedMemBasedOnBlockSize < <int> ) sharedMemBasedOnBlockSize = <int> ; metrics . setSharedMemoryNotOverMax ( sharedMemBasedOnBlockSize ) ; } else { int sharedMemBasedOnBlockSize = op . n ( ) * op . x ( ) . data ( ) . getElementSize ( ) ; if ( sharedMemBasedOnBlockSize < <int> ) sharedMemBasedOnBlockSize = <int> ; metrics . setSharedMemoryNotOverMax ( sharedMemBasedOnBlockSize ) ; result = Nd4j . create ( metrics . getGridSize ( ) ) ; } if ( op . y ( ) ! = null ) { metrics . setSharedMemoryNotOverMax ( metrics . getSharedMemory ( ) * <int> ) ; int xStride = BlasBufferUtil . getBlasStride ( dimension = = null ? op . x ( ) : op . x ( ) . tensorAlongDimension ( <int> , dimension ) ) ; if ( xStride < <int> ) { op . setX ( op . x ( ) . dup ( ) ) ; } int yStride = BlasBufferUtil . getBlasStride ( dimension = = null ? op . y ( ) : op . y ( ) . tensorAlongDimension ( <int> , dimension ) ) ; if ( yStride < <int> ) { op . setY ( op . y ( ) . dup ( ) ) ; } else if ( op . y ( ) . ordering ( ) ! = op . x ( ) . ordering ( ) ) { op . setY ( op . y ( ) . dup ( op . x ( ) . ordering ( ) ) ) ; } Object [ ] kernelParams = new Object [ ] { op . n ( ) , op . x ( ) , KernelFunctions . alloc ( PointerUtil . toShapeInfoBuffer ( op . x ( ) , dimension ) ) , op . y ( ) , KernelFunctions . alloc ( PointerUtil . toShapeInfoBuffer ( op . y ( ) , dimension ) ) , toArgs ( op . extraArgs ( ) , getType ( op ) ) , result , KernelFunctions . alloc ( PointerUtil . toShapeInfoBuffer ( result ) ) , KernelFunctions . alloc ( metrics . getGpuDefinitionInfo ( ) ) , KernelFunctions . alloc ( dimension = = null ? new int [ ] { Integer . MAX_VALUE } : dimension ) , dimension = = null ? <int> : dimension . length , toInt ( ! ( dimension = = null | | dimension [ <int> ] = = Integer . MAX_VALUE ) ) } ; try ( KernelParamsWrapper kParams = new KernelParamsWrapper ( op , sync , kernelParams ) . setResultOp ( op , result ) ) { invokeFunction ( op , sync , metrics , kParams . getContext ( ) , kParams . getKernelParameters ( ) ) ; ctx = kParams . getContext ( ) ; if ( sync ) kParams . sync ( ) ; } catch ( Exception e ) { throw new RuntimeException ( <str> , e ) ; } return ctx ; } else { int xStride = BlasBufferUtil . getBlasStride ( dimension = = null ? op . x ( ) : op . x ( ) . tensorAlongDimension ( <int> , dimension ) ) ; if ( xStride < <int> ) { op . setX ( op . x ( ) . dup ( ) ) ; } int sharedMemBasedOnBlockSize = op . n ( ) * op . x ( ) . data ( ) . getElementSize ( ) ; if ( sharedMemBasedOnBlockSize < <int> ) sharedMemBasedOnBlockSize = <int> ; metrics . setSharedMemoryNotOverMax ( sharedMemBasedOnBlockSize ) ; int length = op . x ( ) . data ( ) . length ( ) ; if ( dimension = = null & & xStride = = <int> & & op . x ( ) . offset ( ) = = <int> ) length = op . n ( ) ; Object [ ] kernelParams = new Object [ ] { length , op . x ( ) , KernelFunctions . alloc ( PointerUtil . toShapeInfoBuffer ( op . x ( ) , dimension ) ) , toArgs ( op . extraArgs ( ) , getType ( op ) ) , result , KernelFunctions . alloc ( PointerUtil . toShapeInfoBuffer ( result ) ) , KernelFunctions . alloc ( metrics . getGpuDefinitionInfo ( ) ) , KernelFunctions . alloc ( dimension = = null ? new int [ ] { Integer . MAX_VALUE } : dimension ) , dimension = = null ? <int> : dimension . length , toInt ( ! ( dimension = = null | | dimension [ <int> ] = = Integer . MAX_VALUE ) ) } ; try ( KernelParamsWrapper kParams = new KernelParamsWrapper ( op , sync , kernelParams ) . setResultOp ( op , result , dimension ) ) { invokeFunction ( op , sync , metrics , kParams . getContext ( ) , kParams . getKernelParameters ( ) ) ; ctx = kParams . getContext ( ) ; if ( sync ) kParams . sync ( ) ; } catch ( Exception e ) { throw new RuntimeException ( <str> + metrics , e ) ; } } return ctx ; } private CudaContext invoke ( ScalarOp op , boolean sync ) { GpuMetrics metrics = GpuMetrics . blockAndThreads ( getType ( op ) , op . n ( ) ) ; metrics . setGridSize ( op . n ( ) ) ; metrics . setBlockSize ( <int> ) ; metrics . setSharedMemory ( metrics . getBlockSize ( ) * op . x ( ) . data ( ) . getElementSize ( ) ) ; CudaContext ctx ; if ( ! KernelFunctionLoader . getInstance ( ) . exists ( op . name ( ) ) | | executionMode ( ) = = ExecutionMode . JAVA ) super . exec ( op ) ; if ( op . y ( ) ! = null ) { metrics . setSharedMemory ( metrics . getSharedMemory ( ) * <int> ) ; int xStride = BlasBufferUtil . getBlasStride ( op . x ( ) ) ; if ( xStride < <int> ) { op . setX ( op . x ( ) . dup ( ) ) ; } int yStride = BlasBufferUtil . getBlasStride ( op . y ( ) ) ; if ( yStride < <int> ) { op . setY ( op . y ( ) . dup ( ) ) ; } Object [ ] kernelParams = new Object [ ] { op . n ( ) , op . x ( ) . offset ( ) , op . y ( ) . offset ( ) , op . x ( ) , op . y ( ) , BlasBufferUtil . getBlasStride ( op . x ( ) ) , BlasBufferUtil . getBlasStride ( op . y ( ) ) , toArgs ( op . extraArgs ( ) , getType ( op ) ) , op . z ( ) , metrics . getBlockSize ( ) } ; try ( KernelParamsWrapper kParams = new KernelParamsWrapper ( op , sync , kernelParams ) . setResultArray ( op . z ( ) ) ) { invokeFunction ( op , sync , metrics , kParams . getContext ( ) , kParams . getKernelParameters ( ) ) ; ctx = kParams . getContext ( ) ; if ( sync ) kParams . sync ( ) ; } catch ( Exception e ) { throw new RuntimeException ( <str> , e ) ; } } else { int xStride = BlasBufferUtil . getBlasStride ( op . x ( ) ) ; if ( xStride < <int> ) { op . setX ( op . x ( ) . dup ( ) ) ; } Object [ ] kernelParams = new Object [ ] { op . n ( ) , op . x ( ) . offset ( ) , PointerUtil . getPointer ( op ) , op . x ( ) , BlasBufferUtil . getBlasStride ( op . x ( ) ) , toArgs ( op . extraArgs ( ) , getType ( op ) ) , op . z ( ) , metrics . getBlockSize ( ) } ; try ( KernelParamsWrapper kParams = new KernelParamsWrapper ( op , sync , kernelParams ) . setResultArray ( op . z ( ) ) ) { invokeFunction ( op , sync , metrics , kParams . getContext ( ) , kParams . getKernelParameters ( ) ) ; ctx = kParams . getContext ( ) ; if ( sync ) kParams . sync ( ) ; } catch ( Exception e ) { throw new RuntimeException ( <str> , e ) ; } } return ctx ; } private CudaContext invoke ( TransformOp op , boolean sync ) { if ( ! KernelFunctionLoader . getInstance ( ) . exists ( op . name ( ) ) | | op . x ( ) instanceof IComplexNDArray | | op . isPassThrough ( ) ) { super . exec ( op ) ; return null ; } GpuMetrics metrics = GpuMetrics . blockAndThreads ( getType ( op ) , op . n ( ) ) ; metrics . setGridSize ( op . n ( ) ) ; metrics . setBlockSize ( <int> ) ; metrics . setSharedMemory ( metrics . getBlockSize ( ) * op . x ( ) . data ( ) . getElementSize ( ) ) ; metrics . setGridSizeNotOverMax ( op . x ( ) . data ( ) . length ( ) ) ; metrics . setBlockSize ( <int> ) ; metrics . setSharedMemoryNotOverMax ( metrics . getBlockSize ( ) * op . x ( ) . data ( ) . getElementSize ( ) ) ; CudaContext ctx ; if ( op . y ( ) ! = null ) { metrics . setSharedMemory ( metrics . getSharedMemory ( ) * <int> ) ; int xStride = BlasBufferUtil . getBlasStride ( op . x ( ) ) ; if ( xStride < <int> ) { op . setX ( op . x ( ) . dup ( ) ) ; } int yStride = BlasBufferUtil . getBlasStride ( op . y ( ) ) ; if ( yStride < <int> ) { op . setY ( op . y ( ) . dup ( ) ) ; } else if ( op . y ( ) . ordering ( ) ! = op . x ( ) . ordering ( ) ) { op . setY ( op . y ( ) . dup ( op . x ( ) . ordering ( ) ) ) ; } Object [ ] kernelParams = new Object [ ] { op . n ( ) , op . x ( ) . offset ( ) , op . y ( ) . offset ( ) , op . x ( ) , op . y ( ) , BlasBufferUtil . getBlasStride ( op . x ( ) ) , BlasBufferUtil . getBlasStride ( op . y ( ) ) , toArgs ( op . extraArgs ( ) , getType ( op ) ) , op . z ( ) , BlasBufferUtil . getBlasStride ( op . z ( ) ) , metrics . getBlockSize ( ) } ; try ( KernelParamsWrapper kParams = new KernelParamsWrapper ( op , sync , kernelParams ) . setResultArray ( op . z ( ) ) ) { invokeFunction ( op , sync , metrics , kParams . getContext ( ) , kParams . getKernelParameters ( ) ) ; ctx = kParams . getContext ( ) ; if ( sync ) kParams . sync ( ) ; } catch ( Exception e ) { throw new RuntimeException ( <str> , e ) ; } } else { Object [ ] kernelParams = new Object [ ] { op . n ( ) , op . x ( ) . offset ( ) , op . x ( ) , BlasBufferUtil . getBlasStride ( op . x ( ) ) , toArgs ( op . extraArgs ( ) , getType ( op ) ) , op . z ( ) , metrics . getBlockSize ( ) } ; try ( KernelParamsWrapper kParams = new KernelParamsWrapper ( op , sync , kernelParams ) . setResultArray ( op . z ( ) ) ) { invokeFunction ( op , sync , metrics , kParams . getContext ( ) , kParams . getKernelParameters ( ) ) ; ctx = kParams . getContext ( ) ; if ( sync ) kParams . sync ( ) ; } catch ( Exception e ) { throw new RuntimeException ( <str> , e ) ; } } return ctx ; } private void invokeFunction ( Op op , boolean sync , GpuMetrics metrics , CudaContext cudaContext , Object . . . kernelParams ) { metrics . validate ( ) ; String functionName = op instanceof TransformOp | | op instanceof Accumulation ? op . name ( ) + <str> : op . name ( ) ; KernelFunctions . invoke ( metrics , sync , functionName , getType ( op ) , cudaContext , kernelParams ) ; } private String getType ( Op op ) { return op . x ( ) . data ( ) . dataType ( ) = = DataBuffer . Type . DOUBLE ? <str> : <str> ; } }