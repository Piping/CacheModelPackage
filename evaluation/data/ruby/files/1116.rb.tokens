require <str> require File . expand_path ( File . dirname ( __FILE__ ) + <str> ) class ImportScripts :: GetSatisfaction < ImportScripts :: Base BATCH_SIZE = <int> def initialize ( path ) @path = path super ( ) @bbcode_to_md = true puts <str> @post_number_map = { } Post . pluck ( <str> , <str> ) . each do | post_id , post_number | @post_number_map [ post_id ] = post_number end end def created_post ( post ) @post_number_map [ post . id ] = post . post_number super end def execute c = Category . find_by ( name : <str> ) || Category . create! ( name : <str> , <str> : Discourse . system_user ) import_users import_posts ( c ) Topic . where ( <str> : c ) . update_all ( <str> : true ) end class RowResolver def load ( row ) @row = row end def self . create ( cols ) Class . new ( RowResolver ) . new ( cols ) end def initialize ( cols ) cols . each_with_index do | col , idx | self . class . send ( <str> , col ) do @row [ idx ] end end end end def load_user_batch! ( users , offset , total ) if users . length > <int> create_users ( users , <str> : offset , <str> : total ) do | user | user end users . clear end end def csv_parse ( name ) filename = <str> @path <str> name <str> first = true row = nil current_row = <str> ; double_quote_count = <int> File . open ( filename ) . each_line do | line | line . strip! current_row << <str> unless current_row . empty? current_row << line raw = begin CSV . parse ( current_row , <str> : <str> ) rescue CSV :: MalformedCSVError = > e puts e . message puts <str> * <int> puts <str> line <str> puts puts current_row puts puts <str> double_quote_count <str> puts <str> * <int> current_row = <str> double_quote_count = <int> next end [ <int> ] if first row = RowResolver . create ( raw ) current_row = <str> double_quote_count = <int> first = false next end row . load ( raw ) yield row current_row = <str> double_quote_count = <int> end end def total_rows ( table ) File . foreach ( <str> @path <str> table <str> ) . inject ( <int> ) { | c , line | c + <int> } - <int> end def import_users puts <str> , <str> count = <int> users = [ ] total = total_rows ( <str> ) csv_parse ( <str> ) do | row | if row . suspended_at puts <str> p row next end id = row . user_id email = row . email if row . email . blank? || row . email !~ <str> email = SecureRandom . hex << <str> end name = row . real_name username = row . nick created_at = DateTime . parse ( row . m_created ) username = name if username == <str> username = email . split ( <str> ) [ <int> ] if username . blank? name = email . split ( <str> ) [ <int> ] if name . blank? users << { id : id , <str> : email , name : name , <str> : username , <str> : created_at , <str> : false } count += <int> if count % BATCH_SIZE == <int> load_user_batch! users , count - users . length , total end end load_user_batch! users , count , total end def import_categories rows = [ ] csv_parse ( <str> ) do | row | rows << { id : row . id , name : row . name , <str> : row . description } end create_categories ( rows ) do | row | row end end def normalize_raw! ( raw ) raw = raw . dup hoisted = { } raw . gsub! ( <str> ) do code = $2 hoist = SecureRandom . hex code . gsub! ( <str> , <str> ) code . gsub! ( <str> , <str> ) code . gsub! ( <str> , <str> ) code . strip! hoisted [ hoist ] = code hoist end raw . gsub! ( <str> , <str> ) hoisted . each do | hoist , code | raw . gsub! ( hoist , <str> << code << <str> ) end raw end def import_post_batch! ( posts , topics , offset , total ) create_posts ( posts , <str> : total , <str> : offset ) do | post | mapped = { } mapped [ <str> ] = post [ <str> ] mapped [ <str> ] = user_id_from_imported_user_id ( post [ <str> ] ) || - <int> mapped [ <str> ] = post [ <str> ] mapped [ <str> ] = post [ <str> ] topic = topics [ post [ <str> ] ] unless topic p <str> post [ <str> ] <str> p post next end unless topic [ <str> ] mapped [ <str> ] = post [ <str> ] || <str> topic [ <str> ] = post [ <str> ] mapped [ <str> ] = post [ <str> ] else parent = topic_lookup_from_imported_post_id ( topic [ <str> ] ) next unless parent mapped [ <str> ] = parent [ <str> ] reply_to_post_id = post_id_from_imported_post_id ( post [ <str> ] ) if reply_to_post_id reply_to_post_number = @post_number_map [ reply_to_post_id ] if reply_to_post_number && reply_to_post_number > <int> mapped [ <str> ] = reply_to_post_number end end end next if topic [ <str> ] or post [ <str> ] mapped end posts . clear end def import_posts ( category ) puts <str> , <str> topic_map = { } csv_parse ( <str> ) do | topic | topic_map [ topic . id ] = { id : topic . id , <str> : topic . id , <str> : topic . subject , <str> : topic . removed == <str> , <str> : true , <str> : normalize_raw! ( topic . additional_detail || topic . subject || <str> ) , <str> : DateTime . parse ( topic . created_at ) , <str> : topic . UserId , <str> : category . name } end total = total_rows ( <str> ) posts = [ ] count = <int> topic_map . each do | _ , topic | posts << topic if topic [ <str> ] end csv_parse ( <str> ) do | row | unless row . created_at puts <str> p row next end row = { id : row . id , <str> : row . topic_id , <str> : row . parent_id , <str> : row . UserId , <str> : normalize_raw! ( row . content ) , <str> : DateTime . parse ( row . created_at ) } posts << row count += <int> if posts . length > <int> && posts . length % BATCH_SIZE == <int> import_post_batch! ( posts , topic_map , count - posts . length , total ) end end import_post_batch! ( posts , topic_map , count - posts . length , total ) if posts . length > <int> end end unless ARGV [ <int> ] && Dir . exist? ( ARGV [ <int> ] ) puts <str> , <str> , <str> , <str> , <str> exit <int> end ImportScripts :: GetSatisfaction . new ( ARGV [ <int> ] ) . perform 
